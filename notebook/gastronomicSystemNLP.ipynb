{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaimeSCotta/IAProject/blob/main/notebook/gastronomicSystemNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "554b9442-be8e-4246-8c96-d1b6901de6b8"
      },
      "source": [
        "# Valoración del sistema gastronómico NLP\n",
        "\n",
        "El objetivo principal de este fichero consiste en diseñar, implementar y evaluar un modelo que resuelva la tarea de extraer la valoración del sistema gastronómico de los países Europeos y analizar si dicho comentario es positivo o negativo (análisis de sentimientos).\n",
        "\n",
        "Para el desarrollo completo, se han identificado tres tareas principales:\n",
        "\n",
        "- Preprocesamiento y preparación de los datos.\n",
        "\n",
        "- Diseño, implementación y pruebas de modelos de lenguaje.\n",
        "\n",
        "- Conclusiones y evaluación del modelo final.\n",
        "\n",
        "Cada una de estas tres tareas principales se encuentra recogida en una sección específica del presente notebook.\n",
        "\n",
        "En la primera sección, **Datos**, se recoge la obtención, tratamiento y modificación de los datos para dejarlos preparados para su utilización.\n",
        "\n",
        "En la segunda sección, **Modelos**, se recogen las distintas aproximaciones que se han planteado para resolver la tarea planteada. Esta sección contiene todos los modelos definidos con su correspondiente entrenamiento y pruebas.\n",
        "\n",
        "En la tercera sección, **Conclusiones**, se recoge la evaluación del modelo final y las conclusiones alcanzadas."
      ],
      "id": "554b9442-be8e-4246-8c96-d1b6901de6b8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Datos"
      ],
      "metadata": {
        "id": "NJDMx5uoWwXJ"
      },
      "id": "NJDMx5uoWwXJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección se aborda la obtención, análisis, tratamiento y preparación de los datos de entrenamiento para su posterior uso. Además, se obtienen los datos de validación. El dataset empleado en esta tarea ha sido obtendio de *Kaggel* (https://www.kaggle.com/datasets/damienbeneschi/krakow-ta-restaurans-data-raw).\n",
        "\n",
        "Las tres subsecciones de este apartado se corresponden con los 3 tratamientos distintos del conjunto de entrenamiento que se han planteado.\n",
        "\n",
        "- **Datos originales**: Se corresponde con el tratamiento sobre los datos originales sin modificar los textos (`Reviews`). Este tratamiento se centra más en preparar los datos tal y como vienen para poder usarlos y menos en investigar nuevas formas de representarlos y sacarles partido.\n",
        "- **Datos divididos**: Se corresponde con un tratamiento alternativo extra en el que, en vez de limitarnos a usar las `Reviews` que nos vienen ya dadas, se desempareja cada par de reseñas para contar con un único conjunto de datos con todos las `Reviews` separadas. Esta aproximación permite aumentar el conjunto de datos proporcionado. Esto ayuda a un mejor entrenamiento y aprendizaje del modelo.\n",
        "\n",
        "- **Datos siamese**: Se corresponde con un tratamiento diferente en el que, se desempareja cada par de reseñas para contar con un conjunto de datos donde se tienen ambas reviews en diferentes columnas, esto es, para posteriormente realizar el embbeding por separado y concatenar el resultado. Esta aproximación se realiza para obtener otro conjunto de resultados que comparar con los previos.\n"
      ],
      "metadata": {
        "id": "BpioMe0vY71p"
      },
      "id": "BpioMe0vY71p"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cabe destacar que, dentro de la subsección de **Datos Originales**, también se encuentra la obtención y análisis de los datos con los que se evaluará el modelo final."
      ],
      "metadata": {
        "id": "j-7kX2uyV-h3"
      },
      "id": "j-7kX2uyV-h3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.1 Datos originales"
      ],
      "metadata": {
        "id": "03BiL7vFWLag"
      },
      "id": "03BiL7vFWLag"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80a8a97f-2ba6-4c86-b2fb-78c24ea4277b"
      },
      "source": [
        "###1.1.1 Imports"
      ],
      "id": "80a8a97f-2ba6-4c86-b2fb-78c24ea4277b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "fc3b9f54-eef0-43dc-872d-6286a93acf02"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "fc3b9f54-eef0-43dc-872d-6286a93acf02"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "a9bf2424-c8cf-4f74-8f9f-ed95423f2f43"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "a9bf2424-c8cf-4f74-8f9f-ed95423f2f43"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB_QwwDbjmcP",
        "outputId": "199c914e-aab2-4db3-bb1e-e8f1f9a599ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "id": "rB_QwwDbjmcP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "3885801a-2264-4c3c-98c2-6bf2c290c4ee"
      },
      "source": [
        "###1.1.2 Carga de los datos"
      ],
      "id": "3885801a-2264-4c3c-98c2-6bf2c290c4ee"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27446839-608f-4b4b-a847-ae517675aa59"
      },
      "source": [
        "Inicialmente, se leen los datos en crudo con los que se va a trabajar y se almacenan en un DataFrame llamado `datos`. Como se puede observar, el DataFrame tiene un total de 125527 registros, es decir, valoraciones entre restaurantes, y consta de 11 columnas:\n",
        "- `RestaurantID: int64` -> identificador del restaurante (de 31 ciudades Europeas).\n",
        "- `Name: object` -> nombre del restaurante en cuestión.\n",
        "- `City: object` -> ubicación de la ciudad del restaurante.\n",
        "- `Cuisine Style: list(object)` -> estilo(s) de cocina del restaurante.\n",
        "- `Ranking: float64` -> clasificación del restaurante entre el número total de restaurantes en la ciudad (medida similar al ID).\n",
        "- `Rating: float64` -> puntuación del restaurante en una escala del 1 al 5.\n",
        "- `Price Range: object` -> rango de precios del restaurante dividido en 3 categorías (\\$, \\$$ o bien \\$$$).\n",
        "- `Number of Reviews: float64` -> numero total de reseñas que ha recibido el restaurante.\n",
        "- `Reviews: object` -> contenido de las dos reseñas principales del restaurante junto con la fecha de publicación.\n",
        "- `URL_TA: object` -> parte de la URL de la página detallada del restaurante que sigue a 'www.tripadvisor.com'.\n",
        "- `ID_TA: object` -> identificación del restaurante en la base de datos de TA obtenida con una letra y un número.\n"
      ],
      "id": "27446839-608f-4b4b-a847-ae517675aa59"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "67c43a94-be1f-42d9-8a13-0916c794f472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "b6e8db7a-2a6c-4b9a-8c39-6bedf54eaf33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                        Name       City  \\\n",
              "0           0  Martine of Martine's Table  Amsterdam   \n",
              "1           1         De Silveren Spiegel  Amsterdam   \n",
              "2           2                     La Rive  Amsterdam   \n",
              "\n",
              "                                       Cuisine Style  Ranking  Rating  \\\n",
              "0                    ['French', 'Dutch', 'European']      1.0     5.0   \n",
              "1  ['Dutch', 'European', 'Vegetarian Friendly', '...      2.0     4.5   \n",
              "2  ['Mediterranean', 'French', 'International', '...      3.0     4.5   \n",
              "\n",
              "  Price Range  Number of Reviews  \\\n",
              "0    $$ - $$$              136.0   \n",
              "1        $$$$              812.0   \n",
              "2        $$$$              567.0   \n",
              "\n",
              "                                             Reviews  \\\n",
              "0  [['Just like home', 'A Warm Welcome to Wintry ...   \n",
              "1  [['Great food and staff', 'just perfect'], ['0...   \n",
              "2  [['Satisfaction', 'Delicious old school restau...   \n",
              "\n",
              "                                              URL_TA      ID_TA  \n",
              "0  /Restaurant_Review-g188590-d11752080-Reviews-M...  d11752080  \n",
              "1  /Restaurant_Review-g188590-d693419-Reviews-De_...    d693419  \n",
              "2  /Restaurant_Review-g188590-d696959-Reviews-La_...    d696959  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-208faa9f-7b85-4857-8d04-a4813558fea7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Name</th>\n",
              "      <th>City</th>\n",
              "      <th>Cuisine Style</th>\n",
              "      <th>Ranking</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Price Range</th>\n",
              "      <th>Number of Reviews</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>URL_TA</th>\n",
              "      <th>ID_TA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Martine of Martine's Table</td>\n",
              "      <td>Amsterdam</td>\n",
              "      <td>['French', 'Dutch', 'European']</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>$$ - $$$</td>\n",
              "      <td>136.0</td>\n",
              "      <td>[['Just like home', 'A Warm Welcome to Wintry ...</td>\n",
              "      <td>/Restaurant_Review-g188590-d11752080-Reviews-M...</td>\n",
              "      <td>d11752080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>De Silveren Spiegel</td>\n",
              "      <td>Amsterdam</td>\n",
              "      <td>['Dutch', 'European', 'Vegetarian Friendly', '...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>$$$$</td>\n",
              "      <td>812.0</td>\n",
              "      <td>[['Great food and staff', 'just perfect'], ['0...</td>\n",
              "      <td>/Restaurant_Review-g188590-d693419-Reviews-De_...</td>\n",
              "      <td>d693419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>La Rive</td>\n",
              "      <td>Amsterdam</td>\n",
              "      <td>['Mediterranean', 'French', 'International', '...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>$$$$</td>\n",
              "      <td>567.0</td>\n",
              "      <td>[['Satisfaction', 'Delicious old school restau...</td>\n",
              "      <td>/Restaurant_Review-g188590-d696959-Reviews-La_...</td>\n",
              "      <td>d696959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-208faa9f-7b85-4857-8d04-a4813558fea7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-208faa9f-7b85-4857-8d04-a4813558fea7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-208faa9f-7b85-4857-8d04-a4813558fea7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fce5a7af-730c-49c4-bd6d-ed551f743a68\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fce5a7af-730c-49c4-bd6d-ed551f743a68')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fce5a7af-730c-49c4-bd6d-ed551f743a68 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "datos = pd.read_csv(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/TA_restaurants_curated.csv\")\n",
        "datos.head(3)"
      ],
      "id": "67c43a94-be1f-42d9-8a13-0916c794f472"
    },
    {
      "cell_type": "code",
      "source": [
        "datos.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxoXHrAydbbK",
        "outputId": "80fb1f2f-7c2c-4818-d88f-8ca1506104ed"
      },
      "id": "xxoXHrAydbbK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 125527 entries, 0 to 125526\n",
            "Data columns (total 11 columns):\n",
            " #   Column             Non-Null Count   Dtype  \n",
            "---  ------             --------------   -----  \n",
            " 0   Unnamed: 0         125527 non-null  int64  \n",
            " 1   Name               125527 non-null  object \n",
            " 2   City               125527 non-null  object \n",
            " 3   Cuisine Style      94176 non-null   object \n",
            " 4   Ranking            115876 non-null  float64\n",
            " 5   Rating             115897 non-null  float64\n",
            " 6   Price Range        77672 non-null   object \n",
            " 7   Number of Reviews  108183 non-null  float64\n",
            " 8   Reviews            115911 non-null  object \n",
            " 9   URL_TA             125527 non-null  object \n",
            " 10  ID_TA              125527 non-null  object \n",
            "dtypes: float64(3), int64(1), object(7)\n",
            "memory usage: 10.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1.3 Preprocesamiento de los datos"
      ],
      "metadata": {
        "id": "-Y-2FltvwMsC"
      },
      "id": "-Y-2FltvwMsC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la tarea que se presenta, es necesario realizar un preprocesamiento de los datos, por ello en las siguientes celdas de código se trataran los datos obtenidos del dataset proporcionado. Se eliminarán datos nulos o vacíos, así como definir el umbral necesario para la correcta clasificación dada la tarea *sentiment analysis*."
      ],
      "metadata": {
        "id": "foTx7SSM1_3c"
      },
      "id": "foTx7SSM1_3c"
    },
    {
      "cell_type": "code",
      "source": [
        "type(datos.Reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QoF1UNNRtVi",
        "outputId": "99b06eba-53d4-468a-90ed-fb3ab9366e5a"
      },
      "id": "5QoF1UNNRtVi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos.Reviews[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w7jGb1O4R4Bw",
        "outputId": "af9c4a10-88fd-45a3-d5e9-dd6fb5b185fc"
      },
      "id": "w7jGb1O4R4Bw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[['Great food and staff', 'just perfect'], ['01/06/2018', '01/04/2018']]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{att : datos[datos[att].isnull()].shape[0] for att in datos.columns}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkWPgphMPh7P",
        "outputId": "f4761888-8e65-4d34-ec03-1946de0ce911"
      },
      "id": "NkWPgphMPh7P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Unnamed: 0': 0,\n",
              " 'Name': 0,\n",
              " 'City': 0,\n",
              " 'Cuisine Style': 31351,\n",
              " 'Ranking': 9651,\n",
              " 'Rating': 9630,\n",
              " 'Price Range': 47855,\n",
              " 'Number of Reviews': 17344,\n",
              " 'Reviews': 9616,\n",
              " 'URL_TA': 0,\n",
              " 'ID_TA': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos.dropna(subset = ['Rating','Reviews'] , inplace=True)"
      ],
      "metadata": {
        "id": "bnm4faDYQ2hH"
      },
      "id": "bnm4faDYQ2hH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{att : datos[datos[att].isnull()].shape[0] for att in datos.columns}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ngF2gJpQMJm",
        "outputId": "1deb44ce-2318-4db1-f940-2b1de7d0df3f"
      },
      "id": "3ngF2gJpQMJm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Unnamed: 0': 0,\n",
              " 'Name': 0,\n",
              " 'City': 0,\n",
              " 'Cuisine Style': 26845,\n",
              " 'Ranking': 145,\n",
              " 'Rating': 0,\n",
              " 'Price Range': 40418,\n",
              " 'Number of Reviews': 7710,\n",
              " 'Reviews': 0,\n",
              " 'URL_TA': 0,\n",
              " 'ID_TA': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es por ello, que se **eliminaran las columnas** que no son necesarias. Para el problema planteado se requiere unicamente la columna `Reviews` y la columna `Rating`."
      ],
      "metadata": {
        "id": "Pp26bDXe9lF5"
      },
      "id": "Pp26bDXe9lF5"
    },
    {
      "cell_type": "code",
      "source": [
        "datos.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNP7TnobAFPK",
        "outputId": "2d03c154-7085-44ce-dd2b-dd2620f39e37"
      },
      "id": "hNP7TnobAFPK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Name', 'City', 'Cuisine Style', 'Ranking', 'Rating',\n",
              "       'Price Range', 'Number of Reviews', 'Reviews', 'URL_TA', 'ID_TA'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_validas = ['Reviews', 'Rating']"
      ],
      "metadata": {
        "id": "-uqA1A0dAn5w"
      },
      "id": "-uqA1A0dAn5w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_eliminar = [columna for columna in datos.columns if columna not in col_validas]"
      ],
      "metadata": {
        "id": "95rSmorHAxfZ"
      },
      "id": "95rSmorHAxfZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_eliminar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-5KGTbKA1-k",
        "outputId": "2a7d2d4c-b917-4576-a195-1746db536eab"
      },
      "id": "h-5KGTbKA1-k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Unnamed: 0',\n",
              " 'Name',\n",
              " 'City',\n",
              " 'Cuisine Style',\n",
              " 'Ranking',\n",
              " 'Price Range',\n",
              " 'Number of Reviews',\n",
              " 'URL_TA',\n",
              " 'ID_TA']"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos = datos.drop(col_eliminar, axis=1)"
      ],
      "metadata": {
        "id": "USJsJWPbA6EW"
      },
      "id": "USJsJWPbA6EW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AhUj9hTfA64G",
        "outputId": "d16a0d66-4e44-4077-f22e-3b8820ddd189"
      },
      "id": "AhUj9hTfA64G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Rating                                            Reviews\n",
              "0          5.0  [['Just like home', 'A Warm Welcome to Wintry ...\n",
              "1          4.5  [['Great food and staff', 'just perfect'], ['0...\n",
              "2          4.5  [['Satisfaction', 'Delicious old school restau...\n",
              "3          5.0  [['True five star dinner', 'A superb evening o...\n",
              "4          4.5  [['Best meal.... EVER', 'super food experience...\n",
              "...        ...                                                ...\n",
              "125450     1.0                                           [[], []]\n",
              "125451     1.0  [['Poor quality, small portions, miserable st....\n",
              "125452     1.0                                           [[], []]\n",
              "125453     1.0                                           [[], []]\n",
              "125454     3.0                                           [[], []]\n",
              "\n",
              "[115892 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74119633-c133-491b-a772-333b4cf391fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>[['Just like home', 'A Warm Welcome to Wintry ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.5</td>\n",
              "      <td>[['Great food and staff', 'just perfect'], ['0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.5</td>\n",
              "      <td>[['Satisfaction', 'Delicious old school restau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>[['True five star dinner', 'A superb evening o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.5</td>\n",
              "      <td>[['Best meal.... EVER', 'super food experience...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125450</th>\n",
              "      <td>1.0</td>\n",
              "      <td>[[], []]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125451</th>\n",
              "      <td>1.0</td>\n",
              "      <td>[['Poor quality, small portions, miserable st....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125452</th>\n",
              "      <td>1.0</td>\n",
              "      <td>[[], []]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125453</th>\n",
              "      <td>1.0</td>\n",
              "      <td>[[], []]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125454</th>\n",
              "      <td>3.0</td>\n",
              "      <td>[[], []]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>115892 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74119633-c133-491b-a772-333b4cf391fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74119633-c133-491b-a772-333b4cf391fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74119633-c133-491b-a772-333b4cf391fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4858a321-22a4-42da-88cc-3bb44645a424\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4858a321-22a4-42da-88cc-3bb44645a424')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4858a321-22a4-42da-88cc-3bb44645a424 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este punto, se observa que se tienen **valores vacíos** definidos como \"[[], [[]\". Es por ello, que resulta indispensable eliminarlos para que el modelo realice un mejor entrenamiento. Además, no se requiere el segundo parámetro de `Reviews`, recordar que se tenia tanto la reseña como la fecha de publicación. Es por ello que se procede a la eliminación de este segundo elemento."
      ],
      "metadata": {
        "id": "L0a48cHoBnsn"
      },
      "id": "L0a48cHoBnsn"
    },
    {
      "cell_type": "code",
      "source": [
        "type(datos.Reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqV4UYvMB4RZ",
        "outputId": "f2349921-88f0-4d62-bea7-fac417bd3ce7"
      },
      "id": "nqV4UYvMB4RZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos.Reviews[0][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y9UsCF9zB8bB",
        "outputId": "435d6287-8d97-4b06-93ae-67b71ed6770f"
      },
      "id": "Y9UsCF9zB8bB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'J'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_review(review):\n",
        "    rev = ''\n",
        "    contador_corchetes = 0\n",
        "\n",
        "    for c in review:\n",
        "        if c == '[':\n",
        "            contador_corchetes += 1\n",
        "        elif c == ']':\n",
        "            contador_corchetes += 1\n",
        "        elif contador_corchetes == 2:\n",
        "            rev += c\n",
        "\n",
        "        if contador_corchetes == 3:\n",
        "            break\n",
        "\n",
        "    return rev"
      ],
      "metadata": {
        "id": "nMg_WMKECCeL"
      },
      "id": "nMg_WMKECCeL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos['Reviews'] = datos['Reviews'].apply(get_review)"
      ],
      "metadata": {
        "id": "CCIiCdXCCK2e"
      },
      "id": "CCIiCdXCCK2e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "p8s7jXScCurM",
        "outputId": "f33c1130-b3ab-4049-aabf-6aeb5a45de6d"
      },
      "id": "p8s7jXScCurM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Rating                                            Reviews\n",
              "0          5.0  'Just like home', 'A Warm Welcome to Wintry Am...\n",
              "1          4.5             'Great food and staff', 'just perfect'\n",
              "2          4.5  'Satisfaction', 'Delicious old school restaurant'\n",
              "3          5.0  'True five star dinner', 'A superb evening of ...\n",
              "4          4.5      'Best meal.... EVER', 'super food experience'\n",
              "...        ...                                                ...\n",
              "125450     1.0                                                   \n",
              "125451     1.0    'Poor quality, small portions, miserable st...'\n",
              "125452     1.0                                                   \n",
              "125453     1.0                                                   \n",
              "125454     3.0                                                   \n",
              "\n",
              "[115892 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea226cdc-fdbb-4bbf-b48c-4a9485dfe74f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>'Just like home', 'A Warm Welcome to Wintry Am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.5</td>\n",
              "      <td>'Great food and staff', 'just perfect'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.5</td>\n",
              "      <td>'Satisfaction', 'Delicious old school restaurant'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>'True five star dinner', 'A superb evening of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.5</td>\n",
              "      <td>'Best meal.... EVER', 'super food experience'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125450</th>\n",
              "      <td>1.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125451</th>\n",
              "      <td>1.0</td>\n",
              "      <td>'Poor quality, small portions, miserable st...'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125452</th>\n",
              "      <td>1.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125453</th>\n",
              "      <td>1.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125454</th>\n",
              "      <td>3.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>115892 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea226cdc-fdbb-4bbf-b48c-4a9485dfe74f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ea226cdc-fdbb-4bbf-b48c-4a9485dfe74f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ea226cdc-fdbb-4bbf-b48c-4a9485dfe74f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b1361fbd-c8e4-4577-b10f-f4f5b3f3f51d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1361fbd-c8e4-4577-b10f-f4f5b3f3f51d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b1361fbd-c8e4-4577-b10f-f4f5b3f3f51d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos.Reviews[125452]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GbG2y-7rC3wm",
        "outputId": "28dbc19d-d6e9-4be3-80d4-deace4f5460f"
      },
      "id": "GbG2y-7rC3wm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos = datos.drop(datos[datos['Reviews'] == ''].index)"
      ],
      "metadata": {
        "id": "GD-J67-MC9Ok"
      },
      "id": "GD-J67-MC9Ok",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "gDA66DssDCg2"
      },
      "id": "gDA66DssDCg2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "MbToI_OvDIlb",
        "outputId": "0c471e8f-db8a-46fd-ab32-e4ba0b9435a2"
      },
      "id": "MbToI_OvDIlb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Rating                                            Reviews\n",
              "0         5.0  'Just like home', 'A Warm Welcome to Wintry Am...\n",
              "1         4.5             'Great food and staff', 'just perfect'\n",
              "2         4.5  'Satisfaction', 'Delicious old school restaurant'\n",
              "3         5.0  'True five star dinner', 'A superb evening of ...\n",
              "4         4.5      'Best meal.... EVER', 'super food experience'\n",
              "...       ...                                                ...\n",
              "96806     2.5                                     'Good Service'\n",
              "96807     4.5   'Super local eatery', 'Small and charming place'\n",
              "96808     2.0                                      'Cordon Bleu'\n",
              "96809     2.0  \"Don't waste your time, go somewhere else!\", '...\n",
              "96810     1.0    'Poor quality, small portions, miserable st...'\n",
              "\n",
              "[96811 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a16e047c-950a-4b70-8681-6498c01cbe0a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>'Just like home', 'A Warm Welcome to Wintry Am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.5</td>\n",
              "      <td>'Great food and staff', 'just perfect'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.5</td>\n",
              "      <td>'Satisfaction', 'Delicious old school restaurant'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>'True five star dinner', 'A superb evening of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.5</td>\n",
              "      <td>'Best meal.... EVER', 'super food experience'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96806</th>\n",
              "      <td>2.5</td>\n",
              "      <td>'Good Service'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96807</th>\n",
              "      <td>4.5</td>\n",
              "      <td>'Super local eatery', 'Small and charming place'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96808</th>\n",
              "      <td>2.0</td>\n",
              "      <td>'Cordon Bleu'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96809</th>\n",
              "      <td>2.0</td>\n",
              "      <td>\"Don't waste your time, go somewhere else!\", '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96810</th>\n",
              "      <td>1.0</td>\n",
              "      <td>'Poor quality, small portions, miserable st...'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96811 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a16e047c-950a-4b70-8681-6498c01cbe0a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a16e047c-950a-4b70-8681-6498c01cbe0a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a16e047c-950a-4b70-8681-6498c01cbe0a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a42ad3ef-0a83-4e1e-81ea-5be8067f9c5c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a42ad3ef-0a83-4e1e-81ea-5be8067f9c5c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a42ad3ef-0a83-4e1e-81ea-5be8067f9c5c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{att : datos[datos[att].isnull()].shape[0] for att in datos.columns}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_cpl9DoDKkS",
        "outputId": "22ec851b-c370-4ada-9768-1c23038f324f"
      },
      "id": "7_cpl9DoDKkS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Rating': 0, 'Reviews': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se ha comentado previamente, se quiere realizar analisis de sentimientos y para ello es necesario el *groud truth*. Es decir, un elemento que identifique la clase correcta de las `Reviews`, es decir, **sentimiento positivo** o **sentimieto negativo**. Al no tener el *groud truth* definido se utilizará la valoración (`Rating`).\n",
        "\n",
        "Es por ello que la primera aproximación fué definirlo de la siguiente manera:\n",
        "- Intervalo [1,3) se clasificara como sentimiento **negativo**.\n",
        "- Intervalo [3] se clasificara como sentimiento **neutro**.\n",
        "- Intervalo (3,5] se clasificara como sentimiento **positivo**.\n",
        "\n",
        "Tras analizar el número de datos que se tenían de cada clasificación, se optó por omitir el \"sentimiento neutro\" y unificarlo con el sentimiento negativo, dado que se tenían muy pocas muestras en comparación con el positivo.\n",
        "\n",
        "Por tanto el intervalo final queda definido como:\n",
        "\n",
        "- Intervalo [1,3] se clasificara como sentimiento **negativo**.\n",
        "- Intervalo (3,5] se clasificara como sentimiento **positivo**."
      ],
      "metadata": {
        "id": "Djo2V5voKU7S"
      },
      "id": "Djo2V5voKU7S"
    },
    {
      "cell_type": "code",
      "source": [
        "datosPos = datos[datos['Rating'] > 3]\n",
        "datosPos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zmPO0SRwi_-W",
        "outputId": "fa59c1f6-1423-45dd-966c-803abedd54fc"
      },
      "id": "zmPO0SRwi_-W",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Rating                                            Reviews\n",
              "0         5.0  'Just like home', 'A Warm Welcome to Wintry Am...\n",
              "1         4.5             'Great food and staff', 'just perfect'\n",
              "2         4.5  'Satisfaction', 'Delicious old school restaurant'\n",
              "3         5.0  'True five star dinner', 'A superb evening of ...\n",
              "4         4.5      'Best meal.... EVER', 'super food experience'\n",
              "...       ...                                                ...\n",
              "96782     5.0                                   'Friendly staff'\n",
              "96791     3.5                  'These people are rude!', 'Avoid'\n",
              "96798     3.5                 'Good service', 'nice atmoshphere'\n",
              "96801     4.0                    'Authentic Swiss & German Food'\n",
              "96807     4.5   'Super local eatery', 'Small and charming place'\n",
              "\n",
              "[86857 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46e18a98-5e89-4267-98b9-5f94fddb3451\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>'Just like home', 'A Warm Welcome to Wintry Am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.5</td>\n",
              "      <td>'Great food and staff', 'just perfect'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.5</td>\n",
              "      <td>'Satisfaction', 'Delicious old school restaurant'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>'True five star dinner', 'A superb evening of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.5</td>\n",
              "      <td>'Best meal.... EVER', 'super food experience'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96782</th>\n",
              "      <td>5.0</td>\n",
              "      <td>'Friendly staff'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96791</th>\n",
              "      <td>3.5</td>\n",
              "      <td>'These people are rude!', 'Avoid'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96798</th>\n",
              "      <td>3.5</td>\n",
              "      <td>'Good service', 'nice atmoshphere'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96801</th>\n",
              "      <td>4.0</td>\n",
              "      <td>'Authentic Swiss &amp; German Food'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96807</th>\n",
              "      <td>4.5</td>\n",
              "      <td>'Super local eatery', 'Small and charming place'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>86857 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46e18a98-5e89-4267-98b9-5f94fddb3451')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46e18a98-5e89-4267-98b9-5f94fddb3451 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46e18a98-5e89-4267-98b9-5f94fddb3451');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3d582a90-eaeb-4a8a-8625-1c76d905c354\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d582a90-eaeb-4a8a-8625-1c76d905c354')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3d582a90-eaeb-4a8a-8625-1c76d905c354 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datosNegativo = datos[datos['Rating'] < 3]\n",
        "datosNegativo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9fCnT0EcjQoQ",
        "outputId": "17a3e0bc-dc72-4b70-be9c-4fe37cd9466d"
      },
      "id": "9fCnT0EcjQoQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Rating                                            Reviews\n",
              "2820      2.5  'This is a great place for Shoarma', 'Amsterda...\n",
              "2885      2.5  'Not the best service on a Fri. sat. or Sun......\n",
              "2898      2.5      'Boring food', 'Worst restaurant I ever had!'\n",
              "2939      2.5     'Good local bar', 'Best Old School Hop-hip DJ'\n",
              "2977      2.5  'Relaxed, chilled and 4 tvs!', 'Always read re...\n",
              "...       ...                                                ...\n",
              "96805     2.0  'Very amicable owner; Good pizzas', 'A very he...\n",
              "96806     2.5                                     'Good Service'\n",
              "96808     2.0                                      'Cordon Bleu'\n",
              "96809     2.0  \"Don't waste your time, go somewhere else!\", '...\n",
              "96810     1.0    'Poor quality, small portions, miserable st...'\n",
              "\n",
              "[3421 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df84dc1e-7bf5-4d09-a599-5173ae0ff5fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2820</th>\n",
              "      <td>2.5</td>\n",
              "      <td>'This is a great place for Shoarma', 'Amsterda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2885</th>\n",
              "      <td>2.5</td>\n",
              "      <td>'Not the best service on a Fri. sat. or Sun......</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2898</th>\n",
              "      <td>2.5</td>\n",
              "      <td>'Boring food', 'Worst restaurant I ever had!'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2939</th>\n",
              "      <td>2.5</td>\n",
              "      <td>'Good local bar', 'Best Old School Hop-hip DJ'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2977</th>\n",
              "      <td>2.5</td>\n",
              "      <td>'Relaxed, chilled and 4 tvs!', 'Always read re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96805</th>\n",
              "      <td>2.0</td>\n",
              "      <td>'Very amicable owner; Good pizzas', 'A very he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96806</th>\n",
              "      <td>2.5</td>\n",
              "      <td>'Good Service'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96808</th>\n",
              "      <td>2.0</td>\n",
              "      <td>'Cordon Bleu'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96809</th>\n",
              "      <td>2.0</td>\n",
              "      <td>\"Don't waste your time, go somewhere else!\", '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96810</th>\n",
              "      <td>1.0</td>\n",
              "      <td>'Poor quality, small portions, miserable st...'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3421 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df84dc1e-7bf5-4d09-a599-5173ae0ff5fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df84dc1e-7bf5-4d09-a599-5173ae0ff5fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df84dc1e-7bf5-4d09-a599-5173ae0ff5fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dd1e9af3-5127-4f5f-a503-fb3e10c3a5d2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd1e9af3-5127-4f5f-a503-fb3e10c3a5d2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dd1e9af3-5127-4f5f-a503-fb3e10c3a5d2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datosNeutro = datos[datos['Rating'] == 3]\n",
        "datosNeutro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZO5UZfLMje56",
        "outputId": "e1c5c30c-89a0-40a1-a293-8a2376a71662"
      },
      "id": "ZO5UZfLMje56",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Rating                                            Reviews\n",
              "2316      3.0  'In general food not good in Amsterdam', 'Good...\n",
              "2568      3.0  'Good for a quick fix if you are really hun......\n",
              "2577      3.0        'Boring', 'Lovely evening sorg ny Darling.'\n",
              "2578      3.0  'Good pizza, great deserts', 'Decent spot for ...\n",
              "2683      3.0  'A very late dinner near the Amsterdam Medi......\n",
              "...       ...                                                ...\n",
              "96777     3.0  'Mediocre vegetarian fried rice but rude ca......\n",
              "96784     3.0                               'Rude and Expensive'\n",
              "96786     3.0   'Terrible service', 'Not the wüst, not the best'\n",
              "96800     3.0     'Not just a restaurant but maybe it should...'\n",
              "96802     3.0  'Horrible!', 'It was really horrible, I would ...\n",
              "\n",
              "[6533 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e319c4cd-d082-4dc3-8aac-a3618431fd64\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2316</th>\n",
              "      <td>3.0</td>\n",
              "      <td>'In general food not good in Amsterdam', 'Good...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2568</th>\n",
              "      <td>3.0</td>\n",
              "      <td>'Good for a quick fix if you are really hun......</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2577</th>\n",
              "      <td>3.0</td>\n",
              "      <td>'Boring', 'Lovely evening sorg ny Darling.'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2578</th>\n",
              "      <td>3.0</td>\n",
              "      <td>'Good pizza, great deserts', 'Decent spot for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2683</th>\n",
              "      <td>3.0</td>\n",
              "      <td>'A very late dinner near the Amsterdam Medi......</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96777</th>\n",
              "      <td>3.0</td>\n",
              "      <td>'Mediocre vegetarian fried rice but rude ca......</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96784</th>\n",
              "      <td>3.0</td>\n",
              "      <td>'Rude and Expensive'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96786</th>\n",
              "      <td>3.0</td>\n",
              "      <td>'Terrible service', 'Not the wüst, not the best'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96800</th>\n",
              "      <td>3.0</td>\n",
              "      <td>'Not just a restaurant but maybe it should...'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96802</th>\n",
              "      <td>3.0</td>\n",
              "      <td>'Horrible!', 'It was really horrible, I would ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6533 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e319c4cd-d082-4dc3-8aac-a3618431fd64')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e319c4cd-d082-4dc3-8aac-a3618431fd64 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e319c4cd-d082-4dc3-8aac-a3618431fd64');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-defb13b3-d4e9-45ff-b3dd-10c47ac91e9b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-defb13b3-d4e9-45ff-b3dd-10c47ac91e9b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-defb13b3-d4e9-45ff-b3dd-10c47ac91e9b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def asignar_valor(x):\n",
        "  if x >=4:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "BWTl4CUtLJcp"
      },
      "id": "BWTl4CUtLJcp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos['Sentimiento'] = datos['Rating'].apply(asignar_valor)"
      ],
      "metadata": {
        "id": "29Yb7f_CKnXK"
      },
      "id": "29Yb7f_CKnXK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "i_TuwZZ5MC6P",
        "outputId": "80b3eeb1-c079-42cb-c996-1f2fe1be3efc"
      },
      "id": "i_TuwZZ5MC6P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Rating                                            Reviews  Sentimiento\n",
              "0     5.0  'Just like home', 'A Warm Welcome to Wintry Am...            1\n",
              "1     4.5             'Great food and staff', 'just perfect'            1\n",
              "2     4.5  'Satisfaction', 'Delicious old school restaurant'            1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29b54e7a-0cf0-4955-b27f-bc21d7d5295b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>'Just like home', 'A Warm Welcome to Wintry Am...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.5</td>\n",
              "      <td>'Great food and staff', 'just perfect'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.5</td>\n",
              "      <td>'Satisfaction', 'Delicious old school restaurant'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29b54e7a-0cf0-4955-b27f-bc21d7d5295b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29b54e7a-0cf0-4955-b27f-bc21d7d5295b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29b54e7a-0cf0-4955-b27f-bc21d7d5295b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35c7e3ee-5249-47d7-a3a4-17db490714f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35c7e3ee-5249-47d7-a3a4-17db490714f9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35c7e3ee-5249-47d7-a3a4-17db490714f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya no es necesaria la columna `Rating`, por ello se elimina. Asimismo, se añadirán dos columnas extras necesarias para el apartado 2.6 de este notebook. Esto es, separar las dos reseñas que se tienen en `Reviews` en dos columnas diferentes `Review1` y `Review2`."
      ],
      "metadata": {
        "id": "38fNcoJhEUTV"
      },
      "id": "38fNcoJhEUTV"
    },
    {
      "cell_type": "code",
      "source": [
        "datos = datos.drop('Rating', axis=1)"
      ],
      "metadata": {
        "id": "kfbEfERDEiHC"
      },
      "id": "kfbEfERDEiHC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "78Sqbe3CErCT",
        "outputId": "e4a2903a-315d-4d24-a78c-f5f7c1210a38"
      },
      "id": "78Sqbe3CErCT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Reviews  Sentimiento\n",
              "0      'Just like home', 'A Warm Welcome to Wintry Am...            1\n",
              "1                 'Great food and staff', 'just perfect'            1\n",
              "2      'Satisfaction', 'Delicious old school restaurant'            1\n",
              "3      'True five star dinner', 'A superb evening of ...            1\n",
              "4          'Best meal.... EVER', 'super food experience'            1\n",
              "...                                                  ...          ...\n",
              "96806                                     'Good Service'            0\n",
              "96807   'Super local eatery', 'Small and charming place'            1\n",
              "96808                                      'Cordon Bleu'            0\n",
              "96809  \"Don't waste your time, go somewhere else!\", '...            0\n",
              "96810    'Poor quality, small portions, miserable st...'            0\n",
              "\n",
              "[96811 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9b030a0-cc80-4f54-9ea2-cc89cfe4e151\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'Just like home', 'A Warm Welcome to Wintry Am...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'Great food and staff', 'just perfect'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Satisfaction', 'Delicious old school restaurant'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'True five star dinner', 'A superb evening of ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'Best meal.... EVER', 'super food experience'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96806</th>\n",
              "      <td>'Good Service'</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96807</th>\n",
              "      <td>'Super local eatery', 'Small and charming place'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96808</th>\n",
              "      <td>'Cordon Bleu'</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96809</th>\n",
              "      <td>\"Don't waste your time, go somewhere else!\", '...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96810</th>\n",
              "      <td>'Poor quality, small portions, miserable st...'</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96811 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9b030a0-cc80-4f54-9ea2-cc89cfe4e151')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d9b030a0-cc80-4f54-9ea2-cc89cfe4e151 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d9b030a0-cc80-4f54-9ea2-cc89cfe4e151');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c911a9b0-655c-45d7-862a-609e027abc3c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c911a9b0-655c-45d7-862a-609e027abc3c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c911a9b0-655c-45d7-862a-609e027abc3c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos.Reviews[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rBvGk3EIMeon",
        "outputId": "33c8b955-8a31-467d-829c-a4a07a511056"
      },
      "id": "rBvGk3EIMeon",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"'Great food and staff', 'just perfect'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos.Reviews[96809]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JPgrtoltKf2P",
        "outputId": "74260c96-c4c7-4807-aef1-048900ff7128"
      },
      "id": "JPgrtoltKf2P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Don\\'t waste your time, go somewhere else!\", \\'Horrible\\''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos.Reviews[96810]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WO3pckSlOIdU",
        "outputId": "64375ac0-a100-4e13-cb7e-6bc069d69e59"
      },
      "id": "WO3pckSlOIdU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"'Poor quality, small portions, miserable st...'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_review(review):\n",
        "    parts = review.split(\", '\")\n",
        "\n",
        "    if len(parts) == 2:\n",
        "        rev1 = parts[0].strip(\"['\").strip(\"'\")\n",
        "        rev2 = parts[1].strip(\"']\").strip(\"'\")\n",
        "    else:\n",
        "        rev1 = review.strip(\"['\").strip(\"'\")\n",
        "        rev2 = ''\n",
        "\n",
        "    return rev1, rev2"
      ],
      "metadata": {
        "id": "4PzJrK-NNBw6"
      },
      "id": "4PzJrK-NNBw6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos[['Review1', 'Review2']] = datos['Reviews'].apply(split_review).apply(pd.Series)"
      ],
      "metadata": {
        "id": "XwTvKeP-G7tY"
      },
      "id": "XwTvKeP-G7tY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "CaOPPyCxHxNf",
        "outputId": "ebb12ec5-1d37-43e4-a62e-e63883b48452"
      },
      "id": "CaOPPyCxHxNf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Reviews  Sentimiento  \\\n",
              "0      'Just like home', 'A Warm Welcome to Wintry Am...            1   \n",
              "1                 'Great food and staff', 'just perfect'            1   \n",
              "2      'Satisfaction', 'Delicious old school restaurant'            1   \n",
              "3      'True five star dinner', 'A superb evening of ...            1   \n",
              "4          'Best meal.... EVER', 'super food experience'            1   \n",
              "...                                                  ...          ...   \n",
              "96806                                     'Good Service'            0   \n",
              "96807   'Super local eatery', 'Small and charming place'            1   \n",
              "96808                                      'Cordon Bleu'            0   \n",
              "96809  \"Don't waste your time, go somewhere else!\", '...            0   \n",
              "96810    'Poor quality, small portions, miserable st...'            0   \n",
              "\n",
              "                                             Review1  \\\n",
              "0                                     Just like home   \n",
              "1                               Great food and staff   \n",
              "2                                       Satisfaction   \n",
              "3                              True five star dinner   \n",
              "4                                 Best meal.... EVER   \n",
              "...                                              ...   \n",
              "96806                                   Good Service   \n",
              "96807                             Super local eatery   \n",
              "96808                                    Cordon Bleu   \n",
              "96809    \"Don't waste your time, go somewhere else!\"   \n",
              "96810  Poor quality, small portions, miserable st...   \n",
              "\n",
              "                                             Review2  \n",
              "0                 A Warm Welcome to Wintry Amsterdam  \n",
              "1                                       just perfect  \n",
              "2                    Delicious old school restaurant  \n",
              "3      A superb evening of fine dining, hospitali...  \n",
              "4                              super food experience  \n",
              "...                                              ...  \n",
              "96806                                                 \n",
              "96807                       Small and charming place  \n",
              "96808                                                 \n",
              "96809                                       Horrible  \n",
              "96810                                                 \n",
              "\n",
              "[96811 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-214cf1b4-daf0-4242-9176-30f81087b50f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentimiento</th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'Just like home', 'A Warm Welcome to Wintry Am...</td>\n",
              "      <td>1</td>\n",
              "      <td>Just like home</td>\n",
              "      <td>A Warm Welcome to Wintry Amsterdam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'Great food and staff', 'just perfect'</td>\n",
              "      <td>1</td>\n",
              "      <td>Great food and staff</td>\n",
              "      <td>just perfect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Satisfaction', 'Delicious old school restaurant'</td>\n",
              "      <td>1</td>\n",
              "      <td>Satisfaction</td>\n",
              "      <td>Delicious old school restaurant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'True five star dinner', 'A superb evening of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>True five star dinner</td>\n",
              "      <td>A superb evening of fine dining, hospitali...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'Best meal.... EVER', 'super food experience'</td>\n",
              "      <td>1</td>\n",
              "      <td>Best meal.... EVER</td>\n",
              "      <td>super food experience</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96806</th>\n",
              "      <td>'Good Service'</td>\n",
              "      <td>0</td>\n",
              "      <td>Good Service</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96807</th>\n",
              "      <td>'Super local eatery', 'Small and charming place'</td>\n",
              "      <td>1</td>\n",
              "      <td>Super local eatery</td>\n",
              "      <td>Small and charming place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96808</th>\n",
              "      <td>'Cordon Bleu'</td>\n",
              "      <td>0</td>\n",
              "      <td>Cordon Bleu</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96809</th>\n",
              "      <td>\"Don't waste your time, go somewhere else!\", '...</td>\n",
              "      <td>0</td>\n",
              "      <td>\"Don't waste your time, go somewhere else!\"</td>\n",
              "      <td>Horrible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96810</th>\n",
              "      <td>'Poor quality, small portions, miserable st...'</td>\n",
              "      <td>0</td>\n",
              "      <td>Poor quality, small portions, miserable st...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96811 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-214cf1b4-daf0-4242-9176-30f81087b50f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-214cf1b4-daf0-4242-9176-30f81087b50f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-214cf1b4-daf0-4242-9176-30f81087b50f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bfd78cc5-0db3-4184-b6e8-bc091cd4b8e7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bfd78cc5-0db3-4184-b6e8-bc091cd4b8e7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bfd78cc5-0db3-4184-b6e8-bc091cd4b8e7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos.Review1[96809]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UGqmZ7KAQCWs",
        "outputId": "322eadd0-e41a-4029-9c20-ba9f21b27b85"
      },
      "id": "UGqmZ7KAQCWs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Don\\'t waste your time, go somewhere else!\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos.Review2[96809]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9Ok68kjWQ2Wp",
        "outputId": "caa7e541-fb1a-402c-8425-413c4590d925"
      },
      "id": "9Ok68kjWQ2Wp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Horrible'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez se tienen los datos en limpio, se procede a realizar el **split** de los datos para dividir el dataset original en datos de entrenamiento, datos de validación y datos de test. Se almacenan dichos datos en `datos_entrenamiento`, `datos_validacion` y `datos_test` respectivamente. Asimismo, destacar que los datos para test no deben disponer del *ground truth*, es por ello que no se procede a concatenar dicha columna. Comentar, que se guardarán los datos limpios en memoria antes del split, en caso de que se requiera su uso."
      ],
      "metadata": {
        "id": "NZ6g79qQcp_O"
      },
      "id": "NZ6g79qQcp_O"
    },
    {
      "cell_type": "code",
      "source": [
        "datos.to_feather(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/valoraciones_Original.feather\")"
      ],
      "metadata": {
        "id": "PXp_p08ISMYo"
      },
      "id": "PXp_p08ISMYo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = datos.drop('Sentimiento', axis=1)\n",
        "y = datos['Sentimiento']\n",
        "\n",
        "# Primero, dividimos en entrenamiento y prueba\n",
        "datos_train, datos_test, groudT_train, groudT_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ahora, tienes dos conjuntos: datos_train, groudT_train para entrenamiento (posteriormente se subdividirá para obtener datos_validacion),\n",
        "# y datos_test, groudT_test para prueba."
      ],
      "metadata": {
        "id": "y1nwXvMHsRQM"
      },
      "id": "y1nwXvMHsRQM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRqHRC46ePhx",
        "outputId": "5a4b067e-ddf5-422c-ddb0-0c6d73bd90e0"
      },
      "id": "ZRqHRC46ePhx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77448, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groudT_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8faG6qb4nwG",
        "outputId": "631a40bd-b3a9-45dd-e0a0-429b932ccede"
      },
      "id": "X8faG6qb4nwG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77448,)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50QhTG9beevE",
        "outputId": "e4169b11-25dd-47d1-ea84-c1c66c5380ae"
      },
      "id": "50QhTG9beevE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19363, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groudT_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt0oii-F4w42",
        "outputId": "918b775a-91ed-4e7f-aa14-b9483870bfb4"
      },
      "id": "Rt0oii-F4w42",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19363,)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_train = pd.concat([datos_train, groudT_train], axis = 1)"
      ],
      "metadata": {
        "id": "RmTqGvvX4XE9"
      },
      "id": "RmTqGvvX4XE9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FLsgAWxI42_7",
        "outputId": "aee1a9cc-afaa-4c2a-ae42-d2db57bd3667"
      },
      "id": "FLsgAWxI42_7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Reviews  \\\n",
              "58202  'Local, Fantastic and Always Inviting', 'Reall...   \n",
              "48595         'good food,.good for lunch whilst at work'   \n",
              "66429       'Zum Dachs Restaruant Serbo-Croatian + G...'   \n",
              "27936    'An excellent restaurant tucked away in Jon...'   \n",
              "89670  'Good first Ethiopian experience', 'Ethiopian ...   \n",
              "...                                                  ...   \n",
              "6265               'Very good', 'Real typical Tapas bar'   \n",
              "54886           'Classic', 'Dantxari - great restaurant'   \n",
              "76820      'Cool place', 'Wonderful owner & atmosphere!'   \n",
              "860     'Great Ribs here', 'Not perfect, but good food!'   \n",
              "15795  'Vegetables grown by monks', 'Friendly staff, ...   \n",
              "\n",
              "                                             Review1  \\\n",
              "58202           Local, Fantastic and Always Inviting   \n",
              "48595       good food,.good for lunch whilst at work   \n",
              "66429     Zum Dachs Restaruant Serbo-Croatian + G...   \n",
              "27936  An excellent restaurant tucked away in Jon...   \n",
              "89670                Good first Ethiopian experience   \n",
              "...                                              ...   \n",
              "6265                                       Very good   \n",
              "54886                                        Classic   \n",
              "76820                                     Cool place   \n",
              "860                                  Great Ribs here   \n",
              "15795                      Vegetables grown by monks   \n",
              "\n",
              "                                        Review2  Sentimiento  \n",
              "58202           Really friendly with good tapas            1  \n",
              "48595                                                      1  \n",
              "66429                                                      1  \n",
              "27936                                                      1  \n",
              "89670                            Ethiopian food            1  \n",
              "...                                         ...          ...  \n",
              "6265                     Real typical Tapas bar            1  \n",
              "54886               Dantxari - great restaurant            1  \n",
              "76820             Wonderful owner & atmosphere!            1  \n",
              "860                 Not perfect, but good food!            1  \n",
              "15795  Friendly staff, cold & cheap beer on tap            0  \n",
              "\n",
              "[77448 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c6e3cc4-6c5d-4f56-ae51-32a85adb55ab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>58202</th>\n",
              "      <td>'Local, Fantastic and Always Inviting', 'Reall...</td>\n",
              "      <td>Local, Fantastic and Always Inviting</td>\n",
              "      <td>Really friendly with good tapas</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48595</th>\n",
              "      <td>'good food,.good for lunch whilst at work'</td>\n",
              "      <td>good food,.good for lunch whilst at work</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66429</th>\n",
              "      <td>'Zum Dachs Restaruant Serbo-Croatian + G...'</td>\n",
              "      <td>Zum Dachs Restaruant Serbo-Croatian + G...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27936</th>\n",
              "      <td>'An excellent restaurant tucked away in Jon...'</td>\n",
              "      <td>An excellent restaurant tucked away in Jon...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89670</th>\n",
              "      <td>'Good first Ethiopian experience', 'Ethiopian ...</td>\n",
              "      <td>Good first Ethiopian experience</td>\n",
              "      <td>Ethiopian food</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6265</th>\n",
              "      <td>'Very good', 'Real typical Tapas bar'</td>\n",
              "      <td>Very good</td>\n",
              "      <td>Real typical Tapas bar</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54886</th>\n",
              "      <td>'Classic', 'Dantxari - great restaurant'</td>\n",
              "      <td>Classic</td>\n",
              "      <td>Dantxari - great restaurant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76820</th>\n",
              "      <td>'Cool place', 'Wonderful owner &amp; atmosphere!'</td>\n",
              "      <td>Cool place</td>\n",
              "      <td>Wonderful owner &amp; atmosphere!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>'Great Ribs here', 'Not perfect, but good food!'</td>\n",
              "      <td>Great Ribs here</td>\n",
              "      <td>Not perfect, but good food!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15795</th>\n",
              "      <td>'Vegetables grown by monks', 'Friendly staff, ...</td>\n",
              "      <td>Vegetables grown by monks</td>\n",
              "      <td>Friendly staff, cold &amp; cheap beer on tap</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>77448 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c6e3cc4-6c5d-4f56-ae51-32a85adb55ab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c6e3cc4-6c5d-4f56-ae51-32a85adb55ab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c6e3cc4-6c5d-4f56-ae51-32a85adb55ab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-743b50c4-9b59-4cb6-9d79-ddcf81a3d6b8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-743b50c4-9b59-4cb6-9d79-ddcf81a3d6b8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-743b50c4-9b59-4cb6-9d79-ddcf81a3d6b8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1.4 Comprobación de longitud mínima"
      ],
      "metadata": {
        "id": "Rqj1sKsmyl3Q"
      },
      "id": "Rqj1sKsmyl3Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección comprobamos cuál es la longitud mínima de los textos de los datos de entrenamiento a fin de conocer con mayor detalle dichos textos y hacernos una idea de qué tipo de tratamiento será necesario realizar de cara a una posible futurura tokenización y generación de *embeddings*.\n"
      ],
      "metadata": {
        "id": "PHetacnXRBb2"
      },
      "id": "PHetacnXRBb2"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_train.Reviews.apply(lambda x: len(str(x).split())).min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fe9AmZayvup",
        "outputId": "7c92c578-ab80-4a94-bd51-d07ba34f0fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "id": "0Fe9AmZayvup"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_train.Reviews.apply(lambda x: len(str(x).split())).max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJPZzWNF50hc",
        "outputId": "065bc70d-ff61-43dc-8d80-8f1c8c0123c1"
      },
      "id": "VJPZzWNF50hc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede apreciar, parece que hay varios textos con una sola palabra. Veamos algunos de ellos:"
      ],
      "metadata": {
        "id": "xm4OfHSazvbk"
      },
      "id": "xm4OfHSazvbk"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_train[datos_train.Reviews.apply(lambda x: len(str(x).split())) == 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "gmLsk_c5yvpY",
        "outputId": "59127349-b6af-4d43-86f5-b70d1a14d5ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Reviews     Review1 Review2  Sentimiento\n",
              "95036        'NICE'        NICE                    1\n",
              "77643        'good'        good                    1\n",
              "16898  'fantastic!'  fantastic!                    1\n",
              "62316         'NYE'         NYE                    0\n",
              "45418         'Wow'         Wow                    1\n",
              "...             ...         ...     ...          ...\n",
              "45525     'scarlet'     scarlet                    1\n",
              "88614        'Cute'        Cute                    1\n",
              "25184       'yummy'       yummy                    1\n",
              "23483        'Gone'        Gone                    0\n",
              "53707         'Nam'         Nam                    1\n",
              "\n",
              "[758 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23ae1e99-ba43-4d7d-afbf-71f696fc2af9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95036</th>\n",
              "      <td>'NICE'</td>\n",
              "      <td>NICE</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77643</th>\n",
              "      <td>'good'</td>\n",
              "      <td>good</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16898</th>\n",
              "      <td>'fantastic!'</td>\n",
              "      <td>fantastic!</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62316</th>\n",
              "      <td>'NYE'</td>\n",
              "      <td>NYE</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45418</th>\n",
              "      <td>'Wow'</td>\n",
              "      <td>Wow</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45525</th>\n",
              "      <td>'scarlet'</td>\n",
              "      <td>scarlet</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88614</th>\n",
              "      <td>'Cute'</td>\n",
              "      <td>Cute</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25184</th>\n",
              "      <td>'yummy'</td>\n",
              "      <td>yummy</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23483</th>\n",
              "      <td>'Gone'</td>\n",
              "      <td>Gone</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53707</th>\n",
              "      <td>'Nam'</td>\n",
              "      <td>Nam</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>758 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23ae1e99-ba43-4d7d-afbf-71f696fc2af9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23ae1e99-ba43-4d7d-afbf-71f696fc2af9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23ae1e99-ba43-4d7d-afbf-71f696fc2af9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0b18058f-3fa5-4682-86dc-1d2a0b6e6b60\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b18058f-3fa5-4682-86dc-1d2a0b6e6b60')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0b18058f-3fa5-4682-86dc-1d2a0b6e6b60 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "id": "gmLsk_c5yvpY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1.5 Guardado en memoria"
      ],
      "metadata": {
        "id": "z9lEl1H_ytuQ"
      },
      "id": "z9lEl1H_ytuQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez realizada la limpieza, selección y estructuración de los datos, guardamos los mismos en ficheros `feather` para poder importarlos directamente siempre que sea necesario y no tener que ejecutar todo el proceso anterior de limpieza y estructuración siempre que queramos usar esos datos en los modelos.\n",
        "\n",
        "Finalmente y a modo de resumen, el dataset de entrenamiento con el que tarbajarán los modelos tiene un total de 77448 registros y 4 columnas:\n",
        "- `Reviews`: contenido únicamente de las dos reseñas principales del restaurante.\n",
        "- `Sentimiento`: *groud truth*, elemento que identifica el sentimiento correcto (1 positivo, 0 negativo).\n",
        "- `Review1`: contenido únicamente de la primera reseña realizada al restaurante dado.\n",
        "- `Review2`: contenido únicamente de la segunda reseña realizada al restaurante dado.\n",
        "\n",
        "\n",
        "Por otro lado, el dataset de validación que se genera, tiene la misma estructura pero cuenta solo con 19363 registros."
      ],
      "metadata": {
        "id": "nSUd6qY6VDGW"
      },
      "id": "nSUd6qY6VDGW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de guardar los datos de entrenamiento en el fichero correspondiente, se ha procedido a resetear los índices de las muestras para evitar que estos den problemas en caso de que, al haber eliminado, reestructurado o limpiado muestras, se haya generado alguna discrepancia o hueco en los mismos y estos hayan dejado de ser consecutivos."
      ],
      "metadata": {
        "id": "V3RmdMvspuSO"
      },
      "id": "V3RmdMvspuSO"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_train.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "bBZ0X6CM1l4F"
      },
      "execution_count": null,
      "outputs": [],
      "id": "bBZ0X6CM1l4F"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "q-96i_bm12zN",
        "outputId": "b7ffda49-25b4-4780-d41f-fb868473017d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Reviews  \\\n",
              "0  'Local, Fantastic and Always Inviting', 'Reall...   \n",
              "1         'good food,.good for lunch whilst at work'   \n",
              "2       'Zum Dachs Restaruant Serbo-Croatian + G...'   \n",
              "\n",
              "                                      Review1  \\\n",
              "0        Local, Fantastic and Always Inviting   \n",
              "1    good food,.good for lunch whilst at work   \n",
              "2  Zum Dachs Restaruant Serbo-Croatian + G...   \n",
              "\n",
              "                           Review2  Sentimiento  \n",
              "0  Really friendly with good tapas            1  \n",
              "1                                             1  \n",
              "2                                             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73ac5305-78d0-488c-88f7-e2a5a7574079\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'Local, Fantastic and Always Inviting', 'Reall...</td>\n",
              "      <td>Local, Fantastic and Always Inviting</td>\n",
              "      <td>Really friendly with good tapas</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'good food,.good for lunch whilst at work'</td>\n",
              "      <td>good food,.good for lunch whilst at work</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Zum Dachs Restaruant Serbo-Croatian + G...'</td>\n",
              "      <td>Zum Dachs Restaruant Serbo-Croatian + G...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73ac5305-78d0-488c-88f7-e2a5a7574079')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73ac5305-78d0-488c-88f7-e2a5a7574079 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73ac5305-78d0-488c-88f7-e2a5a7574079');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b6f4df3f-6d74-4bf9-8181-c0f41c838fd5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6f4df3f-6d74-4bf9-8181-c0f41c838fd5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b6f4df3f-6d74-4bf9-8181-c0f41c838fd5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "id": "q-96i_bm12zN"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCS4sjmf2aqR",
        "outputId": "7a9e3e14-8483-4cc9-e393-78ab505e140e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77448, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "id": "NCS4sjmf2aqR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "a67e90bb-b986-443e-b5a5-9e7e181bfb6d"
      },
      "outputs": [],
      "source": [
        "datos_train.to_feather(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/valoraciones_Original_train.feather\")"
      ],
      "id": "a67e90bb-b986-443e-b5a5-9e7e181bfb6d"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "2g5eHlXQ85aP"
      },
      "id": "2g5eHlXQ85aP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_test.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "kAddGEkAxn22",
        "outputId": "85f15809-cb92-43b5-bc48-1de5c544b858"
      },
      "id": "kAddGEkAxn22",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Reviews  \\\n",
              "0  'Unfriendly staff, no pets allowed', 'Average ...   \n",
              "1           'Christmas Break', 'Cocktails and music'   \n",
              "2  'Interesting type of pizza', 'Best trancio ever.'   \n",
              "\n",
              "                             Review1              Review2  \n",
              "0  Unfriendly staff, no pets allowed  Average Slovak food  \n",
              "1                    Christmas Break  Cocktails and music  \n",
              "2          Interesting type of pizza   Best trancio ever.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-147235ce-6b8a-483a-93b8-a291dd5900f5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'Unfriendly staff, no pets allowed', 'Average ...</td>\n",
              "      <td>Unfriendly staff, no pets allowed</td>\n",
              "      <td>Average Slovak food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'Christmas Break', 'Cocktails and music'</td>\n",
              "      <td>Christmas Break</td>\n",
              "      <td>Cocktails and music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Interesting type of pizza', 'Best trancio ever.'</td>\n",
              "      <td>Interesting type of pizza</td>\n",
              "      <td>Best trancio ever.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-147235ce-6b8a-483a-93b8-a291dd5900f5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-147235ce-6b8a-483a-93b8-a291dd5900f5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-147235ce-6b8a-483a-93b8-a291dd5900f5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a43460dd-a118-4a6a-81dc-a350251dead2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a43460dd-a118-4a6a-81dc-a350251dead2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a43460dd-a118-4a6a-81dc-a350251dead2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6QPxEnIxnz9",
        "outputId": "a9f41148-b211-4770-ff12-fe3dc8da8c45"
      },
      "id": "d6QPxEnIxnz9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19363, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_test.to_feather(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/valoraciones_Original_test.feather\")"
      ],
      "metadata": {
        "id": "PFYDqUh3xnwt"
      },
      "id": "PFYDqUh3xnwt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.2 Datos divididos"
      ],
      "metadata": {
        "id": "3l9pdwSJWhCW"
      },
      "id": "3l9pdwSJWhCW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con este esquema de datos, se pretende separar las dos reseñas que se proporcionan sobre cada restaurante. Con esto, se obtiene un conjunto de datos mayor para entrenamiento lo que podría mejorar el resultado del modelo. Este conjunto de datos, se ulitilzará posteriormente en el apartado 2.5. Asimismo, en este apartado se partirá del conjunto de datos ya limpio obtenido en la sección 1.1."
      ],
      "metadata": {
        "id": "45cXhPDBW8Qy"
      },
      "id": "45cXhPDBW8Qy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85lAOqvoMP7U"
      },
      "source": [
        "###1.2.1 Imports"
      ],
      "id": "85lAOqvoMP7U"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "IYdC0VWVMP7V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "IYdC0VWVMP7V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "zt6c5FXQMP7V"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "zt6c5FXQMP7V"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2.2 Carga de datos"
      ],
      "metadata": {
        "id": "sz_1bepUX51c"
      },
      "id": "sz_1bepUX51c"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxeROdazX-N_",
        "outputId": "c740cc96-2678-418f-9a50-82c7e5376405"
      },
      "id": "PxeROdazX-N_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_paraDividir = pd.read_feather(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/valoraciones_Original.feather\")\n",
        "datos_paraDividir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fxW3QxYHX-wh",
        "outputId": "79b00097-b9fa-483d-8f50-4735f36bab28"
      },
      "id": "fxW3QxYHX-wh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Reviews  Sentimiento  \\\n",
              "0      'Just like home', 'A Warm Welcome to Wintry Am...            1   \n",
              "1                 'Great food and staff', 'just perfect'            1   \n",
              "2      'Satisfaction', 'Delicious old school restaurant'            1   \n",
              "3      'True five star dinner', 'A superb evening of ...            1   \n",
              "4          'Best meal.... EVER', 'super food experience'            1   \n",
              "...                                                  ...          ...   \n",
              "96806                                     'Good Service'            0   \n",
              "96807   'Super local eatery', 'Small and charming place'            1   \n",
              "96808                                      'Cordon Bleu'            0   \n",
              "96809  \"Don't waste your time, go somewhere else!\", '...            0   \n",
              "96810    'Poor quality, small portions, miserable st...'            0   \n",
              "\n",
              "                                             Review1  \\\n",
              "0                                     Just like home   \n",
              "1                               Great food and staff   \n",
              "2                                       Satisfaction   \n",
              "3                              True five star dinner   \n",
              "4                                 Best meal.... EVER   \n",
              "...                                              ...   \n",
              "96806                                   Good Service   \n",
              "96807                             Super local eatery   \n",
              "96808                                    Cordon Bleu   \n",
              "96809    \"Don't waste your time, go somewhere else!\"   \n",
              "96810  Poor quality, small portions, miserable st...   \n",
              "\n",
              "                                             Review2  \n",
              "0                 A Warm Welcome to Wintry Amsterdam  \n",
              "1                                       just perfect  \n",
              "2                    Delicious old school restaurant  \n",
              "3      A superb evening of fine dining, hospitali...  \n",
              "4                              super food experience  \n",
              "...                                              ...  \n",
              "96806                                                 \n",
              "96807                       Small and charming place  \n",
              "96808                                                 \n",
              "96809                                       Horrible  \n",
              "96810                                                 \n",
              "\n",
              "[96811 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a41e5f47-9d38-4e41-86ca-2791f2570b6b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentimiento</th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'Just like home', 'A Warm Welcome to Wintry Am...</td>\n",
              "      <td>1</td>\n",
              "      <td>Just like home</td>\n",
              "      <td>A Warm Welcome to Wintry Amsterdam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'Great food and staff', 'just perfect'</td>\n",
              "      <td>1</td>\n",
              "      <td>Great food and staff</td>\n",
              "      <td>just perfect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Satisfaction', 'Delicious old school restaurant'</td>\n",
              "      <td>1</td>\n",
              "      <td>Satisfaction</td>\n",
              "      <td>Delicious old school restaurant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'True five star dinner', 'A superb evening of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>True five star dinner</td>\n",
              "      <td>A superb evening of fine dining, hospitali...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'Best meal.... EVER', 'super food experience'</td>\n",
              "      <td>1</td>\n",
              "      <td>Best meal.... EVER</td>\n",
              "      <td>super food experience</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96806</th>\n",
              "      <td>'Good Service'</td>\n",
              "      <td>0</td>\n",
              "      <td>Good Service</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96807</th>\n",
              "      <td>'Super local eatery', 'Small and charming place'</td>\n",
              "      <td>1</td>\n",
              "      <td>Super local eatery</td>\n",
              "      <td>Small and charming place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96808</th>\n",
              "      <td>'Cordon Bleu'</td>\n",
              "      <td>0</td>\n",
              "      <td>Cordon Bleu</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96809</th>\n",
              "      <td>\"Don't waste your time, go somewhere else!\", '...</td>\n",
              "      <td>0</td>\n",
              "      <td>\"Don't waste your time, go somewhere else!\"</td>\n",
              "      <td>Horrible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96810</th>\n",
              "      <td>'Poor quality, small portions, miserable st...'</td>\n",
              "      <td>0</td>\n",
              "      <td>Poor quality, small portions, miserable st...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96811 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a41e5f47-9d38-4e41-86ca-2791f2570b6b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a41e5f47-9d38-4e41-86ca-2791f2570b6b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a41e5f47-9d38-4e41-86ca-2791f2570b6b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a5547d5-d057-4e49-9ebc-2595401d69d8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a5547d5-d057-4e49-9ebc-2595401d69d8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a5547d5-d057-4e49-9ebc-2595401d69d8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_paraDividir.Review2[96808]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VH1JsQV4fFMB",
        "outputId": "3da053e1-2ce2-4312-d340-f3356071af56"
      },
      "id": "VH1JsQV4fFMB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2.3 División"
      ],
      "metadata": {
        "id": "_SUW133cYIci"
      },
      "id": "_SUW133cYIci"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos = datos_paraDividir.copy()"
      ],
      "metadata": {
        "id": "5nB80--paztF"
      },
      "id": "5nB80--paztF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos = datos_divididos.melt(id_vars=['Sentimiento'], value_vars=['Review1', 'Review2'], value_name='Reviews').drop(columns=['variable'])"
      ],
      "metadata": {
        "id": "enB4KHgEZ-mG"
      },
      "id": "enB4KHgEZ-mG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KXktTWFTYPlo",
        "outputId": "de9d487d-d704-4a03-91a3-321b33730c47"
      },
      "id": "KXktTWFTYPlo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Sentimiento                   Reviews\n",
              "0                 1            Just like home\n",
              "1                 1      Great food and staff\n",
              "2                 1              Satisfaction\n",
              "3                 1     True five star dinner\n",
              "4                 1        Best meal.... EVER\n",
              "...             ...                       ...\n",
              "193617            0                          \n",
              "193618            1  Small and charming place\n",
              "193619            0                          \n",
              "193620            0                  Horrible\n",
              "193621            0                          \n",
              "\n",
              "[193622 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e8e8d8a-f998-4619-9c1d-b9d197eacc4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentimiento</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Just like home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Great food and staff</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Satisfaction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>True five star dinner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Best meal.... EVER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193617</th>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193618</th>\n",
              "      <td>1</td>\n",
              "      <td>Small and charming place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193619</th>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193620</th>\n",
              "      <td>0</td>\n",
              "      <td>Horrible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193621</th>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>193622 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e8e8d8a-f998-4619-9c1d-b9d197eacc4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e8e8d8a-f998-4619-9c1d-b9d197eacc4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e8e8d8a-f998-4619-9c1d-b9d197eacc4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f33eb1d0-d999-4f5c-a8fc-25e028b6e174\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f33eb1d0-d999-4f5c-a8fc-25e028b6e174')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f33eb1d0-d999-4f5c-a8fc-25e028b6e174 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anteriormente, se vió que se tenían datos vacíos en `Review2`, esto era proque se tenían reseñas unicamente de una persona y no de dos como se comenta en Kaggel. Por ello, pasar de 96811 filas a 193622 (el doble), se tienen que haber añadido filas vacías, observar *id 193617*. Se procederá a su eliminación dado que no aportan ningún tipo de información."
      ],
      "metadata": {
        "id": "wzmTx2fmb3Kz"
      },
      "id": "wzmTx2fmb3Kz"
    },
    {
      "cell_type": "code",
      "source": [
        "def revisar_espacios_en_blanco(review):\n",
        "   if review.strip() == '':\n",
        "        return np.nan\n",
        "   else:\n",
        "        return review.strip()\n",
        "\n",
        "datos_divididos['Reviews'] = datos_divididos['Reviews'].apply(revisar_espacios_en_blanco)\n",
        "\n",
        "valores_espacios_en_blanco = (datos_divididos['Reviews'] == '').sum()\n",
        "\n",
        "valores_nulos = datos_divididos.isnull().sum()\n",
        "\n",
        "print(f\"Espacios en blanco en Reviews: {valores_espacios_en_blanco}\")\n",
        "print(valores_nulos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOoofAereP98",
        "outputId": "805ed02c-d50d-4600-cb43-340fdb43b27d"
      },
      "id": "WOoofAereP98",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Espacios en blanco en Reviews: 0\n",
            "Sentimiento        0\n",
            "Reviews        15162\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos = datos_divididos.dropna(subset=['Reviews'])\n",
        "\n",
        "valores_espacios_en_blanco = (datos_divididos['Reviews'] == '').sum()\n",
        "valores_nulos = datos_divididos.isnull().sum()\n",
        "\n",
        "print(f\"Espacios en blanco en Reviews después de eliminar: {valores_espacios_en_blanco}\")\n",
        "print(valores_nulos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5EjCx8phWUQ",
        "outputId": "0c9ee7cd-0e9e-4b77-f365-1f3933f81fe9"
      },
      "id": "_5EjCx8phWUQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Espacios en blanco en Reviews después de eliminar: 0\n",
            "Sentimiento    0\n",
            "Reviews        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ck2QXIRzMv1q",
        "outputId": "b89cfd17-d5b0-4b28-b70d-3ed1ca2434e5"
      },
      "id": "ck2QXIRzMv1q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Sentimiento                                        Reviews\n",
              "0                 1                                 Just like home\n",
              "1                 1                           Great food and staff\n",
              "2                 1                                   Satisfaction\n",
              "3                 1                          True five star dinner\n",
              "4                 1                             Best meal.... EVER\n",
              "...             ...                                            ...\n",
              "193613            0  It was really horrible, I would never go a...\n",
              "193614            0         38 USD for a pizza!! HORRIBLE PRICING!\n",
              "193616            0  A very helpful and good Sri Lankan attenda...\n",
              "193618            1                       Small and charming place\n",
              "193620            0                                       Horrible\n",
              "\n",
              "[178460 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-358fdfca-1951-4ee5-8fbb-3bc10899f091\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentimiento</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Just like home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Great food and staff</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Satisfaction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>True five star dinner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Best meal.... EVER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193613</th>\n",
              "      <td>0</td>\n",
              "      <td>It was really horrible, I would never go a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193614</th>\n",
              "      <td>0</td>\n",
              "      <td>38 USD for a pizza!! HORRIBLE PRICING!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193616</th>\n",
              "      <td>0</td>\n",
              "      <td>A very helpful and good Sri Lankan attenda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193618</th>\n",
              "      <td>1</td>\n",
              "      <td>Small and charming place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193620</th>\n",
              "      <td>0</td>\n",
              "      <td>Horrible</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178460 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-358fdfca-1951-4ee5-8fbb-3bc10899f091')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-358fdfca-1951-4ee5-8fbb-3bc10899f091 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-358fdfca-1951-4ee5-8fbb-3bc10899f091');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b167c88e-50e5-4def-92dd-9eb0fe6b042e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b167c88e-50e5-4def-92dd-9eb0fe6b042e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b167c88e-50e5-4def-92dd-9eb0fe6b042e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que en la sección 1.1, se procederá a dividir (**split**) tanto en conjunto de train como conjunto de test."
      ],
      "metadata": {
        "id": "fWKE_aMHUeXv"
      },
      "id": "fWKE_aMHUeXv"
    },
    {
      "cell_type": "code",
      "source": [
        "X = datos_divididos.drop('Sentimiento', axis=1)\n",
        "y = datos_divididos['Sentimiento']\n",
        "\n",
        "# Primero, dividimos en entrenamiento y prueba\n",
        "datos_divididos_train, datos_divididos_test, groudT_divididos_train, groudT_divididos_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ahora, tienes dos conjuntos: datos_train, groudT_train para entrenamiento (posteriormente se subdividirá para obtener datos_validacion),\n",
        "# y datos_test, groudT_test para prueba."
      ],
      "metadata": {
        "id": "uAWBTgA8UruS"
      },
      "id": "uAWBTgA8UruS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCf38TAxVEoR",
        "outputId": "d5de6198-1c64-460a-92f5-0e203f3a7af3"
      },
      "id": "QCf38TAxVEoR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(142768, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groudT_divididos_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWwSVAKNVE8B",
        "outputId": "2c993421-b477-4d7b-ca6b-4ffbd0876f9f"
      },
      "id": "FWwSVAKNVE8B",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(142768,)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlr0_wcQVFMi",
        "outputId": "a2982b5b-b5a3-404c-9d00-9d5553f5e315"
      },
      "id": "jlr0_wcQVFMi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35692, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groudT_divididos_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ETdk2UbVFd-",
        "outputId": "68efeef9-194d-4dfb-f21f-87695e7ab262"
      },
      "id": "6ETdk2UbVFd-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35692,)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_train = pd.concat([datos_divididos_train, groudT_divididos_train], axis = 1)"
      ],
      "metadata": {
        "id": "MxPaD2bdVFub"
      },
      "id": "MxPaD2bdVFub",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "bTTZlxIDYwEW",
        "outputId": "e111cfa5-801a-4758-9502-b6b58198b4de"
      },
      "id": "bTTZlxIDYwEW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Reviews  Sentimiento\n",
              "26278                             A most friendly welcome            1\n",
              "59100                                          Nice treat            0\n",
              "56853   Lovely interior design', \"Don't let the lack o...            1\n",
              "117791                         Nice Food and Good Service            1\n",
              "22714                                             Just ok            0\n",
              "...                                                   ...          ...\n",
              "119879                                 Great Chinese food            0\n",
              "103694                    Take a detour off the main drag            1\n",
              "131932                                       Good Burrito            1\n",
              "146867                                         Super Rude            0\n",
              "121958                                          Nice food            1\n",
              "\n",
              "[142768 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d19d60c-4abe-42ef-8eb1-9f8423897263\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26278</th>\n",
              "      <td>A most friendly welcome</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59100</th>\n",
              "      <td>Nice treat</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56853</th>\n",
              "      <td>Lovely interior design', \"Don't let the lack o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117791</th>\n",
              "      <td>Nice Food and Good Service</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22714</th>\n",
              "      <td>Just ok</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119879</th>\n",
              "      <td>Great Chinese food</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103694</th>\n",
              "      <td>Take a detour off the main drag</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131932</th>\n",
              "      <td>Good Burrito</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146867</th>\n",
              "      <td>Super Rude</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121958</th>\n",
              "      <td>Nice food</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>142768 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d19d60c-4abe-42ef-8eb1-9f8423897263')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0d19d60c-4abe-42ef-8eb1-9f8423897263 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0d19d60c-4abe-42ef-8eb1-9f8423897263');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-56b86a95-7e5f-4fab-867a-a3f52ee6f1bc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-56b86a95-7e5f-4fab-867a-a3f52ee6f1bc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-56b86a95-7e5f-4fab-867a-a3f52ee6f1bc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2.4 Comprobación de longitud"
      ],
      "metadata": {
        "id": "qhJHq8koYx30"
      },
      "id": "qhJHq8koYx30"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Del mismo modo que se realizó para el apartado 1.1.4, se comprobará cuál es la longitud mínima de los textos de los datos de entrenamiento. Esto se realiza para tener un mayor conocimiento sobre los datos."
      ],
      "metadata": {
        "id": "BNX50hbo7yNi"
      },
      "id": "BNX50hbo7yNi"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_train.Reviews.apply(lambda x: len(str(x).split())).min()"
      ],
      "metadata": {
        "id": "cVNSN_g3Y6GQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be53e62e-30b8-4985-bef7-6048a215afde"
      },
      "id": "cVNSN_g3Y6GQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_train.Reviews.apply(lambda x: len(str(x).split())).max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHRa-XZDN0sB",
        "outputId": "b38c7f86-e335-45e4-fd90-3075293520f0"
      },
      "id": "AHRa-XZDN0sB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_train[datos_divididos.Reviews.apply(lambda x: len(str(x).split())) == 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "MCQWf-qHN5OI",
        "outputId": "7e2eae60-afdc-4810-9cd0-8af2d5693b56"
      },
      "id": "MCQWf-qHN5OI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Reviews  Sentimiento\n",
              "173745         Brunch            1\n",
              "42672           Lunch            0\n",
              "131903        Average            0\n",
              "98031       Delicious            1\n",
              "129451           Good            1\n",
              "...               ...          ...\n",
              "69092   Superburgers!            1\n",
              "66803        Friendly            1\n",
              "123855   Interesting.            1\n",
              "54886         Classic            1\n",
              "110268     Expectable            0\n",
              "\n",
              "[10389 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a4f3596-cb9e-4645-a13e-21518345e213\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>173745</th>\n",
              "      <td>Brunch</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42672</th>\n",
              "      <td>Lunch</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131903</th>\n",
              "      <td>Average</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98031</th>\n",
              "      <td>Delicious</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129451</th>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69092</th>\n",
              "      <td>Superburgers!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66803</th>\n",
              "      <td>Friendly</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123855</th>\n",
              "      <td>Interesting.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54886</th>\n",
              "      <td>Classic</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110268</th>\n",
              "      <td>Expectable</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10389 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a4f3596-cb9e-4645-a13e-21518345e213')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2a4f3596-cb9e-4645-a13e-21518345e213 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2a4f3596-cb9e-4645-a13e-21518345e213');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-57f24be8-4181-42c2-ab55-b5e05ba89bc3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-57f24be8-4181-42c2-ab55-b5e05ba89bc3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-57f24be8-4181-42c2-ab55-b5e05ba89bc3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2.5 Guardado en memoria"
      ],
      "metadata": {
        "id": "N-KJyb4WYQCq"
      },
      "id": "N-KJyb4WYQCq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, una vez realizada la limpieza, y estructuración de los datos, guardamos los mismos en ficheros `feather` para poder importarlos directamente siempre que sea necesario y no tener que ejecutar todo el proceso anterior de nuevo.\n",
        "\n",
        "A modo de resumen, el dataset de entrenamiento con el que tarbajarán los modelos en el apartado 2.5, tiene un total de 142768 registros (aproximadamente el doble que antes) y 2 columnas:\n",
        "- `Reviews`: contenido únicamente de las dos reseñas principales del restaurante.\n",
        "- `Sentimiento`: *groud truth*, elemento que identifica el sentimiento correcto (1 positivo, 0 negativo).\n",
        "\n",
        "Por otro lado, el dataset de validación que se genera, tiene la misma estructura pero cuenta solo con 35692 registros (recordar que este no contiene los valores de la columna `Sentimiento`)."
      ],
      "metadata": {
        "id": "eI8L0mSB8ReA"
      },
      "id": "eI8L0mSB8ReA"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_train.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "wW_Xz8taYZUp"
      },
      "id": "wW_Xz8taYZUp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_train.head(3)"
      ],
      "metadata": {
        "id": "6kPEzC_UYeWV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "4751ef46-13ee-4e50-b271-a741057d2469"
      },
      "id": "6kPEzC_UYeWV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Reviews  Sentimiento\n",
              "0                            A most friendly welcome            1\n",
              "1                                         Nice treat            0\n",
              "2  Lovely interior design', \"Don't let the lack o...            1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e31732c3-1b50-4389-8943-947c0d2ed1a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A most friendly welcome</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nice treat</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lovely interior design', \"Don't let the lack o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e31732c3-1b50-4389-8943-947c0d2ed1a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e31732c3-1b50-4389-8943-947c0d2ed1a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e31732c3-1b50-4389-8943-947c0d2ed1a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e80865f6-5e54-4180-81b5-4120c0b6e9fd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e80865f6-5e54-4180-81b5-4120c0b6e9fd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e80865f6-5e54-4180-81b5-4120c0b6e9fd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a3r-V8NOccF",
        "outputId": "5b63205f-ad77-4db7-adb9-e277ddd6f695"
      },
      "id": "_a3r-V8NOccF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(142768, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_train.to_feather(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/valoraciones_Separados_train.feather\")"
      ],
      "metadata": {
        "id": "LLdL79sXYgzx"
      },
      "id": "LLdL79sXYgzx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "4no72tNEObrN"
      },
      "id": "4no72tNEObrN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_test.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "JyYVLcffZfib",
        "outputId": "f360692d-70b0-432e-c3e3-61383e3fb894"
      },
      "id": "JyYVLcffZfib",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Reviews\n",
              "0                      perfecto, italiano restaurant\n",
              "1             Great quality for a very honest price.\n",
              "2  Friendly & Yummy', \"The best falafel I've ever..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-087e7a4b-9300-4d5a-84e3-4333527f575b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>perfecto, italiano restaurant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Great quality for a very honest price.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Friendly &amp; Yummy', \"The best falafel I've ever...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-087e7a4b-9300-4d5a-84e3-4333527f575b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-087e7a4b-9300-4d5a-84e3-4333527f575b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-087e7a4b-9300-4d5a-84e3-4333527f575b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f628f717-3d04-431b-b922-8e0f80233525\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f628f717-3d04-431b-b922-8e0f80233525')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f628f717-3d04-431b-b922-8e0f80233525 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5UahbwzZivK",
        "outputId": "0750f16a-69b9-449c-dea9-b7aab11cc873"
      },
      "id": "m5UahbwzZivK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35692, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_divididos_test.to_feather(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/valoraciones_Separados_test.feather\")"
      ],
      "metadata": {
        "id": "phU9T0FSZl_V"
      },
      "id": "phU9T0FSZl_V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.3 Datos Siamese"
      ],
      "metadata": {
        "id": "kf0xyIiBm1mw"
      },
      "id": "kf0xyIiBm1mw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6OlyEQenkPG"
      },
      "source": [
        "###1.3.1 Imports"
      ],
      "id": "k6OlyEQenkPG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "SjmDYpjankPL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "SjmDYpjankPL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "DELD5_1gnkPL"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "DELD5_1gnkPL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.3.2 Carga de datos"
      ],
      "metadata": {
        "id": "CvHzmOUdntM3"
      },
      "id": "CvHzmOUdntM3"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c740cc96-2678-418f-9a50-82c7e5376405",
        "id": "67yUQEwSntM3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "id": "67yUQEwSntM3"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese = pd.read_feather(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/valoraciones_Original.feather\")\n",
        "datos_siamese"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "044f509c-7e0c-4644-8d29-2b1cde232e29",
        "id": "VWO4bKB5ntM3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Reviews  Sentimiento  \\\n",
              "0      'Just like home', 'A Warm Welcome to Wintry Am...            1   \n",
              "1                 'Great food and staff', 'just perfect'            1   \n",
              "2      'Satisfaction', 'Delicious old school restaurant'            1   \n",
              "3      'True five star dinner', 'A superb evening of ...            1   \n",
              "4          'Best meal.... EVER', 'super food experience'            1   \n",
              "...                                                  ...          ...   \n",
              "96806                                     'Good Service'            0   \n",
              "96807   'Super local eatery', 'Small and charming place'            1   \n",
              "96808                                      'Cordon Bleu'            0   \n",
              "96809  \"Don't waste your time, go somewhere else!\", '...            0   \n",
              "96810    'Poor quality, small portions, miserable st...'            0   \n",
              "\n",
              "                                             Review1  \\\n",
              "0                                     Just like home   \n",
              "1                               Great food and staff   \n",
              "2                                       Satisfaction   \n",
              "3                              True five star dinner   \n",
              "4                                 Best meal.... EVER   \n",
              "...                                              ...   \n",
              "96806                                   Good Service   \n",
              "96807                             Super local eatery   \n",
              "96808                                    Cordon Bleu   \n",
              "96809    \"Don't waste your time, go somewhere else!\"   \n",
              "96810  Poor quality, small portions, miserable st...   \n",
              "\n",
              "                                             Review2  \n",
              "0                 A Warm Welcome to Wintry Amsterdam  \n",
              "1                                       just perfect  \n",
              "2                    Delicious old school restaurant  \n",
              "3      A superb evening of fine dining, hospitali...  \n",
              "4                              super food experience  \n",
              "...                                              ...  \n",
              "96806                                                 \n",
              "96807                       Small and charming place  \n",
              "96808                                                 \n",
              "96809                                       Horrible  \n",
              "96810                                                 \n",
              "\n",
              "[96811 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d5952cb-345f-4006-9ea3-f97ac3453e90\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentimiento</th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'Just like home', 'A Warm Welcome to Wintry Am...</td>\n",
              "      <td>1</td>\n",
              "      <td>Just like home</td>\n",
              "      <td>A Warm Welcome to Wintry Amsterdam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'Great food and staff', 'just perfect'</td>\n",
              "      <td>1</td>\n",
              "      <td>Great food and staff</td>\n",
              "      <td>just perfect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Satisfaction', 'Delicious old school restaurant'</td>\n",
              "      <td>1</td>\n",
              "      <td>Satisfaction</td>\n",
              "      <td>Delicious old school restaurant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'True five star dinner', 'A superb evening of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>True five star dinner</td>\n",
              "      <td>A superb evening of fine dining, hospitali...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'Best meal.... EVER', 'super food experience'</td>\n",
              "      <td>1</td>\n",
              "      <td>Best meal.... EVER</td>\n",
              "      <td>super food experience</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96806</th>\n",
              "      <td>'Good Service'</td>\n",
              "      <td>0</td>\n",
              "      <td>Good Service</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96807</th>\n",
              "      <td>'Super local eatery', 'Small and charming place'</td>\n",
              "      <td>1</td>\n",
              "      <td>Super local eatery</td>\n",
              "      <td>Small and charming place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96808</th>\n",
              "      <td>'Cordon Bleu'</td>\n",
              "      <td>0</td>\n",
              "      <td>Cordon Bleu</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96809</th>\n",
              "      <td>\"Don't waste your time, go somewhere else!\", '...</td>\n",
              "      <td>0</td>\n",
              "      <td>\"Don't waste your time, go somewhere else!\"</td>\n",
              "      <td>Horrible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96810</th>\n",
              "      <td>'Poor quality, small portions, miserable st...'</td>\n",
              "      <td>0</td>\n",
              "      <td>Poor quality, small portions, miserable st...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96811 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d5952cb-345f-4006-9ea3-f97ac3453e90')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d5952cb-345f-4006-9ea3-f97ac3453e90 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d5952cb-345f-4006-9ea3-f97ac3453e90');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e1bf2351-a37f-42eb-adef-6779ba51b217\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1bf2351-a37f-42eb-adef-6779ba51b217')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e1bf2351-a37f-42eb-adef-6779ba51b217 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "id": "VWO4bKB5ntM3"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese.Review2[96808]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "51bb2474-dd66-40f0-9940-2c00d04cdc8f",
        "id": "xAXNdDTVntM3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "id": "xAXNdDTVntM3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.3.3 Siamese"
      ],
      "metadata": {
        "id": "myPmGiiVobFK"
      },
      "id": "myPmGiiVobFK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, se requieren dos reseñas para comparar sus embeddings, es decir, comparar la similitud semántica entre los textos. Es por ello, que ya no se requiere la columna `Reviews` y se procede a eliminar."
      ],
      "metadata": {
        "id": "EBFV-1Rd9mGd"
      },
      "id": "EBFV-1Rd9mGd"
    },
    {
      "cell_type": "code",
      "source": [
        "def revisar_espacios_en_blanco(review):\n",
        "   if review.strip() == '':\n",
        "        return np.nan\n",
        "   else:\n",
        "        return review.strip()\n",
        "\n",
        "datos_siamese['Review2'] = datos_siamese['Review2'].apply(revisar_espacios_en_blanco)"
      ],
      "metadata": {
        "id": "9Ds9KUnFoXcH"
      },
      "id": "9Ds9KUnFoXcH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese = datos_siamese.dropna(subset=['Review2'])"
      ],
      "metadata": {
        "id": "xE42oGhtopGZ"
      },
      "id": "xE42oGhtopGZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese = datos_siamese.drop('Reviews', axis=1)"
      ],
      "metadata": {
        "id": "Y8nvadGYoqHO"
      },
      "id": "Y8nvadGYoqHO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xhuosWBno0BH",
        "outputId": "f55f31e7-9a58-4181-9eab-9d8a80df2946"
      },
      "id": "xhuosWBno0BH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Sentimiento                                      Review1  \\\n",
              "0                1                               Just like home   \n",
              "1                1                         Great food and staff   \n",
              "2                1                                 Satisfaction   \n",
              "3                1                        True five star dinner   \n",
              "4                1                           Best meal.... EVER   \n",
              "...            ...                                          ...   \n",
              "96802            0                                    Horrible!   \n",
              "96803            0                                 Good service   \n",
              "96805            0             Very amicable owner; Good pizzas   \n",
              "96807            1                           Super local eatery   \n",
              "96809            0  \"Don't waste your time, go somewhere else!\"   \n",
              "\n",
              "                                             Review2  \n",
              "0                 A Warm Welcome to Wintry Amsterdam  \n",
              "1                                       just perfect  \n",
              "2                    Delicious old school restaurant  \n",
              "3      A superb evening of fine dining, hospitali...  \n",
              "4                              super food experience  \n",
              "...                                              ...  \n",
              "96802  It was really horrible, I would never go a...  \n",
              "96803         38 USD for a pizza!! HORRIBLE PRICING!  \n",
              "96805  A very helpful and good Sri Lankan attenda...  \n",
              "96807                       Small and charming place  \n",
              "96809                                       Horrible  \n",
              "\n",
              "[81649 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eac7b556-7347-43f0-b5ce-43ffe60ce6f5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentimiento</th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Just like home</td>\n",
              "      <td>A Warm Welcome to Wintry Amsterdam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Great food and staff</td>\n",
              "      <td>just perfect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Satisfaction</td>\n",
              "      <td>Delicious old school restaurant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>True five star dinner</td>\n",
              "      <td>A superb evening of fine dining, hospitali...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Best meal.... EVER</td>\n",
              "      <td>super food experience</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96802</th>\n",
              "      <td>0</td>\n",
              "      <td>Horrible!</td>\n",
              "      <td>It was really horrible, I would never go a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96803</th>\n",
              "      <td>0</td>\n",
              "      <td>Good service</td>\n",
              "      <td>38 USD for a pizza!! HORRIBLE PRICING!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96805</th>\n",
              "      <td>0</td>\n",
              "      <td>Very amicable owner; Good pizzas</td>\n",
              "      <td>A very helpful and good Sri Lankan attenda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96807</th>\n",
              "      <td>1</td>\n",
              "      <td>Super local eatery</td>\n",
              "      <td>Small and charming place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96809</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Don't waste your time, go somewhere else!\"</td>\n",
              "      <td>Horrible</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81649 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eac7b556-7347-43f0-b5ce-43ffe60ce6f5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eac7b556-7347-43f0-b5ce-43ffe60ce6f5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eac7b556-7347-43f0-b5ce-43ffe60ce6f5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4df6c435-b030-4a8a-944b-6a996e75c01f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4df6c435-b030-4a8a-944b-6a996e75c01f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4df6c435-b030-4a8a-944b-6a996e75c01f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que en la sección 1.1, se procederá a dividir (**split**) tanto en conjunto de train como conjunto de test."
      ],
      "metadata": {
        "id": "ElHrvwGMo_09"
      },
      "id": "ElHrvwGMo_09"
    },
    {
      "cell_type": "code",
      "source": [
        "X = datos_siamese.drop('Sentimiento', axis=1)\n",
        "y = datos_siamese['Sentimiento']\n",
        "\n",
        "# Primero, dividimos en entrenamiento y prueba\n",
        "datos_siamese_train, datos_siamese_test, groudT_siamese_train, groudT_siamese_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ahora, tienes dos conjuntos: datos_train, groudT_train para entrenamiento (posteriormente se subdividirá para obtener datos_validacion),\n",
        "# y datos_test, groudT_test para prueba."
      ],
      "metadata": {
        "id": "arzrrdCbpFdt"
      },
      "id": "arzrrdCbpFdt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZXfwVMqpUFc",
        "outputId": "f1b8ca92-af6b-48ec-8ddc-89a079bb74d5"
      },
      "id": "eZXfwVMqpUFc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65319, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groudT_siamese_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPekTPpGpUTJ",
        "outputId": "520ec382-c71a-49cb-8323-3bd7f5aed0e9"
      },
      "id": "SPekTPpGpUTJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65319,)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzgpmP-4pUjZ",
        "outputId": "fc76a2d3-2543-435d-ed16-90f42f3d5360"
      },
      "id": "LzgpmP-4pUjZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16330, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groudT_siamese_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKc0_tqBpUzh",
        "outputId": "39118f34-90ab-4f4b-e096-59472aac9f8f"
      },
      "id": "PKc0_tqBpUzh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16330,)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_train = pd.concat([datos_siamese_train, groudT_siamese_train], axis = 1)"
      ],
      "metadata": {
        "id": "CZtI_2dspVBQ"
      },
      "id": "CZtI_2dspVBQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Uinz_y8YphJj",
        "outputId": "a3fb34d0-8594-4ae2-ec3b-a53ac27bf892"
      },
      "id": "Uinz_y8YphJj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   Review1                      Review2  \\\n",
              "60784                          Nice brunch                   Good place   \n",
              "531              Worlds best hot cocolate!                 Great place!   \n",
              "62256               Great food and service                Rated on 7,0!   \n",
              "80106               Delicious and friendly  Great little French Bistro!   \n",
              "77020                          Late dinner             Very nice dinner   \n",
              "...                                    ...                          ...   \n",
              "6861        Very nice food, great location               Great calamari   \n",
              "64642  Great Bavarian food in a cozy place       Traditional restaurant   \n",
              "90931           Italy traditions in Vienna         Very nice restaurant   \n",
              "873                   3 visits over 4 days      Great food & atmosphere   \n",
              "18700                Friendly little place         Depressing brasserie   \n",
              "\n",
              "       Sentimiento  \n",
              "60784            1  \n",
              "531              1  \n",
              "62256            1  \n",
              "80106            0  \n",
              "77020            0  \n",
              "...            ...  \n",
              "6861             1  \n",
              "64642            1  \n",
              "90931            1  \n",
              "873              1  \n",
              "18700            1  \n",
              "\n",
              "[65319 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4dc847a-c2dd-44ad-8156-3da06227cbdd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60784</th>\n",
              "      <td>Nice brunch</td>\n",
              "      <td>Good place</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>Worlds best hot cocolate!</td>\n",
              "      <td>Great place!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62256</th>\n",
              "      <td>Great food and service</td>\n",
              "      <td>Rated on 7,0!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80106</th>\n",
              "      <td>Delicious and friendly</td>\n",
              "      <td>Great little French Bistro!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77020</th>\n",
              "      <td>Late dinner</td>\n",
              "      <td>Very nice dinner</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6861</th>\n",
              "      <td>Very nice food, great location</td>\n",
              "      <td>Great calamari</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64642</th>\n",
              "      <td>Great Bavarian food in a cozy place</td>\n",
              "      <td>Traditional restaurant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90931</th>\n",
              "      <td>Italy traditions in Vienna</td>\n",
              "      <td>Very nice restaurant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>873</th>\n",
              "      <td>3 visits over 4 days</td>\n",
              "      <td>Great food &amp; atmosphere</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18700</th>\n",
              "      <td>Friendly little place</td>\n",
              "      <td>Depressing brasserie</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65319 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4dc847a-c2dd-44ad-8156-3da06227cbdd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4dc847a-c2dd-44ad-8156-3da06227cbdd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4dc847a-c2dd-44ad-8156-3da06227cbdd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3584b8a-2f02-4597-a124-c477d334e6c4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3584b8a-2f02-4597-a124-c477d334e6c4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3584b8a-2f02-4597-a124-c477d334e6c4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.3.4 Comprobación de longitud"
      ],
      "metadata": {
        "id": "MA3LbTijppvt"
      },
      "id": "MA3LbTijppvt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fin de tener mejor entendimiento de los datos para su posterior uso, se comprueba la longitud que te tiene de cada par de reseñas."
      ],
      "metadata": {
        "id": "GnZAquFE-gzp"
      },
      "id": "GnZAquFE-gzp"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_train.Review1.apply(lambda x: len(str(x).split())).min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1fd9bbb-8a00-499b-9f14-c85f60d3e367",
        "id": "px9mO910ppvz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "id": "px9mO910ppvz"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_train.Review1.apply(lambda x: len(str(x).split())).max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ca455a-a8ad-4941-8134-d486cf38847e",
        "id": "i1w4UfcTppv0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "id": "i1w4UfcTppv0"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_train.Review2.apply(lambda x: len(str(x).split())).min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_95gMb-Mp34g",
        "outputId": "423f43d5-fbe1-4858-f6b7-b43184167e75"
      },
      "id": "_95gMb-Mp34g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_train.Review2.apply(lambda x: len(str(x).split())).max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ivwSu6yp6F8",
        "outputId": "cbb45aca-ac98-4d4d-c102-ec5117999a18"
      },
      "id": "9ivwSu6yp6F8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_train[datos_siamese_train.Review1.apply(lambda x: len(str(x).split())) == 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a72c0d04-e509-4ef8-9aec-b30985ca70ba",
        "id": "wGYG2CFhppv0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Review1                             Review2  Sentimiento\n",
              "56780  Excellent  Try the Special Fixed Price Dinner            1\n",
              "8533   Fantastic          Delicious quick serve food            1\n",
              "36647    Sublime                         Outstanding            1\n",
              "95293         No            Great place for family !            1\n",
              "13196      Great                     Nothing special            1\n",
              "...          ...                                 ...          ...\n",
              "2964   McDonalds                       Deal with it.            0\n",
              "79734      Lunch              Pleasantly surprised !            0\n",
              "56064  Satisfied                        Lots of meat            1\n",
              "47725      Empty        Good burgers but overpriced!            1\n",
              "81480      Good!         Another nice find in Prague            1\n",
              "\n",
              "[4774 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9464d79-e101-44d6-93d8-68064915aff4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56780</th>\n",
              "      <td>Excellent</td>\n",
              "      <td>Try the Special Fixed Price Dinner</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8533</th>\n",
              "      <td>Fantastic</td>\n",
              "      <td>Delicious quick serve food</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36647</th>\n",
              "      <td>Sublime</td>\n",
              "      <td>Outstanding</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95293</th>\n",
              "      <td>No</td>\n",
              "      <td>Great place for family !</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13196</th>\n",
              "      <td>Great</td>\n",
              "      <td>Nothing special</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2964</th>\n",
              "      <td>McDonalds</td>\n",
              "      <td>Deal with it.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79734</th>\n",
              "      <td>Lunch</td>\n",
              "      <td>Pleasantly surprised !</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56064</th>\n",
              "      <td>Satisfied</td>\n",
              "      <td>Lots of meat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47725</th>\n",
              "      <td>Empty</td>\n",
              "      <td>Good burgers but overpriced!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81480</th>\n",
              "      <td>Good!</td>\n",
              "      <td>Another nice find in Prague</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4774 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9464d79-e101-44d6-93d8-68064915aff4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e9464d79-e101-44d6-93d8-68064915aff4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e9464d79-e101-44d6-93d8-68064915aff4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ecd3d630-f8f1-4f71-9469-ac4700ab4dd7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ecd3d630-f8f1-4f71-9469-ac4700ab4dd7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ecd3d630-f8f1-4f71-9469-ac4700ab4dd7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "id": "wGYG2CFhppv0"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_train[datos_siamese_train.Review2.apply(lambda x: len(str(x).split())) == 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OECv-OJmqDcU",
        "outputId": "3bc95993-50a7-4ac7-8785-e74edc2cc714"
      },
      "id": "OECv-OJmqDcU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Review1      Review2  Sentimiento\n",
              "33846  very simple , but good quality sushi       Sushi?            1\n",
              "43886               Wonderful Wedding venue         Date            1\n",
              "20961                A bar with a history !    Crazy....            1\n",
              "84469              The best breakfast/lunch        Super            1\n",
              "36647                               Sublime  Outstanding            1\n",
              "...                                     ...          ...          ...\n",
              "61942            A Good Japanese Restaurant       Testwr            1\n",
              "41447                    Bacon Jam is magic       BOOM!!            1\n",
              "80526                         Great burguer       Finest            1\n",
              "90575                     \"Wonderful Kaffe\"    Recomends            0\n",
              "37001                Superb French bistrot!        Lunch            1\n",
              "\n",
              "[4923 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b3662d2-4c72-4522-a558-763cabfb9a77\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33846</th>\n",
              "      <td>very simple , but good quality sushi</td>\n",
              "      <td>Sushi?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43886</th>\n",
              "      <td>Wonderful Wedding venue</td>\n",
              "      <td>Date</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20961</th>\n",
              "      <td>A bar with a history !</td>\n",
              "      <td>Crazy....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84469</th>\n",
              "      <td>The best breakfast/lunch</td>\n",
              "      <td>Super</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36647</th>\n",
              "      <td>Sublime</td>\n",
              "      <td>Outstanding</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61942</th>\n",
              "      <td>A Good Japanese Restaurant</td>\n",
              "      <td>Testwr</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41447</th>\n",
              "      <td>Bacon Jam is magic</td>\n",
              "      <td>BOOM!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80526</th>\n",
              "      <td>Great burguer</td>\n",
              "      <td>Finest</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90575</th>\n",
              "      <td>\"Wonderful Kaffe\"</td>\n",
              "      <td>Recomends</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37001</th>\n",
              "      <td>Superb French bistrot!</td>\n",
              "      <td>Lunch</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4923 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b3662d2-4c72-4522-a558-763cabfb9a77')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b3662d2-4c72-4522-a558-763cabfb9a77 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b3662d2-4c72-4522-a558-763cabfb9a77');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3769cc24-4cb0-41b6-b6d3-a6259e7133d6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3769cc24-4cb0-41b6-b6d3-a6259e7133d6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3769cc24-4cb0-41b6-b6d3-a6259e7133d6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.3.5 Guardado en memoria"
      ],
      "metadata": {
        "id": "ezWGQXOLqPPN"
      },
      "id": "ezWGQXOLqPPN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez realizada la limpieza, y estructuración de los datos, se guardan en ficheros `feather`dichos datos para poder importarlos directamente siempre que sea necesario y no tener que ejecutar todo el proceso anterior de nuevo.\n",
        "\n",
        "A modo de resumen, el dataset de entrenamiento con el que tarbajarán los modelos en el apartado 2.6, tiene un total de 65319 registros (12000 datos menos que la implementación con el conjunto de datos originales) y 3 columnas:\n",
        "- `Sentimiento`: *groud truth*, elemento que identifica el sentimiento correcto (1 positivo, 0 negativo).\n",
        "- `Review1`: contenido únicamente de la primera reseña realizada al restaurante dado.\n",
        "- `Review2`: contenido únicamente de la segunda reseña realizada al restaurante dado.\n",
        "\n",
        "Por otro lado, el dataset de validación que se genera, tiene la misma estructura pero cuenta solo con 16330 registros."
      ],
      "metadata": {
        "id": "EtsOggZYAc8O"
      },
      "id": "EtsOggZYAc8O"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_train.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "zbE98A1GqPPS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "zbE98A1GqPPS"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "0d7bd26a-ae85-4b5c-bbe0-b5423960d2fc",
        "id": "Z9FQY6zPqPPS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Review1        Review2  Sentimiento\n",
              "0                Nice brunch     Good place            1\n",
              "1  Worlds best hot cocolate!   Great place!            1\n",
              "2     Great food and service  Rated on 7,0!            1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-614d9d8d-5fb0-496d-a16e-24a5b43408d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nice brunch</td>\n",
              "      <td>Good place</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Worlds best hot cocolate!</td>\n",
              "      <td>Great place!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great food and service</td>\n",
              "      <td>Rated on 7,0!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-614d9d8d-5fb0-496d-a16e-24a5b43408d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-614d9d8d-5fb0-496d-a16e-24a5b43408d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-614d9d8d-5fb0-496d-a16e-24a5b43408d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bcbb4762-7fb4-4eb6-808f-6049a62f093e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bcbb4762-7fb4-4eb6-808f-6049a62f093e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bcbb4762-7fb4-4eb6-808f-6049a62f093e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "id": "Z9FQY6zPqPPS"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e3425a-056d-4e8d-c5a8-b834f9823804",
        "id": "LLUXto4FqPPS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65319, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "id": "LLUXto4FqPPS"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_train.to_feather(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/valoraciones_Siamese_train.feather\")"
      ],
      "metadata": {
        "id": "_xw4LHRHqPPS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_xw4LHRHqPPS"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "EAwgYJoDqPPS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "EAwgYJoDqPPS"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_test.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "050e0a95-f0fa-4ecb-8800-40be3825dffc",
        "id": "ZlV1A3iyqPPS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 Review1     Review2\n",
              "0                           Lovely food!   Nightmare\n",
              "1  Fish is excellent, not enough veggies     Avarege\n",
              "2                  Very good lunch place  Terrible!!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd023911-320d-4b6a-8fe2-57837b2e701b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lovely food!</td>\n",
              "      <td>Nightmare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fish is excellent, not enough veggies</td>\n",
              "      <td>Avarege</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Very good lunch place</td>\n",
              "      <td>Terrible!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd023911-320d-4b6a-8fe2-57837b2e701b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd023911-320d-4b6a-8fe2-57837b2e701b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd023911-320d-4b6a-8fe2-57837b2e701b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5bac2a77-6111-4818-9885-8c09776cef78\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5bac2a77-6111-4818-9885-8c09776cef78')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5bac2a77-6111-4818-9885-8c09776cef78 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "id": "ZlV1A3iyqPPS"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864b9937-fc6e-4605-ad10-b9b374fcf9e0",
        "id": "s9zBfD4gqPPT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16330, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "id": "s9zBfD4gqPPT"
    },
    {
      "cell_type": "code",
      "source": [
        "datos_siamese_test.to_feather(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/valoraciones_Siamese_test.feather\")"
      ],
      "metadata": {
        "id": "u-MV0V8QqPPT"
      },
      "execution_count": null,
      "outputs": [],
      "id": "u-MV0V8QqPPT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37c594e9-7808-49bb-9298-0821c577699b"
      },
      "source": [
        "#2. Modelos"
      ],
      "id": "37c594e9-7808-49bb-9298-0821c577699b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección se presentan las distintas arquitecturas y aproximaciones definidas para intentar dar solución al problema que nos atañe: ***sentiment analysis***.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "29NyrAUtbiZL"
      },
      "id": "29NyrAUtbiZL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fb3fc8b-060d-4833-867a-2e8b32b42bf8"
      },
      "source": [
        "###2.1 Imports Generales"
      ],
      "id": "7fb3fc8b-060d-4833-867a-2e8b32b42bf8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5394d63a-b190-4e7f-b803-70b6ba396fb4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import warnings"
      ],
      "id": "5394d63a-b190-4e7f-b803-70b6ba396fb4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11687793-3aa6-4a13-b5c5-95ca2ceee4b3"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "11687793-3aa6-4a13-b5c5-95ca2ceee4b3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iS985VCjyda"
      },
      "outputs": [],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "id": "4iS985VCjyda"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "V6eqOwrHEdlo"
      },
      "id": "V6eqOwrHEdlo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbD8Gjf8BXsG"
      },
      "source": [
        "###2.2 Imports modelos y demás"
      ],
      "id": "DbD8Gjf8BXsG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0gw_uPsBjYo",
        "outputId": "3eff3f31-5147-47a7-a1c0-dd5e92d20f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ],
      "id": "n0gw_uPsBjYo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC0YR8QQBjUV",
        "outputId": "58f595e4-2f5b-4534-bbac-cd63b7897267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ],
      "id": "QC0YR8QQBjUV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s5mKG6CBjNv",
        "outputId": "c4e37bc8-d32a-4da4-9e92-a1cbbb897142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ],
      "id": "7s5mKG6CBjNv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lBOr9N4Bt5l"
      },
      "outputs": [],
      "source": [
        "# Imports transformers\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from transformers import AutoConfig\n",
        "from transformers import AutoModel\n",
        "from transformers import AutoTokenizer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Imports utilidades\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "4lBOr9N4Bt5l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wMIGgFRDZVl"
      },
      "outputs": [],
      "source": [
        "# Para que los modelos no inunden de información irreleavante las salidas.\n",
        "# Si no se ejecuta esta celda cada vez que se trunque un texto saldrá una notificiación.\n",
        "transformers.logging.set_verbosity_error()"
      ],
      "id": "6wMIGgFRDZVl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toI_jaffsbZl"
      },
      "source": [
        "##2.3 Definición de variables generales"
      ],
      "id": "toI_jaffsbZl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variables definidas y su uso:\n",
        "* `MAX_LEN`: Tamaño máximo de los subconjuntos de textos que se pasan a los modelos.\n",
        "* `TRAIN_BATCH_SIZE`: Cantidad de muestras con las que se entrena el modelo cada vez. Los valores máximos que soportan nuestras capacidades de computación son entre 8 y 16 según el modelo. Con valores mayores se corre el riesgo de que la sesión de entrenamiento desborde la memoria y colapse.\n",
        "* `VALID_BATCH_SIZE`: Idéntico al `TRAIN_BATCH_SIZE` pero para la etapa de testeo y validación. En este caso, al no haber tantos cálculos durante la validación como durante el entrenamiento, soporta valores mayores.\n",
        "* `EPOCHS`: Número de veces que se quieren entrenar los modelos con el conjunto de datos. Ej: Con 2 epochs el modelo entrenará 2 veces con cada muestra del dataset.\n",
        "* `LEARNING_RATE`: Modificación de la velocidad con la que aprende el modelo.\n",
        "* `TRAIN_SIZE`: Porcentaje de los datos que se usa para el entrenamiento de los modelos. Los datos sobrantes se reservan para el testeo de los modelos y para la obtención de métricas de la calidad de los mismos.\n",
        "* `PASOS_POR_INTERVALO`: Número que indica cada cuantos batches mostrar información relativa a las métricas del modelo en entrenamiento."
      ],
      "metadata": {
        "id": "rrI-XFRhb9rG"
      },
      "id": "rrI-XFRhb9rG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPPX5hsismi3"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 64\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-7\n",
        "#TRAIN_SIZE = 0.3\n",
        "TRAIN_SIZE = 0.5\n",
        "#TRAIN_SIZE = 0.8\n",
        "PASOS_POR_INTERVALO = 10"
      ],
      "id": "NPPX5hsismi3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2s8aIAidb9j"
      },
      "source": [
        "Dadas las limitaciones en la capacidad de cómputo, se han empleado 3 valores distintos para el parámetro `TRAIN_SIZE`:\n",
        "1. `TRAIN_SIZE = 0.3`: Inicialmente y dado que los entrenamientos con más datos llevaban bastante tiempo, se entrenaron algunos modelos con solo el 30% de las muestras para agilizar dicho entrenamiento y tener unas primeras señales de cómo se desenvolvían.\n",
        "1. `TRAIN_SIZE = 0.5`: Se trata de un punto de equilibrio entre usar pocos datos y ser rápidos o usar más con (posiblemente) mejores resultados pero a costa de velocidad. La mayoría de modelos han sido entrenados con este porcentaje de datos por esta misma razón.\n",
        "1. `TRAIN_SIZE = 0.8`: Esta proporción de datos se probó a fin de ver si, con una mayor cantidad de datos, se conseguían mejores resultados. Como los resultados obtenidos fueron similares a los conseguidos con el 50% y como el tiempo de entrenamiento era mayor, se decidió no proseguir con esta aproximación.\n"
      ],
      "id": "f2s8aIAidb9j"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee7f1644-da90-430f-867b-5b36c5bf415b"
      },
      "source": [
        "##2.4 Aproximación 1: Con los datos originales"
      ],
      "id": "ee7f1644-da90-430f-867b-5b36c5bf415b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "El valor por defecto de los hiperparámetros que se han utilizado:\n",
        "- MAX_LEN = 512\n",
        "- TRAIN_BATCH_SIZE = 8\n",
        "- VALID_BATCH_SIZE = 64\n",
        "- EPOCHS = 1\n",
        "- LEARNING_RATE = 1e-5\n",
        "- TRAIN_SIZE = 0.5\n",
        "- PASOS_POR_INTERVALO = 10"
      ],
      "metadata": {
        "id": "x2nj2TEJKzTg"
      },
      "id": "x2nj2TEJKzTg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abdddfde-8ac2-4946-990d-5d9cb91c69e5"
      },
      "source": [
        "###2.4.1 Carga de datos"
      ],
      "id": "abdddfde-8ac2-4946-990d-5d9cb91c69e5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX-XQ50xeqp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c707eec0-b32a-4c4b-953d-ec1ba65b23c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "mX-XQ50xeqp5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4632e373-ed82-40df-a9a5-caf3ba81a380",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9aa62dd-6949-4128-a297-5cc004f04730"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Reviews  \\\n",
              "0      'Local, Fantastic and Always Inviting', 'Reall...   \n",
              "1             'good food,.good for lunch whilst at work'   \n",
              "2           'Zum Dachs Restaruant Serbo-Croatian + G...'   \n",
              "3        'An excellent restaurant tucked away in Jon...'   \n",
              "4      'Good first Ethiopian experience', 'Ethiopian ...   \n",
              "...                                                  ...   \n",
              "77443              'Very good', 'Real typical Tapas bar'   \n",
              "77444           'Classic', 'Dantxari - great restaurant'   \n",
              "77445      'Cool place', 'Wonderful owner & atmosphere!'   \n",
              "77446   'Great Ribs here', 'Not perfect, but good food!'   \n",
              "77447  'Vegetables grown by monks', 'Friendly staff, ...   \n",
              "\n",
              "                                             Review1  \\\n",
              "0               Local, Fantastic and Always Inviting   \n",
              "1           good food,.good for lunch whilst at work   \n",
              "2         Zum Dachs Restaruant Serbo-Croatian + G...   \n",
              "3      An excellent restaurant tucked away in Jon...   \n",
              "4                    Good first Ethiopian experience   \n",
              "...                                              ...   \n",
              "77443                                      Very good   \n",
              "77444                                        Classic   \n",
              "77445                                     Cool place   \n",
              "77446                                Great Ribs here   \n",
              "77447                      Vegetables grown by monks   \n",
              "\n",
              "                                        Review2  Sentimiento  \n",
              "0               Really friendly with good tapas            1  \n",
              "1                                                          1  \n",
              "2                                                          1  \n",
              "3                                                          1  \n",
              "4                                Ethiopian food            1  \n",
              "...                                         ...          ...  \n",
              "77443                    Real typical Tapas bar            1  \n",
              "77444               Dantxari - great restaurant            1  \n",
              "77445             Wonderful owner & atmosphere!            1  \n",
              "77446               Not perfect, but good food!            1  \n",
              "77447  Friendly staff, cold & cheap beer on tap            0  \n",
              "\n",
              "[77448 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa21d799-a9be-4b99-a12a-d2e15700b209\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'Local, Fantastic and Always Inviting', 'Reall...</td>\n",
              "      <td>Local, Fantastic and Always Inviting</td>\n",
              "      <td>Really friendly with good tapas</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'good food,.good for lunch whilst at work'</td>\n",
              "      <td>good food,.good for lunch whilst at work</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Zum Dachs Restaruant Serbo-Croatian + G...'</td>\n",
              "      <td>Zum Dachs Restaruant Serbo-Croatian + G...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'An excellent restaurant tucked away in Jon...'</td>\n",
              "      <td>An excellent restaurant tucked away in Jon...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'Good first Ethiopian experience', 'Ethiopian ...</td>\n",
              "      <td>Good first Ethiopian experience</td>\n",
              "      <td>Ethiopian food</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77443</th>\n",
              "      <td>'Very good', 'Real typical Tapas bar'</td>\n",
              "      <td>Very good</td>\n",
              "      <td>Real typical Tapas bar</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77444</th>\n",
              "      <td>'Classic', 'Dantxari - great restaurant'</td>\n",
              "      <td>Classic</td>\n",
              "      <td>Dantxari - great restaurant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77445</th>\n",
              "      <td>'Cool place', 'Wonderful owner &amp; atmosphere!'</td>\n",
              "      <td>Cool place</td>\n",
              "      <td>Wonderful owner &amp; atmosphere!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77446</th>\n",
              "      <td>'Great Ribs here', 'Not perfect, but good food!'</td>\n",
              "      <td>Great Ribs here</td>\n",
              "      <td>Not perfect, but good food!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77447</th>\n",
              "      <td>'Vegetables grown by monks', 'Friendly staff, ...</td>\n",
              "      <td>Vegetables grown by monks</td>\n",
              "      <td>Friendly staff, cold &amp; cheap beer on tap</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>77448 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa21d799-a9be-4b99-a12a-d2e15700b209')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa21d799-a9be-4b99-a12a-d2e15700b209 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa21d799-a9be-4b99-a12a-d2e15700b209');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2f5e9ff9-6dba-4829-a5cf-e7d74373c478\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f5e9ff9-6dba-4829-a5cf-e7d74373c478')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2f5e9ff9-6dba-4829-a5cf-e7d74373c478 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "datos = pd.read_feather(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/valoraciones_Original_train.feather\")\n",
        "datos"
      ],
      "id": "4632e373-ed82-40df-a9a5-caf3ba81a380"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZP2e-QzqRm2"
      },
      "source": [
        "###2.4.2 Definición tokenizadores y modelos"
      ],
      "id": "FZP2e-QzqRm2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la tarea de analisis de sentimientos que se prentende llevar a cabo, se ha decido utilizar *transformers* preentrenados para la generación de los *embeddings* de los textos y acoplarles nosotros una cabeza a entrenar específicamente diseñada para la tarea que nos atañe, es decir, clasificación de una reseña en función de si ha sido positiva o negativa."
      ],
      "metadata": {
        "id": "igkWniCN_QOx"
      },
      "id": "igkWniCN_QOx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el diseño de las cabezas de clasificación se ha seguido la siguiente aproximación:\n",
        "- Utilización de redes neuronales densas."
      ],
      "metadata": {
        "id": "aa8fEaaRAI21"
      },
      "id": "aa8fEaaRAI21"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los distintos *transformers* que se han empleado para la generación de los *embeddings* han sido:\n",
        "- BERT\n",
        "- RoBERTa\n",
        "\n"
      ],
      "metadata": {
        "id": "qJywLI8Y-xRb"
      },
      "id": "qJywLI8Y-xRb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e63fc176-3531-4ec3-bccd-d46fca1c6fe9"
      },
      "outputs": [],
      "source": [
        "tokenizerB = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "modelB = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "configB = AutoConfig.from_pretrained(\"bert-base-uncased\")"
      ],
      "id": "e63fc176-3531-4ec3-bccd-d46fca1c6fe9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV60uVy3_XhH"
      },
      "outputs": [],
      "source": [
        "tokenizerRB = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "modelRB = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "configRB = AutoConfig.from_pretrained(\"roberta-base\")"
      ],
      "id": "OV60uVy3_XhH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.4.3 Función de generación de conjuntos de train y test: DataLoaders"
      ],
      "metadata": {
        "id": "I5Q1F4Wsdy1_"
      },
      "id": "I5Q1F4Wsdy1_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta función se encarga de generar los *DataLoaders* de entrenamiento y test. Un DataLoader es una herramienta que facilita la carga y gestión de datos durante el entrenamiento de modelos de aprendizaje automático. Es decir, cargar datos de manera eficiente, particionarlos en lotes (batches) y proporcionarlos continuamente al modelo durante el entrenamiento/test.\n",
        "\n",
        "Sus parámetros son:\n",
        "- `dataframe`: El *DataFrame* que contiene la información con la que se quiere hacer los *DataLoaders*.\n",
        "- `tokenizer`: El tokenizador que se utilizará para tokenizar los textos.\n",
        "- `dataset`: La clase *CustomDataset* con la que se definirán los conjuntos de datos.\n",
        "- `collator`: La clase *DataCollator* que se encargará de gestionar los *batches* en cada uno de los *DataLoader*."
      ],
      "metadata": {
        "id": "8bexoBBWAxeH"
      },
      "id": "8bexoBBWAxeH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYaLCKgbeXVZ"
      },
      "outputs": [],
      "source": [
        "def generate_loaders(dataframe, tokenizer, dataset, collator):\n",
        "  train_dataset = dataframe.sample(frac=TRAIN_SIZE, random_state=0)\n",
        "  test_dataset = dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
        "  train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "  print(f\"FULL Dataset:{dataframe.shape}\")\n",
        "  print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
        "  print(f\"TEST Dataset: {test_dataset.shape}\")\n",
        "\n",
        "  training_set = dataset(train_dataset, MAX_LEN)\n",
        "  testing_set = dataset(test_dataset, MAX_LEN)\n",
        "  dc = collator(tokenizer, MAX_LEN)\n",
        "\n",
        "\n",
        "  train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                  'shuffle': True,\n",
        "                  'num_workers': 0,\n",
        "                  'collate_fn': dc\n",
        "                  }\n",
        "\n",
        "  test_params = { 'batch_size': VALID_BATCH_SIZE,\n",
        "                  'shuffle': True,\n",
        "                  'num_workers': 0,\n",
        "                  'collate_fn': dc\n",
        "                }\n",
        "\n",
        "  training_loader = DataLoader(training_set, **train_params)\n",
        "  testing_loader = DataLoader(testing_set, **test_params)\n",
        "  return training_loader, testing_loader"
      ],
      "id": "cYaLCKgbeXVZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.4.4 Single transform approach"
      ],
      "metadata": {
        "id": "9MVdMOjtMKvJ"
      },
      "id": "9MVdMOjtMKvJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta aproximación se plantea una arquitectura para la obtención de *embeddings* con los que entrenará la cabeza de clasificación."
      ],
      "metadata": {
        "id": "RYWXBPt_gh0s"
      },
      "id": "RYWXBPt_gh0s"
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.4.4.1 Definición restaurantsDataset y DataCollatorRestaurant"
      ],
      "metadata": {
        "id": "E4DqT19lM8vB"
      },
      "id": "E4DqT19lM8vB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta clase es la encargada de elaborar las muestras con las que van a entrenar los modelos.\n",
        "\n",
        "Cada muestra consiste en:\n",
        "- La etiqueta *sentimiento*, que representa el valor de la columna `Sentimineto` de los datos, es decir, si el sentimiento es positivo o negativo.\n",
        "- `Reviews`, comentarios que se utilizan para entrenar el modelo.\n",
        "\n",
        "En esta aproximación se busca generar el *embedding* de las reseñas."
      ],
      "metadata": {
        "id": "IuVuTOAtL8QB"
      },
      "id": "IuVuTOAtL8QB"
    },
    {
      "cell_type": "code",
      "source": [
        "type(datos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiGCSBqeJgrs",
        "outputId": "87b080f9-3125-42e4-c85f-857af4879f26"
      },
      "id": "PiGCSBqeJgrs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos"
      ],
      "metadata": {
        "id": "dHkxBE3PKTFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6871f638-cc01-4a85-8c87-a86752546b65"
      },
      "id": "dHkxBE3PKTFf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Reviews  \\\n",
              "0      'Local, Fantastic and Always Inviting', 'Reall...   \n",
              "1             'good food,.good for lunch whilst at work'   \n",
              "2           'Zum Dachs Restaruant Serbo-Croatian + G...'   \n",
              "3        'An excellent restaurant tucked away in Jon...'   \n",
              "4      'Good first Ethiopian experience', 'Ethiopian ...   \n",
              "...                                                  ...   \n",
              "77443              'Very good', 'Real typical Tapas bar'   \n",
              "77444           'Classic', 'Dantxari - great restaurant'   \n",
              "77445      'Cool place', 'Wonderful owner & atmosphere!'   \n",
              "77446   'Great Ribs here', 'Not perfect, but good food!'   \n",
              "77447  'Vegetables grown by monks', 'Friendly staff, ...   \n",
              "\n",
              "                                             Review1  \\\n",
              "0               Local, Fantastic and Always Inviting   \n",
              "1           good food,.good for lunch whilst at work   \n",
              "2         Zum Dachs Restaruant Serbo-Croatian + G...   \n",
              "3      An excellent restaurant tucked away in Jon...   \n",
              "4                    Good first Ethiopian experience   \n",
              "...                                              ...   \n",
              "77443                                      Very good   \n",
              "77444                                        Classic   \n",
              "77445                                     Cool place   \n",
              "77446                                Great Ribs here   \n",
              "77447                      Vegetables grown by monks   \n",
              "\n",
              "                                        Review2  Sentimiento  \n",
              "0               Really friendly with good tapas            1  \n",
              "1                                                          1  \n",
              "2                                                          1  \n",
              "3                                                          1  \n",
              "4                                Ethiopian food            1  \n",
              "...                                         ...          ...  \n",
              "77443                    Real typical Tapas bar            1  \n",
              "77444               Dantxari - great restaurant            1  \n",
              "77445             Wonderful owner & atmosphere!            1  \n",
              "77446               Not perfect, but good food!            1  \n",
              "77447  Friendly staff, cold & cheap beer on tap            0  \n",
              "\n",
              "[77448 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-951a7ec2-f05b-4e52-90d3-0b3e6b9f2fbf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'Local, Fantastic and Always Inviting', 'Reall...</td>\n",
              "      <td>Local, Fantastic and Always Inviting</td>\n",
              "      <td>Really friendly with good tapas</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'good food,.good for lunch whilst at work'</td>\n",
              "      <td>good food,.good for lunch whilst at work</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Zum Dachs Restaruant Serbo-Croatian + G...'</td>\n",
              "      <td>Zum Dachs Restaruant Serbo-Croatian + G...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'An excellent restaurant tucked away in Jon...'</td>\n",
              "      <td>An excellent restaurant tucked away in Jon...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'Good first Ethiopian experience', 'Ethiopian ...</td>\n",
              "      <td>Good first Ethiopian experience</td>\n",
              "      <td>Ethiopian food</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77443</th>\n",
              "      <td>'Very good', 'Real typical Tapas bar'</td>\n",
              "      <td>Very good</td>\n",
              "      <td>Real typical Tapas bar</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77444</th>\n",
              "      <td>'Classic', 'Dantxari - great restaurant'</td>\n",
              "      <td>Classic</td>\n",
              "      <td>Dantxari - great restaurant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77445</th>\n",
              "      <td>'Cool place', 'Wonderful owner &amp; atmosphere!'</td>\n",
              "      <td>Cool place</td>\n",
              "      <td>Wonderful owner &amp; atmosphere!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77446</th>\n",
              "      <td>'Great Ribs here', 'Not perfect, but good food!'</td>\n",
              "      <td>Great Ribs here</td>\n",
              "      <td>Not perfect, but good food!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77447</th>\n",
              "      <td>'Vegetables grown by monks', 'Friendly staff, ...</td>\n",
              "      <td>Vegetables grown by monks</td>\n",
              "      <td>Friendly staff, cold &amp; cheap beer on tap</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>77448 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-951a7ec2-f05b-4e52-90d3-0b3e6b9f2fbf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-951a7ec2-f05b-4e52-90d3-0b3e6b9f2fbf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-951a7ec2-f05b-4e52-90d3-0b3e6b9f2fbf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1559ccd6-22a8-4085-a597-0b580de7d24e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1559ccd6-22a8-4085-a597-0b580de7d24e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1559ccd6-22a8-4085-a597-0b580de7d24e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luS2xMXKpXMa"
      },
      "outputs": [],
      "source": [
        "class restaurantsDataset(Dataset):\n",
        "  def __init__(self, dataframe, max_len):\n",
        "    self.data = dataframe\n",
        "    self.comentario = dataframe.Reviews\n",
        "    self.targets = self.data.Sentimiento\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.comentario)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    comment = self.comentario[index]\n",
        "    target = self.targets[index]\n",
        "\n",
        "    return {\n",
        "        \"comentario\": comment,\n",
        "        \"target\": target\n",
        "    }"
      ],
      "id": "luS2xMXKpXMa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gUE-8tJq4Wb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d78af25-154e-4b59-fa5f-b3896505c3f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'comentario': \"'Local, Fantastic and Always Inviting', 'Really friendly with good tapas'\",\n",
              " 'target': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "datasetRestaurants = restaurantsDataset(datos, MAX_LEN)\n",
        "salida = datasetRestaurants.__getitem__(0)\n",
        "salida"
      ],
      "id": "9gUE-8tJq4Wb"
    },
    {
      "cell_type": "code",
      "source": [
        "aux = encoder_input = tokenizerB(\n",
        "          salida[\"comentario\"],\n",
        "          None,\n",
        "          add_special_tokens=True,\n",
        "          truncation=True,\n",
        "          max_length=MAX_LEN,\n",
        "          pad_to_max_length=True,\n",
        "          return_tensors = \"pt\",\n",
        "          return_token_type_ids=True\n",
        "          )\n",
        "aux[\"input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UolNK2GIc3wn",
        "outputId": "f08d7e52-b8b7-4331-e4c6-5f034f481578"
      },
      "id": "UolNK2GIc3wn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  1005,  2334,  1010, 10392,  1998,  2467, 15085,  1005,  1010,\n",
              "          1005,  2428,  5379,  2007,  2204, 11112,  3022,  1005,   102,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKRDFLwcDB4D"
      },
      "outputs": [],
      "source": [
        "class DataCollatorRestaurant:\n",
        "    def __init__(self, tokenizer, max_len=512):\n",
        "      self.tokenizer = tokenizer\n",
        "      self.max_len = max_len\n",
        "\n",
        "    def __call__(self, input_batch):\n",
        "      data_frame = pd.DataFrame(input_batch)\n",
        "      batch_dict = {column: data_frame[column].tolist() for column in data_frame}\n",
        "\n",
        "      encoder_input = self.tokenizer(\n",
        "          batch_dict[\"comentario\"],\n",
        "          None,\n",
        "          add_special_tokens=True,\n",
        "          truncation=True,\n",
        "          max_length=self.max_len,\n",
        "          pad_to_max_length=True,\n",
        "          return_tensors = \"pt\",\n",
        "          return_token_type_ids=True\n",
        "          )\n",
        "\n",
        "      return {\n",
        "      'ids': encoder_input[\"input_ids\"],\n",
        "      'mask': encoder_input[\"attention_mask\"],\n",
        "      \"target\": torch.Tensor(batch_dict[\"target\"]),\n",
        "      \"token_type_ids\": encoder_input[\"token_type_ids\"]\n",
        "    }"
      ],
      "id": "nKRDFLwcDB4D"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNeSMvUGipqW"
      },
      "source": [
        "####2.4.4.2 Modelo 1: BERT"
      ],
      "id": "LNeSMvUGipqW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbTcX4U-qwFM"
      },
      "source": [
        "##### Definición Dataset y Dataloader"
      ],
      "id": "lbTcX4U-qwFM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empleando la función anteriormente desarrollada, podemos generar los *loaders* sin tener que especificar nada más que el *tokenizer* concreto y el *Dataset* y el *DataCollator*."
      ],
      "metadata": {
        "id": "zYmiLRokcbEi"
      },
      "id": "zYmiLRokcbEi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8MRu5Ht7EuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51af783-5d53-4d1e-b773-dfc6d57e315a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset:(77448, 4)\n",
            "TRAIN Dataset: (23234, 4)\n",
            "TEST Dataset: (54214, 4)\n"
          ]
        }
      ],
      "source": [
        "training_loader, testing_loader = generate_loaders(datos,\n",
        "                                                   tokenizerB,\n",
        "                                                   restaurantsDataset,\n",
        "                                                   DataCollatorRestaurant\n",
        "                                                   )"
      ],
      "id": "V8MRu5Ht7EuK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVkxNFdhu9fy"
      },
      "source": [
        "##### Definición del modelo"
      ],
      "id": "HVkxNFdhu9fy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U50kQHAit4CX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0792fabf-b116-4259-a35e-bfb37346054b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l4): Dropout(p=0.2, inplace=False)\n",
              "  (l5): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (l6): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.dropout = 0.2\n",
        "        self.hidden_embd = 768\n",
        "        self.output_layer = 1\n",
        "\n",
        "        # Layers\n",
        "        self.l1 = BertModel.from_pretrained('bert-base-uncased')\n",
        "        #self.l2 = torch.nn.Linear(self.hidden_embd, 256)\n",
        "        #self.l3 = torch.nn.Linear(256, 64)\n",
        "        self.l4 = torch.nn.Dropout(self.dropout)\n",
        "        # self.l5 = torch.nn.Linear(64, self.output_layer)\n",
        "        self.l5 = torch.nn.Linear(self.hidden_embd, self.output_layer)\n",
        "        self.l6 = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, output_1 = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
        "        #output_2 = self.l2(output_1)\n",
        "        #output_3 = self.l3(output_2)\n",
        "        output_4 = self.l4(output_1)\n",
        "        output_5 = self.l5(output_4)\n",
        "        output = self.l6(output_5)\n",
        "        return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ],
      "id": "U50kQHAit4CX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ObPeMtCvx8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc61ac68-8b83-4303-cad5-2c46ea020b37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 0.01\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE,\n",
        "                             weight_decay=0.01)\n",
        "optimizer"
      ],
      "id": "2ObPeMtCvx8u"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Función de entrenamiento\n"
      ],
      "metadata": {
        "id": "CJhWf1i2gYTn"
      },
      "id": "CJhWf1i2gYTn"
    },
    {
      "cell_type": "code",
      "source": [
        "def trainBert(epoch):\n",
        "  model.train()\n",
        "  loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "  num_iteraciones = len(training_loader)\n",
        "  sum_loss = 0\n",
        "\n",
        "  for iteracion, data in enumerate(training_loader, 0):\n",
        "    ids = data['ids'].to(device)\n",
        "    mask = data['mask'].to(device)\n",
        "    targets = data['target'].to(device)\n",
        "    token_type_ids = data[\"token_type_ids\"].to(device)\n",
        "\n",
        "    output = model(ids, mask, token_type_ids)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    perdida = loss_fn(output.squeeze(), targets)\n",
        "    with torch.no_grad():\n",
        "      sum_loss+=perdida\n",
        "      if iteracion % PASOS_POR_INTERVALO ==0:\n",
        "        print(f'Epoch: {epoch}, iteración; {iteracion} de {num_iteraciones}, Loss: {sum_loss.cpu().numpy()/PASOS_POR_INTERVALO}')\n",
        "        sum_loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    perdida.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "NeMHLNjKgeqC"
      },
      "id": "NeMHLNjKgeqC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Función de entrenamiento v2\n"
      ],
      "metadata": {
        "id": "ab3ASpCjDTj-"
      },
      "id": "ab3ASpCjDTj-"
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_history = []\n",
        "train_accuracy_history = []\n",
        "val_loss_history = []\n",
        "val_accuracy_history = []"
      ],
      "metadata": {
        "id": "cACE6EQgPdJO"
      },
      "id": "cACE6EQgPdJO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainBert(epoch, model, training_loader, optimizer, device):\n",
        "    model.train()\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "    num_iteraciones = len(training_loader)\n",
        "    sum_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for iteracion, data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device)\n",
        "        mask = data['mask'].to(device)\n",
        "        targets = data['target'].to(device)\n",
        "        token_type_ids = data[\"token_type_ids\"].to(device)\n",
        "\n",
        "        output = model(ids, mask, token_type_ids)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calculate loss and update sum_loss\n",
        "        perdida = loss_fn(output.squeeze(), targets)\n",
        "        sum_loss += perdida.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        predictions = torch.sigmoid(output).cpu().numpy() >= 0.5\n",
        "        correct_predictions += (predictions == targets.cpu().numpy()).sum()\n",
        "        total_predictions += targets.size(0)\n",
        "\n",
        "        # Your existing code for backward pass and optimizer step\n",
        "        if iteracion % PASOS_POR_INTERVALO == 0:\n",
        "                print(f'Epoch: {epoch}, iteración: {iteracion} de {num_iteraciones}, Loss: {sum_loss / PASOS_POR_INTERVALO}')\n",
        "                accuracy = metrics.accuracy_score(targets.cpu().numpy(), (torch.sigmoid(output).cpu().numpy() >= 0.5))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        perdida.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate average loss and accuracy for the epoch\n",
        "    epoch_loss = sum_loss / num_iteraciones\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # Append to history\n",
        "    train_loss_history.append(epoch_loss)\n",
        "    train_accuracy_history.append(epoch_accuracy)\n",
        "\n",
        "    return epoch_loss, epoch_accuracy"
      ],
      "metadata": {
        "id": "ucwDjU4ODTkG"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ucwDjU4ODTkG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VRFfPgnwDyl"
      },
      "source": [
        "##### Entrenamiento del modelo (30% de datos)"
      ],
      "id": "7VRFfPgnwDyl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-5\n",
        "- weight_decay=0.01\n",
        "- Dropout + Linear + Sigmoid"
      ],
      "metadata": {
        "id": "qe3FKADAIN0V"
      },
      "id": "qe3FKADAIN0V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwXFZnr_wStU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba16a1cd-2630-42e6-8bf3-591a3254a8a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración; 0 de 1453, Loss: 0.057828837633132936\n",
            "Epoch: 0, iteración; 10 de 1453, Loss: 0.6029022216796875\n",
            "Epoch: 0, iteración; 20 de 1453, Loss: 0.6289915561676025\n",
            "Epoch: 0, iteración; 30 de 1453, Loss: 0.6424582481384278\n",
            "Epoch: 0, iteración; 40 de 1453, Loss: 0.6494301319122314\n",
            "Epoch: 0, iteración; 50 de 1453, Loss: 0.612917137145996\n",
            "Epoch: 0, iteración; 60 de 1453, Loss: 0.5878406524658203\n",
            "Epoch: 0, iteración; 70 de 1453, Loss: 0.6408910274505615\n",
            "Epoch: 0, iteración; 80 de 1453, Loss: 0.6027796745300293\n",
            "Epoch: 0, iteración; 90 de 1453, Loss: 0.5816263198852539\n",
            "Epoch: 0, iteración; 100 de 1453, Loss: 0.6241870880126953\n",
            "Epoch: 0, iteración; 110 de 1453, Loss: 0.6019627094268799\n",
            "Epoch: 0, iteración; 120 de 1453, Loss: 0.6104374408721924\n",
            "Epoch: 0, iteración; 130 de 1453, Loss: 0.5722097396850586\n",
            "Epoch: 0, iteración; 140 de 1453, Loss: 0.5774763107299805\n",
            "Epoch: 0, iteración; 150 de 1453, Loss: 0.6381230354309082\n",
            "Epoch: 0, iteración; 160 de 1453, Loss: 0.5934973239898682\n",
            "Epoch: 0, iteración; 170 de 1453, Loss: 0.571992301940918\n",
            "Epoch: 0, iteración; 180 de 1453, Loss: 0.6108989715576172\n",
            "Epoch: 0, iteración; 190 de 1453, Loss: 0.619542407989502\n",
            "Epoch: 0, iteración; 200 de 1453, Loss: 0.6231203079223633\n",
            "Epoch: 0, iteración; 210 de 1453, Loss: 0.5819140911102295\n",
            "Epoch: 0, iteración; 220 de 1453, Loss: 0.6191450119018554\n",
            "Epoch: 0, iteración; 230 de 1453, Loss: 0.5833595275878907\n",
            "Epoch: 0, iteración; 240 de 1453, Loss: 0.6163963794708252\n",
            "Epoch: 0, iteración; 250 de 1453, Loss: 0.553319787979126\n",
            "Epoch: 0, iteración; 260 de 1453, Loss: 0.5937069892883301\n",
            "Epoch: 0, iteración; 270 de 1453, Loss: 0.6044059276580811\n",
            "Epoch: 0, iteración; 280 de 1453, Loss: 0.588834571838379\n",
            "Epoch: 0, iteración; 290 de 1453, Loss: 0.6119094848632812\n",
            "Epoch: 0, iteración; 300 de 1453, Loss: 0.5967086791992188\n",
            "Epoch: 0, iteración; 310 de 1453, Loss: 0.639983081817627\n",
            "Epoch: 0, iteración; 320 de 1453, Loss: 0.5615781784057617\n",
            "Epoch: 0, iteración; 330 de 1453, Loss: 0.5352803707122803\n",
            "Epoch: 0, iteración; 340 de 1453, Loss: 0.517295503616333\n",
            "Epoch: 0, iteración; 350 de 1453, Loss: 0.5566316604614258\n",
            "Epoch: 0, iteración; 360 de 1453, Loss: 0.602024507522583\n",
            "Epoch: 0, iteración; 370 de 1453, Loss: 0.5654801845550537\n",
            "Epoch: 0, iteración; 380 de 1453, Loss: 0.5479113101959229\n",
            "Epoch: 0, iteración; 390 de 1453, Loss: 0.5551844596862793\n",
            "Epoch: 0, iteración; 400 de 1453, Loss: 0.5678696155548095\n",
            "Epoch: 0, iteración; 410 de 1453, Loss: 0.5274642467498779\n",
            "Epoch: 0, iteración; 420 de 1453, Loss: 0.49310693740844724\n",
            "Epoch: 0, iteración; 430 de 1453, Loss: 0.5677095413208008\n",
            "Epoch: 0, iteración; 440 de 1453, Loss: 0.5565835475921631\n",
            "Epoch: 0, iteración; 450 de 1453, Loss: 0.5641867637634277\n",
            "Epoch: 0, iteración; 460 de 1453, Loss: 0.5487274646759033\n",
            "Epoch: 0, iteración; 470 de 1453, Loss: 0.5581049919128418\n",
            "Epoch: 0, iteración; 480 de 1453, Loss: 0.6162014961242676\n",
            "Epoch: 0, iteración; 490 de 1453, Loss: 0.5854801177978516\n",
            "Epoch: 0, iteración; 500 de 1453, Loss: 0.5645856857299805\n",
            "Epoch: 0, iteración; 510 de 1453, Loss: 0.5582792282104492\n",
            "Epoch: 0, iteración; 520 de 1453, Loss: 0.5817488193511963\n",
            "Epoch: 0, iteración; 530 de 1453, Loss: 0.5927280426025391\n",
            "Epoch: 0, iteración; 540 de 1453, Loss: 0.5809897422790528\n",
            "Epoch: 0, iteración; 550 de 1453, Loss: 0.5538846492767334\n",
            "Epoch: 0, iteración; 560 de 1453, Loss: 0.5820806980133056\n",
            "Epoch: 0, iteración; 570 de 1453, Loss: 0.5562690258026123\n",
            "Epoch: 0, iteración; 580 de 1453, Loss: 0.5539257526397705\n",
            "Epoch: 0, iteración; 590 de 1453, Loss: 0.5924704074859619\n",
            "Epoch: 0, iteración; 600 de 1453, Loss: 0.5549216747283936\n",
            "Epoch: 0, iteración; 610 de 1453, Loss: 0.5518268585205078\n",
            "Epoch: 0, iteración; 620 de 1453, Loss: 0.5399570941925049\n",
            "Epoch: 0, iteración; 630 de 1453, Loss: 0.6058401107788086\n",
            "Epoch: 0, iteración; 640 de 1453, Loss: 0.5160316467285156\n",
            "Epoch: 0, iteración; 650 de 1453, Loss: 0.5921311855316163\n",
            "Epoch: 0, iteración; 660 de 1453, Loss: 0.5804746627807618\n",
            "Epoch: 0, iteración; 670 de 1453, Loss: 0.5627571105957031\n",
            "Epoch: 0, iteración; 680 de 1453, Loss: 0.5684306144714355\n",
            "Epoch: 0, iteración; 690 de 1453, Loss: 0.5315129280090332\n",
            "Epoch: 0, iteración; 700 de 1453, Loss: 0.5989033699035644\n",
            "Epoch: 0, iteración; 710 de 1453, Loss: 0.5906280517578125\n",
            "Epoch: 0, iteración; 720 de 1453, Loss: 0.516271448135376\n",
            "Epoch: 0, iteración; 730 de 1453, Loss: 0.5181310176849365\n",
            "Epoch: 0, iteración; 740 de 1453, Loss: 0.5653529644012452\n",
            "Epoch: 0, iteración; 750 de 1453, Loss: 0.5555500984191895\n",
            "Epoch: 0, iteración; 760 de 1453, Loss: 0.6052642822265625\n",
            "Epoch: 0, iteración; 770 de 1453, Loss: 0.5246589183807373\n",
            "Epoch: 0, iteración; 780 de 1453, Loss: 0.5753364562988281\n",
            "Epoch: 0, iteración; 790 de 1453, Loss: 0.5410550117492676\n",
            "Epoch: 0, iteración; 800 de 1453, Loss: 0.5240247249603271\n",
            "Epoch: 0, iteración; 810 de 1453, Loss: 0.552750539779663\n",
            "Epoch: 0, iteración; 820 de 1453, Loss: 0.547118091583252\n",
            "Epoch: 0, iteración; 830 de 1453, Loss: 0.564188289642334\n",
            "Epoch: 0, iteración; 840 de 1453, Loss: 0.5217006206512451\n",
            "Epoch: 0, iteración; 850 de 1453, Loss: 0.5331395626068115\n",
            "Epoch: 0, iteración; 860 de 1453, Loss: 0.5411865711212158\n",
            "Epoch: 0, iteración; 870 de 1453, Loss: 0.5683773517608642\n",
            "Epoch: 0, iteración; 880 de 1453, Loss: 0.5438485145568848\n",
            "Epoch: 0, iteración; 890 de 1453, Loss: 0.5328357219696045\n",
            "Epoch: 0, iteración; 900 de 1453, Loss: 0.5116473197937011\n",
            "Epoch: 0, iteración; 910 de 1453, Loss: 0.5630823135375976\n",
            "Epoch: 0, iteración; 920 de 1453, Loss: 0.5580938816070556\n",
            "Epoch: 0, iteración; 930 de 1453, Loss: 0.5492951393127441\n",
            "Epoch: 0, iteración; 940 de 1453, Loss: 0.5154078006744385\n",
            "Epoch: 0, iteración; 950 de 1453, Loss: 0.5665249347686767\n",
            "Epoch: 0, iteración; 960 de 1453, Loss: 0.5332368850708008\n",
            "Epoch: 0, iteración; 970 de 1453, Loss: 0.5497910022735596\n",
            "Epoch: 0, iteración; 980 de 1453, Loss: 0.5301149368286133\n",
            "Epoch: 0, iteración; 990 de 1453, Loss: 0.533475112915039\n",
            "Epoch: 0, iteración; 1000 de 1453, Loss: 0.660572624206543\n",
            "Epoch: 0, iteración; 1010 de 1453, Loss: 0.5342117309570312\n",
            "Epoch: 0, iteración; 1020 de 1453, Loss: 0.5327378273010254\n",
            "Epoch: 0, iteración; 1030 de 1453, Loss: 0.5250893115997315\n",
            "Epoch: 0, iteración; 1040 de 1453, Loss: 0.5569490432739258\n",
            "Epoch: 0, iteración; 1050 de 1453, Loss: 0.5394851207733155\n",
            "Epoch: 0, iteración; 1060 de 1453, Loss: 0.5317196846008301\n",
            "Epoch: 0, iteración; 1070 de 1453, Loss: 0.5964471817016601\n",
            "Epoch: 0, iteración; 1080 de 1453, Loss: 0.5701563835144043\n",
            "Epoch: 0, iteración; 1090 de 1453, Loss: 0.587861442565918\n",
            "Epoch: 0, iteración; 1100 de 1453, Loss: 0.5595415592193603\n",
            "Epoch: 0, iteración; 1110 de 1453, Loss: 0.5620845317840576\n",
            "Epoch: 0, iteración; 1120 de 1453, Loss: 0.5644109725952149\n",
            "Epoch: 0, iteración; 1130 de 1453, Loss: 0.5402450084686279\n",
            "Epoch: 0, iteración; 1140 de 1453, Loss: 0.5268630981445312\n",
            "Epoch: 0, iteración; 1150 de 1453, Loss: 0.5570945262908935\n",
            "Epoch: 0, iteración; 1160 de 1453, Loss: 0.5808464050292969\n",
            "Epoch: 0, iteración; 1170 de 1453, Loss: 0.5406016349792481\n",
            "Epoch: 0, iteración; 1180 de 1453, Loss: 0.5865823268890381\n",
            "Epoch: 0, iteración; 1190 de 1453, Loss: 0.5545713424682617\n",
            "Epoch: 0, iteración; 1200 de 1453, Loss: 0.5538350105285644\n",
            "Epoch: 0, iteración; 1210 de 1453, Loss: 0.5660338401794434\n",
            "Epoch: 0, iteración; 1220 de 1453, Loss: 0.543822956085205\n",
            "Epoch: 0, iteración; 1230 de 1453, Loss: 0.5152994632720947\n",
            "Epoch: 0, iteración; 1240 de 1453, Loss: 0.5581724166870117\n",
            "Epoch: 0, iteración; 1250 de 1453, Loss: 0.5722317695617676\n",
            "Epoch: 0, iteración; 1260 de 1453, Loss: 0.5701731204986572\n",
            "Epoch: 0, iteración; 1270 de 1453, Loss: 0.5199818134307861\n",
            "Epoch: 0, iteración; 1280 de 1453, Loss: 0.5234247207641601\n",
            "Epoch: 0, iteración; 1290 de 1453, Loss: 0.5700553894042969\n",
            "Epoch: 0, iteración; 1300 de 1453, Loss: 0.5332615375518799\n",
            "Epoch: 0, iteración; 1310 de 1453, Loss: 0.5542730808258056\n",
            "Epoch: 0, iteración; 1320 de 1453, Loss: 0.5209779739379883\n",
            "Epoch: 0, iteración; 1330 de 1453, Loss: 0.5831156253814698\n",
            "Epoch: 0, iteración; 1340 de 1453, Loss: 0.5554922103881836\n",
            "Epoch: 0, iteración; 1350 de 1453, Loss: 0.5239564895629882\n",
            "Epoch: 0, iteración; 1360 de 1453, Loss: 0.56146240234375\n",
            "Epoch: 0, iteración; 1370 de 1453, Loss: 0.5369698524475097\n",
            "Epoch: 0, iteración; 1380 de 1453, Loss: 0.5340178489685059\n",
            "Epoch: 0, iteración; 1390 de 1453, Loss: 0.5098429679870605\n",
            "Epoch: 0, iteración; 1400 de 1453, Loss: 0.5336995601654053\n",
            "Epoch: 0, iteración; 1410 de 1453, Loss: 0.6478946685791016\n",
            "Epoch: 0, iteración; 1420 de 1453, Loss: 0.5580214023590088\n",
            "Epoch: 0, iteración; 1430 de 1453, Loss: 0.5851059913635254\n",
            "Epoch: 0, iteración; 1440 de 1453, Loss: 0.5709729671478272\n",
            "Epoch: 0, iteración; 1450 de 1453, Loss: 0.5268720149993896\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainBert(epoch)"
      ],
      "id": "wwXFZnr_wStU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au4Xa3eZmgpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8ddbf3-164b-4392-de93-45eb5a499507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "id": "Au4Xa3eZmgpc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a90TNTnwofqq"
      },
      "source": [
        "##### Evaluación del modelo"
      ],
      "id": "a90TNTnwofqq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32VY2-wlohVw"
      },
      "outputs": [],
      "source": [
        "def validationBert(epoch):\n",
        "  model.eval()\n",
        "  fin_targets=[]\n",
        "  fin_outputs=[]\n",
        "  num_iteraciones = len(testing_loader)\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testing_loader, 0):\n",
        "      ids = data['ids'].to(device)\n",
        "      mask = data['mask'].to(device)\n",
        "      token_type_ids = data['token_type_ids'].to(device)\n",
        "      targets = data['target'].to(device)\n",
        "\n",
        "      print(f\"Batch {i} de {num_iteraciones}\")\n",
        "\n",
        "      outputs = model(ids, mask, token_type_ids)\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "  return fin_outputs, fin_targets"
      ],
      "id": "32VY2-wlohVw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "HjEpQEurO0V0"
      },
      "id": "HjEpQEurO0V0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VI6trS61dukC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a9fea4-d54f-4cae-c58b-8491253caaed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado correctamente\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30.pth\"):\n",
        "  model = BERTClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "id": "VI6trS61dukC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBko0YQvpRr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74ced72-0a93-4014-c67a-77ff775b00e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 de 848\n",
            "Batch 1 de 848\n",
            "Batch 2 de 848\n",
            "Batch 3 de 848\n",
            "Batch 4 de 848\n",
            "Batch 5 de 848\n",
            "Batch 6 de 848\n",
            "Batch 7 de 848\n",
            "Batch 8 de 848\n",
            "Batch 9 de 848\n",
            "Batch 10 de 848\n",
            "Batch 11 de 848\n",
            "Batch 12 de 848\n",
            "Batch 13 de 848\n",
            "Batch 14 de 848\n",
            "Batch 15 de 848\n",
            "Batch 16 de 848\n",
            "Batch 17 de 848\n",
            "Batch 18 de 848\n",
            "Batch 19 de 848\n",
            "Batch 20 de 848\n",
            "Batch 21 de 848\n",
            "Batch 22 de 848\n",
            "Batch 23 de 848\n",
            "Batch 24 de 848\n",
            "Batch 25 de 848\n",
            "Batch 26 de 848\n",
            "Batch 27 de 848\n",
            "Batch 28 de 848\n",
            "Batch 29 de 848\n",
            "Batch 30 de 848\n",
            "Batch 31 de 848\n",
            "Batch 32 de 848\n",
            "Batch 33 de 848\n",
            "Batch 34 de 848\n",
            "Batch 35 de 848\n",
            "Batch 36 de 848\n",
            "Batch 37 de 848\n",
            "Batch 38 de 848\n",
            "Batch 39 de 848\n",
            "Batch 40 de 848\n",
            "Batch 41 de 848\n",
            "Batch 42 de 848\n",
            "Batch 43 de 848\n",
            "Batch 44 de 848\n",
            "Batch 45 de 848\n",
            "Batch 46 de 848\n",
            "Batch 47 de 848\n",
            "Batch 48 de 848\n",
            "Batch 49 de 848\n",
            "Batch 50 de 848\n",
            "Batch 51 de 848\n",
            "Batch 52 de 848\n",
            "Batch 53 de 848\n",
            "Batch 54 de 848\n",
            "Batch 55 de 848\n",
            "Batch 56 de 848\n",
            "Batch 57 de 848\n",
            "Batch 58 de 848\n",
            "Batch 59 de 848\n",
            "Batch 60 de 848\n",
            "Batch 61 de 848\n",
            "Batch 62 de 848\n",
            "Batch 63 de 848\n",
            "Batch 64 de 848\n",
            "Batch 65 de 848\n",
            "Batch 66 de 848\n",
            "Batch 67 de 848\n",
            "Batch 68 de 848\n",
            "Batch 69 de 848\n",
            "Batch 70 de 848\n",
            "Batch 71 de 848\n",
            "Batch 72 de 848\n",
            "Batch 73 de 848\n",
            "Batch 74 de 848\n",
            "Batch 75 de 848\n",
            "Batch 76 de 848\n",
            "Batch 77 de 848\n",
            "Batch 78 de 848\n",
            "Batch 79 de 848\n",
            "Batch 80 de 848\n",
            "Batch 81 de 848\n",
            "Batch 82 de 848\n",
            "Batch 83 de 848\n",
            "Batch 84 de 848\n",
            "Batch 85 de 848\n",
            "Batch 86 de 848\n",
            "Batch 87 de 848\n",
            "Batch 88 de 848\n",
            "Batch 89 de 848\n",
            "Batch 90 de 848\n",
            "Batch 91 de 848\n",
            "Batch 92 de 848\n",
            "Batch 93 de 848\n",
            "Batch 94 de 848\n",
            "Batch 95 de 848\n",
            "Batch 96 de 848\n",
            "Batch 97 de 848\n",
            "Batch 98 de 848\n",
            "Batch 99 de 848\n",
            "Batch 100 de 848\n",
            "Batch 101 de 848\n",
            "Batch 102 de 848\n",
            "Batch 103 de 848\n",
            "Batch 104 de 848\n",
            "Batch 105 de 848\n",
            "Batch 106 de 848\n",
            "Batch 107 de 848\n",
            "Batch 108 de 848\n",
            "Batch 109 de 848\n",
            "Batch 110 de 848\n",
            "Batch 111 de 848\n",
            "Batch 112 de 848\n",
            "Batch 113 de 848\n",
            "Batch 114 de 848\n",
            "Batch 115 de 848\n",
            "Batch 116 de 848\n",
            "Batch 117 de 848\n",
            "Batch 118 de 848\n",
            "Batch 119 de 848\n",
            "Batch 120 de 848\n",
            "Batch 121 de 848\n",
            "Batch 122 de 848\n",
            "Batch 123 de 848\n",
            "Batch 124 de 848\n",
            "Batch 125 de 848\n",
            "Batch 126 de 848\n",
            "Batch 127 de 848\n",
            "Batch 128 de 848\n",
            "Batch 129 de 848\n",
            "Batch 130 de 848\n",
            "Batch 131 de 848\n",
            "Batch 132 de 848\n",
            "Batch 133 de 848\n",
            "Batch 134 de 848\n",
            "Batch 135 de 848\n",
            "Batch 136 de 848\n",
            "Batch 137 de 848\n",
            "Batch 138 de 848\n",
            "Batch 139 de 848\n",
            "Batch 140 de 848\n",
            "Batch 141 de 848\n",
            "Batch 142 de 848\n",
            "Batch 143 de 848\n",
            "Batch 144 de 848\n",
            "Batch 145 de 848\n",
            "Batch 146 de 848\n",
            "Batch 147 de 848\n",
            "Batch 148 de 848\n",
            "Batch 149 de 848\n",
            "Batch 150 de 848\n",
            "Batch 151 de 848\n",
            "Batch 152 de 848\n",
            "Batch 153 de 848\n",
            "Batch 154 de 848\n",
            "Batch 155 de 848\n",
            "Batch 156 de 848\n",
            "Batch 157 de 848\n",
            "Batch 158 de 848\n",
            "Batch 159 de 848\n",
            "Batch 160 de 848\n",
            "Batch 161 de 848\n",
            "Batch 162 de 848\n",
            "Batch 163 de 848\n",
            "Batch 164 de 848\n",
            "Batch 165 de 848\n",
            "Batch 166 de 848\n",
            "Batch 167 de 848\n",
            "Batch 168 de 848\n",
            "Batch 169 de 848\n",
            "Batch 170 de 848\n",
            "Batch 171 de 848\n",
            "Batch 172 de 848\n",
            "Batch 173 de 848\n",
            "Batch 174 de 848\n",
            "Batch 175 de 848\n",
            "Batch 176 de 848\n",
            "Batch 177 de 848\n",
            "Batch 178 de 848\n",
            "Batch 179 de 848\n",
            "Batch 180 de 848\n",
            "Batch 181 de 848\n",
            "Batch 182 de 848\n",
            "Batch 183 de 848\n",
            "Batch 184 de 848\n",
            "Batch 185 de 848\n",
            "Batch 186 de 848\n",
            "Batch 187 de 848\n",
            "Batch 188 de 848\n",
            "Batch 189 de 848\n",
            "Batch 190 de 848\n",
            "Batch 191 de 848\n",
            "Batch 192 de 848\n",
            "Batch 193 de 848\n",
            "Batch 194 de 848\n",
            "Batch 195 de 848\n",
            "Batch 196 de 848\n",
            "Batch 197 de 848\n",
            "Batch 198 de 848\n",
            "Batch 199 de 848\n",
            "Batch 200 de 848\n",
            "Batch 201 de 848\n",
            "Batch 202 de 848\n",
            "Batch 203 de 848\n",
            "Batch 204 de 848\n",
            "Batch 205 de 848\n",
            "Batch 206 de 848\n",
            "Batch 207 de 848\n",
            "Batch 208 de 848\n",
            "Batch 209 de 848\n",
            "Batch 210 de 848\n",
            "Batch 211 de 848\n",
            "Batch 212 de 848\n",
            "Batch 213 de 848\n",
            "Batch 214 de 848\n",
            "Batch 215 de 848\n",
            "Batch 216 de 848\n",
            "Batch 217 de 848\n",
            "Batch 218 de 848\n",
            "Batch 219 de 848\n",
            "Batch 220 de 848\n",
            "Batch 221 de 848\n",
            "Batch 222 de 848\n",
            "Batch 223 de 848\n",
            "Batch 224 de 848\n",
            "Batch 225 de 848\n",
            "Batch 226 de 848\n",
            "Batch 227 de 848\n",
            "Batch 228 de 848\n",
            "Batch 229 de 848\n",
            "Batch 230 de 848\n",
            "Batch 231 de 848\n",
            "Batch 232 de 848\n",
            "Batch 233 de 848\n",
            "Batch 234 de 848\n",
            "Batch 235 de 848\n",
            "Batch 236 de 848\n",
            "Batch 237 de 848\n",
            "Batch 238 de 848\n",
            "Batch 239 de 848\n",
            "Batch 240 de 848\n",
            "Batch 241 de 848\n",
            "Batch 242 de 848\n",
            "Batch 243 de 848\n",
            "Batch 244 de 848\n",
            "Batch 245 de 848\n",
            "Batch 246 de 848\n",
            "Batch 247 de 848\n",
            "Batch 248 de 848\n",
            "Batch 249 de 848\n",
            "Batch 250 de 848\n",
            "Batch 251 de 848\n",
            "Batch 252 de 848\n",
            "Batch 253 de 848\n",
            "Batch 254 de 848\n",
            "Batch 255 de 848\n",
            "Batch 256 de 848\n",
            "Batch 257 de 848\n",
            "Batch 258 de 848\n",
            "Batch 259 de 848\n",
            "Batch 260 de 848\n",
            "Batch 261 de 848\n",
            "Batch 262 de 848\n",
            "Batch 263 de 848\n",
            "Batch 264 de 848\n",
            "Batch 265 de 848\n",
            "Batch 266 de 848\n",
            "Batch 267 de 848\n",
            "Batch 268 de 848\n",
            "Batch 269 de 848\n",
            "Batch 270 de 848\n",
            "Batch 271 de 848\n",
            "Batch 272 de 848\n",
            "Batch 273 de 848\n",
            "Batch 274 de 848\n",
            "Batch 275 de 848\n",
            "Batch 276 de 848\n",
            "Batch 277 de 848\n",
            "Batch 278 de 848\n",
            "Batch 279 de 848\n",
            "Batch 280 de 848\n",
            "Batch 281 de 848\n",
            "Batch 282 de 848\n",
            "Batch 283 de 848\n",
            "Batch 284 de 848\n",
            "Batch 285 de 848\n",
            "Batch 286 de 848\n",
            "Batch 287 de 848\n",
            "Batch 288 de 848\n",
            "Batch 289 de 848\n",
            "Batch 290 de 848\n",
            "Batch 291 de 848\n",
            "Batch 292 de 848\n",
            "Batch 293 de 848\n",
            "Batch 294 de 848\n",
            "Batch 295 de 848\n",
            "Batch 296 de 848\n",
            "Batch 297 de 848\n",
            "Batch 298 de 848\n",
            "Batch 299 de 848\n",
            "Batch 300 de 848\n",
            "Batch 301 de 848\n",
            "Batch 302 de 848\n",
            "Batch 303 de 848\n",
            "Batch 304 de 848\n",
            "Batch 305 de 848\n",
            "Batch 306 de 848\n",
            "Batch 307 de 848\n",
            "Batch 308 de 848\n",
            "Batch 309 de 848\n",
            "Batch 310 de 848\n",
            "Batch 311 de 848\n",
            "Batch 312 de 848\n",
            "Batch 313 de 848\n",
            "Batch 314 de 848\n",
            "Batch 315 de 848\n",
            "Batch 316 de 848\n",
            "Batch 317 de 848\n",
            "Batch 318 de 848\n",
            "Batch 319 de 848\n",
            "Batch 320 de 848\n",
            "Batch 321 de 848\n",
            "Batch 322 de 848\n",
            "Batch 323 de 848\n",
            "Batch 324 de 848\n",
            "Batch 325 de 848\n",
            "Batch 326 de 848\n",
            "Batch 327 de 848\n",
            "Batch 328 de 848\n",
            "Batch 329 de 848\n",
            "Batch 330 de 848\n",
            "Batch 331 de 848\n",
            "Batch 332 de 848\n",
            "Batch 333 de 848\n",
            "Batch 334 de 848\n",
            "Batch 335 de 848\n",
            "Batch 336 de 848\n",
            "Batch 337 de 848\n",
            "Batch 338 de 848\n",
            "Batch 339 de 848\n",
            "Batch 340 de 848\n",
            "Batch 341 de 848\n",
            "Batch 342 de 848\n",
            "Batch 343 de 848\n",
            "Batch 344 de 848\n",
            "Batch 345 de 848\n",
            "Batch 346 de 848\n",
            "Batch 347 de 848\n",
            "Batch 348 de 848\n",
            "Batch 349 de 848\n",
            "Batch 350 de 848\n",
            "Batch 351 de 848\n",
            "Batch 352 de 848\n",
            "Batch 353 de 848\n",
            "Batch 354 de 848\n",
            "Batch 355 de 848\n",
            "Batch 356 de 848\n",
            "Batch 357 de 848\n",
            "Batch 358 de 848\n",
            "Batch 359 de 848\n",
            "Batch 360 de 848\n",
            "Batch 361 de 848\n",
            "Batch 362 de 848\n",
            "Batch 363 de 848\n",
            "Batch 364 de 848\n",
            "Batch 365 de 848\n",
            "Batch 366 de 848\n",
            "Batch 367 de 848\n",
            "Batch 368 de 848\n",
            "Batch 369 de 848\n",
            "Batch 370 de 848\n",
            "Batch 371 de 848\n",
            "Batch 372 de 848\n",
            "Batch 373 de 848\n",
            "Batch 374 de 848\n",
            "Batch 375 de 848\n",
            "Batch 376 de 848\n",
            "Batch 377 de 848\n",
            "Batch 378 de 848\n",
            "Batch 379 de 848\n",
            "Batch 380 de 848\n",
            "Batch 381 de 848\n",
            "Batch 382 de 848\n",
            "Batch 383 de 848\n",
            "Batch 384 de 848\n",
            "Batch 385 de 848\n",
            "Batch 386 de 848\n",
            "Batch 387 de 848\n",
            "Batch 388 de 848\n",
            "Batch 389 de 848\n",
            "Batch 390 de 848\n",
            "Batch 391 de 848\n",
            "Batch 392 de 848\n",
            "Batch 393 de 848\n",
            "Batch 394 de 848\n",
            "Batch 395 de 848\n",
            "Batch 396 de 848\n",
            "Batch 397 de 848\n",
            "Batch 398 de 848\n",
            "Batch 399 de 848\n",
            "Batch 400 de 848\n",
            "Batch 401 de 848\n",
            "Batch 402 de 848\n",
            "Batch 403 de 848\n",
            "Batch 404 de 848\n",
            "Batch 405 de 848\n",
            "Batch 406 de 848\n",
            "Batch 407 de 848\n",
            "Batch 408 de 848\n",
            "Batch 409 de 848\n",
            "Batch 410 de 848\n",
            "Batch 411 de 848\n",
            "Batch 412 de 848\n",
            "Batch 413 de 848\n",
            "Batch 414 de 848\n",
            "Batch 415 de 848\n",
            "Batch 416 de 848\n",
            "Batch 417 de 848\n",
            "Batch 418 de 848\n",
            "Batch 419 de 848\n",
            "Batch 420 de 848\n",
            "Batch 421 de 848\n",
            "Batch 422 de 848\n",
            "Batch 423 de 848\n",
            "Batch 424 de 848\n",
            "Batch 425 de 848\n",
            "Batch 426 de 848\n",
            "Batch 427 de 848\n",
            "Batch 428 de 848\n",
            "Batch 429 de 848\n",
            "Batch 430 de 848\n",
            "Batch 431 de 848\n",
            "Batch 432 de 848\n",
            "Batch 433 de 848\n",
            "Batch 434 de 848\n",
            "Batch 435 de 848\n",
            "Batch 436 de 848\n",
            "Batch 437 de 848\n",
            "Batch 438 de 848\n",
            "Batch 439 de 848\n",
            "Batch 440 de 848\n",
            "Batch 441 de 848\n",
            "Batch 442 de 848\n",
            "Batch 443 de 848\n",
            "Batch 444 de 848\n",
            "Batch 445 de 848\n",
            "Batch 446 de 848\n",
            "Batch 447 de 848\n",
            "Batch 448 de 848\n",
            "Batch 449 de 848\n",
            "Batch 450 de 848\n",
            "Batch 451 de 848\n",
            "Batch 452 de 848\n",
            "Batch 453 de 848\n",
            "Batch 454 de 848\n",
            "Batch 455 de 848\n",
            "Batch 456 de 848\n",
            "Batch 457 de 848\n",
            "Batch 458 de 848\n",
            "Batch 459 de 848\n",
            "Batch 460 de 848\n",
            "Batch 461 de 848\n",
            "Batch 462 de 848\n",
            "Batch 463 de 848\n",
            "Batch 464 de 848\n",
            "Batch 465 de 848\n",
            "Batch 466 de 848\n",
            "Batch 467 de 848\n",
            "Batch 468 de 848\n",
            "Batch 469 de 848\n",
            "Batch 470 de 848\n",
            "Batch 471 de 848\n",
            "Batch 472 de 848\n",
            "Batch 473 de 848\n",
            "Batch 474 de 848\n",
            "Batch 475 de 848\n",
            "Batch 476 de 848\n",
            "Batch 477 de 848\n",
            "Batch 478 de 848\n",
            "Batch 479 de 848\n",
            "Batch 480 de 848\n",
            "Batch 481 de 848\n",
            "Batch 482 de 848\n",
            "Batch 483 de 848\n",
            "Batch 484 de 848\n",
            "Batch 485 de 848\n",
            "Batch 486 de 848\n",
            "Batch 487 de 848\n",
            "Batch 488 de 848\n",
            "Batch 489 de 848\n",
            "Batch 490 de 848\n",
            "Batch 491 de 848\n",
            "Batch 492 de 848\n",
            "Batch 493 de 848\n",
            "Batch 494 de 848\n",
            "Batch 495 de 848\n",
            "Batch 496 de 848\n",
            "Batch 497 de 848\n",
            "Batch 498 de 848\n",
            "Batch 499 de 848\n",
            "Batch 500 de 848\n",
            "Batch 501 de 848\n",
            "Batch 502 de 848\n",
            "Batch 503 de 848\n",
            "Batch 504 de 848\n",
            "Batch 505 de 848\n",
            "Batch 506 de 848\n",
            "Batch 507 de 848\n",
            "Batch 508 de 848\n",
            "Batch 509 de 848\n",
            "Batch 510 de 848\n",
            "Batch 511 de 848\n",
            "Batch 512 de 848\n",
            "Batch 513 de 848\n",
            "Batch 514 de 848\n",
            "Batch 515 de 848\n",
            "Batch 516 de 848\n",
            "Batch 517 de 848\n",
            "Batch 518 de 848\n",
            "Batch 519 de 848\n",
            "Batch 520 de 848\n",
            "Batch 521 de 848\n",
            "Batch 522 de 848\n",
            "Batch 523 de 848\n",
            "Batch 524 de 848\n",
            "Batch 525 de 848\n",
            "Batch 526 de 848\n",
            "Batch 527 de 848\n",
            "Batch 528 de 848\n",
            "Batch 529 de 848\n",
            "Batch 530 de 848\n",
            "Batch 531 de 848\n",
            "Batch 532 de 848\n",
            "Batch 533 de 848\n",
            "Batch 534 de 848\n",
            "Batch 535 de 848\n",
            "Batch 536 de 848\n",
            "Batch 537 de 848\n",
            "Batch 538 de 848\n",
            "Batch 539 de 848\n",
            "Batch 540 de 848\n",
            "Batch 541 de 848\n",
            "Batch 542 de 848\n",
            "Batch 543 de 848\n",
            "Batch 544 de 848\n",
            "Batch 545 de 848\n",
            "Batch 546 de 848\n",
            "Batch 547 de 848\n",
            "Batch 548 de 848\n",
            "Batch 549 de 848\n",
            "Batch 550 de 848\n",
            "Batch 551 de 848\n",
            "Batch 552 de 848\n",
            "Batch 553 de 848\n",
            "Batch 554 de 848\n",
            "Batch 555 de 848\n",
            "Batch 556 de 848\n",
            "Batch 557 de 848\n",
            "Batch 558 de 848\n",
            "Batch 559 de 848\n",
            "Batch 560 de 848\n",
            "Batch 561 de 848\n",
            "Batch 562 de 848\n",
            "Batch 563 de 848\n",
            "Batch 564 de 848\n",
            "Batch 565 de 848\n",
            "Batch 566 de 848\n",
            "Batch 567 de 848\n",
            "Batch 568 de 848\n",
            "Batch 569 de 848\n",
            "Batch 570 de 848\n",
            "Batch 571 de 848\n",
            "Batch 572 de 848\n",
            "Batch 573 de 848\n",
            "Batch 574 de 848\n",
            "Batch 575 de 848\n",
            "Batch 576 de 848\n",
            "Batch 577 de 848\n",
            "Batch 578 de 848\n",
            "Batch 579 de 848\n",
            "Batch 580 de 848\n",
            "Batch 581 de 848\n",
            "Batch 582 de 848\n",
            "Batch 583 de 848\n",
            "Batch 584 de 848\n",
            "Batch 585 de 848\n",
            "Batch 586 de 848\n",
            "Batch 587 de 848\n",
            "Batch 588 de 848\n",
            "Batch 589 de 848\n",
            "Batch 590 de 848\n",
            "Batch 591 de 848\n",
            "Batch 592 de 848\n",
            "Batch 593 de 848\n",
            "Batch 594 de 848\n",
            "Batch 595 de 848\n",
            "Batch 596 de 848\n",
            "Batch 597 de 848\n",
            "Batch 598 de 848\n",
            "Batch 599 de 848\n",
            "Batch 600 de 848\n",
            "Batch 601 de 848\n",
            "Batch 602 de 848\n",
            "Batch 603 de 848\n",
            "Batch 604 de 848\n",
            "Batch 605 de 848\n",
            "Batch 606 de 848\n",
            "Batch 607 de 848\n",
            "Batch 608 de 848\n",
            "Batch 609 de 848\n",
            "Batch 610 de 848\n",
            "Batch 611 de 848\n",
            "Batch 612 de 848\n",
            "Batch 613 de 848\n",
            "Batch 614 de 848\n",
            "Batch 615 de 848\n",
            "Batch 616 de 848\n",
            "Batch 617 de 848\n",
            "Batch 618 de 848\n",
            "Batch 619 de 848\n",
            "Batch 620 de 848\n",
            "Batch 621 de 848\n",
            "Batch 622 de 848\n",
            "Batch 623 de 848\n",
            "Batch 624 de 848\n",
            "Batch 625 de 848\n",
            "Batch 626 de 848\n",
            "Batch 627 de 848\n",
            "Batch 628 de 848\n",
            "Batch 629 de 848\n",
            "Batch 630 de 848\n",
            "Batch 631 de 848\n",
            "Batch 632 de 848\n",
            "Batch 633 de 848\n",
            "Batch 634 de 848\n",
            "Batch 635 de 848\n",
            "Batch 636 de 848\n",
            "Batch 637 de 848\n",
            "Batch 638 de 848\n",
            "Batch 639 de 848\n",
            "Batch 640 de 848\n",
            "Batch 641 de 848\n",
            "Batch 642 de 848\n",
            "Batch 643 de 848\n",
            "Batch 644 de 848\n",
            "Batch 645 de 848\n",
            "Batch 646 de 848\n",
            "Batch 647 de 848\n",
            "Batch 648 de 848\n",
            "Batch 649 de 848\n",
            "Batch 650 de 848\n",
            "Batch 651 de 848\n",
            "Batch 652 de 848\n",
            "Batch 653 de 848\n",
            "Batch 654 de 848\n",
            "Batch 655 de 848\n",
            "Batch 656 de 848\n",
            "Batch 657 de 848\n",
            "Batch 658 de 848\n",
            "Batch 659 de 848\n",
            "Batch 660 de 848\n",
            "Batch 661 de 848\n",
            "Batch 662 de 848\n",
            "Batch 663 de 848\n",
            "Batch 664 de 848\n",
            "Batch 665 de 848\n",
            "Batch 666 de 848\n",
            "Batch 667 de 848\n",
            "Batch 668 de 848\n",
            "Batch 669 de 848\n",
            "Batch 670 de 848\n",
            "Batch 671 de 848\n",
            "Batch 672 de 848\n",
            "Batch 673 de 848\n",
            "Batch 674 de 848\n",
            "Batch 675 de 848\n",
            "Batch 676 de 848\n",
            "Batch 677 de 848\n",
            "Batch 678 de 848\n",
            "Batch 679 de 848\n",
            "Batch 680 de 848\n",
            "Batch 681 de 848\n",
            "Batch 682 de 848\n",
            "Batch 683 de 848\n",
            "Batch 684 de 848\n",
            "Batch 685 de 848\n",
            "Batch 686 de 848\n",
            "Batch 687 de 848\n",
            "Batch 688 de 848\n",
            "Batch 689 de 848\n",
            "Batch 690 de 848\n",
            "Batch 691 de 848\n",
            "Batch 692 de 848\n",
            "Batch 693 de 848\n",
            "Batch 694 de 848\n",
            "Batch 695 de 848\n",
            "Batch 696 de 848\n",
            "Batch 697 de 848\n",
            "Batch 698 de 848\n",
            "Batch 699 de 848\n",
            "Batch 700 de 848\n",
            "Batch 701 de 848\n",
            "Batch 702 de 848\n",
            "Batch 703 de 848\n",
            "Batch 704 de 848\n",
            "Batch 705 de 848\n",
            "Batch 706 de 848\n",
            "Batch 707 de 848\n",
            "Batch 708 de 848\n",
            "Batch 709 de 848\n",
            "Batch 710 de 848\n",
            "Batch 711 de 848\n",
            "Batch 712 de 848\n",
            "Batch 713 de 848\n",
            "Batch 714 de 848\n",
            "Batch 715 de 848\n",
            "Batch 716 de 848\n",
            "Batch 717 de 848\n",
            "Batch 718 de 848\n",
            "Batch 719 de 848\n",
            "Batch 720 de 848\n",
            "Batch 721 de 848\n",
            "Batch 722 de 848\n",
            "Batch 723 de 848\n",
            "Batch 724 de 848\n",
            "Batch 725 de 848\n",
            "Batch 726 de 848\n",
            "Batch 727 de 848\n",
            "Batch 728 de 848\n",
            "Batch 729 de 848\n",
            "Batch 730 de 848\n",
            "Batch 731 de 848\n",
            "Batch 732 de 848\n",
            "Batch 733 de 848\n",
            "Batch 734 de 848\n",
            "Batch 735 de 848\n",
            "Batch 736 de 848\n",
            "Batch 737 de 848\n",
            "Batch 738 de 848\n",
            "Batch 739 de 848\n",
            "Batch 740 de 848\n",
            "Batch 741 de 848\n",
            "Batch 742 de 848\n",
            "Batch 743 de 848\n",
            "Batch 744 de 848\n",
            "Batch 745 de 848\n",
            "Batch 746 de 848\n",
            "Batch 747 de 848\n",
            "Batch 748 de 848\n",
            "Batch 749 de 848\n",
            "Batch 750 de 848\n",
            "Batch 751 de 848\n",
            "Batch 752 de 848\n",
            "Batch 753 de 848\n",
            "Batch 754 de 848\n",
            "Batch 755 de 848\n",
            "Batch 756 de 848\n",
            "Batch 757 de 848\n",
            "Batch 758 de 848\n",
            "Batch 759 de 848\n",
            "Batch 760 de 848\n",
            "Batch 761 de 848\n",
            "Batch 762 de 848\n",
            "Batch 763 de 848\n",
            "Batch 764 de 848\n",
            "Batch 765 de 848\n",
            "Batch 766 de 848\n",
            "Batch 767 de 848\n",
            "Batch 768 de 848\n",
            "Batch 769 de 848\n",
            "Batch 770 de 848\n",
            "Batch 771 de 848\n",
            "Batch 772 de 848\n",
            "Batch 773 de 848\n",
            "Batch 774 de 848\n",
            "Batch 775 de 848\n",
            "Batch 776 de 848\n",
            "Batch 777 de 848\n",
            "Batch 778 de 848\n",
            "Batch 779 de 848\n",
            "Batch 780 de 848\n",
            "Batch 781 de 848\n",
            "Batch 782 de 848\n",
            "Batch 783 de 848\n",
            "Batch 784 de 848\n",
            "Batch 785 de 848\n",
            "Batch 786 de 848\n",
            "Batch 787 de 848\n",
            "Batch 788 de 848\n",
            "Batch 789 de 848\n",
            "Batch 790 de 848\n",
            "Batch 791 de 848\n",
            "Batch 792 de 848\n",
            "Batch 793 de 848\n",
            "Batch 794 de 848\n",
            "Batch 795 de 848\n",
            "Batch 796 de 848\n",
            "Batch 797 de 848\n",
            "Batch 798 de 848\n",
            "Batch 799 de 848\n",
            "Batch 800 de 848\n",
            "Batch 801 de 848\n",
            "Batch 802 de 848\n",
            "Batch 803 de 848\n",
            "Batch 804 de 848\n",
            "Batch 805 de 848\n",
            "Batch 806 de 848\n",
            "Batch 807 de 848\n",
            "Batch 808 de 848\n",
            "Batch 809 de 848\n",
            "Batch 810 de 848\n",
            "Batch 811 de 848\n",
            "Batch 812 de 848\n",
            "Batch 813 de 848\n",
            "Batch 814 de 848\n",
            "Batch 815 de 848\n",
            "Batch 816 de 848\n",
            "Batch 817 de 848\n",
            "Batch 818 de 848\n",
            "Batch 819 de 848\n",
            "Batch 820 de 848\n",
            "Batch 821 de 848\n",
            "Batch 822 de 848\n",
            "Batch 823 de 848\n",
            "Batch 824 de 848\n",
            "Batch 825 de 848\n",
            "Batch 826 de 848\n",
            "Batch 827 de 848\n",
            "Batch 828 de 848\n",
            "Batch 829 de 848\n",
            "Batch 830 de 848\n",
            "Batch 831 de 848\n",
            "Batch 832 de 848\n",
            "Batch 833 de 848\n",
            "Batch 834 de 848\n",
            "Batch 835 de 848\n",
            "Batch 836 de 848\n",
            "Batch 837 de 848\n",
            "Batch 838 de 848\n",
            "Batch 839 de 848\n",
            "Batch 840 de 848\n",
            "Batch 841 de 848\n",
            "Batch 842 de 848\n",
            "Batch 843 de 848\n",
            "Batch 844 de 848\n",
            "Batch 845 de 848\n",
            "Batch 846 de 848\n",
            "Batch 847 de 848\n",
            "Accuracy Score = 0.7164385583059726\n",
            "F1 Score (Micro) = 0.7164385583059726\n",
            "F1 Score (Macro) = 0.4173983128257482\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationBert(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "\n",
        "  targets = np.array(targets).flatten().astype(int)\n",
        "\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "id": "XBko0YQvpRr_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA01-MlTCvP0"
      },
      "source": [
        "##### Entrenamiento del modelo (30% de datos) v2"
      ],
      "id": "nA01-MlTCvP0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-5\n",
        "- weight_decay=0.01\n",
        "- Dropout + Linear + Sigmoid\n",
        "- Funcion de entrenamiento v2"
      ],
      "metadata": {
        "id": "zieQSwX4CvQA"
      },
      "id": "zieQSwX4CvQA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ada55022-0f2e-4aec-c336-8a84962b183b",
        "id": "UMqbBxv-CvQB"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración: 0 de 2905, Loss: 0.06562252044677734\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 10 de 2905, Loss: 0.5719175666570664\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 20 de 2905, Loss: 0.5797299295663834\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 30 de 2905, Loss: 0.6012768596410751\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 40 de 2905, Loss: 0.5032866299152374\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 50 de 2905, Loss: 0.6381739705801011\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 60 de 2905, Loss: 0.5761262685060501\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 70 de 2905, Loss: 0.5888657093048095\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 80 de 2905, Loss: 0.6371831864118576\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 90 de 2905, Loss: 0.5663395345211029\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 100 de 2905, Loss: 0.6483917713165284\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 110 de 2905, Loss: 0.5219224393367767\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 120 de 2905, Loss: 0.6405450284481049\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 130 de 2905, Loss: 0.5763162434101105\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 140 de 2905, Loss: 0.5149652272462845\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 150 de 2905, Loss: 0.552099734544754\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 160 de 2905, Loss: 0.6243373930454255\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 170 de 2905, Loss: 0.601717546582222\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 180 de 2905, Loss: 0.6119310587644577\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 190 de 2905, Loss: 0.5815445125102997\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 200 de 2905, Loss: 0.7361316084861755\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 210 de 2905, Loss: 0.5870849847793579\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 220 de 2905, Loss: 0.6605635225772858\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 230 de 2905, Loss: 0.5353938937187195\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 240 de 2905, Loss: 0.59041268825531\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 250 de 2905, Loss: 0.5654532194137574\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 260 de 2905, Loss: 0.6599483668804169\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 270 de 2905, Loss: 0.5536571830511093\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 280 de 2905, Loss: 0.5059285581111908\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 290 de 2905, Loss: 0.4811325818300247\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 300 de 2905, Loss: 0.6242913126945495\n",
            "Accuracy: 0.375\n",
            "Epoch: 0, iteración: 310 de 2905, Loss: 0.576808413863182\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 320 de 2905, Loss: 0.6485463827848434\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 330 de 2905, Loss: 0.6370949059724808\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 340 de 2905, Loss: 0.6137012600898742\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 350 de 2905, Loss: 0.6115188062191009\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 360 de 2905, Loss: 0.5440954327583313\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 370 de 2905, Loss: 0.6244725465774537\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 380 de 2905, Loss: 0.5444776505231858\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 390 de 2905, Loss: 0.6111603170633316\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 400 de 2905, Loss: 0.646176141500473\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 410 de 2905, Loss: 0.48728331327438357\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 420 de 2905, Loss: 0.6233222663402558\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 430 de 2905, Loss: 0.5519519358873367\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 440 de 2905, Loss: 0.5054696440696717\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 450 de 2905, Loss: 0.5153823971748352\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 460 de 2905, Loss: 0.5383288055658341\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 470 de 2905, Loss: 0.5760242223739624\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 480 de 2905, Loss: 0.5882072508335113\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 490 de 2905, Loss: 0.4671129614114761\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 500 de 2905, Loss: 0.6735816448926926\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 510 de 2905, Loss: 0.625584852695465\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 520 de 2905, Loss: 0.5656035631895066\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 530 de 2905, Loss: 0.5767834544181824\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 540 de 2905, Loss: 0.6840751558542252\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 550 de 2905, Loss: 0.5876858055591583\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 560 de 2905, Loss: 0.566792231798172\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 570 de 2905, Loss: 0.633819317817688\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 580 de 2905, Loss: 0.5973203241825104\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 590 de 2905, Loss: 0.5597304791212082\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 600 de 2905, Loss: 0.5211765438318252\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 610 de 2905, Loss: 0.621269690990448\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 620 de 2905, Loss: 0.6534752190113068\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 630 de 2905, Loss: 0.5417791873216629\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 640 de 2905, Loss: 0.6042797356843949\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 650 de 2905, Loss: 0.6338808596134186\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 660 de 2905, Loss: 0.5258525550365448\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 670 de 2905, Loss: 0.7025026738643646\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 680 de 2905, Loss: 0.6116874277591705\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 690 de 2905, Loss: 0.5404713213443756\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 700 de 2905, Loss: 0.6320938766002655\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 710 de 2905, Loss: 0.5790699988603591\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 720 de 2905, Loss: 0.6915909647941589\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 730 de 2905, Loss: 0.5728864520788193\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 740 de 2905, Loss: 0.5488579481840133\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 750 de 2905, Loss: 0.6159958422183991\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 760 de 2905, Loss: 0.6101268947124481\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 770 de 2905, Loss: 0.562900161743164\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 780 de 2905, Loss: 0.5470271468162536\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 790 de 2905, Loss: 0.6844292372465134\n",
            "Accuracy: 0.375\n",
            "Epoch: 0, iteración: 800 de 2905, Loss: 0.6251312702894211\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 810 de 2905, Loss: 0.5658163964748383\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 820 de 2905, Loss: 0.5223510414361954\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 830 de 2905, Loss: 0.5654731392860413\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 840 de 2905, Loss: 0.5646674513816834\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 850 de 2905, Loss: 0.610277333855629\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 860 de 2905, Loss: 0.5503158122301102\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 870 de 2905, Loss: 0.570577684044838\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 880 de 2905, Loss: 0.4981099098920822\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 890 de 2905, Loss: 0.5865154951810837\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 900 de 2905, Loss: 0.5252566188573837\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 910 de 2905, Loss: 0.6111129969358444\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 920 de 2905, Loss: 0.615647691488266\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 930 de 2905, Loss: 0.6038081854581833\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 940 de 2905, Loss: 0.608418133854866\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 950 de 2905, Loss: 0.6117182224988937\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 960 de 2905, Loss: 0.6779496133327484\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 970 de 2905, Loss: 0.6252646088600159\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 980 de 2905, Loss: 0.612252727150917\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 990 de 2905, Loss: 0.5510382443666458\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1000 de 2905, Loss: 0.5074020862579346\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 1010 de 2905, Loss: 0.5936226844787598\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1020 de 2905, Loss: 0.5048426419496537\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1030 de 2905, Loss: 0.5871988356113433\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1040 de 2905, Loss: 0.6380040675401688\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1050 de 2905, Loss: 0.6738348066806793\n",
            "Accuracy: 0.25\n",
            "Epoch: 0, iteración: 1060 de 2905, Loss: 0.6124864131212234\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 1070 de 2905, Loss: 0.6112744092941285\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1080 de 2905, Loss: 0.6512445449829102\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 1090 de 2905, Loss: 0.5913605183362961\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1100 de 2905, Loss: 0.568477937579155\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1110 de 2905, Loss: 0.6236843347549439\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1120 de 2905, Loss: 0.5440505802631378\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1130 de 2905, Loss: 0.5995924830436706\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1140 de 2905, Loss: 0.5298179537057877\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1150 de 2905, Loss: 0.7152998566627502\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1160 de 2905, Loss: 0.6553636431694031\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1170 de 2905, Loss: 0.5480706453323364\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 1180 de 2905, Loss: 0.5142279744148255\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 1190 de 2905, Loss: 0.5438232153654099\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1200 de 2905, Loss: 0.600784820318222\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1210 de 2905, Loss: 0.6948605597019195\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1220 de 2905, Loss: 0.6339592337608337\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1230 de 2905, Loss: 0.763992965221405\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 1240 de 2905, Loss: 0.5884537488222122\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1250 de 2905, Loss: 0.6031473577022552\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1260 de 2905, Loss: 0.6192653089761734\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1270 de 2905, Loss: 0.6501174002885819\n",
            "Accuracy: 0.375\n",
            "Epoch: 0, iteración: 1280 de 2905, Loss: 0.6500771582126618\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1290 de 2905, Loss: 0.5773050367832184\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1300 de 2905, Loss: 0.5215033620595932\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1310 de 2905, Loss: 0.6433812975883484\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1320 de 2905, Loss: 0.5326625913381576\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1330 de 2905, Loss: 0.5658180624246597\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1340 de 2905, Loss: 0.7031150370836258\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1350 de 2905, Loss: 0.6890481293201447\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 1360 de 2905, Loss: 0.6012943595647812\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1370 de 2905, Loss: 0.5811892479658127\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1380 de 2905, Loss: 0.651053324341774\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1390 de 2905, Loss: 0.6409656524658203\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1400 de 2905, Loss: 0.6018539488315582\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1410 de 2905, Loss: 0.5813709169626236\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1420 de 2905, Loss: 0.7008999198675155\n",
            "Accuracy: 0.375\n",
            "Epoch: 0, iteración: 1430 de 2905, Loss: 0.5934851348400116\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1440 de 2905, Loss: 0.6124416619539261\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1450 de 2905, Loss: 0.6229350656270981\n",
            "Accuracy: 0.375\n",
            "Epoch: 0, iteración: 1460 de 2905, Loss: 0.6125890254974365\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1470 de 2905, Loss: 0.4996965855360031\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1480 de 2905, Loss: 0.6781306326389313\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1490 de 2905, Loss: 0.6213025540113449\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1500 de 2905, Loss: 0.5800185322761535\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1510 de 2905, Loss: 0.5138658463954926\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1520 de 2905, Loss: 0.6110457926988602\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1530 de 2905, Loss: 0.5542096436023712\n",
            "Accuracy: 0.375\n",
            "Epoch: 0, iteración: 1540 de 2905, Loss: 0.5768886208534241\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1550 de 2905, Loss: 0.7048754394054413\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1560 de 2905, Loss: 0.6119006752967835\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1570 de 2905, Loss: 0.6749254614114761\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1580 de 2905, Loss: 0.5380586743354797\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1590 de 2905, Loss: 0.5908818185329437\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 1600 de 2905, Loss: 0.5783118337392807\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1610 de 2905, Loss: 0.5662766218185424\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1620 de 2905, Loss: 0.6354394495487213\n",
            "Accuracy: 0.375\n",
            "Epoch: 0, iteración: 1630 de 2905, Loss: 0.554477646946907\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1640 de 2905, Loss: 0.6349893242120743\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1650 de 2905, Loss: 0.5207583576440811\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1660 de 2905, Loss: 0.6229813754558563\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1670 de 2905, Loss: 0.5883090168237686\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 1680 de 2905, Loss: 0.5433302164077759\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1690 de 2905, Loss: 0.5764240801334382\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 1700 de 2905, Loss: 0.6704759210348129\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1710 de 2905, Loss: 0.5880675703287125\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1720 de 2905, Loss: 0.6342232137918472\n",
            "Accuracy: 0.375\n",
            "Epoch: 0, iteración: 1730 de 2905, Loss: 0.611767441034317\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1740 de 2905, Loss: 0.6326790064573288\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 1750 de 2905, Loss: 0.5483549028635025\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1760 de 2905, Loss: 0.6334442108869552\n",
            "Accuracy: 0.375\n",
            "Epoch: 0, iteración: 1770 de 2905, Loss: 0.5124500930309296\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1780 de 2905, Loss: 0.5770270138978958\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1790 de 2905, Loss: 0.5302738875150681\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1800 de 2905, Loss: 0.6350266754627227\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1810 de 2905, Loss: 0.6124565750360489\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1820 de 2905, Loss: 0.5773692280054092\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1830 de 2905, Loss: 0.6463266313076019\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1840 de 2905, Loss: 0.6451770931482315\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1850 de 2905, Loss: 0.6102552384138107\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1860 de 2905, Loss: 0.6331390827894211\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1870 de 2905, Loss: 0.621818920969963\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1880 de 2905, Loss: 0.6320552915334702\n",
            "Accuracy: 0.375\n",
            "Epoch: 0, iteración: 1890 de 2905, Loss: 0.5617760807275772\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1900 de 2905, Loss: 0.5701388210058213\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1910 de 2905, Loss: 0.5689601004123688\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1920 de 2905, Loss: 0.588504183292389\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1930 de 2905, Loss: 0.5894497811794281\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1940 de 2905, Loss: 0.5880782246589661\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1950 de 2905, Loss: 0.5661663502454758\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 1960 de 2905, Loss: 0.5769934833049775\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 1970 de 2905, Loss: 0.5879581809043884\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1980 de 2905, Loss: 0.5069396734237671\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 1990 de 2905, Loss: 0.6593112885951996\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2000 de 2905, Loss: 0.6463635772466659\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 2010 de 2905, Loss: 0.6231471985578537\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2020 de 2905, Loss: 0.6669497728347779\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2030 de 2905, Loss: 0.56930370926857\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 2040 de 2905, Loss: 0.5581672966480256\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2050 de 2905, Loss: 0.5557160049676895\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2060 de 2905, Loss: 0.4969425082206726\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2070 de 2905, Loss: 0.6581579357385635\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2080 de 2905, Loss: 0.576044625043869\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2090 de 2905, Loss: 0.6704967886209487\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2100 de 2905, Loss: 0.6348547995090484\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2110 de 2905, Loss: 0.6668196678161621\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2120 de 2905, Loss: 0.5594361126422882\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2130 de 2905, Loss: 0.5691958874464035\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2140 de 2905, Loss: 0.6231548696756363\n",
            "Accuracy: 0.375\n",
            "Epoch: 0, iteración: 2150 de 2905, Loss: 0.5671813607215881\n",
            "Accuracy: 0.375\n",
            "Epoch: 0, iteración: 2160 de 2905, Loss: 0.5887051284313202\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2170 de 2905, Loss: 0.4980176776647568\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2180 de 2905, Loss: 0.5769670218229294\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2190 de 2905, Loss: 0.5771934360265731\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2200 de 2905, Loss: 0.6355657398700714\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2210 de 2905, Loss: 0.5766209363937378\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2220 de 2905, Loss: 0.5891123443841935\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2230 de 2905, Loss: 0.5535714328289032\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2240 de 2905, Loss: 0.5883287131786347\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2250 de 2905, Loss: 0.5765633523464203\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 2260 de 2905, Loss: 0.5994784533977509\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 2270 de 2905, Loss: 0.5528027981519699\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2280 de 2905, Loss: 0.6467331439256668\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2290 de 2905, Loss: 0.6122621685266495\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 2300 de 2905, Loss: 0.6109330236911774\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 2310 de 2905, Loss: 0.6338255792856217\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2320 de 2905, Loss: 0.567376896739006\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2330 de 2905, Loss: 0.5341149181127548\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2340 de 2905, Loss: 0.6672141790390015\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2350 de 2905, Loss: 0.6215829253196716\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2360 de 2905, Loss: 0.5219173312187195\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2370 de 2905, Loss: 0.6671577632427216\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2380 de 2905, Loss: 0.599905526638031\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2390 de 2905, Loss: 0.5247197866439819\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2400 de 2905, Loss: 0.5885240137577057\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2410 de 2905, Loss: 0.6578262209892273\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2420 de 2905, Loss: 0.6002720415592193\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2430 de 2905, Loss: 0.6104037165641785\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2440 de 2905, Loss: 0.5456766545772552\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2450 de 2905, Loss: 0.5768688440322876\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2460 de 2905, Loss: 0.6464549869298934\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 2470 de 2905, Loss: 0.5551564395427704\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2480 de 2905, Loss: 0.6114068895578384\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 2490 de 2905, Loss: 0.542805477976799\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2500 de 2905, Loss: 0.5995405793190003\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2510 de 2905, Loss: 0.5545193433761597\n",
            "Accuracy: 1.0\n",
            "Epoch: 0, iteración: 2520 de 2905, Loss: 0.5885217398405075\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2530 de 2905, Loss: 0.5651353091001511\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2540 de 2905, Loss: 0.6007414907217026\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2550 de 2905, Loss: 0.5888970136642456\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2560 de 2905, Loss: 0.5773668050765991\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2570 de 2905, Loss: 0.6117323577404022\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2580 de 2905, Loss: 0.6926986247301101\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2590 de 2905, Loss: 0.6357309967279434\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2600 de 2905, Loss: 0.5367283344268798\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2610 de 2905, Loss: 0.6118993997573853\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2620 de 2905, Loss: 0.6332278549671173\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2630 de 2905, Loss: 0.5994495242834091\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 2640 de 2905, Loss: 0.623128467798233\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2650 de 2905, Loss: 0.6105226844549179\n",
            "Accuracy: 0.375\n",
            "Epoch: 0, iteración: 2660 de 2905, Loss: 0.600196897983551\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2670 de 2905, Loss: 0.6217744708061218\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 2680 de 2905, Loss: 0.558494046330452\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2690 de 2905, Loss: 0.5679632037878036\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2700 de 2905, Loss: 0.5886457234621048\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2710 de 2905, Loss: 0.5669187545776367\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2720 de 2905, Loss: 0.5892928719520569\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2730 de 2905, Loss: 0.566024312376976\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 2740 de 2905, Loss: 0.7032582253217697\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2750 de 2905, Loss: 0.48850670754909514\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2760 de 2905, Loss: 0.6692183256149292\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2770 de 2905, Loss: 0.5994555592536926\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2780 de 2905, Loss: 0.5773358017206192\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2790 de 2905, Loss: 0.6343626856803894\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 2800 de 2905, Loss: 0.6238446056842804\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2810 de 2905, Loss: 0.5568830072879791\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2820 de 2905, Loss: 0.6110470682382584\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2830 de 2905, Loss: 0.5765053898096084\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2840 de 2905, Loss: 0.532036030292511\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2850 de 2905, Loss: 0.5656401515007019\n",
            "Accuracy: 0.75\n",
            "Epoch: 0, iteración: 2860 de 2905, Loss: 0.5527626991271972\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2870 de 2905, Loss: 0.5886660724878311\n",
            "Accuracy: 0.5\n",
            "Epoch: 0, iteración: 2880 de 2905, Loss: 0.5763582050800323\n",
            "Accuracy: 0.625\n",
            "Epoch: 0, iteración: 2890 de 2905, Loss: 0.6244197368621827\n",
            "Accuracy: 0.875\n",
            "Epoch: 0, iteración: 2900 de 2905, Loss: 0.5761491179466247\n",
            "Accuracy: 0.75\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  train_loss, train_accuracy = trainBert(epoch, model, training_loader, optimizer, device)"
      ],
      "id": "UMqbBxv-CvQB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8f7374-c604-4d3e-e48d-f3b91fb70767",
        "id": "nAYnt7x2CvQB"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30_v2.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "id": "nAYnt7x2CvQB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya_X8G8fCyt3"
      },
      "source": [
        "##### Evaluación del modelo"
      ],
      "id": "ya_X8G8fCyt3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbNR-js8Cyt_"
      },
      "outputs": [],
      "source": [
        "def validationBert(model, validation_loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    sum_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(validation_loader, 0):\n",
        "            ids = data['ids'].to(device)\n",
        "            mask = data['mask'].to(device)\n",
        "            token_type_ids = data['token_type_ids'].to(device)\n",
        "            targets = data['target'].to(device)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            # Calculate loss\n",
        "            perdida = loss_fn(outputs.squeeze(), targets)\n",
        "            sum_loss += perdida.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            predictions = torch.sigmoid(outputs).cpu().numpy() >= 0.5\n",
        "            correct_predictions += (predictions == targets.cpu().numpy()).sum()\n",
        "            total_predictions += targets.size(0)\n",
        "\n",
        "    # Calculate average loss and accuracy for the epoch\n",
        "    epoch_loss = sum_loss / len(validation_loader)\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # Append to history\n",
        "    val_loss_history.append(epoch_loss)\n",
        "    val_accuracy_history.append(epoch_accuracy)\n",
        "\n",
        "    print(f\"Accuracy Score = {epoch_accuracy}\")\n",
        "\n",
        "    return epoch_loss, epoch_accuracy"
      ],
      "id": "zbNR-js8Cyt_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "q1YKaUC9CyuA"
      },
      "id": "q1YKaUC9CyuA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e0c12b-f961-4d1c-d486-ab34b2bd8cf5",
        "id": "O26KmriYCyuA"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado correctamente\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30_v2.pth\"):\n",
        "  model = BERTClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30_v2.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30_v2.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "id": "O26KmriYCyuA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f11e4a-b790-45bb-d0cb-cb8f3769421e",
        "id": "V0sbi_jgCyuA"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 de 848\n",
            "Batch 1 de 848\n",
            "Batch 2 de 848\n",
            "Batch 3 de 848\n",
            "Batch 4 de 848\n",
            "Batch 5 de 848\n",
            "Batch 6 de 848\n",
            "Batch 7 de 848\n",
            "Batch 8 de 848\n",
            "Batch 9 de 848\n",
            "Batch 10 de 848\n",
            "Batch 11 de 848\n",
            "Batch 12 de 848\n",
            "Batch 13 de 848\n",
            "Batch 14 de 848\n",
            "Batch 15 de 848\n",
            "Batch 16 de 848\n",
            "Batch 17 de 848\n",
            "Batch 18 de 848\n",
            "Batch 19 de 848\n",
            "Batch 20 de 848\n",
            "Batch 21 de 848\n",
            "Batch 22 de 848\n",
            "Batch 23 de 848\n",
            "Batch 24 de 848\n",
            "Batch 25 de 848\n",
            "Batch 26 de 848\n",
            "Batch 27 de 848\n",
            "Batch 28 de 848\n",
            "Batch 29 de 848\n",
            "Batch 30 de 848\n",
            "Batch 31 de 848\n",
            "Batch 32 de 848\n",
            "Batch 33 de 848\n",
            "Batch 34 de 848\n",
            "Batch 35 de 848\n",
            "Batch 36 de 848\n",
            "Batch 37 de 848\n",
            "Batch 38 de 848\n",
            "Batch 39 de 848\n",
            "Batch 40 de 848\n",
            "Batch 41 de 848\n",
            "Batch 42 de 848\n",
            "Batch 43 de 848\n",
            "Batch 44 de 848\n",
            "Batch 45 de 848\n",
            "Batch 46 de 848\n",
            "Batch 47 de 848\n",
            "Batch 48 de 848\n",
            "Batch 49 de 848\n",
            "Batch 50 de 848\n",
            "Batch 51 de 848\n",
            "Batch 52 de 848\n",
            "Batch 53 de 848\n",
            "Batch 54 de 848\n",
            "Batch 55 de 848\n",
            "Batch 56 de 848\n",
            "Batch 57 de 848\n",
            "Batch 58 de 848\n",
            "Batch 59 de 848\n",
            "Batch 60 de 848\n",
            "Batch 61 de 848\n",
            "Batch 62 de 848\n",
            "Batch 63 de 848\n",
            "Batch 64 de 848\n",
            "Batch 65 de 848\n",
            "Batch 66 de 848\n",
            "Batch 67 de 848\n",
            "Batch 68 de 848\n",
            "Batch 69 de 848\n",
            "Batch 70 de 848\n",
            "Batch 71 de 848\n",
            "Batch 72 de 848\n",
            "Batch 73 de 848\n",
            "Batch 74 de 848\n",
            "Batch 75 de 848\n",
            "Batch 76 de 848\n",
            "Batch 77 de 848\n",
            "Batch 78 de 848\n",
            "Batch 79 de 848\n",
            "Batch 80 de 848\n",
            "Batch 81 de 848\n",
            "Batch 82 de 848\n",
            "Batch 83 de 848\n",
            "Batch 84 de 848\n",
            "Batch 85 de 848\n",
            "Batch 86 de 848\n",
            "Batch 87 de 848\n",
            "Batch 88 de 848\n",
            "Batch 89 de 848\n",
            "Batch 90 de 848\n",
            "Batch 91 de 848\n",
            "Batch 92 de 848\n",
            "Batch 93 de 848\n",
            "Batch 94 de 848\n",
            "Batch 95 de 848\n",
            "Batch 96 de 848\n",
            "Batch 97 de 848\n",
            "Batch 98 de 848\n",
            "Batch 99 de 848\n",
            "Batch 100 de 848\n",
            "Batch 101 de 848\n",
            "Batch 102 de 848\n",
            "Batch 103 de 848\n",
            "Batch 104 de 848\n",
            "Batch 105 de 848\n",
            "Batch 106 de 848\n",
            "Batch 107 de 848\n",
            "Batch 108 de 848\n",
            "Batch 109 de 848\n",
            "Batch 110 de 848\n",
            "Batch 111 de 848\n",
            "Batch 112 de 848\n",
            "Batch 113 de 848\n",
            "Batch 114 de 848\n",
            "Batch 115 de 848\n",
            "Batch 116 de 848\n",
            "Batch 117 de 848\n",
            "Batch 118 de 848\n",
            "Batch 119 de 848\n",
            "Batch 120 de 848\n",
            "Batch 121 de 848\n",
            "Batch 122 de 848\n",
            "Batch 123 de 848\n",
            "Batch 124 de 848\n",
            "Batch 125 de 848\n",
            "Batch 126 de 848\n",
            "Batch 127 de 848\n",
            "Batch 128 de 848\n",
            "Batch 129 de 848\n",
            "Batch 130 de 848\n",
            "Batch 131 de 848\n",
            "Batch 132 de 848\n",
            "Batch 133 de 848\n",
            "Batch 134 de 848\n",
            "Batch 135 de 848\n",
            "Batch 136 de 848\n",
            "Batch 137 de 848\n",
            "Batch 138 de 848\n",
            "Batch 139 de 848\n",
            "Batch 140 de 848\n",
            "Batch 141 de 848\n",
            "Batch 142 de 848\n",
            "Batch 143 de 848\n",
            "Batch 144 de 848\n",
            "Batch 145 de 848\n",
            "Batch 146 de 848\n",
            "Batch 147 de 848\n",
            "Batch 148 de 848\n",
            "Batch 149 de 848\n",
            "Batch 150 de 848\n",
            "Batch 151 de 848\n",
            "Batch 152 de 848\n",
            "Batch 153 de 848\n",
            "Batch 154 de 848\n",
            "Batch 155 de 848\n",
            "Batch 156 de 848\n",
            "Batch 157 de 848\n",
            "Batch 158 de 848\n",
            "Batch 159 de 848\n",
            "Batch 160 de 848\n",
            "Batch 161 de 848\n",
            "Batch 162 de 848\n",
            "Batch 163 de 848\n",
            "Batch 164 de 848\n",
            "Batch 165 de 848\n",
            "Batch 166 de 848\n",
            "Batch 167 de 848\n",
            "Batch 168 de 848\n",
            "Batch 169 de 848\n",
            "Batch 170 de 848\n",
            "Batch 171 de 848\n",
            "Batch 172 de 848\n",
            "Batch 173 de 848\n",
            "Batch 174 de 848\n",
            "Batch 175 de 848\n",
            "Batch 176 de 848\n",
            "Batch 177 de 848\n",
            "Batch 178 de 848\n",
            "Batch 179 de 848\n",
            "Batch 180 de 848\n",
            "Batch 181 de 848\n",
            "Batch 182 de 848\n",
            "Batch 183 de 848\n",
            "Batch 184 de 848\n",
            "Batch 185 de 848\n",
            "Batch 186 de 848\n",
            "Batch 187 de 848\n",
            "Batch 188 de 848\n",
            "Batch 189 de 848\n",
            "Batch 190 de 848\n",
            "Batch 191 de 848\n",
            "Batch 192 de 848\n",
            "Batch 193 de 848\n",
            "Batch 194 de 848\n",
            "Batch 195 de 848\n",
            "Batch 196 de 848\n",
            "Batch 197 de 848\n",
            "Batch 198 de 848\n",
            "Batch 199 de 848\n",
            "Batch 200 de 848\n",
            "Batch 201 de 848\n",
            "Batch 202 de 848\n",
            "Batch 203 de 848\n",
            "Batch 204 de 848\n",
            "Batch 205 de 848\n",
            "Batch 206 de 848\n",
            "Batch 207 de 848\n",
            "Batch 208 de 848\n",
            "Batch 209 de 848\n",
            "Batch 210 de 848\n",
            "Batch 211 de 848\n",
            "Batch 212 de 848\n",
            "Batch 213 de 848\n",
            "Batch 214 de 848\n",
            "Batch 215 de 848\n",
            "Batch 216 de 848\n",
            "Batch 217 de 848\n",
            "Batch 218 de 848\n",
            "Batch 219 de 848\n",
            "Batch 220 de 848\n",
            "Batch 221 de 848\n",
            "Batch 222 de 848\n",
            "Batch 223 de 848\n",
            "Batch 224 de 848\n",
            "Batch 225 de 848\n",
            "Batch 226 de 848\n",
            "Batch 227 de 848\n",
            "Batch 228 de 848\n",
            "Batch 229 de 848\n",
            "Batch 230 de 848\n",
            "Batch 231 de 848\n",
            "Batch 232 de 848\n",
            "Batch 233 de 848\n",
            "Batch 234 de 848\n",
            "Batch 235 de 848\n",
            "Batch 236 de 848\n",
            "Batch 237 de 848\n",
            "Batch 238 de 848\n",
            "Batch 239 de 848\n",
            "Batch 240 de 848\n",
            "Batch 241 de 848\n",
            "Batch 242 de 848\n",
            "Batch 243 de 848\n",
            "Batch 244 de 848\n",
            "Batch 245 de 848\n",
            "Batch 246 de 848\n",
            "Batch 247 de 848\n",
            "Batch 248 de 848\n",
            "Batch 249 de 848\n",
            "Batch 250 de 848\n",
            "Batch 251 de 848\n",
            "Batch 252 de 848\n",
            "Batch 253 de 848\n",
            "Batch 254 de 848\n",
            "Batch 255 de 848\n",
            "Batch 256 de 848\n",
            "Batch 257 de 848\n",
            "Batch 258 de 848\n",
            "Batch 259 de 848\n",
            "Batch 260 de 848\n",
            "Batch 261 de 848\n",
            "Batch 262 de 848\n",
            "Batch 263 de 848\n",
            "Batch 264 de 848\n",
            "Batch 265 de 848\n",
            "Batch 266 de 848\n",
            "Batch 267 de 848\n",
            "Batch 268 de 848\n",
            "Batch 269 de 848\n",
            "Batch 270 de 848\n",
            "Batch 271 de 848\n",
            "Batch 272 de 848\n",
            "Batch 273 de 848\n",
            "Batch 274 de 848\n",
            "Batch 275 de 848\n",
            "Batch 276 de 848\n",
            "Batch 277 de 848\n",
            "Batch 278 de 848\n",
            "Batch 279 de 848\n",
            "Batch 280 de 848\n",
            "Batch 281 de 848\n",
            "Batch 282 de 848\n",
            "Batch 283 de 848\n",
            "Batch 284 de 848\n",
            "Batch 285 de 848\n",
            "Batch 286 de 848\n",
            "Batch 287 de 848\n",
            "Batch 288 de 848\n",
            "Batch 289 de 848\n",
            "Batch 290 de 848\n",
            "Batch 291 de 848\n",
            "Batch 292 de 848\n",
            "Batch 293 de 848\n",
            "Batch 294 de 848\n",
            "Batch 295 de 848\n",
            "Batch 296 de 848\n",
            "Batch 297 de 848\n",
            "Batch 298 de 848\n",
            "Batch 299 de 848\n",
            "Batch 300 de 848\n",
            "Batch 301 de 848\n",
            "Batch 302 de 848\n",
            "Batch 303 de 848\n",
            "Batch 304 de 848\n",
            "Batch 305 de 848\n",
            "Batch 306 de 848\n",
            "Batch 307 de 848\n",
            "Batch 308 de 848\n",
            "Batch 309 de 848\n",
            "Batch 310 de 848\n",
            "Batch 311 de 848\n",
            "Batch 312 de 848\n",
            "Batch 313 de 848\n",
            "Batch 314 de 848\n",
            "Batch 315 de 848\n",
            "Batch 316 de 848\n",
            "Batch 317 de 848\n",
            "Batch 318 de 848\n",
            "Batch 319 de 848\n",
            "Batch 320 de 848\n",
            "Batch 321 de 848\n",
            "Batch 322 de 848\n",
            "Batch 323 de 848\n",
            "Batch 324 de 848\n",
            "Batch 325 de 848\n",
            "Batch 326 de 848\n",
            "Batch 327 de 848\n",
            "Batch 328 de 848\n",
            "Batch 329 de 848\n",
            "Batch 330 de 848\n",
            "Batch 331 de 848\n",
            "Batch 332 de 848\n",
            "Batch 333 de 848\n",
            "Batch 334 de 848\n",
            "Batch 335 de 848\n",
            "Batch 336 de 848\n",
            "Batch 337 de 848\n",
            "Batch 338 de 848\n",
            "Batch 339 de 848\n",
            "Batch 340 de 848\n",
            "Batch 341 de 848\n",
            "Batch 342 de 848\n",
            "Batch 343 de 848\n",
            "Batch 344 de 848\n",
            "Batch 345 de 848\n",
            "Batch 346 de 848\n",
            "Batch 347 de 848\n",
            "Batch 348 de 848\n",
            "Batch 349 de 848\n",
            "Batch 350 de 848\n",
            "Batch 351 de 848\n",
            "Batch 352 de 848\n",
            "Batch 353 de 848\n",
            "Batch 354 de 848\n",
            "Batch 355 de 848\n",
            "Batch 356 de 848\n",
            "Batch 357 de 848\n",
            "Batch 358 de 848\n",
            "Batch 359 de 848\n",
            "Batch 360 de 848\n",
            "Batch 361 de 848\n",
            "Batch 362 de 848\n",
            "Batch 363 de 848\n",
            "Batch 364 de 848\n",
            "Batch 365 de 848\n",
            "Batch 366 de 848\n",
            "Batch 367 de 848\n",
            "Batch 368 de 848\n",
            "Batch 369 de 848\n",
            "Batch 370 de 848\n",
            "Batch 371 de 848\n",
            "Batch 372 de 848\n",
            "Batch 373 de 848\n",
            "Batch 374 de 848\n",
            "Batch 375 de 848\n",
            "Batch 376 de 848\n",
            "Batch 377 de 848\n",
            "Batch 378 de 848\n",
            "Batch 379 de 848\n",
            "Batch 380 de 848\n",
            "Batch 381 de 848\n",
            "Batch 382 de 848\n",
            "Batch 383 de 848\n",
            "Batch 384 de 848\n",
            "Batch 385 de 848\n",
            "Batch 386 de 848\n",
            "Batch 387 de 848\n",
            "Batch 388 de 848\n",
            "Batch 389 de 848\n",
            "Batch 390 de 848\n",
            "Batch 391 de 848\n",
            "Batch 392 de 848\n",
            "Batch 393 de 848\n",
            "Batch 394 de 848\n",
            "Batch 395 de 848\n",
            "Batch 396 de 848\n",
            "Batch 397 de 848\n",
            "Batch 398 de 848\n",
            "Batch 399 de 848\n",
            "Batch 400 de 848\n",
            "Batch 401 de 848\n",
            "Batch 402 de 848\n",
            "Batch 403 de 848\n",
            "Batch 404 de 848\n",
            "Batch 405 de 848\n",
            "Batch 406 de 848\n",
            "Batch 407 de 848\n",
            "Batch 408 de 848\n",
            "Batch 409 de 848\n",
            "Batch 410 de 848\n",
            "Batch 411 de 848\n",
            "Batch 412 de 848\n",
            "Batch 413 de 848\n",
            "Batch 414 de 848\n",
            "Batch 415 de 848\n",
            "Batch 416 de 848\n",
            "Batch 417 de 848\n",
            "Batch 418 de 848\n",
            "Batch 419 de 848\n",
            "Batch 420 de 848\n",
            "Batch 421 de 848\n",
            "Batch 422 de 848\n",
            "Batch 423 de 848\n",
            "Batch 424 de 848\n",
            "Batch 425 de 848\n",
            "Batch 426 de 848\n",
            "Batch 427 de 848\n",
            "Batch 428 de 848\n",
            "Batch 429 de 848\n",
            "Batch 430 de 848\n",
            "Batch 431 de 848\n",
            "Batch 432 de 848\n",
            "Batch 433 de 848\n",
            "Batch 434 de 848\n",
            "Batch 435 de 848\n",
            "Batch 436 de 848\n",
            "Batch 437 de 848\n",
            "Batch 438 de 848\n",
            "Batch 439 de 848\n",
            "Batch 440 de 848\n",
            "Batch 441 de 848\n",
            "Batch 442 de 848\n",
            "Batch 443 de 848\n",
            "Batch 444 de 848\n",
            "Batch 445 de 848\n",
            "Batch 446 de 848\n",
            "Batch 447 de 848\n",
            "Batch 448 de 848\n",
            "Batch 449 de 848\n",
            "Batch 450 de 848\n",
            "Batch 451 de 848\n",
            "Batch 452 de 848\n",
            "Batch 453 de 848\n",
            "Batch 454 de 848\n",
            "Batch 455 de 848\n",
            "Batch 456 de 848\n",
            "Batch 457 de 848\n",
            "Batch 458 de 848\n",
            "Batch 459 de 848\n",
            "Batch 460 de 848\n",
            "Batch 461 de 848\n",
            "Batch 462 de 848\n",
            "Batch 463 de 848\n",
            "Batch 464 de 848\n",
            "Batch 465 de 848\n",
            "Batch 466 de 848\n",
            "Batch 467 de 848\n",
            "Batch 468 de 848\n",
            "Batch 469 de 848\n",
            "Batch 470 de 848\n",
            "Batch 471 de 848\n",
            "Batch 472 de 848\n",
            "Batch 473 de 848\n",
            "Batch 474 de 848\n",
            "Batch 475 de 848\n",
            "Batch 476 de 848\n",
            "Batch 477 de 848\n",
            "Batch 478 de 848\n",
            "Batch 479 de 848\n",
            "Batch 480 de 848\n",
            "Batch 481 de 848\n",
            "Batch 482 de 848\n",
            "Batch 483 de 848\n",
            "Batch 484 de 848\n",
            "Batch 485 de 848\n",
            "Batch 486 de 848\n",
            "Batch 487 de 848\n",
            "Batch 488 de 848\n",
            "Batch 489 de 848\n",
            "Batch 490 de 848\n",
            "Batch 491 de 848\n",
            "Batch 492 de 848\n",
            "Batch 493 de 848\n",
            "Batch 494 de 848\n",
            "Batch 495 de 848\n",
            "Batch 496 de 848\n",
            "Batch 497 de 848\n",
            "Batch 498 de 848\n",
            "Batch 499 de 848\n",
            "Batch 500 de 848\n",
            "Batch 501 de 848\n",
            "Batch 502 de 848\n",
            "Batch 503 de 848\n",
            "Batch 504 de 848\n",
            "Batch 505 de 848\n",
            "Batch 506 de 848\n",
            "Batch 507 de 848\n",
            "Batch 508 de 848\n",
            "Batch 509 de 848\n",
            "Batch 510 de 848\n",
            "Batch 511 de 848\n",
            "Batch 512 de 848\n",
            "Batch 513 de 848\n",
            "Batch 514 de 848\n",
            "Batch 515 de 848\n",
            "Batch 516 de 848\n",
            "Batch 517 de 848\n",
            "Batch 518 de 848\n",
            "Batch 519 de 848\n",
            "Batch 520 de 848\n",
            "Batch 521 de 848\n",
            "Batch 522 de 848\n",
            "Batch 523 de 848\n",
            "Batch 524 de 848\n",
            "Batch 525 de 848\n",
            "Batch 526 de 848\n",
            "Batch 527 de 848\n",
            "Batch 528 de 848\n",
            "Batch 529 de 848\n",
            "Batch 530 de 848\n",
            "Batch 531 de 848\n",
            "Batch 532 de 848\n",
            "Batch 533 de 848\n",
            "Batch 534 de 848\n",
            "Batch 535 de 848\n",
            "Batch 536 de 848\n",
            "Batch 537 de 848\n",
            "Batch 538 de 848\n",
            "Batch 539 de 848\n",
            "Batch 540 de 848\n",
            "Batch 541 de 848\n",
            "Batch 542 de 848\n",
            "Batch 543 de 848\n",
            "Batch 544 de 848\n",
            "Batch 545 de 848\n",
            "Batch 546 de 848\n",
            "Batch 547 de 848\n",
            "Batch 548 de 848\n",
            "Batch 549 de 848\n",
            "Batch 550 de 848\n",
            "Batch 551 de 848\n",
            "Batch 552 de 848\n",
            "Batch 553 de 848\n",
            "Batch 554 de 848\n",
            "Batch 555 de 848\n",
            "Batch 556 de 848\n",
            "Batch 557 de 848\n",
            "Batch 558 de 848\n",
            "Batch 559 de 848\n",
            "Batch 560 de 848\n",
            "Batch 561 de 848\n",
            "Batch 562 de 848\n",
            "Batch 563 de 848\n",
            "Batch 564 de 848\n",
            "Batch 565 de 848\n",
            "Batch 566 de 848\n",
            "Batch 567 de 848\n",
            "Batch 568 de 848\n",
            "Batch 569 de 848\n",
            "Batch 570 de 848\n",
            "Batch 571 de 848\n",
            "Batch 572 de 848\n",
            "Batch 573 de 848\n",
            "Batch 574 de 848\n",
            "Batch 575 de 848\n",
            "Batch 576 de 848\n",
            "Batch 577 de 848\n",
            "Batch 578 de 848\n",
            "Batch 579 de 848\n",
            "Batch 580 de 848\n",
            "Batch 581 de 848\n",
            "Batch 582 de 848\n",
            "Batch 583 de 848\n",
            "Batch 584 de 848\n",
            "Batch 585 de 848\n",
            "Batch 586 de 848\n",
            "Batch 587 de 848\n",
            "Batch 588 de 848\n",
            "Batch 589 de 848\n",
            "Batch 590 de 848\n",
            "Batch 591 de 848\n",
            "Batch 592 de 848\n",
            "Batch 593 de 848\n",
            "Batch 594 de 848\n",
            "Batch 595 de 848\n",
            "Batch 596 de 848\n",
            "Batch 597 de 848\n",
            "Batch 598 de 848\n",
            "Batch 599 de 848\n",
            "Batch 600 de 848\n",
            "Batch 601 de 848\n",
            "Batch 602 de 848\n",
            "Batch 603 de 848\n",
            "Batch 604 de 848\n",
            "Batch 605 de 848\n",
            "Batch 606 de 848\n",
            "Batch 607 de 848\n",
            "Batch 608 de 848\n",
            "Batch 609 de 848\n",
            "Batch 610 de 848\n",
            "Batch 611 de 848\n",
            "Batch 612 de 848\n",
            "Batch 613 de 848\n",
            "Batch 614 de 848\n",
            "Batch 615 de 848\n",
            "Batch 616 de 848\n",
            "Batch 617 de 848\n",
            "Batch 618 de 848\n",
            "Batch 619 de 848\n",
            "Batch 620 de 848\n",
            "Batch 621 de 848\n",
            "Batch 622 de 848\n",
            "Batch 623 de 848\n",
            "Batch 624 de 848\n",
            "Batch 625 de 848\n",
            "Batch 626 de 848\n",
            "Batch 627 de 848\n",
            "Batch 628 de 848\n",
            "Batch 629 de 848\n",
            "Batch 630 de 848\n",
            "Batch 631 de 848\n",
            "Batch 632 de 848\n",
            "Batch 633 de 848\n",
            "Batch 634 de 848\n",
            "Batch 635 de 848\n",
            "Batch 636 de 848\n",
            "Batch 637 de 848\n",
            "Batch 638 de 848\n",
            "Batch 639 de 848\n",
            "Batch 640 de 848\n",
            "Batch 641 de 848\n",
            "Batch 642 de 848\n",
            "Batch 643 de 848\n",
            "Batch 644 de 848\n",
            "Batch 645 de 848\n",
            "Batch 646 de 848\n",
            "Batch 647 de 848\n",
            "Batch 648 de 848\n",
            "Batch 649 de 848\n",
            "Batch 650 de 848\n",
            "Batch 651 de 848\n",
            "Batch 652 de 848\n",
            "Batch 653 de 848\n",
            "Batch 654 de 848\n",
            "Batch 655 de 848\n",
            "Batch 656 de 848\n",
            "Batch 657 de 848\n",
            "Batch 658 de 848\n",
            "Batch 659 de 848\n",
            "Batch 660 de 848\n",
            "Batch 661 de 848\n",
            "Batch 662 de 848\n",
            "Batch 663 de 848\n",
            "Batch 664 de 848\n",
            "Batch 665 de 848\n",
            "Batch 666 de 848\n",
            "Batch 667 de 848\n",
            "Batch 668 de 848\n",
            "Batch 669 de 848\n",
            "Batch 670 de 848\n",
            "Batch 671 de 848\n",
            "Batch 672 de 848\n",
            "Batch 673 de 848\n",
            "Batch 674 de 848\n",
            "Batch 675 de 848\n",
            "Batch 676 de 848\n",
            "Batch 677 de 848\n",
            "Batch 678 de 848\n",
            "Batch 679 de 848\n",
            "Batch 680 de 848\n",
            "Batch 681 de 848\n",
            "Batch 682 de 848\n",
            "Batch 683 de 848\n",
            "Batch 684 de 848\n",
            "Batch 685 de 848\n",
            "Batch 686 de 848\n",
            "Batch 687 de 848\n",
            "Batch 688 de 848\n",
            "Batch 689 de 848\n",
            "Batch 690 de 848\n",
            "Batch 691 de 848\n",
            "Batch 692 de 848\n",
            "Batch 693 de 848\n",
            "Batch 694 de 848\n",
            "Batch 695 de 848\n",
            "Batch 696 de 848\n",
            "Batch 697 de 848\n",
            "Batch 698 de 848\n",
            "Batch 699 de 848\n",
            "Batch 700 de 848\n",
            "Batch 701 de 848\n",
            "Batch 702 de 848\n",
            "Batch 703 de 848\n",
            "Batch 704 de 848\n",
            "Batch 705 de 848\n",
            "Batch 706 de 848\n",
            "Batch 707 de 848\n",
            "Batch 708 de 848\n",
            "Batch 709 de 848\n",
            "Batch 710 de 848\n",
            "Batch 711 de 848\n",
            "Batch 712 de 848\n",
            "Batch 713 de 848\n",
            "Batch 714 de 848\n",
            "Batch 715 de 848\n",
            "Batch 716 de 848\n",
            "Batch 717 de 848\n",
            "Batch 718 de 848\n",
            "Batch 719 de 848\n",
            "Batch 720 de 848\n",
            "Batch 721 de 848\n",
            "Batch 722 de 848\n",
            "Batch 723 de 848\n",
            "Batch 724 de 848\n",
            "Batch 725 de 848\n",
            "Batch 726 de 848\n",
            "Batch 727 de 848\n",
            "Batch 728 de 848\n",
            "Batch 729 de 848\n",
            "Batch 730 de 848\n",
            "Batch 731 de 848\n",
            "Batch 732 de 848\n",
            "Batch 733 de 848\n",
            "Batch 734 de 848\n",
            "Batch 735 de 848\n",
            "Batch 736 de 848\n",
            "Batch 737 de 848\n",
            "Batch 738 de 848\n",
            "Batch 739 de 848\n",
            "Batch 740 de 848\n",
            "Batch 741 de 848\n",
            "Batch 742 de 848\n",
            "Batch 743 de 848\n",
            "Batch 744 de 848\n",
            "Batch 745 de 848\n",
            "Batch 746 de 848\n",
            "Batch 747 de 848\n",
            "Batch 748 de 848\n",
            "Batch 749 de 848\n",
            "Batch 750 de 848\n",
            "Batch 751 de 848\n",
            "Batch 752 de 848\n",
            "Batch 753 de 848\n",
            "Batch 754 de 848\n",
            "Batch 755 de 848\n",
            "Batch 756 de 848\n",
            "Batch 757 de 848\n",
            "Batch 758 de 848\n",
            "Batch 759 de 848\n",
            "Batch 760 de 848\n",
            "Batch 761 de 848\n",
            "Batch 762 de 848\n",
            "Batch 763 de 848\n",
            "Batch 764 de 848\n",
            "Batch 765 de 848\n",
            "Batch 766 de 848\n",
            "Batch 767 de 848\n",
            "Batch 768 de 848\n",
            "Batch 769 de 848\n",
            "Batch 770 de 848\n",
            "Batch 771 de 848\n",
            "Batch 772 de 848\n",
            "Batch 773 de 848\n",
            "Batch 774 de 848\n",
            "Batch 775 de 848\n",
            "Batch 776 de 848\n",
            "Batch 777 de 848\n",
            "Batch 778 de 848\n",
            "Batch 779 de 848\n",
            "Batch 780 de 848\n",
            "Batch 781 de 848\n",
            "Batch 782 de 848\n",
            "Batch 783 de 848\n",
            "Batch 784 de 848\n",
            "Batch 785 de 848\n",
            "Batch 786 de 848\n",
            "Batch 787 de 848\n",
            "Batch 788 de 848\n",
            "Batch 789 de 848\n",
            "Batch 790 de 848\n",
            "Batch 791 de 848\n",
            "Batch 792 de 848\n",
            "Batch 793 de 848\n",
            "Batch 794 de 848\n",
            "Batch 795 de 848\n",
            "Batch 796 de 848\n",
            "Batch 797 de 848\n",
            "Batch 798 de 848\n",
            "Batch 799 de 848\n",
            "Batch 800 de 848\n",
            "Batch 801 de 848\n",
            "Batch 802 de 848\n",
            "Batch 803 de 848\n",
            "Batch 804 de 848\n",
            "Batch 805 de 848\n",
            "Batch 806 de 848\n",
            "Batch 807 de 848\n",
            "Batch 808 de 848\n",
            "Batch 809 de 848\n",
            "Batch 810 de 848\n",
            "Batch 811 de 848\n",
            "Batch 812 de 848\n",
            "Batch 813 de 848\n",
            "Batch 814 de 848\n",
            "Batch 815 de 848\n",
            "Batch 816 de 848\n",
            "Batch 817 de 848\n",
            "Batch 818 de 848\n",
            "Batch 819 de 848\n",
            "Batch 820 de 848\n",
            "Batch 821 de 848\n",
            "Batch 822 de 848\n",
            "Batch 823 de 848\n",
            "Batch 824 de 848\n",
            "Batch 825 de 848\n",
            "Batch 826 de 848\n",
            "Batch 827 de 848\n",
            "Batch 828 de 848\n",
            "Batch 829 de 848\n",
            "Batch 830 de 848\n",
            "Batch 831 de 848\n",
            "Batch 832 de 848\n",
            "Batch 833 de 848\n",
            "Batch 834 de 848\n",
            "Batch 835 de 848\n",
            "Batch 836 de 848\n",
            "Batch 837 de 848\n",
            "Batch 838 de 848\n",
            "Batch 839 de 848\n",
            "Batch 840 de 848\n",
            "Batch 841 de 848\n",
            "Batch 842 de 848\n",
            "Batch 843 de 848\n",
            "Batch 844 de 848\n",
            "Batch 845 de 848\n",
            "Batch 846 de 848\n",
            "Batch 847 de 848\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Negation, the `-` operator, on a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-85c567ee1c1b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# Cálculo de métricas de validación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[1;32m    726\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Target size ({target.size()}) must be the same as input size ({input.size()})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Negation, the `-` operator, on a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead."
          ]
        }
      ],
      "source": [
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  avg_val_loss, val_accuracy = validationBert(model, testing_loader, loss_fn, device)"
      ],
      "id": "V0sbi_jgCyuA"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Training and Validation Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_accuracy_history, label='Training Accuracy')\n",
        "plt.plot(val_accuracy_history, label='Validation Accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Training and Validation Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_loss_history, label='Training Loss')\n",
        "plt.plot(val_loss_history, label='Validation Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nf9RfBbWDK0Y"
      },
      "id": "nf9RfBbWDK0Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IPno8yWigzH"
      },
      "source": [
        "##### Entrenamiento del modelo (50% de datos)"
      ],
      "id": "3IPno8yWigzH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-5\n",
        "- weight_decay=0.01\n",
        "- Dropout + Linear + Sigmoid"
      ],
      "metadata": {
        "id": "3bAph9W7JHpY"
      },
      "id": "3bAph9W7JHpY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab30cff3-ae41-4da3-827b-f2a40e2e8cbb",
        "id": "qakGjJdRigzM"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración; 0 de 4841, Loss: 0.067620450258255\n",
            "Epoch: 0, iteración; 10 de 4841, Loss: 0.6401959896087647\n",
            "Epoch: 0, iteración; 20 de 4841, Loss: 0.6790625095367432\n",
            "Epoch: 0, iteración; 30 de 4841, Loss: 0.636180305480957\n",
            "Epoch: 0, iteración; 40 de 4841, Loss: 0.615803575515747\n",
            "Epoch: 0, iteración; 50 de 4841, Loss: 0.5928953647613525\n",
            "Epoch: 0, iteración; 60 de 4841, Loss: 0.5950827121734619\n",
            "Epoch: 0, iteración; 70 de 4841, Loss: 0.6225556373596192\n",
            "Epoch: 0, iteración; 80 de 4841, Loss: 0.6262527465820312\n",
            "Epoch: 0, iteración; 90 de 4841, Loss: 0.6704085826873779\n",
            "Epoch: 0, iteración; 100 de 4841, Loss: 0.5660880088806153\n",
            "Epoch: 0, iteración; 110 de 4841, Loss: 0.5891512870788574\n",
            "Epoch: 0, iteración; 120 de 4841, Loss: 0.5690562725067139\n",
            "Epoch: 0, iteración; 130 de 4841, Loss: 0.6277326107025146\n",
            "Epoch: 0, iteración; 140 de 4841, Loss: 0.5980307102203369\n",
            "Epoch: 0, iteración; 150 de 4841, Loss: 0.5786302089691162\n",
            "Epoch: 0, iteración; 160 de 4841, Loss: 0.6489881992340087\n",
            "Epoch: 0, iteración; 170 de 4841, Loss: 0.5393592834472656\n",
            "Epoch: 0, iteración; 180 de 4841, Loss: 0.6667495250701905\n",
            "Epoch: 0, iteración; 190 de 4841, Loss: 0.6090113162994385\n",
            "Epoch: 0, iteración; 200 de 4841, Loss: 0.6042981147766113\n",
            "Epoch: 0, iteración; 210 de 4841, Loss: 0.5562125682830811\n",
            "Epoch: 0, iteración; 220 de 4841, Loss: 0.6250152587890625\n",
            "Epoch: 0, iteración; 230 de 4841, Loss: 0.5797287464141846\n",
            "Epoch: 0, iteración; 240 de 4841, Loss: 0.5820215225219727\n",
            "Epoch: 0, iteración; 250 de 4841, Loss: 0.5627236366271973\n",
            "Epoch: 0, iteración; 260 de 4841, Loss: 0.5695945262908936\n",
            "Epoch: 0, iteración; 270 de 4841, Loss: 0.5915817260742188\n",
            "Epoch: 0, iteración; 280 de 4841, Loss: 0.5495197296142578\n",
            "Epoch: 0, iteración; 290 de 4841, Loss: 0.6068787097930908\n",
            "Epoch: 0, iteración; 300 de 4841, Loss: 0.631460428237915\n",
            "Epoch: 0, iteración; 310 de 4841, Loss: 0.6082886219024658\n",
            "Epoch: 0, iteración; 320 de 4841, Loss: 0.606642770767212\n",
            "Epoch: 0, iteración; 330 de 4841, Loss: 0.6121068000793457\n",
            "Epoch: 0, iteración; 340 de 4841, Loss: 0.6108444213867188\n",
            "Epoch: 0, iteración; 350 de 4841, Loss: 0.6411845207214355\n",
            "Epoch: 0, iteración; 360 de 4841, Loss: 0.5864518165588379\n",
            "Epoch: 0, iteración; 370 de 4841, Loss: 0.6372950553894043\n",
            "Epoch: 0, iteración; 380 de 4841, Loss: 0.5744706630706787\n",
            "Epoch: 0, iteración; 390 de 4841, Loss: 0.5841310024261475\n",
            "Epoch: 0, iteración; 400 de 4841, Loss: 0.5804859638214112\n",
            "Epoch: 0, iteración; 410 de 4841, Loss: 0.5680671215057373\n",
            "Epoch: 0, iteración; 420 de 4841, Loss: 0.5468954086303711\n",
            "Epoch: 0, iteración; 430 de 4841, Loss: 0.5956437587738037\n",
            "Epoch: 0, iteración; 440 de 4841, Loss: 0.5210260868072509\n",
            "Epoch: 0, iteración; 450 de 4841, Loss: 0.5500447273254394\n",
            "Epoch: 0, iteración; 460 de 4841, Loss: 0.5752652168273926\n",
            "Epoch: 0, iteración; 470 de 4841, Loss: 0.560142707824707\n",
            "Epoch: 0, iteración; 480 de 4841, Loss: 0.5761887550354003\n",
            "Epoch: 0, iteración; 490 de 4841, Loss: 0.5778646469116211\n",
            "Epoch: 0, iteración; 500 de 4841, Loss: 0.5233136177062988\n",
            "Epoch: 0, iteración; 510 de 4841, Loss: 0.545984411239624\n",
            "Epoch: 0, iteración; 520 de 4841, Loss: 0.641881799697876\n",
            "Epoch: 0, iteración; 530 de 4841, Loss: 0.568964672088623\n",
            "Epoch: 0, iteración; 540 de 4841, Loss: 0.6330692291259765\n",
            "Epoch: 0, iteración; 550 de 4841, Loss: 0.5410346984863281\n",
            "Epoch: 0, iteración; 560 de 4841, Loss: 0.633858585357666\n",
            "Epoch: 0, iteración; 570 de 4841, Loss: 0.6077178001403809\n",
            "Epoch: 0, iteración; 580 de 4841, Loss: 0.5098548412322998\n",
            "Epoch: 0, iteración; 590 de 4841, Loss: 0.6164947509765625\n",
            "Epoch: 0, iteración; 600 de 4841, Loss: 0.5805582046508789\n",
            "Epoch: 0, iteración; 610 de 4841, Loss: 0.5247857093811035\n",
            "Epoch: 0, iteración; 620 de 4841, Loss: 0.5869471549987793\n",
            "Epoch: 0, iteración; 630 de 4841, Loss: 0.5689478874206543\n",
            "Epoch: 0, iteración; 640 de 4841, Loss: 0.571108055114746\n",
            "Epoch: 0, iteración; 650 de 4841, Loss: 0.5241982936859131\n",
            "Epoch: 0, iteración; 660 de 4841, Loss: 0.5664725780487061\n",
            "Epoch: 0, iteración; 670 de 4841, Loss: 0.5772261619567871\n",
            "Epoch: 0, iteración; 680 de 4841, Loss: 0.46405801773071287\n",
            "Epoch: 0, iteración; 690 de 4841, Loss: 0.5363720417022705\n",
            "Epoch: 0, iteración; 700 de 4841, Loss: 0.5566173553466797\n",
            "Epoch: 0, iteración; 710 de 4841, Loss: 0.5011982917785645\n",
            "Epoch: 0, iteración; 720 de 4841, Loss: 0.5524994373321533\n",
            "Epoch: 0, iteración; 730 de 4841, Loss: 0.6688055992126465\n",
            "Epoch: 0, iteración; 740 de 4841, Loss: 0.5808986186981201\n",
            "Epoch: 0, iteración; 750 de 4841, Loss: 0.564202356338501\n",
            "Epoch: 0, iteración; 760 de 4841, Loss: 0.5568315505981445\n",
            "Epoch: 0, iteración; 770 de 4841, Loss: 0.5027121067047119\n",
            "Epoch: 0, iteración; 780 de 4841, Loss: 0.5077766418457031\n",
            "Epoch: 0, iteración; 790 de 4841, Loss: 0.5382068634033204\n",
            "Epoch: 0, iteración; 800 de 4841, Loss: 0.5719078063964844\n",
            "Epoch: 0, iteración; 810 de 4841, Loss: 0.624750804901123\n",
            "Epoch: 0, iteración; 820 de 4841, Loss: 0.6120494842529297\n",
            "Epoch: 0, iteración; 830 de 4841, Loss: 0.5206179618835449\n",
            "Epoch: 0, iteración; 840 de 4841, Loss: 0.557524585723877\n",
            "Epoch: 0, iteración; 850 de 4841, Loss: 0.5632938385009766\n",
            "Epoch: 0, iteración; 860 de 4841, Loss: 0.6050653457641602\n",
            "Epoch: 0, iteración; 870 de 4841, Loss: 0.5251437187194824\n",
            "Epoch: 0, iteración; 880 de 4841, Loss: 0.5028220653533936\n",
            "Epoch: 0, iteración; 890 de 4841, Loss: 0.5495881080627442\n",
            "Epoch: 0, iteración; 900 de 4841, Loss: 0.6406683444976806\n",
            "Epoch: 0, iteración; 910 de 4841, Loss: 0.519324541091919\n",
            "Epoch: 0, iteración; 920 de 4841, Loss: 0.5368908882141114\n",
            "Epoch: 0, iteración; 930 de 4841, Loss: 0.5282161712646485\n",
            "Epoch: 0, iteración; 940 de 4841, Loss: 0.5631831169128418\n",
            "Epoch: 0, iteración; 950 de 4841, Loss: 0.5777354717254639\n",
            "Epoch: 0, iteración; 960 de 4841, Loss: 0.5316629409790039\n",
            "Epoch: 0, iteración; 970 de 4841, Loss: 0.5695140838623047\n",
            "Epoch: 0, iteración; 980 de 4841, Loss: 0.507757568359375\n",
            "Epoch: 0, iteración; 990 de 4841, Loss: 0.46700272560119627\n",
            "Epoch: 0, iteración; 1000 de 4841, Loss: 0.5284052848815918\n",
            "Epoch: 0, iteración; 1010 de 4841, Loss: 0.5033587455749512\n",
            "Epoch: 0, iteración; 1020 de 4841, Loss: 0.5403049468994141\n",
            "Epoch: 0, iteración; 1030 de 4841, Loss: 0.5130756378173829\n",
            "Epoch: 0, iteración; 1040 de 4841, Loss: 0.5308436393737793\n",
            "Epoch: 0, iteración; 1050 de 4841, Loss: 0.506157636642456\n",
            "Epoch: 0, iteración; 1060 de 4841, Loss: 0.5860042572021484\n",
            "Epoch: 0, iteración; 1070 de 4841, Loss: 0.5233758926391602\n",
            "Epoch: 0, iteración; 1080 de 4841, Loss: 0.5819717407226562\n",
            "Epoch: 0, iteración; 1090 de 4841, Loss: 0.5699958801269531\n",
            "Epoch: 0, iteración; 1100 de 4841, Loss: 0.6320727348327637\n",
            "Epoch: 0, iteración; 1110 de 4841, Loss: 0.49780969619750975\n",
            "Epoch: 0, iteración; 1120 de 4841, Loss: 0.5622701168060302\n",
            "Epoch: 0, iteración; 1130 de 4841, Loss: 0.48981237411499023\n",
            "Epoch: 0, iteración; 1140 de 4841, Loss: 0.5186872005462646\n",
            "Epoch: 0, iteración; 1150 de 4841, Loss: 0.5224852085113525\n",
            "Epoch: 0, iteración; 1160 de 4841, Loss: 0.5382130146026611\n",
            "Epoch: 0, iteración; 1170 de 4841, Loss: 0.5585520744323731\n",
            "Epoch: 0, iteración; 1180 de 4841, Loss: 0.5402756214141846\n",
            "Epoch: 0, iteración; 1190 de 4841, Loss: 0.5465103626251221\n",
            "Epoch: 0, iteración; 1200 de 4841, Loss: 0.6100862979888916\n",
            "Epoch: 0, iteración; 1210 de 4841, Loss: 0.6152403354644775\n",
            "Epoch: 0, iteración; 1220 de 4841, Loss: 0.5329653739929199\n",
            "Epoch: 0, iteración; 1230 de 4841, Loss: 0.5342480659484863\n",
            "Epoch: 0, iteración; 1240 de 4841, Loss: 0.5711104869842529\n",
            "Epoch: 0, iteración; 1250 de 4841, Loss: 0.5685783386230469\n",
            "Epoch: 0, iteración; 1260 de 4841, Loss: 0.5424998760223388\n",
            "Epoch: 0, iteración; 1270 de 4841, Loss: 0.5490983963012696\n",
            "Epoch: 0, iteración; 1280 de 4841, Loss: 0.5778781414031983\n",
            "Epoch: 0, iteración; 1290 de 4841, Loss: 0.5612752437591553\n",
            "Epoch: 0, iteración; 1300 de 4841, Loss: 0.5738325119018555\n",
            "Epoch: 0, iteración; 1310 de 4841, Loss: 0.5761303424835205\n",
            "Epoch: 0, iteración; 1320 de 4841, Loss: 0.5431459426879883\n",
            "Epoch: 0, iteración; 1330 de 4841, Loss: 0.49936890602111816\n",
            "Epoch: 0, iteración; 1340 de 4841, Loss: 0.5022769927978515\n",
            "Epoch: 0, iteración; 1350 de 4841, Loss: 0.5306902408599854\n",
            "Epoch: 0, iteración; 1360 de 4841, Loss: 0.5275452136993408\n",
            "Epoch: 0, iteración; 1370 de 4841, Loss: 0.519055700302124\n",
            "Epoch: 0, iteración; 1380 de 4841, Loss: 0.5370886325836182\n",
            "Epoch: 0, iteración; 1390 de 4841, Loss: 0.5756605625152588\n",
            "Epoch: 0, iteración; 1400 de 4841, Loss: 0.5081933975219727\n",
            "Epoch: 0, iteración; 1410 de 4841, Loss: 0.5461589813232421\n",
            "Epoch: 0, iteración; 1420 de 4841, Loss: 0.5928447723388672\n",
            "Epoch: 0, iteración; 1430 de 4841, Loss: 0.5214805126190185\n",
            "Epoch: 0, iteración; 1440 de 4841, Loss: 0.5533836841583252\n",
            "Epoch: 0, iteración; 1450 de 4841, Loss: 0.5415185928344727\n",
            "Epoch: 0, iteración; 1460 de 4841, Loss: 0.5601385593414306\n",
            "Epoch: 0, iteración; 1470 de 4841, Loss: 0.6400893688201904\n",
            "Epoch: 0, iteración; 1480 de 4841, Loss: 0.5466148376464843\n",
            "Epoch: 0, iteración; 1490 de 4841, Loss: 0.5619148731231689\n",
            "Epoch: 0, iteración; 1500 de 4841, Loss: 0.5086212158203125\n",
            "Epoch: 0, iteración; 1510 de 4841, Loss: 0.4822216033935547\n",
            "Epoch: 0, iteración; 1520 de 4841, Loss: 0.6018047332763672\n",
            "Epoch: 0, iteración; 1530 de 4841, Loss: 0.5395347118377686\n",
            "Epoch: 0, iteración; 1540 de 4841, Loss: 0.5922419548034668\n",
            "Epoch: 0, iteración; 1550 de 4841, Loss: 0.5845789909362793\n",
            "Epoch: 0, iteración; 1560 de 4841, Loss: 0.5252731323242188\n",
            "Epoch: 0, iteración; 1570 de 4841, Loss: 0.48334307670593263\n",
            "Epoch: 0, iteración; 1580 de 4841, Loss: 0.6240840911865234\n",
            "Epoch: 0, iteración; 1590 de 4841, Loss: 0.5058200836181641\n",
            "Epoch: 0, iteración; 1600 de 4841, Loss: 0.5363160133361816\n",
            "Epoch: 0, iteración; 1610 de 4841, Loss: 0.5492159843444824\n",
            "Epoch: 0, iteración; 1620 de 4841, Loss: 0.5593379020690918\n",
            "Epoch: 0, iteración; 1630 de 4841, Loss: 0.5535356521606445\n",
            "Epoch: 0, iteración; 1640 de 4841, Loss: 0.5464544773101807\n",
            "Epoch: 0, iteración; 1650 de 4841, Loss: 0.5524677276611328\n",
            "Epoch: 0, iteración; 1660 de 4841, Loss: 0.5199160099029541\n",
            "Epoch: 0, iteración; 1670 de 4841, Loss: 0.5094471931457519\n",
            "Epoch: 0, iteración; 1680 de 4841, Loss: 0.5237683296203614\n",
            "Epoch: 0, iteración; 1690 de 4841, Loss: 0.5180016994476319\n",
            "Epoch: 0, iteración; 1700 de 4841, Loss: 0.4838536739349365\n",
            "Epoch: 0, iteración; 1710 de 4841, Loss: 0.5275227069854737\n",
            "Epoch: 0, iteración; 1720 de 4841, Loss: 0.5205921649932861\n",
            "Epoch: 0, iteración; 1730 de 4841, Loss: 0.6081387042999268\n",
            "Epoch: 0, iteración; 1740 de 4841, Loss: 0.5889313697814942\n",
            "Epoch: 0, iteración; 1750 de 4841, Loss: 0.5902199268341064\n",
            "Epoch: 0, iteración; 1760 de 4841, Loss: 0.4730694770812988\n",
            "Epoch: 0, iteración; 1770 de 4841, Loss: 0.5563098907470703\n",
            "Epoch: 0, iteración; 1780 de 4841, Loss: 0.557317066192627\n",
            "Epoch: 0, iteración; 1790 de 4841, Loss: 0.5804052352905273\n",
            "Epoch: 0, iteración; 1800 de 4841, Loss: 0.509317684173584\n",
            "Epoch: 0, iteración; 1810 de 4841, Loss: 0.5327750682830811\n",
            "Epoch: 0, iteración; 1820 de 4841, Loss: 0.5277973651885987\n",
            "Epoch: 0, iteración; 1830 de 4841, Loss: 0.5320097923278808\n",
            "Epoch: 0, iteración; 1840 de 4841, Loss: 0.5194830894470215\n",
            "Epoch: 0, iteración; 1850 de 4841, Loss: 0.5257878780364991\n",
            "Epoch: 0, iteración; 1860 de 4841, Loss: 0.5763609886169434\n",
            "Epoch: 0, iteración; 1870 de 4841, Loss: 0.5441036701202393\n",
            "Epoch: 0, iteración; 1880 de 4841, Loss: 0.5789097785949707\n",
            "Epoch: 0, iteración; 1890 de 4841, Loss: 0.48252034187316895\n",
            "Epoch: 0, iteración; 1900 de 4841, Loss: 0.4858377933502197\n",
            "Epoch: 0, iteración; 1910 de 4841, Loss: 0.5972553253173828\n",
            "Epoch: 0, iteración; 1920 de 4841, Loss: 0.5649293422698974\n",
            "Epoch: 0, iteración; 1930 de 4841, Loss: 0.5703916549682617\n",
            "Epoch: 0, iteración; 1940 de 4841, Loss: 0.6416390419006348\n",
            "Epoch: 0, iteración; 1950 de 4841, Loss: 0.530395793914795\n",
            "Epoch: 0, iteración; 1960 de 4841, Loss: 0.6330521583557129\n",
            "Epoch: 0, iteración; 1970 de 4841, Loss: 0.6340750217437744\n",
            "Epoch: 0, iteración; 1980 de 4841, Loss: 0.5510251998901368\n",
            "Epoch: 0, iteración; 1990 de 4841, Loss: 0.679610300064087\n",
            "Epoch: 0, iteración; 2000 de 4841, Loss: 0.5754966259002685\n",
            "Epoch: 0, iteración; 2010 de 4841, Loss: 0.5667521476745605\n",
            "Epoch: 0, iteración; 2020 de 4841, Loss: 0.5965287685394287\n",
            "Epoch: 0, iteración; 2030 de 4841, Loss: 0.6026582241058349\n",
            "Epoch: 0, iteración; 2040 de 4841, Loss: 0.5871417999267579\n",
            "Epoch: 0, iteración; 2050 de 4841, Loss: 0.5442562103271484\n",
            "Epoch: 0, iteración; 2060 de 4841, Loss: 0.5674659729003906\n",
            "Epoch: 0, iteración; 2070 de 4841, Loss: 0.5285174369812011\n",
            "Epoch: 0, iteración; 2080 de 4841, Loss: 0.5376157760620117\n",
            "Epoch: 0, iteración; 2090 de 4841, Loss: 0.5319630622863769\n",
            "Epoch: 0, iteración; 2100 de 4841, Loss: 0.5332504272460937\n",
            "Epoch: 0, iteración; 2110 de 4841, Loss: 0.5622074604034424\n",
            "Epoch: 0, iteración; 2120 de 4841, Loss: 0.5761685371398926\n",
            "Epoch: 0, iteración; 2130 de 4841, Loss: 0.5878432273864747\n",
            "Epoch: 0, iteración; 2140 de 4841, Loss: 0.4916234970092773\n",
            "Epoch: 0, iteración; 2150 de 4841, Loss: 0.552874231338501\n",
            "Epoch: 0, iteración; 2160 de 4841, Loss: 0.567839527130127\n",
            "Epoch: 0, iteración; 2170 de 4841, Loss: 0.5928695678710938\n",
            "Epoch: 0, iteración; 2180 de 4841, Loss: 0.5428627014160157\n",
            "Epoch: 0, iteración; 2190 de 4841, Loss: 0.5525586128234863\n",
            "Epoch: 0, iteración; 2200 de 4841, Loss: 0.5547256946563721\n",
            "Epoch: 0, iteración; 2210 de 4841, Loss: 0.5700377464294434\n",
            "Epoch: 0, iteración; 2220 de 4841, Loss: 0.5971846103668212\n",
            "Epoch: 0, iteración; 2230 de 4841, Loss: 0.6053571224212646\n",
            "Epoch: 0, iteración; 2240 de 4841, Loss: 0.5322936058044434\n",
            "Epoch: 0, iteración; 2250 de 4841, Loss: 0.48930978775024414\n",
            "Epoch: 0, iteración; 2260 de 4841, Loss: 0.5324790954589844\n",
            "Epoch: 0, iteración; 2270 de 4841, Loss: 0.5849390983581543\n",
            "Epoch: 0, iteración; 2280 de 4841, Loss: 0.519193172454834\n",
            "Epoch: 0, iteración; 2290 de 4841, Loss: 0.5914411067962646\n",
            "Epoch: 0, iteración; 2300 de 4841, Loss: 0.4845894336700439\n",
            "Epoch: 0, iteración; 2310 de 4841, Loss: 0.5383104801177978\n",
            "Epoch: 0, iteración; 2320 de 4841, Loss: 0.6203041076660156\n",
            "Epoch: 0, iteración; 2330 de 4841, Loss: 0.6231517791748047\n",
            "Epoch: 0, iteración; 2340 de 4841, Loss: 0.5251988410949707\n",
            "Epoch: 0, iteración; 2350 de 4841, Loss: 0.5874836921691895\n",
            "Epoch: 0, iteración; 2360 de 4841, Loss: 0.5468403339385987\n",
            "Epoch: 0, iteración; 2370 de 4841, Loss: 0.6213899612426758\n",
            "Epoch: 0, iteración; 2380 de 4841, Loss: 0.5801979064941406\n",
            "Epoch: 0, iteración; 2390 de 4841, Loss: 0.5644264698028565\n",
            "Epoch: 0, iteración; 2400 de 4841, Loss: 0.5448832511901855\n",
            "Epoch: 0, iteración; 2410 de 4841, Loss: 0.544426155090332\n",
            "Epoch: 0, iteración; 2420 de 4841, Loss: 0.5600268363952636\n",
            "Epoch: 0, iteración; 2430 de 4841, Loss: 0.5630002021789551\n",
            "Epoch: 0, iteración; 2440 de 4841, Loss: 0.5275781631469727\n",
            "Epoch: 0, iteración; 2450 de 4841, Loss: 0.6113099098205567\n",
            "Epoch: 0, iteración; 2460 de 4841, Loss: 0.5195264339447021\n",
            "Epoch: 0, iteración; 2470 de 4841, Loss: 0.484022855758667\n",
            "Epoch: 0, iteración; 2480 de 4841, Loss: 0.583066177368164\n",
            "Epoch: 0, iteración; 2490 de 4841, Loss: 0.531353235244751\n",
            "Epoch: 0, iteración; 2500 de 4841, Loss: 0.5575695991516113\n",
            "Epoch: 0, iteración; 2510 de 4841, Loss: 0.49703569412231446\n",
            "Epoch: 0, iteración; 2520 de 4841, Loss: 0.4738017082214355\n",
            "Epoch: 0, iteración; 2530 de 4841, Loss: 0.523803424835205\n",
            "Epoch: 0, iteración; 2540 de 4841, Loss: 0.5807331085205079\n",
            "Epoch: 0, iteración; 2550 de 4841, Loss: 0.5512325286865234\n",
            "Epoch: 0, iteración; 2560 de 4841, Loss: 0.5674978256225586\n",
            "Epoch: 0, iteración; 2570 de 4841, Loss: 0.5414969444274902\n",
            "Epoch: 0, iteración; 2580 de 4841, Loss: 0.5139457225799561\n",
            "Epoch: 0, iteración; 2590 de 4841, Loss: 0.5663619041442871\n",
            "Epoch: 0, iteración; 2600 de 4841, Loss: 0.5493044853210449\n",
            "Epoch: 0, iteración; 2610 de 4841, Loss: 0.5673559188842774\n",
            "Epoch: 0, iteración; 2620 de 4841, Loss: 0.5246109008789063\n",
            "Epoch: 0, iteración; 2630 de 4841, Loss: 0.5094550132751465\n",
            "Epoch: 0, iteración; 2640 de 4841, Loss: 0.6088175773620605\n",
            "Epoch: 0, iteración; 2650 de 4841, Loss: 0.5772683143615722\n",
            "Epoch: 0, iteración; 2660 de 4841, Loss: 0.5277080535888672\n",
            "Epoch: 0, iteración; 2670 de 4841, Loss: 0.5809934139251709\n",
            "Epoch: 0, iteración; 2680 de 4841, Loss: 0.5653777599334717\n",
            "Epoch: 0, iteración; 2690 de 4841, Loss: 0.5507194519042968\n",
            "Epoch: 0, iteración; 2700 de 4841, Loss: 0.5163183212280273\n",
            "Epoch: 0, iteración; 2710 de 4841, Loss: 0.49021220207214355\n",
            "Epoch: 0, iteración; 2720 de 4841, Loss: 0.5138347148895264\n",
            "Epoch: 0, iteración; 2730 de 4841, Loss: 0.6689048767089844\n",
            "Epoch: 0, iteración; 2740 de 4841, Loss: 0.6326876640319824\n",
            "Epoch: 0, iteración; 2750 de 4841, Loss: 0.5332793235778809\n",
            "Epoch: 0, iteración; 2760 de 4841, Loss: 0.5213462829589843\n",
            "Epoch: 0, iteración; 2770 de 4841, Loss: 0.5754936218261719\n",
            "Epoch: 0, iteración; 2780 de 4841, Loss: 0.6138404369354248\n",
            "Epoch: 0, iteración; 2790 de 4841, Loss: 0.5827375888824463\n",
            "Epoch: 0, iteración; 2800 de 4841, Loss: 0.6341294288635254\n",
            "Epoch: 0, iteración; 2810 de 4841, Loss: 0.5407789707183838\n",
            "Epoch: 0, iteración; 2820 de 4841, Loss: 0.5727503299713135\n",
            "Epoch: 0, iteración; 2830 de 4841, Loss: 0.551280403137207\n",
            "Epoch: 0, iteración; 2840 de 4841, Loss: 0.5352114677429199\n",
            "Epoch: 0, iteración; 2850 de 4841, Loss: 0.5663200378417969\n",
            "Epoch: 0, iteración; 2860 de 4841, Loss: 0.5526519775390625\n",
            "Epoch: 0, iteración; 2870 de 4841, Loss: 0.5881209373474121\n",
            "Epoch: 0, iteración; 2880 de 4841, Loss: 0.5363192081451416\n",
            "Epoch: 0, iteración; 2890 de 4841, Loss: 0.5726879596710205\n",
            "Epoch: 0, iteración; 2900 de 4841, Loss: 0.4862618923187256\n",
            "Epoch: 0, iteración; 2910 de 4841, Loss: 0.5312782287597656\n",
            "Epoch: 0, iteración; 2920 de 4841, Loss: 0.5331676959991455\n",
            "Epoch: 0, iteración; 2930 de 4841, Loss: 0.5543828964233398\n",
            "Epoch: 0, iteración; 2940 de 4841, Loss: 0.6105451107025146\n",
            "Epoch: 0, iteración; 2950 de 4841, Loss: 0.5758874893188477\n",
            "Epoch: 0, iteración; 2960 de 4841, Loss: 0.5452620506286621\n",
            "Epoch: 0, iteración; 2970 de 4841, Loss: 0.6051726818084717\n",
            "Epoch: 0, iteración; 2980 de 4841, Loss: 0.619855546951294\n",
            "Epoch: 0, iteración; 2990 de 4841, Loss: 0.5829072952270508\n",
            "Epoch: 0, iteración; 3000 de 4841, Loss: 0.5234421253204345\n",
            "Epoch: 0, iteración; 3010 de 4841, Loss: 0.5500624179840088\n",
            "Epoch: 0, iteración; 3020 de 4841, Loss: 0.5271115303039551\n",
            "Epoch: 0, iteración; 3030 de 4841, Loss: 0.5857753753662109\n",
            "Epoch: 0, iteración; 3040 de 4841, Loss: 0.5441348075866699\n",
            "Epoch: 0, iteración; 3050 de 4841, Loss: 0.6351062774658203\n",
            "Epoch: 0, iteración; 3060 de 4841, Loss: 0.6177299499511719\n",
            "Epoch: 0, iteración; 3070 de 4841, Loss: 0.5778625011444092\n",
            "Epoch: 0, iteración; 3080 de 4841, Loss: 0.5580598831176757\n",
            "Epoch: 0, iteración; 3090 de 4841, Loss: 0.5947901248931885\n",
            "Epoch: 0, iteración; 3100 de 4841, Loss: 0.6006803512573242\n",
            "Epoch: 0, iteración; 3110 de 4841, Loss: 0.5513200283050537\n",
            "Epoch: 0, iteración; 3120 de 4841, Loss: 0.5250356674194336\n",
            "Epoch: 0, iteración; 3130 de 4841, Loss: 0.5877913475036621\n",
            "Epoch: 0, iteración; 3140 de 4841, Loss: 0.5057024002075196\n",
            "Epoch: 0, iteración; 3150 de 4841, Loss: 0.499301815032959\n",
            "Epoch: 0, iteración; 3160 de 4841, Loss: 0.584505271911621\n",
            "Epoch: 0, iteración; 3170 de 4841, Loss: 0.6157026767730713\n",
            "Epoch: 0, iteración; 3180 de 4841, Loss: 0.6250824451446533\n",
            "Epoch: 0, iteración; 3190 de 4841, Loss: 0.5086087226867676\n",
            "Epoch: 0, iteración; 3200 de 4841, Loss: 0.5926441192626953\n",
            "Epoch: 0, iteración; 3210 de 4841, Loss: 0.6167366981506348\n",
            "Epoch: 0, iteración; 3220 de 4841, Loss: 0.5403470039367676\n",
            "Epoch: 0, iteración; 3230 de 4841, Loss: 0.5484273433685303\n",
            "Epoch: 0, iteración; 3240 de 4841, Loss: 0.5620934963226318\n",
            "Epoch: 0, iteración; 3250 de 4841, Loss: 0.48882293701171875\n",
            "Epoch: 0, iteración; 3260 de 4841, Loss: 0.5680200576782226\n",
            "Epoch: 0, iteración; 3270 de 4841, Loss: 0.547853422164917\n",
            "Epoch: 0, iteración; 3280 de 4841, Loss: 0.5453956127166748\n",
            "Epoch: 0, iteración; 3290 de 4841, Loss: 0.6003145217895508\n",
            "Epoch: 0, iteración; 3300 de 4841, Loss: 0.5622374534606933\n",
            "Epoch: 0, iteración; 3310 de 4841, Loss: 0.6040408134460449\n",
            "Epoch: 0, iteración; 3320 de 4841, Loss: 0.5435351371765137\n",
            "Epoch: 0, iteración; 3330 de 4841, Loss: 0.4794439792633057\n",
            "Epoch: 0, iteración; 3340 de 4841, Loss: 0.5205193996429444\n",
            "Epoch: 0, iteración; 3350 de 4841, Loss: 0.5257418155670166\n",
            "Epoch: 0, iteración; 3360 de 4841, Loss: 0.497876501083374\n",
            "Epoch: 0, iteración; 3370 de 4841, Loss: 0.5999797821044922\n",
            "Epoch: 0, iteración; 3380 de 4841, Loss: 0.537824296951294\n",
            "Epoch: 0, iteración; 3390 de 4841, Loss: 0.5697150707244873\n",
            "Epoch: 0, iteración; 3400 de 4841, Loss: 0.524634313583374\n",
            "Epoch: 0, iteración; 3410 de 4841, Loss: 0.5495255947113037\n",
            "Epoch: 0, iteración; 3420 de 4841, Loss: 0.5280274868011474\n",
            "Epoch: 0, iteración; 3430 de 4841, Loss: 0.5631861686706543\n",
            "Epoch: 0, iteración; 3440 de 4841, Loss: 0.491942310333252\n",
            "Epoch: 0, iteración; 3450 de 4841, Loss: 0.6456112384796142\n",
            "Epoch: 0, iteración; 3460 de 4841, Loss: 0.5461406230926513\n",
            "Epoch: 0, iteración; 3470 de 4841, Loss: 0.5291484832763672\n",
            "Epoch: 0, iteración; 3480 de 4841, Loss: 0.566492748260498\n",
            "Epoch: 0, iteración; 3490 de 4841, Loss: 0.5795501708984375\n",
            "Epoch: 0, iteración; 3500 de 4841, Loss: 0.5509473800659179\n",
            "Epoch: 0, iteración; 3510 de 4841, Loss: 0.5350383758544922\n",
            "Epoch: 0, iteración; 3520 de 4841, Loss: 0.5755741596221924\n",
            "Epoch: 0, iteración; 3530 de 4841, Loss: 0.5612472057342529\n",
            "Epoch: 0, iteración; 3540 de 4841, Loss: 0.5586468696594238\n",
            "Epoch: 0, iteración; 3550 de 4841, Loss: 0.6080938339233398\n",
            "Epoch: 0, iteración; 3560 de 4841, Loss: 0.5815078735351562\n",
            "Epoch: 0, iteración; 3570 de 4841, Loss: 0.5822124004364013\n",
            "Epoch: 0, iteración; 3580 de 4841, Loss: 0.551283597946167\n",
            "Epoch: 0, iteración; 3590 de 4841, Loss: 0.5920299530029297\n",
            "Epoch: 0, iteración; 3600 de 4841, Loss: 0.5107376098632812\n",
            "Epoch: 0, iteración; 3610 de 4841, Loss: 0.5993890762329102\n",
            "Epoch: 0, iteración; 3620 de 4841, Loss: 0.558515214920044\n",
            "Epoch: 0, iteración; 3630 de 4841, Loss: 0.6044922828674316\n",
            "Epoch: 0, iteración; 3640 de 4841, Loss: 0.532669973373413\n",
            "Epoch: 0, iteración; 3650 de 4841, Loss: 0.505102014541626\n",
            "Epoch: 0, iteración; 3660 de 4841, Loss: 0.60055513381958\n",
            "Epoch: 0, iteración; 3670 de 4841, Loss: 0.5773681640625\n",
            "Epoch: 0, iteración; 3680 de 4841, Loss: 0.5164472103118897\n",
            "Epoch: 0, iteración; 3690 de 4841, Loss: 0.5622657775878906\n",
            "Epoch: 0, iteración; 3700 de 4841, Loss: 0.6098562240600586\n",
            "Epoch: 0, iteración; 3710 de 4841, Loss: 0.5440914630889893\n",
            "Epoch: 0, iteración; 3720 de 4841, Loss: 0.5819881439208985\n",
            "Epoch: 0, iteración; 3730 de 4841, Loss: 0.553013801574707\n",
            "Epoch: 0, iteración; 3740 de 4841, Loss: 0.5156731605529785\n",
            "Epoch: 0, iteración; 3750 de 4841, Loss: 0.5206592559814454\n",
            "Epoch: 0, iteración; 3760 de 4841, Loss: 0.5709054946899415\n",
            "Epoch: 0, iteración; 3770 de 4841, Loss: 0.5017943382263184\n",
            "Epoch: 0, iteración; 3780 de 4841, Loss: 0.609404468536377\n",
            "Epoch: 0, iteración; 3790 de 4841, Loss: 0.5810400485992432\n",
            "Epoch: 0, iteración; 3800 de 4841, Loss: 0.5354925632476807\n",
            "Epoch: 0, iteración; 3810 de 4841, Loss: 0.5436601638793945\n",
            "Epoch: 0, iteración; 3820 de 4841, Loss: 0.58768310546875\n",
            "Epoch: 0, iteración; 3830 de 4841, Loss: 0.5615468978881836\n",
            "Epoch: 0, iteración; 3840 de 4841, Loss: 0.519141960144043\n",
            "Epoch: 0, iteración; 3850 de 4841, Loss: 0.47565512657165526\n",
            "Epoch: 0, iteración; 3860 de 4841, Loss: 0.5673295974731445\n",
            "Epoch: 0, iteración; 3870 de 4841, Loss: 0.6144417285919189\n",
            "Epoch: 0, iteración; 3880 de 4841, Loss: 0.5637370109558105\n",
            "Epoch: 0, iteración; 3890 de 4841, Loss: 0.49764370918273926\n",
            "Epoch: 0, iteración; 3900 de 4841, Loss: 0.5006515502929687\n",
            "Epoch: 0, iteración; 3910 de 4841, Loss: 0.5794919013977051\n",
            "Epoch: 0, iteración; 3920 de 4841, Loss: 0.5479552268981933\n",
            "Epoch: 0, iteración; 3930 de 4841, Loss: 0.5538944244384766\n",
            "Epoch: 0, iteración; 3940 de 4841, Loss: 0.4853806018829346\n",
            "Epoch: 0, iteración; 3950 de 4841, Loss: 0.570301103591919\n",
            "Epoch: 0, iteración; 3960 de 4841, Loss: 0.4556079387664795\n",
            "Epoch: 0, iteración; 3970 de 4841, Loss: 0.5794027805328369\n",
            "Epoch: 0, iteración; 3980 de 4841, Loss: 0.5877837181091309\n",
            "Epoch: 0, iteración; 3990 de 4841, Loss: 0.5376073837280273\n",
            "Epoch: 0, iteración; 4000 de 4841, Loss: 0.6111425399780274\n",
            "Epoch: 0, iteración; 4010 de 4841, Loss: 0.505276107788086\n",
            "Epoch: 0, iteración; 4020 de 4841, Loss: 0.553607177734375\n",
            "Epoch: 0, iteración; 4030 de 4841, Loss: 0.5649720191955566\n",
            "Epoch: 0, iteración; 4040 de 4841, Loss: 0.5120209693908692\n",
            "Epoch: 0, iteración; 4050 de 4841, Loss: 0.6623208045959472\n",
            "Epoch: 0, iteración; 4060 de 4841, Loss: 0.5255173683166504\n",
            "Epoch: 0, iteración; 4070 de 4841, Loss: 0.6134079456329345\n",
            "Epoch: 0, iteración; 4080 de 4841, Loss: 0.6090794086456299\n",
            "Epoch: 0, iteración; 4090 de 4841, Loss: 0.5414650917053223\n",
            "Epoch: 0, iteración; 4100 de 4841, Loss: 0.5917167663574219\n",
            "Epoch: 0, iteración; 4110 de 4841, Loss: 0.5465140819549561\n",
            "Epoch: 0, iteración; 4120 de 4841, Loss: 0.6249746799468994\n",
            "Epoch: 0, iteración; 4130 de 4841, Loss: 0.5553008556365967\n",
            "Epoch: 0, iteración; 4140 de 4841, Loss: 0.5021726131439209\n",
            "Epoch: 0, iteración; 4150 de 4841, Loss: 0.5475086212158203\n",
            "Epoch: 0, iteración; 4160 de 4841, Loss: 0.56463623046875\n",
            "Epoch: 0, iteración; 4170 de 4841, Loss: 0.5137827396392822\n",
            "Epoch: 0, iteración; 4180 de 4841, Loss: 0.5496849536895752\n",
            "Epoch: 0, iteración; 4190 de 4841, Loss: 0.505210018157959\n",
            "Epoch: 0, iteración; 4200 de 4841, Loss: 0.5373067855834961\n",
            "Epoch: 0, iteración; 4210 de 4841, Loss: 0.5410278797149658\n",
            "Epoch: 0, iteración; 4220 de 4841, Loss: 0.5043302536010742\n",
            "Epoch: 0, iteración; 4230 de 4841, Loss: 0.6080733299255371\n",
            "Epoch: 0, iteración; 4240 de 4841, Loss: 0.5699184894561767\n",
            "Epoch: 0, iteración; 4250 de 4841, Loss: 0.5581862449645996\n",
            "Epoch: 0, iteración; 4260 de 4841, Loss: 0.5636523246765137\n",
            "Epoch: 0, iteración; 4270 de 4841, Loss: 0.5922683715820313\n",
            "Epoch: 0, iteración; 4280 de 4841, Loss: 0.6138128280639649\n",
            "Epoch: 0, iteración; 4290 de 4841, Loss: 0.5913071155548095\n",
            "Epoch: 0, iteración; 4300 de 4841, Loss: 0.543892240524292\n",
            "Epoch: 0, iteración; 4310 de 4841, Loss: 0.5469866275787354\n",
            "Epoch: 0, iteración; 4320 de 4841, Loss: 0.5720079421997071\n",
            "Epoch: 0, iteración; 4330 de 4841, Loss: 0.5651204109191894\n",
            "Epoch: 0, iteración; 4340 de 4841, Loss: 0.5709457874298096\n",
            "Epoch: 0, iteración; 4350 de 4841, Loss: 0.5877537250518798\n",
            "Epoch: 0, iteración; 4360 de 4841, Loss: 0.5845614910125733\n",
            "Epoch: 0, iteración; 4370 de 4841, Loss: 0.5476045608520508\n",
            "Epoch: 0, iteración; 4380 de 4841, Loss: 0.5152392387390137\n",
            "Epoch: 0, iteración; 4390 de 4841, Loss: 0.5874135971069336\n",
            "Epoch: 0, iteración; 4400 de 4841, Loss: 0.5285778522491456\n",
            "Epoch: 0, iteración; 4410 de 4841, Loss: 0.584444236755371\n",
            "Epoch: 0, iteración; 4420 de 4841, Loss: 0.5930389881134033\n",
            "Epoch: 0, iteración; 4430 de 4841, Loss: 0.6078046798706055\n",
            "Epoch: 0, iteración; 4440 de 4841, Loss: 0.5391096115112305\n",
            "Epoch: 0, iteración; 4450 de 4841, Loss: 0.4929338932037354\n",
            "Epoch: 0, iteración; 4460 de 4841, Loss: 0.5733497619628907\n",
            "Epoch: 0, iteración; 4470 de 4841, Loss: 0.656468677520752\n",
            "Epoch: 0, iteración; 4480 de 4841, Loss: 0.5641242027282715\n",
            "Epoch: 0, iteración; 4490 de 4841, Loss: 0.5692673683166504\n",
            "Epoch: 0, iteración; 4500 de 4841, Loss: 0.5571382999420166\n",
            "Epoch: 0, iteración; 4510 de 4841, Loss: 0.5870539665222168\n",
            "Epoch: 0, iteración; 4520 de 4841, Loss: 0.5531857490539551\n",
            "Epoch: 0, iteración; 4530 de 4841, Loss: 0.5456773281097412\n",
            "Epoch: 0, iteración; 4540 de 4841, Loss: 0.5243570327758789\n",
            "Epoch: 0, iteración; 4550 de 4841, Loss: 0.520671796798706\n",
            "Epoch: 0, iteración; 4560 de 4841, Loss: 0.5691445827484131\n",
            "Epoch: 0, iteración; 4570 de 4841, Loss: 0.6242331504821778\n",
            "Epoch: 0, iteración; 4580 de 4841, Loss: 0.5530009746551514\n",
            "Epoch: 0, iteración; 4590 de 4841, Loss: 0.5308582782745361\n",
            "Epoch: 0, iteración; 4600 de 4841, Loss: 0.5521031379699707\n",
            "Epoch: 0, iteración; 4610 de 4841, Loss: 0.600377082824707\n",
            "Epoch: 0, iteración; 4620 de 4841, Loss: 0.5635542869567871\n",
            "Epoch: 0, iteración; 4630 de 4841, Loss: 0.5798590183258057\n",
            "Epoch: 0, iteración; 4640 de 4841, Loss: 0.5523743152618408\n",
            "Epoch: 0, iteración; 4650 de 4841, Loss: 0.5270557880401612\n",
            "Epoch: 0, iteración; 4660 de 4841, Loss: 0.5417262077331543\n",
            "Epoch: 0, iteración; 4670 de 4841, Loss: 0.5238090038299561\n",
            "Epoch: 0, iteración; 4680 de 4841, Loss: 0.5536172389984131\n",
            "Epoch: 0, iteración; 4690 de 4841, Loss: 0.6104559421539306\n",
            "Epoch: 0, iteración; 4700 de 4841, Loss: 0.48755803108215334\n",
            "Epoch: 0, iteración; 4710 de 4841, Loss: 0.5428946495056153\n",
            "Epoch: 0, iteración; 4720 de 4841, Loss: 0.5999977588653564\n",
            "Epoch: 0, iteración; 4730 de 4841, Loss: 0.5376510143280029\n",
            "Epoch: 0, iteración; 4740 de 4841, Loss: 0.4894322395324707\n",
            "Epoch: 0, iteración; 4750 de 4841, Loss: 0.5318717956542969\n",
            "Epoch: 0, iteración; 4760 de 4841, Loss: 0.5866756916046143\n",
            "Epoch: 0, iteración; 4770 de 4841, Loss: 0.5932486534118653\n",
            "Epoch: 0, iteración; 4780 de 4841, Loss: 0.5383410930633545\n",
            "Epoch: 0, iteración; 4790 de 4841, Loss: 0.5528188228607178\n",
            "Epoch: 0, iteración; 4800 de 4841, Loss: 0.5989328384399414\n",
            "Epoch: 0, iteración; 4810 de 4841, Loss: 0.5470865726470947\n",
            "Epoch: 0, iteración; 4820 de 4841, Loss: 0.46350851058959963\n",
            "Epoch: 0, iteración; 4830 de 4841, Loss: 0.5304588317871094\n",
            "Epoch: 0, iteración; 4840 de 4841, Loss: 0.5171566486358643\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainBert(epoch)"
      ],
      "id": "qakGjJdRigzM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1wYaMv4igzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225141cc-1d16-4454-98f8-6b13ea128a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_50.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "id": "C1wYaMv4igzM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krD6TS-tl-Pc"
      },
      "source": [
        "##### Evaluación del modelo"
      ],
      "id": "krD6TS-tl-Pc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp5azDorl-Ph"
      },
      "outputs": [],
      "source": [
        "def validationBert(epoch):\n",
        "  model.eval()\n",
        "  fin_targets=[]\n",
        "  fin_outputs=[]\n",
        "  num_iteraciones = len(testing_loader)\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testing_loader, 0):\n",
        "      ids = data['ids'].to(device)\n",
        "      mask = data['mask'].to(device)\n",
        "      token_type_ids = data['token_type_ids'].to(device)\n",
        "      targets = data['target'].to(device)\n",
        "\n",
        "      print(f\"Batch {i} de {num_iteraciones}\")\n",
        "\n",
        "      outputs = model(ids, mask, token_type_ids)\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "  return fin_outputs, fin_targets"
      ],
      "id": "Vp5azDorl-Ph"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "OxRFuVaMl-Ph"
      },
      "id": "OxRFuVaMl-Ph"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjTIFwbal-Pi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9db6a40-8a28-4b7d-f0a3-680a7eb09304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La ruta existe\n",
            "Modelo cargado correctamente\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_50.pth\"):\n",
        "  print(\"La ruta existe\")\n",
        "  model = BERTClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_50.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_50.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "id": "pjTIFwbal-Pi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f44f06-f1f2-44df-a549-aed5c2b3355b",
        "id": "NfiOrJqVl-Pi"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 de 606\n",
            "Batch 1 de 606\n",
            "Batch 2 de 606\n",
            "Batch 3 de 606\n",
            "Batch 4 de 606\n",
            "Batch 5 de 606\n",
            "Batch 6 de 606\n",
            "Batch 7 de 606\n",
            "Batch 8 de 606\n",
            "Batch 9 de 606\n",
            "Batch 10 de 606\n",
            "Batch 11 de 606\n",
            "Batch 12 de 606\n",
            "Batch 13 de 606\n",
            "Batch 14 de 606\n",
            "Batch 15 de 606\n",
            "Batch 16 de 606\n",
            "Batch 17 de 606\n",
            "Batch 18 de 606\n",
            "Batch 19 de 606\n",
            "Batch 20 de 606\n",
            "Batch 21 de 606\n",
            "Batch 22 de 606\n",
            "Batch 23 de 606\n",
            "Batch 24 de 606\n",
            "Batch 25 de 606\n",
            "Batch 26 de 606\n",
            "Batch 27 de 606\n",
            "Batch 28 de 606\n",
            "Batch 29 de 606\n",
            "Batch 30 de 606\n",
            "Batch 31 de 606\n",
            "Batch 32 de 606\n",
            "Batch 33 de 606\n",
            "Batch 34 de 606\n",
            "Batch 35 de 606\n",
            "Batch 36 de 606\n",
            "Batch 37 de 606\n",
            "Batch 38 de 606\n",
            "Batch 39 de 606\n",
            "Batch 40 de 606\n",
            "Batch 41 de 606\n",
            "Batch 42 de 606\n",
            "Batch 43 de 606\n",
            "Batch 44 de 606\n",
            "Batch 45 de 606\n",
            "Batch 46 de 606\n",
            "Batch 47 de 606\n",
            "Batch 48 de 606\n",
            "Batch 49 de 606\n",
            "Batch 50 de 606\n",
            "Batch 51 de 606\n",
            "Batch 52 de 606\n",
            "Batch 53 de 606\n",
            "Batch 54 de 606\n",
            "Batch 55 de 606\n",
            "Batch 56 de 606\n",
            "Batch 57 de 606\n",
            "Batch 58 de 606\n",
            "Batch 59 de 606\n",
            "Batch 60 de 606\n",
            "Batch 61 de 606\n",
            "Batch 62 de 606\n",
            "Batch 63 de 606\n",
            "Batch 64 de 606\n",
            "Batch 65 de 606\n",
            "Batch 66 de 606\n",
            "Batch 67 de 606\n",
            "Batch 68 de 606\n",
            "Batch 69 de 606\n",
            "Batch 70 de 606\n",
            "Batch 71 de 606\n",
            "Batch 72 de 606\n",
            "Batch 73 de 606\n",
            "Batch 74 de 606\n",
            "Batch 75 de 606\n",
            "Batch 76 de 606\n",
            "Batch 77 de 606\n",
            "Batch 78 de 606\n",
            "Batch 79 de 606\n",
            "Batch 80 de 606\n",
            "Batch 81 de 606\n",
            "Batch 82 de 606\n",
            "Batch 83 de 606\n",
            "Batch 84 de 606\n",
            "Batch 85 de 606\n",
            "Batch 86 de 606\n",
            "Batch 87 de 606\n",
            "Batch 88 de 606\n",
            "Batch 89 de 606\n",
            "Batch 90 de 606\n",
            "Batch 91 de 606\n",
            "Batch 92 de 606\n",
            "Batch 93 de 606\n",
            "Batch 94 de 606\n",
            "Batch 95 de 606\n",
            "Batch 96 de 606\n",
            "Batch 97 de 606\n",
            "Batch 98 de 606\n",
            "Batch 99 de 606\n",
            "Batch 100 de 606\n",
            "Batch 101 de 606\n",
            "Batch 102 de 606\n",
            "Batch 103 de 606\n",
            "Batch 104 de 606\n",
            "Batch 105 de 606\n",
            "Batch 106 de 606\n",
            "Batch 107 de 606\n",
            "Batch 108 de 606\n",
            "Batch 109 de 606\n",
            "Batch 110 de 606\n",
            "Batch 111 de 606\n",
            "Batch 112 de 606\n",
            "Batch 113 de 606\n",
            "Batch 114 de 606\n",
            "Batch 115 de 606\n",
            "Batch 116 de 606\n",
            "Batch 117 de 606\n",
            "Batch 118 de 606\n",
            "Batch 119 de 606\n",
            "Batch 120 de 606\n",
            "Batch 121 de 606\n",
            "Batch 122 de 606\n",
            "Batch 123 de 606\n",
            "Batch 124 de 606\n",
            "Batch 125 de 606\n",
            "Batch 126 de 606\n",
            "Batch 127 de 606\n",
            "Batch 128 de 606\n",
            "Batch 129 de 606\n",
            "Batch 130 de 606\n",
            "Batch 131 de 606\n",
            "Batch 132 de 606\n",
            "Batch 133 de 606\n",
            "Batch 134 de 606\n",
            "Batch 135 de 606\n",
            "Batch 136 de 606\n",
            "Batch 137 de 606\n",
            "Batch 138 de 606\n",
            "Batch 139 de 606\n",
            "Batch 140 de 606\n",
            "Batch 141 de 606\n",
            "Batch 142 de 606\n",
            "Batch 143 de 606\n",
            "Batch 144 de 606\n",
            "Batch 145 de 606\n",
            "Batch 146 de 606\n",
            "Batch 147 de 606\n",
            "Batch 148 de 606\n",
            "Batch 149 de 606\n",
            "Batch 150 de 606\n",
            "Batch 151 de 606\n",
            "Batch 152 de 606\n",
            "Batch 153 de 606\n",
            "Batch 154 de 606\n",
            "Batch 155 de 606\n",
            "Batch 156 de 606\n",
            "Batch 157 de 606\n",
            "Batch 158 de 606\n",
            "Batch 159 de 606\n",
            "Batch 160 de 606\n",
            "Batch 161 de 606\n",
            "Batch 162 de 606\n",
            "Batch 163 de 606\n",
            "Batch 164 de 606\n",
            "Batch 165 de 606\n",
            "Batch 166 de 606\n",
            "Batch 167 de 606\n",
            "Batch 168 de 606\n",
            "Batch 169 de 606\n",
            "Batch 170 de 606\n",
            "Batch 171 de 606\n",
            "Batch 172 de 606\n",
            "Batch 173 de 606\n",
            "Batch 174 de 606\n",
            "Batch 175 de 606\n",
            "Batch 176 de 606\n",
            "Batch 177 de 606\n",
            "Batch 178 de 606\n",
            "Batch 179 de 606\n",
            "Batch 180 de 606\n",
            "Batch 181 de 606\n",
            "Batch 182 de 606\n",
            "Batch 183 de 606\n",
            "Batch 184 de 606\n",
            "Batch 185 de 606\n",
            "Batch 186 de 606\n",
            "Batch 187 de 606\n",
            "Batch 188 de 606\n",
            "Batch 189 de 606\n",
            "Batch 190 de 606\n",
            "Batch 191 de 606\n",
            "Batch 192 de 606\n",
            "Batch 193 de 606\n",
            "Batch 194 de 606\n",
            "Batch 195 de 606\n",
            "Batch 196 de 606\n",
            "Batch 197 de 606\n",
            "Batch 198 de 606\n",
            "Batch 199 de 606\n",
            "Batch 200 de 606\n",
            "Batch 201 de 606\n",
            "Batch 202 de 606\n",
            "Batch 203 de 606\n",
            "Batch 204 de 606\n",
            "Batch 205 de 606\n",
            "Batch 206 de 606\n",
            "Batch 207 de 606\n",
            "Batch 208 de 606\n",
            "Batch 209 de 606\n",
            "Batch 210 de 606\n",
            "Batch 211 de 606\n",
            "Batch 212 de 606\n",
            "Batch 213 de 606\n",
            "Batch 214 de 606\n",
            "Batch 215 de 606\n",
            "Batch 216 de 606\n",
            "Batch 217 de 606\n",
            "Batch 218 de 606\n",
            "Batch 219 de 606\n",
            "Batch 220 de 606\n",
            "Batch 221 de 606\n",
            "Batch 222 de 606\n",
            "Batch 223 de 606\n",
            "Batch 224 de 606\n",
            "Batch 225 de 606\n",
            "Batch 226 de 606\n",
            "Batch 227 de 606\n",
            "Batch 228 de 606\n",
            "Batch 229 de 606\n",
            "Batch 230 de 606\n",
            "Batch 231 de 606\n",
            "Batch 232 de 606\n",
            "Batch 233 de 606\n",
            "Batch 234 de 606\n",
            "Batch 235 de 606\n",
            "Batch 236 de 606\n",
            "Batch 237 de 606\n",
            "Batch 238 de 606\n",
            "Batch 239 de 606\n",
            "Batch 240 de 606\n",
            "Batch 241 de 606\n",
            "Batch 242 de 606\n",
            "Batch 243 de 606\n",
            "Batch 244 de 606\n",
            "Batch 245 de 606\n",
            "Batch 246 de 606\n",
            "Batch 247 de 606\n",
            "Batch 248 de 606\n",
            "Batch 249 de 606\n",
            "Batch 250 de 606\n",
            "Batch 251 de 606\n",
            "Batch 252 de 606\n",
            "Batch 253 de 606\n",
            "Batch 254 de 606\n",
            "Batch 255 de 606\n",
            "Batch 256 de 606\n",
            "Batch 257 de 606\n",
            "Batch 258 de 606\n",
            "Batch 259 de 606\n",
            "Batch 260 de 606\n",
            "Batch 261 de 606\n",
            "Batch 262 de 606\n",
            "Batch 263 de 606\n",
            "Batch 264 de 606\n",
            "Batch 265 de 606\n",
            "Batch 266 de 606\n",
            "Batch 267 de 606\n",
            "Batch 268 de 606\n",
            "Batch 269 de 606\n",
            "Batch 270 de 606\n",
            "Batch 271 de 606\n",
            "Batch 272 de 606\n",
            "Batch 273 de 606\n",
            "Batch 274 de 606\n",
            "Batch 275 de 606\n",
            "Batch 276 de 606\n",
            "Batch 277 de 606\n",
            "Batch 278 de 606\n",
            "Batch 279 de 606\n",
            "Batch 280 de 606\n",
            "Batch 281 de 606\n",
            "Batch 282 de 606\n",
            "Batch 283 de 606\n",
            "Batch 284 de 606\n",
            "Batch 285 de 606\n",
            "Batch 286 de 606\n",
            "Batch 287 de 606\n",
            "Batch 288 de 606\n",
            "Batch 289 de 606\n",
            "Batch 290 de 606\n",
            "Batch 291 de 606\n",
            "Batch 292 de 606\n",
            "Batch 293 de 606\n",
            "Batch 294 de 606\n",
            "Batch 295 de 606\n",
            "Batch 296 de 606\n",
            "Batch 297 de 606\n",
            "Batch 298 de 606\n",
            "Batch 299 de 606\n",
            "Batch 300 de 606\n",
            "Batch 301 de 606\n",
            "Batch 302 de 606\n",
            "Batch 303 de 606\n",
            "Batch 304 de 606\n",
            "Batch 305 de 606\n",
            "Batch 306 de 606\n",
            "Batch 307 de 606\n",
            "Batch 308 de 606\n",
            "Batch 309 de 606\n",
            "Batch 310 de 606\n",
            "Batch 311 de 606\n",
            "Batch 312 de 606\n",
            "Batch 313 de 606\n",
            "Batch 314 de 606\n",
            "Batch 315 de 606\n",
            "Batch 316 de 606\n",
            "Batch 317 de 606\n",
            "Batch 318 de 606\n",
            "Batch 319 de 606\n",
            "Batch 320 de 606\n",
            "Batch 321 de 606\n",
            "Batch 322 de 606\n",
            "Batch 323 de 606\n",
            "Batch 324 de 606\n",
            "Batch 325 de 606\n",
            "Batch 326 de 606\n",
            "Batch 327 de 606\n",
            "Batch 328 de 606\n",
            "Batch 329 de 606\n",
            "Batch 330 de 606\n",
            "Batch 331 de 606\n",
            "Batch 332 de 606\n",
            "Batch 333 de 606\n",
            "Batch 334 de 606\n",
            "Batch 335 de 606\n",
            "Batch 336 de 606\n",
            "Batch 337 de 606\n",
            "Batch 338 de 606\n",
            "Batch 339 de 606\n",
            "Batch 340 de 606\n",
            "Batch 341 de 606\n",
            "Batch 342 de 606\n",
            "Batch 343 de 606\n",
            "Batch 344 de 606\n",
            "Batch 345 de 606\n",
            "Batch 346 de 606\n",
            "Batch 347 de 606\n",
            "Batch 348 de 606\n",
            "Batch 349 de 606\n",
            "Batch 350 de 606\n",
            "Batch 351 de 606\n",
            "Batch 352 de 606\n",
            "Batch 353 de 606\n",
            "Batch 354 de 606\n",
            "Batch 355 de 606\n",
            "Batch 356 de 606\n",
            "Batch 357 de 606\n",
            "Batch 358 de 606\n",
            "Batch 359 de 606\n",
            "Batch 360 de 606\n",
            "Batch 361 de 606\n",
            "Batch 362 de 606\n",
            "Batch 363 de 606\n",
            "Batch 364 de 606\n",
            "Batch 365 de 606\n",
            "Batch 366 de 606\n",
            "Batch 367 de 606\n",
            "Batch 368 de 606\n",
            "Batch 369 de 606\n",
            "Batch 370 de 606\n",
            "Batch 371 de 606\n",
            "Batch 372 de 606\n",
            "Batch 373 de 606\n",
            "Batch 374 de 606\n",
            "Batch 375 de 606\n",
            "Batch 376 de 606\n",
            "Batch 377 de 606\n",
            "Batch 378 de 606\n",
            "Batch 379 de 606\n",
            "Batch 380 de 606\n",
            "Batch 381 de 606\n",
            "Batch 382 de 606\n",
            "Batch 383 de 606\n",
            "Batch 384 de 606\n",
            "Batch 385 de 606\n",
            "Batch 386 de 606\n",
            "Batch 387 de 606\n",
            "Batch 388 de 606\n",
            "Batch 389 de 606\n",
            "Batch 390 de 606\n",
            "Batch 391 de 606\n",
            "Batch 392 de 606\n",
            "Batch 393 de 606\n",
            "Batch 394 de 606\n",
            "Batch 395 de 606\n",
            "Batch 396 de 606\n",
            "Batch 397 de 606\n",
            "Batch 398 de 606\n",
            "Batch 399 de 606\n",
            "Batch 400 de 606\n",
            "Batch 401 de 606\n",
            "Batch 402 de 606\n",
            "Batch 403 de 606\n",
            "Batch 404 de 606\n",
            "Batch 405 de 606\n",
            "Batch 406 de 606\n",
            "Batch 407 de 606\n",
            "Batch 408 de 606\n",
            "Batch 409 de 606\n",
            "Batch 410 de 606\n",
            "Batch 411 de 606\n",
            "Batch 412 de 606\n",
            "Batch 413 de 606\n",
            "Batch 414 de 606\n",
            "Batch 415 de 606\n",
            "Batch 416 de 606\n",
            "Batch 417 de 606\n",
            "Batch 418 de 606\n",
            "Batch 419 de 606\n",
            "Batch 420 de 606\n",
            "Batch 421 de 606\n",
            "Batch 422 de 606\n",
            "Batch 423 de 606\n",
            "Batch 424 de 606\n",
            "Batch 425 de 606\n",
            "Batch 426 de 606\n",
            "Batch 427 de 606\n",
            "Batch 428 de 606\n",
            "Batch 429 de 606\n",
            "Batch 430 de 606\n",
            "Batch 431 de 606\n",
            "Batch 432 de 606\n",
            "Batch 433 de 606\n",
            "Batch 434 de 606\n",
            "Batch 435 de 606\n",
            "Batch 436 de 606\n",
            "Batch 437 de 606\n",
            "Batch 438 de 606\n",
            "Batch 439 de 606\n",
            "Batch 440 de 606\n",
            "Batch 441 de 606\n",
            "Batch 442 de 606\n",
            "Batch 443 de 606\n",
            "Batch 444 de 606\n",
            "Batch 445 de 606\n",
            "Batch 446 de 606\n",
            "Batch 447 de 606\n",
            "Batch 448 de 606\n",
            "Batch 449 de 606\n",
            "Batch 450 de 606\n",
            "Batch 451 de 606\n",
            "Batch 452 de 606\n",
            "Batch 453 de 606\n",
            "Batch 454 de 606\n",
            "Batch 455 de 606\n",
            "Batch 456 de 606\n",
            "Batch 457 de 606\n",
            "Batch 458 de 606\n",
            "Batch 459 de 606\n",
            "Batch 460 de 606\n",
            "Batch 461 de 606\n",
            "Batch 462 de 606\n",
            "Batch 463 de 606\n",
            "Batch 464 de 606\n",
            "Batch 465 de 606\n",
            "Batch 466 de 606\n",
            "Batch 467 de 606\n",
            "Batch 468 de 606\n",
            "Batch 469 de 606\n",
            "Batch 470 de 606\n",
            "Batch 471 de 606\n",
            "Batch 472 de 606\n",
            "Batch 473 de 606\n",
            "Batch 474 de 606\n",
            "Batch 475 de 606\n",
            "Batch 476 de 606\n",
            "Batch 477 de 606\n",
            "Batch 478 de 606\n",
            "Batch 479 de 606\n",
            "Batch 480 de 606\n",
            "Batch 481 de 606\n",
            "Batch 482 de 606\n",
            "Batch 483 de 606\n",
            "Batch 484 de 606\n",
            "Batch 485 de 606\n",
            "Batch 486 de 606\n",
            "Batch 487 de 606\n",
            "Batch 488 de 606\n",
            "Batch 489 de 606\n",
            "Batch 490 de 606\n",
            "Batch 491 de 606\n",
            "Batch 492 de 606\n",
            "Batch 493 de 606\n",
            "Batch 494 de 606\n",
            "Batch 495 de 606\n",
            "Batch 496 de 606\n",
            "Batch 497 de 606\n",
            "Batch 498 de 606\n",
            "Batch 499 de 606\n",
            "Batch 500 de 606\n",
            "Batch 501 de 606\n",
            "Batch 502 de 606\n",
            "Batch 503 de 606\n",
            "Batch 504 de 606\n",
            "Batch 505 de 606\n",
            "Batch 506 de 606\n",
            "Batch 507 de 606\n",
            "Batch 508 de 606\n",
            "Batch 509 de 606\n",
            "Batch 510 de 606\n",
            "Batch 511 de 606\n",
            "Batch 512 de 606\n",
            "Batch 513 de 606\n",
            "Batch 514 de 606\n",
            "Batch 515 de 606\n",
            "Batch 516 de 606\n",
            "Batch 517 de 606\n",
            "Batch 518 de 606\n",
            "Batch 519 de 606\n",
            "Batch 520 de 606\n",
            "Batch 521 de 606\n",
            "Batch 522 de 606\n",
            "Batch 523 de 606\n",
            "Batch 524 de 606\n",
            "Batch 525 de 606\n",
            "Batch 526 de 606\n",
            "Batch 527 de 606\n",
            "Batch 528 de 606\n",
            "Batch 529 de 606\n",
            "Batch 530 de 606\n",
            "Batch 531 de 606\n",
            "Batch 532 de 606\n",
            "Batch 533 de 606\n",
            "Batch 534 de 606\n",
            "Batch 535 de 606\n",
            "Batch 536 de 606\n",
            "Batch 537 de 606\n",
            "Batch 538 de 606\n",
            "Batch 539 de 606\n",
            "Batch 540 de 606\n",
            "Batch 541 de 606\n",
            "Batch 542 de 606\n",
            "Batch 543 de 606\n",
            "Batch 544 de 606\n",
            "Batch 545 de 606\n",
            "Batch 546 de 606\n",
            "Batch 547 de 606\n",
            "Batch 548 de 606\n",
            "Batch 549 de 606\n",
            "Batch 550 de 606\n",
            "Batch 551 de 606\n",
            "Batch 552 de 606\n",
            "Batch 553 de 606\n",
            "Batch 554 de 606\n",
            "Batch 555 de 606\n",
            "Batch 556 de 606\n",
            "Batch 557 de 606\n",
            "Batch 558 de 606\n",
            "Batch 559 de 606\n",
            "Batch 560 de 606\n",
            "Batch 561 de 606\n",
            "Batch 562 de 606\n",
            "Batch 563 de 606\n",
            "Batch 564 de 606\n",
            "Batch 565 de 606\n",
            "Batch 566 de 606\n",
            "Batch 567 de 606\n",
            "Batch 568 de 606\n",
            "Batch 569 de 606\n",
            "Batch 570 de 606\n",
            "Batch 571 de 606\n",
            "Batch 572 de 606\n",
            "Batch 573 de 606\n",
            "Batch 574 de 606\n",
            "Batch 575 de 606\n",
            "Batch 576 de 606\n",
            "Batch 577 de 606\n",
            "Batch 578 de 606\n",
            "Batch 579 de 606\n",
            "Batch 580 de 606\n",
            "Batch 581 de 606\n",
            "Batch 582 de 606\n",
            "Batch 583 de 606\n",
            "Batch 584 de 606\n",
            "Batch 585 de 606\n",
            "Batch 586 de 606\n",
            "Batch 587 de 606\n",
            "Batch 588 de 606\n",
            "Batch 589 de 606\n",
            "Batch 590 de 606\n",
            "Batch 591 de 606\n",
            "Batch 592 de 606\n",
            "Batch 593 de 606\n",
            "Batch 594 de 606\n",
            "Batch 595 de 606\n",
            "Batch 596 de 606\n",
            "Batch 597 de 606\n",
            "Batch 598 de 606\n",
            "Batch 599 de 606\n",
            "Batch 600 de 606\n",
            "Batch 601 de 606\n",
            "Batch 602 de 606\n",
            "Batch 603 de 606\n",
            "Batch 604 de 606\n",
            "Batch 605 de 606\n",
            "Accuracy Score = 0.7167131494680301\n",
            "F1 Score (Micro) = 0.7167131494680301\n",
            "F1 Score (Macro) = 0.41749150094768195\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationBert(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "\n",
        "  targets = np.array(targets).flatten().astype(int)\n",
        "\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "id": "NfiOrJqVl-Pi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-MRl_vyJgki"
      },
      "source": [
        "##### Entrenamiento del modelo (50% de datos v2)"
      ],
      "id": "Y-MRl_vyJgki"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- EPOCHS = 2\n",
        "- LR 1e-3\n",
        "- weight_decay=0.01\n",
        "- Dropout + Linear + Sigmoid"
      ],
      "metadata": {
        "id": "oEGY7q9GJgkq"
      },
      "id": "oEGY7q9GJgkq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff581eff-6f7f-482d-ad1f-78492cd22b74",
        "id": "nciovBO7Jgkq"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración; 0 de 4841, Loss: 0.05903231501579285\n",
            "Epoch: 0, iteración; 10 de 4841, Loss: 0.5955514907836914\n",
            "Epoch: 0, iteración; 20 de 4841, Loss: 0.5261722087860108\n",
            "Epoch: 0, iteración; 30 de 4841, Loss: 0.5769295692443848\n",
            "Epoch: 0, iteración; 40 de 4841, Loss: 0.5525286197662354\n",
            "Epoch: 0, iteración; 50 de 4841, Loss: 0.7117277145385742\n",
            "Epoch: 0, iteración; 60 de 4841, Loss: 0.5891118526458741\n",
            "Epoch: 0, iteración; 70 de 4841, Loss: 0.5869298934936523\n",
            "Epoch: 0, iteración; 80 de 4841, Loss: 0.6172382831573486\n",
            "Epoch: 0, iteración; 90 de 4841, Loss: 0.5180586338043213\n",
            "Epoch: 0, iteración; 100 de 4841, Loss: 0.5631719589233398\n",
            "Epoch: 0, iteración; 110 de 4841, Loss: 0.5246448040008544\n",
            "Epoch: 0, iteración; 120 de 4841, Loss: 0.620419979095459\n",
            "Epoch: 0, iteración; 130 de 4841, Loss: 0.6034989356994629\n",
            "Epoch: 0, iteración; 140 de 4841, Loss: 0.5394625663757324\n",
            "Epoch: 0, iteración; 150 de 4841, Loss: 0.6000142097473145\n",
            "Epoch: 0, iteración; 160 de 4841, Loss: 0.5840436935424804\n",
            "Epoch: 0, iteración; 170 de 4841, Loss: 0.5602570056915284\n",
            "Epoch: 0, iteración; 180 de 4841, Loss: 0.6139203548431397\n",
            "Epoch: 0, iteración; 190 de 4841, Loss: 0.653544569015503\n",
            "Epoch: 0, iteración; 200 de 4841, Loss: 0.679002332687378\n",
            "Epoch: 0, iteración; 210 de 4841, Loss: 0.596777868270874\n",
            "Epoch: 0, iteración; 220 de 4841, Loss: 0.5590575218200684\n",
            "Epoch: 0, iteración; 230 de 4841, Loss: 0.5534641742706299\n",
            "Epoch: 0, iteración; 240 de 4841, Loss: 0.6557984828948975\n",
            "Epoch: 0, iteración; 250 de 4841, Loss: 0.5746619224548339\n",
            "Epoch: 0, iteración; 260 de 4841, Loss: 0.5479868412017822\n",
            "Epoch: 0, iteración; 270 de 4841, Loss: 0.5752886772155762\n",
            "Epoch: 0, iteración; 280 de 4841, Loss: 0.5377577781677246\n",
            "Epoch: 0, iteración; 290 de 4841, Loss: 0.6378469467163086\n",
            "Epoch: 0, iteración; 300 de 4841, Loss: 0.5558849334716797\n",
            "Epoch: 0, iteración; 310 de 4841, Loss: 0.6582778453826904\n",
            "Epoch: 0, iteración; 320 de 4841, Loss: 0.5559728145599365\n",
            "Epoch: 0, iteración; 330 de 4841, Loss: 0.577180004119873\n",
            "Epoch: 0, iteración; 340 de 4841, Loss: 0.5664247512817383\n",
            "Epoch: 0, iteración; 350 de 4841, Loss: 0.6351364612579345\n",
            "Epoch: 0, iteración; 360 de 4841, Loss: 0.567540454864502\n",
            "Epoch: 0, iteración; 370 de 4841, Loss: 0.5761822700500489\n",
            "Epoch: 0, iteración; 380 de 4841, Loss: 0.5178231716156005\n",
            "Epoch: 0, iteración; 390 de 4841, Loss: 0.5048550605773926\n",
            "Epoch: 0, iteración; 400 de 4841, Loss: 0.6509235858917236\n",
            "Epoch: 0, iteración; 410 de 4841, Loss: 0.5612411975860596\n",
            "Epoch: 0, iteración; 420 de 4841, Loss: 0.6128285884857178\n",
            "Epoch: 0, iteración; 430 de 4841, Loss: 0.5042614459991455\n",
            "Epoch: 0, iteración; 440 de 4841, Loss: 0.5768789291381836\n",
            "Epoch: 0, iteración; 450 de 4841, Loss: 0.5754650592803955\n",
            "Epoch: 0, iteración; 460 de 4841, Loss: 0.6375041007995605\n",
            "Epoch: 0, iteración; 470 de 4841, Loss: 0.646171236038208\n",
            "Epoch: 0, iteración; 480 de 4841, Loss: 0.5887233734130859\n",
            "Epoch: 0, iteración; 490 de 4841, Loss: 0.6546797752380371\n",
            "Epoch: 0, iteración; 500 de 4841, Loss: 0.5630545139312744\n",
            "Epoch: 0, iteración; 510 de 4841, Loss: 0.5803188800811767\n",
            "Epoch: 0, iteración; 520 de 4841, Loss: 0.5644715785980224\n",
            "Epoch: 0, iteración; 530 de 4841, Loss: 0.5533320903778076\n",
            "Epoch: 0, iteración; 540 de 4841, Loss: 0.5859517574310302\n",
            "Epoch: 0, iteración; 550 de 4841, Loss: 0.6018940925598144\n",
            "Epoch: 0, iteración; 560 de 4841, Loss: 0.6017993450164795\n",
            "Epoch: 0, iteración; 570 de 4841, Loss: 0.576032304763794\n",
            "Epoch: 0, iteración; 580 de 4841, Loss: 0.586478853225708\n",
            "Epoch: 0, iteración; 590 de 4841, Loss: 0.591124153137207\n",
            "Epoch: 0, iteración; 600 de 4841, Loss: 0.5590696811676026\n",
            "Epoch: 0, iteración; 610 de 4841, Loss: 0.6330661773681641\n",
            "Epoch: 0, iteración; 620 de 4841, Loss: 0.6670211791992188\n",
            "Epoch: 0, iteración; 630 de 4841, Loss: 0.5572186946868897\n",
            "Epoch: 0, iteración; 640 de 4841, Loss: 0.6423755645751953\n",
            "Epoch: 0, iteración; 650 de 4841, Loss: 0.5492234230041504\n",
            "Epoch: 0, iteración; 660 de 4841, Loss: 0.4378842353820801\n",
            "Epoch: 0, iteración; 670 de 4841, Loss: 0.6489562034606934\n",
            "Epoch: 0, iteración; 680 de 4841, Loss: 0.5979962348937988\n",
            "Epoch: 0, iteración; 690 de 4841, Loss: 0.6618606090545655\n",
            "Epoch: 0, iteración; 700 de 4841, Loss: 0.6083074569702148\n",
            "Epoch: 0, iteración; 710 de 4841, Loss: 0.6376091480255127\n",
            "Epoch: 0, iteración; 720 de 4841, Loss: 0.5549191474914551\n",
            "Epoch: 0, iteración; 730 de 4841, Loss: 0.5210259914398193\n",
            "Epoch: 0, iteración; 740 de 4841, Loss: 0.6453627586364746\n",
            "Epoch: 0, iteración; 750 de 4841, Loss: 0.6251317024230957\n",
            "Epoch: 0, iteración; 760 de 4841, Loss: 0.5319433689117432\n",
            "Epoch: 0, iteración; 770 de 4841, Loss: 0.6704208850860596\n",
            "Epoch: 0, iteración; 780 de 4841, Loss: 0.5884544849395752\n",
            "Epoch: 0, iteración; 790 de 4841, Loss: 0.6123826980590821\n",
            "Epoch: 0, iteración; 800 de 4841, Loss: 0.6056068897247314\n",
            "Epoch: 0, iteración; 810 de 4841, Loss: 0.6132836818695069\n",
            "Epoch: 0, iteración; 820 de 4841, Loss: 0.5705083847045899\n",
            "Epoch: 0, iteración; 830 de 4841, Loss: 0.6427961349487304\n",
            "Epoch: 0, iteración; 840 de 4841, Loss: 0.6223628520965576\n",
            "Epoch: 0, iteración; 850 de 4841, Loss: 0.622847604751587\n",
            "Epoch: 0, iteración; 860 de 4841, Loss: 0.6119465351104736\n",
            "Epoch: 0, iteración; 870 de 4841, Loss: 0.6416945934295655\n",
            "Epoch: 0, iteración; 880 de 4841, Loss: 0.6020623683929444\n",
            "Epoch: 0, iteración; 890 de 4841, Loss: 0.530468225479126\n",
            "Epoch: 0, iteración; 900 de 4841, Loss: 0.5884275436401367\n",
            "Epoch: 0, iteración; 910 de 4841, Loss: 0.5898564338684082\n",
            "Epoch: 0, iteración; 920 de 4841, Loss: 0.6255177021026611\n",
            "Epoch: 0, iteración; 930 de 4841, Loss: 0.5653768539428711\n",
            "Epoch: 0, iteración; 940 de 4841, Loss: 0.5427441120147705\n",
            "Epoch: 0, iteración; 950 de 4841, Loss: 0.5998953342437744\n",
            "Epoch: 0, iteración; 960 de 4841, Loss: 0.5869377136230469\n",
            "Epoch: 0, iteración; 970 de 4841, Loss: 0.64933180809021\n",
            "Epoch: 0, iteración; 980 de 4841, Loss: 0.5889790534973145\n",
            "Epoch: 0, iteración; 990 de 4841, Loss: 0.5759255886077881\n",
            "Epoch: 0, iteración; 1000 de 4841, Loss: 0.5766153812408448\n",
            "Epoch: 0, iteración; 1010 de 4841, Loss: 0.566185188293457\n",
            "Epoch: 0, iteración; 1020 de 4841, Loss: 0.5664957523345947\n",
            "Epoch: 0, iteración; 1030 de 4841, Loss: 0.6328647613525391\n",
            "Epoch: 0, iteración; 1040 de 4841, Loss: 0.6123593330383301\n",
            "Epoch: 0, iteración; 1050 de 4841, Loss: 0.5456601142883301\n",
            "Epoch: 0, iteración; 1060 de 4841, Loss: 0.5773186206817627\n",
            "Epoch: 0, iteración; 1070 de 4841, Loss: 0.6789997577667236\n",
            "Epoch: 0, iteración; 1080 de 4841, Loss: 0.5463480949401855\n",
            "Epoch: 0, iteración; 1090 de 4841, Loss: 0.5540327548980712\n",
            "Epoch: 0, iteración; 1100 de 4841, Loss: 0.5768074989318848\n",
            "Epoch: 0, iteración; 1110 de 4841, Loss: 0.6236834526062012\n",
            "Epoch: 0, iteración; 1120 de 4841, Loss: 0.5885971069335938\n",
            "Epoch: 0, iteración; 1130 de 4841, Loss: 0.5886330604553223\n",
            "Epoch: 0, iteración; 1140 de 4841, Loss: 0.6762449264526367\n",
            "Epoch: 0, iteración; 1150 de 4841, Loss: 0.5789454936981201\n",
            "Epoch: 0, iteración; 1160 de 4841, Loss: 0.5802402496337891\n",
            "Epoch: 0, iteración; 1170 de 4841, Loss: 0.5090659618377685\n",
            "Epoch: 0, iteración; 1180 de 4841, Loss: 0.5653770446777344\n",
            "Epoch: 0, iteración; 1190 de 4841, Loss: 0.661992073059082\n",
            "Epoch: 0, iteración; 1200 de 4841, Loss: 0.5586062908172608\n",
            "Epoch: 0, iteración; 1210 de 4841, Loss: 0.568514633178711\n",
            "Epoch: 0, iteración; 1220 de 4841, Loss: 0.6918909072875976\n",
            "Epoch: 0, iteración; 1230 de 4841, Loss: 0.6206366062164307\n",
            "Epoch: 0, iteración; 1240 de 4841, Loss: 0.654601001739502\n",
            "Epoch: 0, iteración; 1250 de 4841, Loss: 0.6892114639282226\n",
            "Epoch: 0, iteración; 1260 de 4841, Loss: 0.5429429531097412\n",
            "Epoch: 0, iteración; 1270 de 4841, Loss: 0.5774649620056153\n",
            "Epoch: 0, iteración; 1280 de 4841, Loss: 0.549289608001709\n",
            "Epoch: 0, iteración; 1290 de 4841, Loss: 0.6879214286804199\n",
            "Epoch: 0, iteración; 1300 de 4841, Loss: 0.49799046516418455\n",
            "Epoch: 0, iteración; 1310 de 4841, Loss: 0.648306131362915\n",
            "Epoch: 0, iteración; 1320 de 4841, Loss: 0.5085200309753418\n",
            "Epoch: 0, iteración; 1330 de 4841, Loss: 0.633228874206543\n",
            "Epoch: 0, iteración; 1340 de 4841, Loss: 0.5645999431610107\n",
            "Epoch: 0, iteración; 1350 de 4841, Loss: 0.5818778038024902\n",
            "Epoch: 0, iteración; 1360 de 4841, Loss: 0.5978867053985596\n",
            "Epoch: 0, iteración; 1370 de 4841, Loss: 0.5784393787384033\n",
            "Epoch: 0, iteración; 1380 de 4841, Loss: 0.6418454647064209\n",
            "Epoch: 0, iteración; 1390 de 4841, Loss: 0.5921692848205566\n",
            "Epoch: 0, iteración; 1400 de 4841, Loss: 0.6229972839355469\n",
            "Epoch: 0, iteración; 1410 de 4841, Loss: 0.6134861469268799\n",
            "Epoch: 0, iteración; 1420 de 4841, Loss: 0.5472925662994385\n",
            "Epoch: 0, iteración; 1430 de 4841, Loss: 0.6223474025726319\n",
            "Epoch: 0, iteración; 1440 de 4841, Loss: 0.5875895977020263\n",
            "Epoch: 0, iteración; 1450 de 4841, Loss: 0.5572773933410644\n",
            "Epoch: 0, iteración; 1460 de 4841, Loss: 0.6452419757843018\n",
            "Epoch: 0, iteración; 1470 de 4841, Loss: 0.5683506965637207\n",
            "Epoch: 0, iteración; 1480 de 4841, Loss: 0.5464325428009034\n",
            "Epoch: 0, iteración; 1490 de 4841, Loss: 0.5764834880828857\n",
            "Epoch: 0, iteración; 1500 de 4841, Loss: 0.6814167976379395\n",
            "Epoch: 0, iteración; 1510 de 4841, Loss: 0.5880309104919433\n",
            "Epoch: 0, iteración; 1520 de 4841, Loss: 0.6348997116088867\n",
            "Epoch: 0, iteración; 1530 de 4841, Loss: 0.6114431381225586\n",
            "Epoch: 0, iteración; 1540 de 4841, Loss: 0.6127179622650146\n",
            "Epoch: 0, iteración; 1550 de 4841, Loss: 0.5800264835357666\n",
            "Epoch: 0, iteración; 1560 de 4841, Loss: 0.6224357604980468\n",
            "Epoch: 0, iteración; 1570 de 4841, Loss: 0.6878965377807618\n",
            "Epoch: 0, iteración; 1580 de 4841, Loss: 0.6420966148376465\n",
            "Epoch: 0, iteración; 1590 de 4841, Loss: 0.6118099689483643\n",
            "Epoch: 0, iteración; 1600 de 4841, Loss: 0.6201637744903564\n",
            "Epoch: 0, iteración; 1610 de 4841, Loss: 0.5941147804260254\n",
            "Epoch: 0, iteración; 1620 de 4841, Loss: 0.6316109657287597\n",
            "Epoch: 0, iteración; 1630 de 4841, Loss: 0.5708850383758545\n",
            "Epoch: 0, iteración; 1640 de 4841, Loss: 0.5481875896453857\n",
            "Epoch: 0, iteración; 1650 de 4841, Loss: 0.6775380611419678\n",
            "Epoch: 0, iteración; 1660 de 4841, Loss: 0.5601631164550781\n",
            "Epoch: 0, iteración; 1670 de 4841, Loss: 0.5676534175872803\n",
            "Epoch: 0, iteración; 1680 de 4841, Loss: 0.5094403266906739\n",
            "Epoch: 0, iteración; 1690 de 4841, Loss: 0.564481258392334\n",
            "Epoch: 0, iteración; 1700 de 4841, Loss: 0.5509751796722412\n",
            "Epoch: 0, iteración; 1710 de 4841, Loss: 0.6121373176574707\n",
            "Epoch: 0, iteración; 1720 de 4841, Loss: 0.5999663352966309\n",
            "Epoch: 0, iteración; 1730 de 4841, Loss: 0.5765127658843994\n",
            "Epoch: 0, iteración; 1740 de 4841, Loss: 0.6249231815338134\n",
            "Epoch: 0, iteración; 1750 de 4841, Loss: 0.6066720008850097\n",
            "Epoch: 0, iteración; 1760 de 4841, Loss: 0.5880275249481202\n",
            "Epoch: 0, iteración; 1770 de 4841, Loss: 0.541752290725708\n",
            "Epoch: 0, iteración; 1780 de 4841, Loss: 0.602020263671875\n",
            "Epoch: 0, iteración; 1790 de 4841, Loss: 0.6684284210205078\n",
            "Epoch: 0, iteración; 1800 de 4841, Loss: 0.7007498741149902\n",
            "Epoch: 0, iteración; 1810 de 4841, Loss: 0.5532186985015869\n",
            "Epoch: 0, iteración; 1820 de 4841, Loss: 0.5571418762207031\n",
            "Epoch: 0, iteración; 1830 de 4841, Loss: 0.5451079845428467\n",
            "Epoch: 0, iteración; 1840 de 4841, Loss: 0.6312816143035889\n",
            "Epoch: 0, iteración; 1850 de 4841, Loss: 0.5547269821166992\n",
            "Epoch: 0, iteración; 1860 de 4841, Loss: 0.5904313087463379\n",
            "Epoch: 0, iteración; 1870 de 4841, Loss: 0.6682527542114258\n",
            "Epoch: 0, iteración; 1880 de 4841, Loss: 0.655748701095581\n",
            "Epoch: 0, iteración; 1890 de 4841, Loss: 0.5705038547515869\n",
            "Epoch: 0, iteración; 1900 de 4841, Loss: 0.5786254405975342\n",
            "Epoch: 0, iteración; 1910 de 4841, Loss: 0.675615644454956\n",
            "Epoch: 0, iteración; 1920 de 4841, Loss: 0.6187985420227051\n",
            "Epoch: 0, iteración; 1930 de 4841, Loss: 0.5792062759399415\n",
            "Epoch: 0, iteración; 1940 de 4841, Loss: 0.594309139251709\n",
            "Epoch: 0, iteración; 1950 de 4841, Loss: 0.6551785469055176\n",
            "Epoch: 0, iteración; 1960 de 4841, Loss: 0.5813737869262695\n",
            "Epoch: 0, iteración; 1970 de 4841, Loss: 0.6025519847869873\n",
            "Epoch: 0, iteración; 1980 de 4841, Loss: 0.591306495666504\n",
            "Epoch: 0, iteración; 1990 de 4841, Loss: 0.4922785758972168\n",
            "Epoch: 0, iteración; 2000 de 4841, Loss: 0.5890531063079834\n",
            "Epoch: 0, iteración; 2010 de 4841, Loss: 0.4935274124145508\n",
            "Epoch: 0, iteración; 2020 de 4841, Loss: 0.5884843349456788\n",
            "Epoch: 0, iteración; 2030 de 4841, Loss: 0.4909502506256104\n",
            "Epoch: 0, iteración; 2040 de 4841, Loss: 0.5404898166656494\n",
            "Epoch: 0, iteración; 2050 de 4841, Loss: 0.5516420841217041\n",
            "Epoch: 0, iteración; 2060 de 4841, Loss: 0.5156632900238037\n",
            "Epoch: 0, iteración; 2070 de 4841, Loss: 0.6366705894470215\n",
            "Epoch: 0, iteración; 2080 de 4841, Loss: 0.7220263481140137\n",
            "Epoch: 0, iteración; 2090 de 4841, Loss: 0.7414658546447754\n",
            "Epoch: 0, iteración; 2100 de 4841, Loss: 0.5550285816192627\n",
            "Epoch: 0, iteración; 2110 de 4841, Loss: 0.5894570350646973\n",
            "Epoch: 0, iteración; 2120 de 4841, Loss: 0.5438379287719727\n",
            "Epoch: 0, iteración; 2130 de 4841, Loss: 0.5424293994903564\n",
            "Epoch: 0, iteración; 2140 de 4841, Loss: 0.6339097023010254\n",
            "Epoch: 0, iteración; 2150 de 4841, Loss: 0.5645708560943603\n",
            "Epoch: 0, iteración; 2160 de 4841, Loss: 0.5765037059783935\n",
            "Epoch: 0, iteración; 2170 de 4841, Loss: 0.7154189109802246\n",
            "Epoch: 0, iteración; 2180 de 4841, Loss: 0.6444656372070312\n",
            "Epoch: 0, iteración; 2190 de 4841, Loss: 0.5791365623474121\n",
            "Epoch: 0, iteración; 2200 de 4841, Loss: 0.5359724044799805\n",
            "Epoch: 0, iteración; 2210 de 4841, Loss: 0.5666584014892578\n",
            "Epoch: 0, iteración; 2220 de 4841, Loss: 0.600615119934082\n",
            "Epoch: 0, iteración; 2230 de 4841, Loss: 0.6238170623779297\n",
            "Epoch: 0, iteración; 2240 de 4841, Loss: 0.633746862411499\n",
            "Epoch: 0, iteración; 2250 de 4841, Loss: 0.5668679237365722\n",
            "Epoch: 0, iteración; 2260 de 4841, Loss: 0.544252347946167\n",
            "Epoch: 0, iteración; 2270 de 4841, Loss: 0.542946195602417\n",
            "Epoch: 0, iteración; 2280 de 4841, Loss: 0.6920252323150635\n",
            "Epoch: 0, iteración; 2290 de 4841, Loss: 0.6565082550048829\n",
            "Epoch: 0, iteración; 2300 de 4841, Loss: 0.5225389957427978\n",
            "Epoch: 0, iteración; 2310 de 4841, Loss: 0.588753604888916\n",
            "Epoch: 0, iteración; 2320 de 4841, Loss: 0.6004114627838135\n",
            "Epoch: 0, iteración; 2330 de 4841, Loss: 0.5997202873229981\n",
            "Epoch: 0, iteración; 2340 de 4841, Loss: 0.5774796485900879\n",
            "Epoch: 0, iteración; 2350 de 4841, Loss: 0.6783931732177735\n",
            "Epoch: 0, iteración; 2360 de 4841, Loss: 0.6215548515319824\n",
            "Epoch: 0, iteración; 2370 de 4841, Loss: 0.6418485641479492\n",
            "Epoch: 0, iteración; 2380 de 4841, Loss: 0.6629382610321045\n",
            "Epoch: 0, iteración; 2390 de 4841, Loss: 0.601229190826416\n",
            "Epoch: 0, iteración; 2400 de 4841, Loss: 0.6496929168701172\n",
            "Epoch: 0, iteración; 2410 de 4841, Loss: 0.5843514442443848\n",
            "Epoch: 0, iteración; 2420 de 4841, Loss: 0.5841834545135498\n",
            "Epoch: 0, iteración; 2430 de 4841, Loss: 0.6395980834960937\n",
            "Epoch: 0, iteración; 2440 de 4841, Loss: 0.5209543228149414\n",
            "Epoch: 0, iteración; 2450 de 4841, Loss: 0.6770291805267334\n",
            "Epoch: 0, iteración; 2460 de 4841, Loss: 0.5995602607727051\n",
            "Epoch: 0, iteración; 2470 de 4841, Loss: 0.5587440490722656\n",
            "Epoch: 0, iteración; 2480 de 4841, Loss: 0.5659878253936768\n",
            "Epoch: 0, iteración; 2490 de 4841, Loss: 0.610493803024292\n",
            "Epoch: 0, iteración; 2500 de 4841, Loss: 0.6668254375457764\n",
            "Epoch: 0, iteración; 2510 de 4841, Loss: 0.5897319316864014\n",
            "Epoch: 0, iteración; 2520 de 4841, Loss: 0.5364455223083496\n",
            "Epoch: 0, iteración; 2530 de 4841, Loss: 0.6655110359191895\n",
            "Epoch: 0, iteración; 2540 de 4841, Loss: 0.6325871467590332\n",
            "Epoch: 0, iteración; 2550 de 4841, Loss: 0.6223373889923096\n",
            "Epoch: 0, iteración; 2560 de 4841, Loss: 0.6298723220825195\n",
            "Epoch: 0, iteración; 2570 de 4841, Loss: 0.5915327072143555\n",
            "Epoch: 0, iteración; 2580 de 4841, Loss: 0.6621543407440186\n",
            "Epoch: 0, iteración; 2590 de 4841, Loss: 0.6610878467559814\n",
            "Epoch: 0, iteración; 2600 de 4841, Loss: 0.6670033931732178\n",
            "Epoch: 0, iteración; 2610 de 4841, Loss: 0.5974748611450196\n",
            "Epoch: 0, iteración; 2620 de 4841, Loss: 0.5512036800384521\n",
            "Epoch: 0, iteración; 2630 de 4841, Loss: 0.6219296932220459\n",
            "Epoch: 0, iteración; 2640 de 4841, Loss: 0.580170726776123\n",
            "Epoch: 0, iteración; 2650 de 4841, Loss: 0.6406292915344238\n",
            "Epoch: 0, iteración; 2660 de 4841, Loss: 0.6002230644226074\n",
            "Epoch: 0, iteración; 2670 de 4841, Loss: 0.6620088577270508\n",
            "Epoch: 0, iteración; 2680 de 4841, Loss: 0.6113178253173828\n",
            "Epoch: 0, iteración; 2690 de 4841, Loss: 0.5617279052734375\n",
            "Epoch: 0, iteración; 2700 de 4841, Loss: 0.6010125160217286\n",
            "Epoch: 0, iteración; 2710 de 4841, Loss: 0.6421113014221191\n",
            "Epoch: 0, iteración; 2720 de 4841, Loss: 0.6531012535095215\n",
            "Epoch: 0, iteración; 2730 de 4841, Loss: 0.6393670082092285\n",
            "Epoch: 0, iteración; 2740 de 4841, Loss: 0.5329773426055908\n",
            "Epoch: 0, iteración; 2750 de 4841, Loss: 0.5398048400878906\n",
            "Epoch: 0, iteración; 2760 de 4841, Loss: 0.6236494064331055\n",
            "Epoch: 0, iteración; 2770 de 4841, Loss: 0.5772538661956788\n",
            "Epoch: 0, iteración; 2780 de 4841, Loss: 0.5196759223937988\n",
            "Epoch: 0, iteración; 2790 de 4841, Loss: 0.5997774124145507\n",
            "Epoch: 0, iteración; 2800 de 4841, Loss: 0.5526856899261474\n",
            "Epoch: 0, iteración; 2810 de 4841, Loss: 0.5648274421691895\n",
            "Epoch: 0, iteración; 2820 de 4841, Loss: 0.6589747428894043\n",
            "Epoch: 0, iteración; 2830 de 4841, Loss: 0.6580889225006104\n",
            "Epoch: 0, iteración; 2840 de 4841, Loss: 0.6112709045410156\n",
            "Epoch: 0, iteración; 2850 de 4841, Loss: 0.6000531196594239\n",
            "Epoch: 0, iteración; 2860 de 4841, Loss: 0.6009799003601074\n",
            "Epoch: 0, iteración; 2870 de 4841, Loss: 0.5675436496734619\n",
            "Epoch: 0, iteración; 2880 de 4841, Loss: 0.6222229480743409\n",
            "Epoch: 0, iteración; 2890 de 4841, Loss: 0.6220517635345459\n",
            "Epoch: 0, iteración; 2900 de 4841, Loss: 0.5569660186767578\n",
            "Epoch: 0, iteración; 2910 de 4841, Loss: 0.5439280033111572\n",
            "Epoch: 0, iteración; 2920 de 4841, Loss: 0.5884782791137695\n",
            "Epoch: 0, iteración; 2930 de 4841, Loss: 0.5198856830596924\n",
            "Epoch: 0, iteración; 2940 de 4841, Loss: 0.6236327171325684\n",
            "Epoch: 0, iteración; 2950 de 4841, Loss: 0.646761703491211\n",
            "Epoch: 0, iteración; 2960 de 4841, Loss: 0.5303895950317383\n",
            "Epoch: 0, iteración; 2970 de 4841, Loss: 0.5301159381866455\n",
            "Epoch: 0, iteración; 2980 de 4841, Loss: 0.6002305030822754\n",
            "Epoch: 0, iteración; 2990 de 4841, Loss: 0.6236983299255371\n",
            "Epoch: 0, iteración; 3000 de 4841, Loss: 0.5883278369903564\n",
            "Epoch: 0, iteración; 3010 de 4841, Loss: 0.6231772422790527\n",
            "Epoch: 0, iteración; 3020 de 4841, Loss: 0.588411283493042\n",
            "Epoch: 0, iteración; 3030 de 4841, Loss: 0.5650032997131348\n",
            "Epoch: 0, iteración; 3040 de 4841, Loss: 0.6226162910461426\n",
            "Epoch: 0, iteración; 3050 de 4841, Loss: 0.5319633483886719\n",
            "Epoch: 0, iteración; 3060 de 4841, Loss: 0.6112656593322754\n",
            "Epoch: 0, iteración; 3070 de 4841, Loss: 0.5547575950622559\n",
            "Epoch: 0, iteración; 3080 de 4841, Loss: 0.7035410881042481\n",
            "Epoch: 0, iteración; 3090 de 4841, Loss: 0.5995014190673829\n",
            "Epoch: 0, iteración; 3100 de 4841, Loss: 0.5440536975860596\n",
            "Epoch: 0, iteración; 3110 de 4841, Loss: 0.6437918663024902\n",
            "Epoch: 0, iteración; 3120 de 4841, Loss: 0.6212681293487549\n",
            "Epoch: 0, iteración; 3130 de 4841, Loss: 0.6329440116882324\n",
            "Epoch: 0, iteración; 3140 de 4841, Loss: 0.5581481456756592\n",
            "Epoch: 0, iteración; 3150 de 4841, Loss: 0.5246408462524415\n",
            "Epoch: 0, iteración; 3160 de 4841, Loss: 0.6009850978851319\n",
            "Epoch: 0, iteración; 3170 de 4841, Loss: 0.5544651985168457\n",
            "Epoch: 0, iteración; 3180 de 4841, Loss: 0.5999728202819824\n",
            "Epoch: 0, iteración; 3190 de 4841, Loss: 0.6345248222351074\n",
            "Epoch: 0, iteración; 3200 de 4841, Loss: 0.5774544715881348\n",
            "Epoch: 0, iteración; 3210 de 4841, Loss: 0.599455738067627\n",
            "Epoch: 0, iteración; 3220 de 4841, Loss: 0.6572687149047851\n",
            "Epoch: 0, iteración; 3230 de 4841, Loss: 0.6341135978698731\n",
            "Epoch: 0, iteración; 3240 de 4841, Loss: 0.5363827228546143\n",
            "Epoch: 0, iteración; 3250 de 4841, Loss: 0.566747522354126\n",
            "Epoch: 0, iteración; 3260 de 4841, Loss: 0.5667885780334473\n",
            "Epoch: 0, iteración; 3270 de 4841, Loss: 0.6352852821350098\n",
            "Epoch: 0, iteración; 3280 de 4841, Loss: 0.5998912811279297\n",
            "Epoch: 0, iteración; 3290 de 4841, Loss: 0.5776212692260743\n",
            "Epoch: 0, iteración; 3300 de 4841, Loss: 0.5423739910125732\n",
            "Epoch: 0, iteración; 3310 de 4841, Loss: 0.6121061325073243\n",
            "Epoch: 0, iteración; 3320 de 4841, Loss: 0.5768179893493652\n",
            "Epoch: 0, iteración; 3330 de 4841, Loss: 0.7247693538665771\n",
            "Epoch: 0, iteración; 3340 de 4841, Loss: 0.5553486347198486\n",
            "Epoch: 0, iteración; 3350 de 4841, Loss: 0.6640093326568604\n",
            "Epoch: 0, iteración; 3360 de 4841, Loss: 0.6682982444763184\n",
            "Epoch: 0, iteración; 3370 de 4841, Loss: 0.6036515235900879\n",
            "Epoch: 0, iteración; 3380 de 4841, Loss: 0.6209589004516601\n",
            "Epoch: 0, iteración; 3390 de 4841, Loss: 0.6124782085418701\n",
            "Epoch: 0, iteración; 3400 de 4841, Loss: 0.5501391410827636\n",
            "Epoch: 0, iteración; 3410 de 4841, Loss: 0.6384244441986084\n",
            "Epoch: 0, iteración; 3420 de 4841, Loss: 0.5740866184234619\n",
            "Epoch: 0, iteración; 3430 de 4841, Loss: 0.5692991733551025\n",
            "Epoch: 0, iteración; 3440 de 4841, Loss: 0.599761962890625\n",
            "Epoch: 0, iteración; 3450 de 4841, Loss: 0.6326763153076171\n",
            "Epoch: 0, iteración; 3460 de 4841, Loss: 0.6132520198822021\n",
            "Epoch: 0, iteración; 3470 de 4841, Loss: 0.6697468280792236\n",
            "Epoch: 0, iteración; 3480 de 4841, Loss: 0.6132251739501953\n",
            "Epoch: 0, iteración; 3490 de 4841, Loss: 0.6158581733703613\n",
            "Epoch: 0, iteración; 3500 de 4841, Loss: 0.5879929542541504\n",
            "Epoch: 0, iteración; 3510 de 4841, Loss: 0.652105188369751\n",
            "Epoch: 0, iteración; 3520 de 4841, Loss: 0.6321744441986084\n",
            "Epoch: 0, iteración; 3530 de 4841, Loss: 0.5191693305969238\n",
            "Epoch: 0, iteración; 3540 de 4841, Loss: 0.5300052165985107\n",
            "Epoch: 0, iteración; 3550 de 4841, Loss: 0.6246865749359131\n",
            "Epoch: 0, iteración; 3560 de 4841, Loss: 0.5450620651245117\n",
            "Epoch: 0, iteración; 3570 de 4841, Loss: 0.5646107196807861\n",
            "Epoch: 0, iteración; 3580 de 4841, Loss: 0.6559147834777832\n",
            "Epoch: 0, iteración; 3590 de 4841, Loss: 0.5843898773193359\n",
            "Epoch: 0, iteración; 3600 de 4841, Loss: 0.6226794719696045\n",
            "Epoch: 0, iteración; 3610 de 4841, Loss: 0.6234718799591065\n",
            "Epoch: 0, iteración; 3620 de 4841, Loss: 0.6010666847229004\n",
            "Epoch: 0, iteración; 3630 de 4841, Loss: 0.6247843742370606\n",
            "Epoch: 0, iteración; 3640 de 4841, Loss: 0.555291223526001\n",
            "Epoch: 0, iteración; 3650 de 4841, Loss: 0.5192648887634277\n",
            "Epoch: 0, iteración; 3660 de 4841, Loss: 0.6462659358978271\n",
            "Epoch: 0, iteración; 3670 de 4841, Loss: 0.6115371227264405\n",
            "Epoch: 0, iteración; 3680 de 4841, Loss: 0.6131278991699218\n",
            "Epoch: 0, iteración; 3690 de 4841, Loss: 0.5479623317718506\n",
            "Epoch: 0, iteración; 3700 de 4841, Loss: 0.6338186264038086\n",
            "Epoch: 0, iteración; 3710 de 4841, Loss: 0.6235875606536865\n",
            "Epoch: 0, iteración; 3720 de 4841, Loss: 0.6102404594421387\n",
            "Epoch: 0, iteración; 3730 de 4841, Loss: 0.5141195297241211\n",
            "Epoch: 0, iteración; 3740 de 4841, Loss: 0.5539280891418457\n",
            "Epoch: 0, iteración; 3750 de 4841, Loss: 0.5531054496765136\n",
            "Epoch: 0, iteración; 3760 de 4841, Loss: 0.5998083114624023\n",
            "Epoch: 0, iteración; 3770 de 4841, Loss: 0.6475436210632324\n",
            "Epoch: 0, iteración; 3780 de 4841, Loss: 0.6136008739471436\n",
            "Epoch: 0, iteración; 3790 de 4841, Loss: 0.5889980316162109\n",
            "Epoch: 0, iteración; 3800 de 4841, Loss: 0.5885303020477295\n",
            "Epoch: 0, iteración; 3810 de 4841, Loss: 0.6800392627716064\n",
            "Epoch: 0, iteración; 3820 de 4841, Loss: 0.5875846862792968\n",
            "Epoch: 0, iteración; 3830 de 4841, Loss: 0.5679273128509521\n",
            "Epoch: 0, iteración; 3840 de 4841, Loss: 0.5881388187408447\n",
            "Epoch: 0, iteración; 3850 de 4841, Loss: 0.5666175842285156\n",
            "Epoch: 0, iteración; 3860 de 4841, Loss: 0.5652608871459961\n",
            "Epoch: 0, iteración; 3870 de 4841, Loss: 0.5655828475952148\n",
            "Epoch: 0, iteración; 3880 de 4841, Loss: 0.5537420272827148\n",
            "Epoch: 0, iteración; 3890 de 4841, Loss: 0.6926516532897949\n",
            "Epoch: 0, iteración; 3900 de 4841, Loss: 0.6241339206695556\n",
            "Epoch: 0, iteración; 3910 de 4841, Loss: 0.6230890274047851\n",
            "Epoch: 0, iteración; 3920 de 4841, Loss: 0.6540087223052978\n",
            "Epoch: 0, iteración; 3930 de 4841, Loss: 0.5613394737243652\n",
            "Epoch: 0, iteración; 3940 de 4841, Loss: 0.5773603916168213\n",
            "Epoch: 0, iteración; 3950 de 4841, Loss: 0.5455874443054199\n",
            "Epoch: 0, iteración; 3960 de 4841, Loss: 0.5786054611206055\n",
            "Epoch: 0, iteración; 3970 de 4841, Loss: 0.5771750926971435\n",
            "Epoch: 0, iteración; 3980 de 4841, Loss: 0.5538905143737793\n",
            "Epoch: 0, iteración; 3990 de 4841, Loss: 0.5651724815368653\n",
            "Epoch: 0, iteración; 4000 de 4841, Loss: 0.6478763580322265\n",
            "Epoch: 0, iteración; 4010 de 4841, Loss: 0.6469654083251953\n",
            "Epoch: 0, iteración; 4020 de 4841, Loss: 0.5439776420593262\n",
            "Epoch: 0, iteración; 4030 de 4841, Loss: 0.5195452690124511\n",
            "Epoch: 0, iteración; 4040 de 4841, Loss: 0.5652509212493897\n",
            "Epoch: 0, iteración; 4050 de 4841, Loss: 0.6240311622619629\n",
            "Epoch: 0, iteración; 4060 de 4841, Loss: 0.6592203140258789\n",
            "Epoch: 0, iteración; 4070 de 4841, Loss: 0.6578229427337646\n",
            "Epoch: 0, iteración; 4080 de 4841, Loss: 0.5890379428863526\n",
            "Epoch: 0, iteración; 4090 de 4841, Loss: 0.601198387145996\n",
            "Epoch: 0, iteración; 4100 de 4841, Loss: 0.5786019325256347\n",
            "Epoch: 0, iteración; 4110 de 4841, Loss: 0.6107507228851319\n",
            "Epoch: 0, iteración; 4120 de 4841, Loss: 0.5673560619354248\n",
            "Epoch: 0, iteración; 4130 de 4841, Loss: 0.6110466003417969\n",
            "Epoch: 0, iteración; 4140 de 4841, Loss: 0.5998314380645752\n",
            "Epoch: 0, iteración; 4150 de 4841, Loss: 0.622786569595337\n",
            "Epoch: 0, iteración; 4160 de 4841, Loss: 0.610752010345459\n",
            "Epoch: 0, iteración; 4170 de 4841, Loss: 0.62209153175354\n",
            "Epoch: 0, iteración; 4180 de 4841, Loss: 0.5561532974243164\n",
            "Epoch: 0, iteración; 4190 de 4841, Loss: 0.5457234859466553\n",
            "Epoch: 0, iteración; 4200 de 4841, Loss: 0.5897529602050782\n",
            "Epoch: 0, iteración; 4210 de 4841, Loss: 0.6117321014404297\n",
            "Epoch: 0, iteración; 4220 de 4841, Loss: 0.6450911521911621\n",
            "Epoch: 0, iteración; 4230 de 4841, Loss: 0.5998964786529541\n",
            "Epoch: 0, iteración; 4240 de 4841, Loss: 0.5896693706512451\n",
            "Epoch: 0, iteración; 4250 de 4841, Loss: 0.5684420585632324\n",
            "Epoch: 0, iteración; 4260 de 4841, Loss: 0.5657173156738281\n",
            "Epoch: 0, iteración; 4270 de 4841, Loss: 0.6336507320404052\n",
            "Epoch: 0, iteración; 4280 de 4841, Loss: 0.5885099411010742\n",
            "Epoch: 0, iteración; 4290 de 4841, Loss: 0.6104634284973145\n",
            "Epoch: 0, iteración; 4300 de 4841, Loss: 0.6018386840820312\n",
            "Epoch: 0, iteración; 4310 de 4841, Loss: 0.6330535888671875\n",
            "Epoch: 0, iteración; 4320 de 4841, Loss: 0.6202717781066894\n",
            "Epoch: 0, iteración; 4330 de 4841, Loss: 0.5137964248657226\n",
            "Epoch: 0, iteración; 4340 de 4841, Loss: 0.6118481159210205\n",
            "Epoch: 0, iteración; 4350 de 4841, Loss: 0.6008055210113525\n",
            "Epoch: 0, iteración; 4360 de 4841, Loss: 0.5209001541137696\n",
            "Epoch: 0, iteración; 4370 de 4841, Loss: 0.565851354598999\n",
            "Epoch: 0, iteración; 4380 de 4841, Loss: 0.6228888988494873\n",
            "Epoch: 0, iteración; 4390 de 4841, Loss: 0.6571061134338378\n",
            "Epoch: 0, iteración; 4400 de 4841, Loss: 0.5532258510589599\n",
            "Epoch: 0, iteración; 4410 de 4841, Loss: 0.5662102699279785\n",
            "Epoch: 0, iteración; 4420 de 4841, Loss: 0.5999819755554199\n",
            "Epoch: 0, iteración; 4430 de 4841, Loss: 0.5316253662109375\n",
            "Epoch: 0, iteración; 4440 de 4841, Loss: 0.6693624496459961\n",
            "Epoch: 0, iteración; 4450 de 4841, Loss: 0.5205951690673828\n",
            "Epoch: 0, iteración; 4460 de 4841, Loss: 0.577054214477539\n",
            "Epoch: 0, iteración; 4470 de 4841, Loss: 0.5767734050750732\n",
            "Epoch: 0, iteración; 4480 de 4841, Loss: 0.5761550903320313\n",
            "Epoch: 0, iteración; 4490 de 4841, Loss: 0.5299787044525146\n",
            "Epoch: 0, iteración; 4500 de 4841, Loss: 0.6002701759338379\n",
            "Epoch: 0, iteración; 4510 de 4841, Loss: 0.5645007133483887\n",
            "Epoch: 0, iteración; 4520 de 4841, Loss: 0.6480044841766357\n",
            "Epoch: 0, iteración; 4530 de 4841, Loss: 0.5995983600616455\n",
            "Epoch: 0, iteración; 4540 de 4841, Loss: 0.5533897399902343\n",
            "Epoch: 0, iteración; 4550 de 4841, Loss: 0.5649418354034423\n",
            "Epoch: 0, iteración; 4560 de 4841, Loss: 0.6117210388183594\n",
            "Epoch: 0, iteración; 4570 de 4841, Loss: 0.588849401473999\n",
            "Epoch: 0, iteración; 4580 de 4841, Loss: 0.599560022354126\n",
            "Epoch: 0, iteración; 4590 de 4841, Loss: 0.5550434589385986\n",
            "Epoch: 0, iteración; 4600 de 4841, Loss: 0.588561725616455\n",
            "Epoch: 0, iteración; 4610 de 4841, Loss: 0.588831615447998\n",
            "Epoch: 0, iteración; 4620 de 4841, Loss: 0.5655060768127441\n",
            "Epoch: 0, iteración; 4630 de 4841, Loss: 0.6002013206481933\n",
            "Epoch: 0, iteración; 4640 de 4841, Loss: 0.5414454460144043\n",
            "Epoch: 0, iteración; 4650 de 4841, Loss: 0.6002182006835938\n",
            "Epoch: 0, iteración; 4660 de 4841, Loss: 0.6588142395019532\n",
            "Epoch: 0, iteración; 4670 de 4841, Loss: 0.6575656414031983\n",
            "Epoch: 0, iteración; 4680 de 4841, Loss: 0.6453420639038085\n",
            "Epoch: 0, iteración; 4690 de 4841, Loss: 0.5467340469360351\n",
            "Epoch: 0, iteración; 4700 de 4841, Loss: 0.5782197475433349\n",
            "Epoch: 0, iteración; 4710 de 4841, Loss: 0.5772467613220215\n",
            "Epoch: 0, iteración; 4720 de 4841, Loss: 0.5554593563079834\n",
            "Epoch: 0, iteración; 4730 de 4841, Loss: 0.5768699645996094\n",
            "Epoch: 0, iteración; 4740 de 4841, Loss: 0.5546075820922851\n",
            "Epoch: 0, iteración; 4750 de 4841, Loss: 0.6118453502655029\n",
            "Epoch: 0, iteración; 4760 de 4841, Loss: 0.6470681667327881\n",
            "Epoch: 0, iteración; 4770 de 4841, Loss: 0.6345456123352051\n",
            "Epoch: 0, iteración; 4780 de 4841, Loss: 0.5667509078979492\n",
            "Epoch: 0, iteración; 4790 de 4841, Loss: 0.5559743404388428\n",
            "Epoch: 0, iteración; 4800 de 4841, Loss: 0.6001595020294189\n",
            "Epoch: 0, iteración; 4810 de 4841, Loss: 0.6120378017425537\n",
            "Epoch: 0, iteración; 4820 de 4841, Loss: 0.6003969669342041\n",
            "Epoch: 0, iteración; 4830 de 4841, Loss: 0.6669443130493165\n",
            "Epoch: 0, iteración; 4840 de 4841, Loss: 0.6438178062438965\n",
            "Epoch: 1, iteración; 0 de 4841, Loss: 0.067671799659729\n",
            "Epoch: 1, iteración; 10 de 4841, Loss: 0.5680711746215821\n",
            "Epoch: 1, iteración; 20 de 4841, Loss: 0.6722880363464355\n",
            "Epoch: 1, iteración; 30 de 4841, Loss: 0.6013667106628418\n",
            "Epoch: 1, iteración; 40 de 4841, Loss: 0.621748971939087\n",
            "Epoch: 1, iteración; 50 de 4841, Loss: 0.6900693893432617\n",
            "Epoch: 1, iteración; 60 de 4841, Loss: 0.6497109413146973\n",
            "Epoch: 1, iteración; 70 de 4841, Loss: 0.5876305580139161\n",
            "Epoch: 1, iteración; 80 de 4841, Loss: 0.6308845043182373\n",
            "Epoch: 1, iteración; 90 de 4841, Loss: 0.6394716739654541\n",
            "Epoch: 1, iteración; 100 de 4841, Loss: 0.5956311702728272\n",
            "Epoch: 1, iteración; 110 de 4841, Loss: 0.5637324810028076\n",
            "Epoch: 1, iteración; 120 de 4841, Loss: 0.5517932891845703\n",
            "Epoch: 1, iteración; 130 de 4841, Loss: 0.6449772834777832\n",
            "Epoch: 1, iteración; 140 de 4841, Loss: 0.6105387687683106\n",
            "Epoch: 1, iteración; 150 de 4841, Loss: 0.5341156959533692\n",
            "Epoch: 1, iteración; 160 de 4841, Loss: 0.5998822212219238\n",
            "Epoch: 1, iteración; 170 de 4841, Loss: 0.5318152904510498\n",
            "Epoch: 1, iteración; 180 de 4841, Loss: 0.6118430137634278\n",
            "Epoch: 1, iteración; 190 de 4841, Loss: 0.5651140689849854\n",
            "Epoch: 1, iteración; 200 de 4841, Loss: 0.6001526832580566\n",
            "Epoch: 1, iteración; 210 de 4841, Loss: 0.5413692951202392\n",
            "Epoch: 1, iteración; 220 de 4841, Loss: 0.48203840255737307\n",
            "Epoch: 1, iteración; 230 de 4841, Loss: 0.5880527496337891\n",
            "Epoch: 1, iteración; 240 de 4841, Loss: 0.5643430709838867\n",
            "Epoch: 1, iteración; 250 de 4841, Loss: 0.6245554447174072\n",
            "Epoch: 1, iteración; 260 de 4841, Loss: 0.5641741752624512\n",
            "Epoch: 1, iteración; 270 de 4841, Loss: 0.5641845226287842\n",
            "Epoch: 1, iteración; 280 de 4841, Loss: 0.5763028144836426\n",
            "Epoch: 1, iteración; 290 de 4841, Loss: 0.6591540336608886\n",
            "Epoch: 1, iteración; 300 de 4841, Loss: 0.6459622859954834\n",
            "Epoch: 1, iteración; 310 de 4841, Loss: 0.5443920135498047\n",
            "Epoch: 1, iteración; 320 de 4841, Loss: 0.589499568939209\n",
            "Epoch: 1, iteración; 330 de 4841, Loss: 0.589373779296875\n",
            "Epoch: 1, iteración; 340 de 4841, Loss: 0.5419779777526855\n",
            "Epoch: 1, iteración; 350 de 4841, Loss: 0.5761626243591309\n",
            "Epoch: 1, iteración; 360 de 4841, Loss: 0.6235704898834229\n",
            "Epoch: 1, iteración; 370 de 4841, Loss: 0.6120210647583008\n",
            "Epoch: 1, iteración; 380 de 4841, Loss: 0.612147855758667\n",
            "Epoch: 1, iteración; 390 de 4841, Loss: 0.5659719944000244\n",
            "Epoch: 1, iteración; 400 de 4841, Loss: 0.688955545425415\n",
            "Epoch: 1, iteración; 410 de 4841, Loss: 0.6648523330688476\n",
            "Epoch: 1, iteración; 420 de 4841, Loss: 0.5816081523895263\n",
            "Epoch: 1, iteración; 430 de 4841, Loss: 0.5192980766296387\n",
            "Epoch: 1, iteración; 440 de 4841, Loss: 0.6769242286682129\n",
            "Epoch: 1, iteración; 450 de 4841, Loss: 0.5794412612915039\n",
            "Epoch: 1, iteración; 460 de 4841, Loss: 0.5554798126220704\n",
            "Epoch: 1, iteración; 470 de 4841, Loss: 0.633878517150879\n",
            "Epoch: 1, iteración; 480 de 4841, Loss: 0.532817792892456\n",
            "Epoch: 1, iteración; 490 de 4841, Loss: 0.5544514656066895\n",
            "Epoch: 1, iteración; 500 de 4841, Loss: 0.6349199771881103\n",
            "Epoch: 1, iteración; 510 de 4841, Loss: 0.5880411624908447\n",
            "Epoch: 1, iteración; 520 de 4841, Loss: 0.6107115745544434\n",
            "Epoch: 1, iteración; 530 de 4841, Loss: 0.6893162727355957\n",
            "Epoch: 1, iteración; 540 de 4841, Loss: 0.6116952419281005\n",
            "Epoch: 1, iteración; 550 de 4841, Loss: 0.5583889007568359\n",
            "Epoch: 1, iteración; 560 de 4841, Loss: 0.5576311111450195\n",
            "Epoch: 1, iteración; 570 de 4841, Loss: 0.5779459953308106\n",
            "Epoch: 1, iteración; 580 de 4841, Loss: 0.6234555721282959\n",
            "Epoch: 1, iteración; 590 de 4841, Loss: 0.6006031513214112\n",
            "Epoch: 1, iteración; 600 de 4841, Loss: 0.6457106590270996\n",
            "Epoch: 1, iteración; 610 de 4841, Loss: 0.568597936630249\n",
            "Epoch: 1, iteración; 620 de 4841, Loss: 0.6657455921173095\n",
            "Epoch: 1, iteración; 630 de 4841, Loss: 0.611294174194336\n",
            "Epoch: 1, iteración; 640 de 4841, Loss: 0.568696928024292\n",
            "Epoch: 1, iteración; 650 de 4841, Loss: 0.5456916332244873\n",
            "Epoch: 1, iteración; 660 de 4841, Loss: 0.6227947235107422\n",
            "Epoch: 1, iteración; 670 de 4841, Loss: 0.6118196010589599\n",
            "Epoch: 1, iteración; 680 de 4841, Loss: 0.5451189041137695\n",
            "Epoch: 1, iteración; 690 de 4841, Loss: 0.6454945087432862\n",
            "Epoch: 1, iteración; 700 de 4841, Loss: 0.6446630477905273\n",
            "Epoch: 1, iteración; 710 de 4841, Loss: 0.6108872413635253\n",
            "Epoch: 1, iteración; 720 de 4841, Loss: 0.6023993492126465\n",
            "Epoch: 1, iteración; 730 de 4841, Loss: 0.7156840801239014\n",
            "Epoch: 1, iteración; 740 de 4841, Loss: 0.5627066612243652\n",
            "Epoch: 1, iteración; 750 de 4841, Loss: 0.590778923034668\n",
            "Epoch: 1, iteración; 760 de 4841, Loss: 0.5040986061096191\n",
            "Epoch: 1, iteración; 770 de 4841, Loss: 0.6226742267608643\n",
            "Epoch: 1, iteración; 780 de 4841, Loss: 0.600001335144043\n",
            "Epoch: 1, iteración; 790 de 4841, Loss: 0.5997168064117432\n",
            "Epoch: 1, iteración; 800 de 4841, Loss: 0.5420618057250977\n",
            "Epoch: 1, iteración; 810 de 4841, Loss: 0.5997817039489746\n",
            "Epoch: 1, iteración; 820 de 4841, Loss: 0.5881132125854492\n",
            "Epoch: 1, iteración; 830 de 4841, Loss: 0.6231452465057373\n",
            "Epoch: 1, iteración; 840 de 4841, Loss: 0.6117029190063477\n",
            "Epoch: 1, iteración; 850 de 4841, Loss: 0.5658158779144287\n",
            "Epoch: 1, iteración; 860 de 4841, Loss: 0.6122071266174316\n",
            "Epoch: 1, iteración; 870 de 4841, Loss: 0.5656759738922119\n",
            "Epoch: 1, iteración; 880 de 4841, Loss: 0.6123590469360352\n",
            "Epoch: 1, iteración; 890 de 4841, Loss: 0.5211891651153564\n",
            "Epoch: 1, iteración; 900 de 4841, Loss: 0.6000261306762695\n",
            "Epoch: 1, iteración; 910 de 4841, Loss: 0.6698761940002441\n",
            "Epoch: 1, iteración; 920 de 4841, Loss: 0.5659904479980469\n",
            "Epoch: 1, iteración; 930 de 4841, Loss: 0.5203817844390869\n",
            "Epoch: 1, iteración; 940 de 4841, Loss: 0.5648962974548339\n",
            "Epoch: 1, iteración; 950 de 4841, Loss: 0.6356986999511719\n",
            "Epoch: 1, iteración; 960 de 4841, Loss: 0.6349911212921142\n",
            "Epoch: 1, iteración; 970 de 4841, Loss: 0.5773669242858886\n",
            "Epoch: 1, iteración; 980 de 4841, Loss: 0.6561284542083741\n",
            "Epoch: 1, iteración; 990 de 4841, Loss: 0.6004583358764648\n",
            "Epoch: 1, iteración; 1000 de 4841, Loss: 0.5352541446685791\n",
            "Epoch: 1, iteración; 1010 de 4841, Loss: 0.5325725555419922\n",
            "Epoch: 1, iteración; 1020 de 4841, Loss: 0.5652758598327636\n",
            "Epoch: 1, iteración; 1030 de 4841, Loss: 0.5889657020568848\n",
            "Epoch: 1, iteración; 1040 de 4841, Loss: 0.5636223316192627\n",
            "Epoch: 1, iteración; 1050 de 4841, Loss: 0.6357582092285157\n",
            "Epoch: 1, iteración; 1060 de 4841, Loss: 0.5993970394134521\n",
            "Epoch: 1, iteración; 1070 de 4841, Loss: 0.5419232368469238\n",
            "Epoch: 1, iteración; 1080 de 4841, Loss: 0.5880509853363037\n",
            "Epoch: 1, iteración; 1090 de 4841, Loss: 0.600460147857666\n",
            "Epoch: 1, iteración; 1100 de 4841, Loss: 0.6113529205322266\n",
            "Epoch: 1, iteración; 1110 de 4841, Loss: 0.636525297164917\n",
            "Epoch: 1, iteración; 1120 de 4841, Loss: 0.6191159725189209\n",
            "Epoch: 1, iteración; 1130 de 4841, Loss: 0.6226019382476806\n",
            "Epoch: 1, iteración; 1140 de 4841, Loss: 0.675835371017456\n",
            "Epoch: 1, iteración; 1150 de 4841, Loss: 0.6157378673553466\n",
            "Epoch: 1, iteración; 1160 de 4841, Loss: 0.5969866275787353\n",
            "Epoch: 1, iteración; 1170 de 4841, Loss: 0.6217926979064942\n",
            "Epoch: 1, iteración; 1180 de 4841, Loss: 0.6253631114959717\n",
            "Epoch: 1, iteración; 1190 de 4841, Loss: 0.5871493339538574\n",
            "Epoch: 1, iteración; 1200 de 4841, Loss: 0.5861769676208496\n",
            "Epoch: 1, iteración; 1210 de 4841, Loss: 0.5689961433410644\n",
            "Epoch: 1, iteración; 1220 de 4841, Loss: 0.5669027328491211\n",
            "Epoch: 1, iteración; 1230 de 4841, Loss: 0.6977249622344971\n",
            "Epoch: 1, iteración; 1240 de 4841, Loss: 0.6253580093383789\n",
            "Epoch: 1, iteración; 1250 de 4841, Loss: 0.6018123149871826\n",
            "Epoch: 1, iteración; 1260 de 4841, Loss: 0.5896681308746338\n",
            "Epoch: 1, iteración; 1270 de 4841, Loss: 0.6240933895111084\n",
            "Epoch: 1, iteración; 1280 de 4841, Loss: 0.6227554321289063\n",
            "Epoch: 1, iteración; 1290 de 4841, Loss: 0.5928441047668457\n",
            "Epoch: 1, iteración; 1300 de 4841, Loss: 0.6338803768157959\n",
            "Epoch: 1, iteración; 1310 de 4841, Loss: 0.5939930438995361\n",
            "Epoch: 1, iteración; 1320 de 4841, Loss: 0.525407075881958\n",
            "Epoch: 1, iteración; 1330 de 4841, Loss: 0.6346185684204102\n",
            "Epoch: 1, iteración; 1340 de 4841, Loss: 0.6495348453521729\n",
            "Epoch: 1, iteración; 1350 de 4841, Loss: 0.6060971736907959\n",
            "Epoch: 1, iteración; 1360 de 4841, Loss: 0.5844482421875\n",
            "Epoch: 1, iteración; 1370 de 4841, Loss: 0.5904526233673095\n",
            "Epoch: 1, iteración; 1380 de 4841, Loss: 0.5435830116271972\n",
            "Epoch: 1, iteración; 1390 de 4841, Loss: 0.6004091262817383\n",
            "Epoch: 1, iteración; 1400 de 4841, Loss: 0.5764134883880615\n",
            "Epoch: 1, iteración; 1410 de 4841, Loss: 0.6259979248046875\n",
            "Epoch: 1, iteración; 1420 de 4841, Loss: 0.6580392360687256\n",
            "Epoch: 1, iteración; 1430 de 4841, Loss: 0.6021817207336426\n",
            "Epoch: 1, iteración; 1440 de 4841, Loss: 0.570088529586792\n",
            "Epoch: 1, iteración; 1450 de 4841, Loss: 0.6580436706542969\n",
            "Epoch: 1, iteración; 1460 de 4841, Loss: 0.5353949069976807\n",
            "Epoch: 1, iteración; 1470 de 4841, Loss: 0.554165267944336\n",
            "Epoch: 1, iteración; 1480 de 4841, Loss: 0.6234218120574951\n",
            "Epoch: 1, iteración; 1490 de 4841, Loss: 0.6122586727142334\n",
            "Epoch: 1, iteración; 1500 de 4841, Loss: 0.612074899673462\n",
            "Epoch: 1, iteración; 1510 de 4841, Loss: 0.5301766395568848\n",
            "Epoch: 1, iteración; 1520 de 4841, Loss: 0.5882633686065674\n",
            "Epoch: 1, iteración; 1530 de 4841, Loss: 0.5890422821044922\n",
            "Epoch: 1, iteración; 1540 de 4841, Loss: 0.5878218650817871\n",
            "Epoch: 1, iteración; 1550 de 4841, Loss: 0.5418364524841308\n",
            "Epoch: 1, iteración; 1560 de 4841, Loss: 0.563929557800293\n",
            "Epoch: 1, iteración; 1570 de 4841, Loss: 0.6358785629272461\n",
            "Epoch: 1, iteración; 1580 de 4841, Loss: 0.5403309822082519\n",
            "Epoch: 1, iteración; 1590 de 4841, Loss: 0.5999775886535644\n",
            "Epoch: 1, iteración; 1600 de 4841, Loss: 0.5767185688018799\n",
            "Epoch: 1, iteración; 1610 de 4841, Loss: 0.5653961658477783\n",
            "Epoch: 1, iteración; 1620 de 4841, Loss: 0.5650087356567383\n",
            "Epoch: 1, iteración; 1630 de 4841, Loss: 0.5777020454406738\n",
            "Epoch: 1, iteración; 1640 de 4841, Loss: 0.5646678447723389\n",
            "Epoch: 1, iteración; 1650 de 4841, Loss: 0.6589841842651367\n",
            "Epoch: 1, iteración; 1660 de 4841, Loss: 0.6232115745544433\n",
            "Epoch: 1, iteración; 1670 de 4841, Loss: 0.5871825218200684\n",
            "Epoch: 1, iteración; 1680 de 4841, Loss: 0.6119470119476318\n",
            "Epoch: 1, iteración; 1690 de 4841, Loss: 0.5440011978149414\n",
            "Epoch: 1, iteración; 1700 de 4841, Loss: 0.6104197025299072\n",
            "Epoch: 1, iteración; 1710 de 4841, Loss: 0.5551617622375489\n",
            "Epoch: 1, iteración; 1720 de 4841, Loss: 0.6001046180725098\n",
            "Epoch: 1, iteración; 1730 de 4841, Loss: 0.6110552787780762\n",
            "Epoch: 1, iteración; 1740 de 4841, Loss: 0.5773232460021973\n",
            "Epoch: 1, iteración; 1750 de 4841, Loss: 0.6454578399658203\n",
            "Epoch: 1, iteración; 1760 de 4841, Loss: 0.5776761531829834\n",
            "Epoch: 1, iteración; 1770 de 4841, Loss: 0.5997629642486573\n",
            "Epoch: 1, iteración; 1780 de 4841, Loss: 0.6331363677978515\n",
            "Epoch: 1, iteración; 1790 de 4841, Loss: 0.601453447341919\n",
            "Epoch: 1, iteración; 1800 de 4841, Loss: 0.6007100582122803\n",
            "Epoch: 1, iteración; 1810 de 4841, Loss: 0.5457391738891602\n",
            "Epoch: 1, iteración; 1820 de 4841, Loss: 0.5777290821075439\n",
            "Epoch: 1, iteración; 1830 de 4841, Loss: 0.5546028137207031\n",
            "Epoch: 1, iteración; 1840 de 4841, Loss: 0.5066590309143066\n",
            "Epoch: 1, iteración; 1850 de 4841, Loss: 0.5645128726959229\n",
            "Epoch: 1, iteración; 1860 de 4841, Loss: 0.5877680301666259\n",
            "Epoch: 1, iteración; 1870 de 4841, Loss: 0.5760065078735351\n",
            "Epoch: 1, iteración; 1880 de 4841, Loss: 0.540065336227417\n",
            "Epoch: 1, iteración; 1890 de 4841, Loss: 0.6961999893188476\n",
            "Epoch: 1, iteración; 1900 de 4841, Loss: 0.5532350540161133\n",
            "Epoch: 1, iteración; 1910 de 4841, Loss: 0.5887104988098144\n",
            "Epoch: 1, iteración; 1920 de 4841, Loss: 0.5652654647827149\n",
            "Epoch: 1, iteración; 1930 de 4841, Loss: 0.6462390422821045\n",
            "Epoch: 1, iteración; 1940 de 4841, Loss: 0.6000831604003907\n",
            "Epoch: 1, iteración; 1950 de 4841, Loss: 0.5766880989074707\n",
            "Epoch: 1, iteración; 1960 de 4841, Loss: 0.5426928997039795\n",
            "Epoch: 1, iteración; 1970 de 4841, Loss: 0.6456920146942139\n",
            "Epoch: 1, iteración; 1980 de 4841, Loss: 0.6348400592803956\n",
            "Epoch: 1, iteración; 1990 de 4841, Loss: 0.5331334590911865\n",
            "Epoch: 1, iteración; 2000 de 4841, Loss: 0.5656662940979004\n",
            "Epoch: 1, iteración; 2010 de 4841, Loss: 0.5990906715393066\n",
            "Epoch: 1, iteración; 2020 de 4841, Loss: 0.623046875\n",
            "Epoch: 1, iteración; 2030 de 4841, Loss: 0.5308250427246094\n",
            "Epoch: 1, iteración; 2040 de 4841, Loss: 0.565473222732544\n",
            "Epoch: 1, iteración; 2050 de 4841, Loss: 0.5297483921051025\n",
            "Epoch: 1, iteración; 2060 de 4841, Loss: 0.5766006469726562\n",
            "Epoch: 1, iteración; 2070 de 4841, Loss: 0.5643925666809082\n",
            "Epoch: 1, iteración; 2080 de 4841, Loss: 0.6123469352722168\n",
            "Epoch: 1, iteración; 2090 de 4841, Loss: 0.6242849349975585\n",
            "Epoch: 1, iteración; 2100 de 4841, Loss: 0.5893699645996093\n",
            "Epoch: 1, iteración; 2110 de 4841, Loss: 0.6347530841827392\n",
            "Epoch: 1, iteración; 2120 de 4841, Loss: 0.5658091545104981\n",
            "Epoch: 1, iteración; 2130 de 4841, Loss: 0.577760887145996\n",
            "Epoch: 1, iteración; 2140 de 4841, Loss: 0.6238240242004395\n",
            "Epoch: 1, iteración; 2150 de 4841, Loss: 0.6005375862121582\n",
            "Epoch: 1, iteración; 2160 de 4841, Loss: 0.5887987613677979\n",
            "Epoch: 1, iteración; 2170 de 4841, Loss: 0.6459529399871826\n",
            "Epoch: 1, iteración; 2180 de 4841, Loss: 0.601123857498169\n",
            "Epoch: 1, iteración; 2190 de 4841, Loss: 0.5892430782318115\n",
            "Epoch: 1, iteración; 2200 de 4841, Loss: 0.5895778179168701\n",
            "Epoch: 1, iteración; 2210 de 4841, Loss: 0.5659003257751465\n",
            "Epoch: 1, iteración; 2220 de 4841, Loss: 0.5440967559814454\n",
            "Epoch: 1, iteración; 2230 de 4841, Loss: 0.6000389575958252\n",
            "Epoch: 1, iteración; 2240 de 4841, Loss: 0.6690305233001709\n",
            "Epoch: 1, iteración; 2250 de 4841, Loss: 0.6667927742004395\n",
            "Epoch: 1, iteración; 2260 de 4841, Loss: 0.5240761756896972\n",
            "Epoch: 1, iteración; 2270 de 4841, Loss: 0.578066635131836\n",
            "Epoch: 1, iteración; 2280 de 4841, Loss: 0.531862735748291\n",
            "Epoch: 1, iteración; 2290 de 4841, Loss: 0.5414785385131836\n",
            "Epoch: 1, iteración; 2300 de 4841, Loss: 0.5638190269470215\n",
            "Epoch: 1, iteración; 2310 de 4841, Loss: 0.5762856483459473\n",
            "Epoch: 1, iteración; 2320 de 4841, Loss: 0.503411054611206\n",
            "Epoch: 1, iteración; 2330 de 4841, Loss: 0.5147973537445069\n",
            "Epoch: 1, iteración; 2340 de 4841, Loss: 0.6125998497009277\n",
            "Epoch: 1, iteración; 2350 de 4841, Loss: 0.5271447181701661\n",
            "Epoch: 1, iteración; 2360 de 4841, Loss: 0.6609867572784424\n",
            "Epoch: 1, iteración; 2370 de 4841, Loss: 0.576068115234375\n",
            "Epoch: 1, iteración; 2380 de 4841, Loss: 0.6475006103515625\n",
            "Epoch: 1, iteración; 2390 de 4841, Loss: 0.5887548923492432\n",
            "Epoch: 1, iteración; 2400 de 4841, Loss: 0.5538083076477051\n",
            "Epoch: 1, iteración; 2410 de 4841, Loss: 0.6226401329040527\n",
            "Epoch: 1, iteración; 2420 de 4841, Loss: 0.7027152061462403\n",
            "Epoch: 1, iteración; 2430 de 4841, Loss: 0.5773632049560546\n",
            "Epoch: 1, iteración; 2440 de 4841, Loss: 0.5890404224395752\n",
            "Epoch: 1, iteración; 2450 de 4841, Loss: 0.556666374206543\n",
            "Epoch: 1, iteración; 2460 de 4841, Loss: 0.6108748912811279\n",
            "Epoch: 1, iteración; 2470 de 4841, Loss: 0.6459342479705811\n",
            "Epoch: 1, iteración; 2480 de 4841, Loss: 0.6106225967407226\n",
            "Epoch: 1, iteración; 2490 de 4841, Loss: 0.49037799835205076\n",
            "Epoch: 1, iteración; 2500 de 4841, Loss: 0.4714388847351074\n",
            "Epoch: 1, iteración; 2510 de 4841, Loss: 0.6129560947418213\n",
            "Epoch: 1, iteración; 2520 de 4841, Loss: 0.686436939239502\n",
            "Epoch: 1, iteración; 2530 de 4841, Loss: 0.5639922618865967\n",
            "Epoch: 1, iteración; 2540 de 4841, Loss: 0.6112710952758789\n",
            "Epoch: 1, iteración; 2550 de 4841, Loss: 0.5769242763519287\n",
            "Epoch: 1, iteración; 2560 de 4841, Loss: 0.5879546165466308\n",
            "Epoch: 1, iteración; 2570 de 4841, Loss: 0.5067198753356934\n",
            "Epoch: 1, iteración; 2580 de 4841, Loss: 0.48055424690246584\n",
            "Epoch: 1, iteración; 2590 de 4841, Loss: 0.6004987716674804\n",
            "Epoch: 1, iteración; 2600 de 4841, Loss: 0.5881730556488037\n",
            "Epoch: 1, iteración; 2610 de 4841, Loss: 0.6369515895843506\n",
            "Epoch: 1, iteración; 2620 de 4841, Loss: 0.5634010791778564\n",
            "Epoch: 1, iteración; 2630 de 4841, Loss: 0.5880070686340332\n",
            "Epoch: 1, iteración; 2640 de 4841, Loss: 0.6595259666442871\n",
            "Epoch: 1, iteración; 2650 de 4841, Loss: 0.5666849136352539\n",
            "Epoch: 1, iteración; 2660 de 4841, Loss: 0.6228783607482911\n",
            "Epoch: 1, iteración; 2670 de 4841, Loss: 0.6102737426757813\n",
            "Epoch: 1, iteración; 2680 de 4841, Loss: 0.555980110168457\n",
            "Epoch: 1, iteración; 2690 de 4841, Loss: 0.5891820907592773\n",
            "Epoch: 1, iteración; 2700 de 4841, Loss: 0.6118359088897705\n",
            "Epoch: 1, iteración; 2710 de 4841, Loss: 0.5774605751037598\n",
            "Epoch: 1, iteración; 2720 de 4841, Loss: 0.6806700229644775\n",
            "Epoch: 1, iteración; 2730 de 4841, Loss: 0.6351958274841308\n",
            "Epoch: 1, iteración; 2740 de 4841, Loss: 0.578751516342163\n",
            "Epoch: 1, iteración; 2750 de 4841, Loss: 0.5461668014526367\n",
            "Epoch: 1, iteración; 2760 de 4841, Loss: 0.588134479522705\n",
            "Epoch: 1, iteración; 2770 de 4841, Loss: 0.5418109893798828\n",
            "Epoch: 1, iteración; 2780 de 4841, Loss: 0.5644673824310302\n",
            "Epoch: 1, iteración; 2790 de 4841, Loss: 0.6360127449035644\n",
            "Epoch: 1, iteración; 2800 de 4841, Loss: 0.5767773151397705\n",
            "Epoch: 1, iteración; 2810 de 4841, Loss: 0.6123415946960449\n",
            "Epoch: 1, iteración; 2820 de 4841, Loss: 0.5768440723419189\n",
            "Epoch: 1, iteración; 2830 de 4841, Loss: 0.6115630626678467\n",
            "Epoch: 1, iteración; 2840 de 4841, Loss: 0.6235026836395263\n",
            "Epoch: 1, iteración; 2850 de 4841, Loss: 0.6222070217132568\n",
            "Epoch: 1, iteración; 2860 de 4841, Loss: 0.6007840633392334\n",
            "Epoch: 1, iteración; 2870 de 4841, Loss: 0.6439997673034668\n",
            "Epoch: 1, iteración; 2880 de 4841, Loss: 0.5575730800628662\n",
            "Epoch: 1, iteración; 2890 de 4841, Loss: 0.6226160049438476\n",
            "Epoch: 1, iteración; 2900 de 4841, Loss: 0.5575391769409179\n",
            "Epoch: 1, iteración; 2910 de 4841, Loss: 0.6995004177093506\n",
            "Epoch: 1, iteración; 2920 de 4841, Loss: 0.5393399715423584\n",
            "Epoch: 1, iteración; 2930 de 4841, Loss: 0.6007071018218995\n",
            "Epoch: 1, iteración; 2940 de 4841, Loss: 0.5323050498962403\n",
            "Epoch: 1, iteración; 2950 de 4841, Loss: 0.6121355056762695\n",
            "Epoch: 1, iteración; 2960 de 4841, Loss: 0.5647906303405762\n",
            "Epoch: 1, iteración; 2970 de 4841, Loss: 0.5889990329742432\n",
            "Epoch: 1, iteración; 2980 de 4841, Loss: 0.6359333515167236\n",
            "Epoch: 1, iteración; 2990 de 4841, Loss: 0.5184281826019287\n",
            "Epoch: 1, iteración; 3000 de 4841, Loss: 0.5406262397766113\n",
            "Epoch: 1, iteración; 3010 de 4841, Loss: 0.6717551708221435\n",
            "Epoch: 1, iteración; 3020 de 4841, Loss: 0.5300566196441651\n",
            "Epoch: 1, iteración; 3030 de 4841, Loss: 0.5533248901367187\n",
            "Epoch: 1, iteración; 3040 de 4841, Loss: 0.6239917755126954\n",
            "Epoch: 1, iteración; 3050 de 4841, Loss: 0.6001031875610352\n",
            "Epoch: 1, iteración; 3060 de 4841, Loss: 0.6589113712310791\n",
            "Epoch: 1, iteración; 3070 de 4841, Loss: 0.6233743667602539\n",
            "Epoch: 1, iteración; 3080 de 4841, Loss: 0.6221924781799316\n",
            "Epoch: 1, iteración; 3090 de 4841, Loss: 0.5350172042846679\n",
            "Epoch: 1, iteración; 3100 de 4841, Loss: 0.5886547088623046\n",
            "Epoch: 1, iteración; 3110 de 4841, Loss: 0.6231959819793701\n",
            "Epoch: 1, iteración; 3120 de 4841, Loss: 0.6456081390380859\n",
            "Epoch: 1, iteración; 3130 de 4841, Loss: 0.5782060146331787\n",
            "Epoch: 1, iteración; 3140 de 4841, Loss: 0.6226962566375732\n",
            "Epoch: 1, iteración; 3150 de 4841, Loss: 0.5890776157379151\n",
            "Epoch: 1, iteración; 3160 de 4841, Loss: 0.6007952690124512\n",
            "Epoch: 1, iteración; 3170 de 4841, Loss: 0.5899269104003906\n",
            "Epoch: 1, iteración; 3180 de 4841, Loss: 0.6331262111663818\n",
            "Epoch: 1, iteración; 3190 de 4841, Loss: 0.6228363990783692\n",
            "Epoch: 1, iteración; 3200 de 4841, Loss: 0.5902530670166015\n",
            "Epoch: 1, iteración; 3210 de 4841, Loss: 0.5805609703063965\n",
            "Epoch: 1, iteración; 3220 de 4841, Loss: 0.6230847835540771\n",
            "Epoch: 1, iteración; 3230 de 4841, Loss: 0.5554707050323486\n",
            "Epoch: 1, iteración; 3240 de 4841, Loss: 0.5896368980407715\n",
            "Epoch: 1, iteración; 3250 de 4841, Loss: 0.6222761154174805\n",
            "Epoch: 1, iteración; 3260 de 4841, Loss: 0.5787827968597412\n",
            "Epoch: 1, iteración; 3270 de 4841, Loss: 0.588254165649414\n",
            "Epoch: 1, iteración; 3280 de 4841, Loss: 0.5896718502044678\n",
            "Epoch: 1, iteración; 3290 de 4841, Loss: 0.6555639743804932\n",
            "Epoch: 1, iteración; 3300 de 4841, Loss: 0.5795068264007568\n",
            "Epoch: 1, iteración; 3310 de 4841, Loss: 0.5800015449523925\n",
            "Epoch: 1, iteración; 3320 de 4841, Loss: 0.6435393333435059\n",
            "Epoch: 1, iteración; 3330 de 4841, Loss: 0.5779245853424072\n",
            "Epoch: 1, iteración; 3340 de 4841, Loss: 0.6112147331237793\n",
            "Epoch: 1, iteración; 3350 de 4841, Loss: 0.5554885387420654\n",
            "Epoch: 1, iteración; 3360 de 4841, Loss: 0.5442142486572266\n",
            "Epoch: 1, iteración; 3370 de 4841, Loss: 0.542823314666748\n",
            "Epoch: 1, iteración; 3380 de 4841, Loss: 0.5522158145904541\n",
            "Epoch: 1, iteración; 3390 de 4841, Loss: 0.6490164756774902\n",
            "Epoch: 1, iteración; 3400 de 4841, Loss: 0.5765722274780274\n",
            "Epoch: 1, iteración; 3410 de 4841, Loss: 0.5645327568054199\n",
            "Epoch: 1, iteración; 3420 de 4841, Loss: 0.5528679847717285\n",
            "Epoch: 1, iteración; 3430 de 4841, Loss: 0.6709479331970215\n",
            "Epoch: 1, iteración; 3440 de 4841, Loss: 0.6339646816253662\n",
            "Epoch: 1, iteración; 3450 de 4841, Loss: 0.5435546398162842\n",
            "Epoch: 1, iteración; 3460 de 4841, Loss: 0.6006373882293701\n",
            "Epoch: 1, iteración; 3470 de 4841, Loss: 0.6007150650024414\n",
            "Epoch: 1, iteración; 3480 de 4841, Loss: 0.6443362712860108\n",
            "Epoch: 1, iteración; 3490 de 4841, Loss: 0.6331616401672363\n",
            "Epoch: 1, iteración; 3500 de 4841, Loss: 0.5037094116210937\n",
            "Epoch: 1, iteración; 3510 de 4841, Loss: 0.6334257602691651\n",
            "Epoch: 1, iteración; 3520 de 4841, Loss: 0.6001091957092285\n",
            "Epoch: 1, iteración; 3530 de 4841, Loss: 0.49760966300964354\n",
            "Epoch: 1, iteración; 3540 de 4841, Loss: 0.6462921142578125\n",
            "Epoch: 1, iteración; 3550 de 4841, Loss: 0.6343078136444091\n",
            "Epoch: 1, iteración; 3560 de 4841, Loss: 0.5770277500152587\n",
            "Epoch: 1, iteración; 3570 de 4841, Loss: 0.6803620815277099\n",
            "Epoch: 1, iteración; 3580 de 4841, Loss: 0.6337996006011963\n",
            "Epoch: 1, iteración; 3590 de 4841, Loss: 0.5159722805023194\n",
            "Epoch: 1, iteración; 3600 de 4841, Loss: 0.6006110668182373\n",
            "Epoch: 1, iteración; 3610 de 4841, Loss: 0.6335935592651367\n",
            "Epoch: 1, iteración; 3620 de 4841, Loss: 0.6007009029388428\n",
            "Epoch: 1, iteración; 3630 de 4841, Loss: 0.6447837352752686\n",
            "Epoch: 1, iteración; 3640 de 4841, Loss: 0.5471361160278321\n",
            "Epoch: 1, iteración; 3650 de 4841, Loss: 0.5569287300109863\n",
            "Epoch: 1, iteración; 3660 de 4841, Loss: 0.5891741752624512\n",
            "Epoch: 1, iteración; 3670 de 4841, Loss: 0.5885693550109863\n",
            "Epoch: 1, iteración; 3680 de 4841, Loss: 0.5768997192382812\n",
            "Epoch: 1, iteración; 3690 de 4841, Loss: 0.6818221092224122\n",
            "Epoch: 1, iteración; 3700 de 4841, Loss: 0.5779213428497314\n",
            "Epoch: 1, iteración; 3710 de 4841, Loss: 0.5665187358856201\n",
            "Epoch: 1, iteración; 3720 de 4841, Loss: 0.519755744934082\n",
            "Epoch: 1, iteración; 3730 de 4841, Loss: 0.6351420402526855\n",
            "Epoch: 1, iteración; 3740 de 4841, Loss: 0.5519733905792237\n",
            "Epoch: 1, iteración; 3750 de 4841, Loss: 0.6358920097351074\n",
            "Epoch: 1, iteración; 3760 de 4841, Loss: 0.6467832088470459\n",
            "Epoch: 1, iteración; 3770 de 4841, Loss: 0.6552728176116943\n",
            "Epoch: 1, iteración; 3780 de 4841, Loss: 0.654532527923584\n",
            "Epoch: 1, iteración; 3790 de 4841, Loss: 0.5624814987182617\n",
            "Epoch: 1, iteración; 3800 de 4841, Loss: 0.5805187225341797\n",
            "Epoch: 1, iteración; 3810 de 4841, Loss: 0.6745564460754394\n",
            "Epoch: 1, iteración; 3820 de 4841, Loss: 0.600735092163086\n",
            "Epoch: 1, iteración; 3830 de 4841, Loss: 0.5703361511230469\n",
            "Epoch: 1, iteración; 3840 de 4841, Loss: 0.6324723243713379\n",
            "Epoch: 1, iteración; 3850 de 4841, Loss: 0.631236982345581\n",
            "Epoch: 1, iteración; 3860 de 4841, Loss: 0.6303964614868164\n",
            "Epoch: 1, iteración; 3870 de 4841, Loss: 0.5697410106658936\n",
            "Epoch: 1, iteración; 3880 de 4841, Loss: 0.5909807205200195\n",
            "Epoch: 1, iteración; 3890 de 4841, Loss: 0.6653133392333984\n",
            "Epoch: 1, iteración; 3900 de 4841, Loss: 0.6722613334655761\n",
            "Epoch: 1, iteración; 3910 de 4841, Loss: 0.5725312232971191\n",
            "Epoch: 1, iteración; 3920 de 4841, Loss: 0.6793982505798339\n",
            "Epoch: 1, iteración; 3930 de 4841, Loss: 0.5554877281188965\n",
            "Epoch: 1, iteración; 3940 de 4841, Loss: 0.5913092613220214\n",
            "Epoch: 1, iteración; 3950 de 4841, Loss: 0.5352590560913086\n",
            "Epoch: 1, iteración; 3960 de 4841, Loss: 0.5883083343505859\n",
            "Epoch: 1, iteración; 3970 de 4841, Loss: 0.6229722976684571\n",
            "Epoch: 1, iteración; 3980 de 4841, Loss: 0.6116392135620117\n",
            "Epoch: 1, iteración; 3990 de 4841, Loss: 0.5776293754577637\n",
            "Epoch: 1, iteración; 4000 de 4841, Loss: 0.6560634136199951\n",
            "Epoch: 1, iteración; 4010 de 4841, Loss: 0.6653472423553467\n",
            "Epoch: 1, iteración; 4020 de 4841, Loss: 0.5819302558898926\n",
            "Epoch: 1, iteración; 4030 de 4841, Loss: 0.5800949096679687\n",
            "Epoch: 1, iteración; 4040 de 4841, Loss: 0.6108798503875732\n",
            "Epoch: 1, iteración; 4050 de 4841, Loss: 0.6016446590423584\n",
            "Epoch: 1, iteración; 4060 de 4841, Loss: 0.5446715354919434\n",
            "Epoch: 1, iteración; 4070 de 4841, Loss: 0.7668614864349366\n",
            "Epoch: 1, iteración; 4080 de 4841, Loss: 0.610695743560791\n",
            "Epoch: 1, iteración; 4090 de 4841, Loss: 0.660667896270752\n",
            "Epoch: 1, iteración; 4100 de 4841, Loss: 0.5841590881347656\n",
            "Epoch: 1, iteración; 4110 de 4841, Loss: 0.5835001468658447\n",
            "Epoch: 1, iteración; 4120 de 4841, Loss: 0.6430355072021484\n",
            "Epoch: 1, iteración; 4130 de 4841, Loss: 0.5822570323944092\n",
            "Epoch: 1, iteración; 4140 de 4841, Loss: 0.5371511936187744\n",
            "Epoch: 1, iteración; 4150 de 4841, Loss: 0.7021054744720459\n",
            "Epoch: 1, iteración; 4160 de 4841, Loss: 0.5781443119049072\n",
            "Epoch: 1, iteración; 4170 de 4841, Loss: 0.6562931060791015\n",
            "Epoch: 1, iteración; 4180 de 4841, Loss: 0.6529119968414306\n",
            "Epoch: 1, iteración; 4190 de 4841, Loss: 0.5916008949279785\n",
            "Epoch: 1, iteración; 4200 de 4841, Loss: 0.5927188873291016\n",
            "Epoch: 1, iteración; 4210 de 4841, Loss: 0.6223345756530761\n",
            "Epoch: 1, iteración; 4220 de 4841, Loss: 0.5169337749481201\n",
            "Epoch: 1, iteración; 4230 de 4841, Loss: 0.5666087150573731\n",
            "Epoch: 1, iteración; 4240 de 4841, Loss: 0.5643514633178711\n",
            "Epoch: 1, iteración; 4250 de 4841, Loss: 0.5886430740356445\n",
            "Epoch: 1, iteración; 4260 de 4841, Loss: 0.7069888114929199\n",
            "Epoch: 1, iteración; 4270 de 4841, Loss: 0.5427385807037354\n",
            "Epoch: 1, iteración; 4280 de 4841, Loss: 0.6004188537597657\n",
            "Epoch: 1, iteración; 4290 de 4841, Loss: 0.5535234451293946\n",
            "Epoch: 1, iteración; 4300 de 4841, Loss: 0.6117954254150391\n",
            "Epoch: 1, iteración; 4310 de 4841, Loss: 0.6674286842346191\n",
            "Epoch: 1, iteración; 4320 de 4841, Loss: 0.6113923072814942\n",
            "Epoch: 1, iteración; 4330 de 4841, Loss: 0.5674118518829345\n",
            "Epoch: 1, iteración; 4340 de 4841, Loss: 0.5788196086883545\n",
            "Epoch: 1, iteración; 4350 de 4841, Loss: 0.5674981117248535\n",
            "Epoch: 1, iteración; 4360 de 4841, Loss: 0.5766598224639893\n",
            "Epoch: 1, iteración; 4370 de 4841, Loss: 0.6003395557403565\n",
            "Epoch: 1, iteración; 4380 de 4841, Loss: 0.6227129936218262\n",
            "Epoch: 1, iteración; 4390 de 4841, Loss: 0.5548270225524903\n",
            "Epoch: 1, iteración; 4400 de 4841, Loss: 0.6222103118896485\n",
            "Epoch: 1, iteración; 4410 de 4841, Loss: 0.5655318260192871\n",
            "Epoch: 1, iteración; 4420 de 4841, Loss: 0.5766774177551269\n",
            "Epoch: 1, iteración; 4430 de 4841, Loss: 0.5189030647277832\n",
            "Epoch: 1, iteración; 4440 de 4841, Loss: 0.6126375675201416\n",
            "Epoch: 1, iteración; 4450 de 4841, Loss: 0.576565933227539\n",
            "Epoch: 1, iteración; 4460 de 4841, Loss: 0.6116034030914307\n",
            "Epoch: 1, iteración; 4470 de 4841, Loss: 0.6115942001342773\n",
            "Epoch: 1, iteración; 4480 de 4841, Loss: 0.6230997085571289\n",
            "Epoch: 1, iteración; 4490 de 4841, Loss: 0.6666932106018066\n",
            "Epoch: 1, iteración; 4500 de 4841, Loss: 0.6209948539733887\n",
            "Epoch: 1, iteración; 4510 de 4841, Loss: 0.5799324989318848\n",
            "Epoch: 1, iteración; 4520 de 4841, Loss: 0.5270967483520508\n",
            "Epoch: 1, iteración; 4530 de 4841, Loss: 0.6327363967895507\n",
            "Epoch: 1, iteración; 4540 de 4841, Loss: 0.6118791580200196\n",
            "Epoch: 1, iteración; 4550 de 4841, Loss: 0.5554449081420898\n",
            "Epoch: 1, iteración; 4560 de 4841, Loss: 0.5894975662231445\n",
            "Epoch: 1, iteración; 4570 de 4841, Loss: 0.6228592872619629\n",
            "Epoch: 1, iteración; 4580 de 4841, Loss: 0.588167953491211\n",
            "Epoch: 1, iteración; 4590 de 4841, Loss: 0.5542101860046387\n",
            "Epoch: 1, iteración; 4600 de 4841, Loss: 0.6786482810974122\n",
            "Epoch: 1, iteración; 4610 de 4841, Loss: 0.5340065479278564\n",
            "Epoch: 1, iteración; 4620 de 4841, Loss: 0.5887075424194336\n",
            "Epoch: 1, iteración; 4630 de 4841, Loss: 0.6100342750549317\n",
            "Epoch: 1, iteración; 4640 de 4841, Loss: 0.6112513542175293\n",
            "Epoch: 1, iteración; 4650 de 4841, Loss: 0.5781620502471924\n",
            "Epoch: 1, iteración; 4660 de 4841, Loss: 0.5446516513824463\n",
            "Epoch: 1, iteración; 4670 de 4841, Loss: 0.5658185958862305\n",
            "Epoch: 1, iteración; 4680 de 4841, Loss: 0.600634241104126\n",
            "Epoch: 1, iteración; 4690 de 4841, Loss: 0.6918574333190918\n",
            "Epoch: 1, iteración; 4700 de 4841, Loss: 0.5669947624206543\n",
            "Epoch: 1, iteración; 4710 de 4841, Loss: 0.6000972270965577\n",
            "Epoch: 1, iteración; 4720 de 4841, Loss: 0.5661997318267822\n",
            "Epoch: 1, iteración; 4730 de 4841, Loss: 0.5784936904907226\n",
            "Epoch: 1, iteración; 4740 de 4841, Loss: 0.5661192417144776\n",
            "Epoch: 1, iteración; 4750 de 4841, Loss: 0.5887417316436767\n",
            "Epoch: 1, iteración; 4760 de 4841, Loss: 0.6119264602661133\n",
            "Epoch: 1, iteración; 4770 de 4841, Loss: 0.5775559902191162\n",
            "Epoch: 1, iteración; 4780 de 4841, Loss: 0.6341427803039551\n",
            "Epoch: 1, iteración; 4790 de 4841, Loss: 0.6002057552337646\n",
            "Epoch: 1, iteración; 4800 de 4841, Loss: 0.5884576797485351\n",
            "Epoch: 1, iteración; 4810 de 4841, Loss: 0.6221590518951416\n",
            "Epoch: 1, iteración; 4820 de 4841, Loss: 0.5676879405975341\n",
            "Epoch: 1, iteración; 4830 de 4841, Loss: 0.6224714279174804\n",
            "Epoch: 1, iteración; 4840 de 4841, Loss: 0.6011175632476806\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainBert(epoch)"
      ],
      "id": "nciovBO7Jgkq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5600c8-0b94-488c-932f-ce7eaa5448d5",
        "id": "yDR6nTo6Jgkq"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_50_v2.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "id": "yDR6nTo6Jgkq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMio1RB1JkJw"
      },
      "source": [
        "##### Evaluación del modelo"
      ],
      "id": "bMio1RB1JkJw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liSJt1RZJkJx"
      },
      "outputs": [],
      "source": [
        "def validationBert(epoch):\n",
        "  model.eval()\n",
        "  fin_targets=[]\n",
        "  fin_outputs=[]\n",
        "  num_iteraciones = len(testing_loader)\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testing_loader, 0):\n",
        "      ids = data['ids'].to(device)\n",
        "      mask = data['mask'].to(device)\n",
        "      token_type_ids = data['token_type_ids'].to(device)\n",
        "      targets = data['target'].to(device)\n",
        "\n",
        "      print(f\"Batch {i} de {num_iteraciones}\")\n",
        "\n",
        "      outputs = model(ids, mask, token_type_ids)\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "  return fin_outputs, fin_targets"
      ],
      "id": "liSJt1RZJkJx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "q0LL26RpJkJx"
      },
      "id": "q0LL26RpJkJx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6fc0d7d-6bd5-4b41-b844-589d8fd6c276",
        "id": "z-0sBh2kJkJx"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La ruta existe\n",
            "Modelo cargado correctamente\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_50_v2.pth\"):\n",
        "  print(\"La ruta existe\")\n",
        "  model = BERTClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_50_v2.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_50_v2.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "id": "z-0sBh2kJkJx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c99c03d-4658-4cd3-e3f8-fe7dd6e97533",
        "id": "uRgipb0wJkJy"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 de 606\n",
            "Batch 1 de 606\n",
            "Batch 2 de 606\n",
            "Batch 3 de 606\n",
            "Batch 4 de 606\n",
            "Batch 5 de 606\n",
            "Batch 6 de 606\n",
            "Batch 7 de 606\n",
            "Batch 8 de 606\n",
            "Batch 9 de 606\n",
            "Batch 10 de 606\n",
            "Batch 11 de 606\n",
            "Batch 12 de 606\n",
            "Batch 13 de 606\n",
            "Batch 14 de 606\n",
            "Batch 15 de 606\n",
            "Batch 16 de 606\n",
            "Batch 17 de 606\n",
            "Batch 18 de 606\n",
            "Batch 19 de 606\n",
            "Batch 20 de 606\n",
            "Batch 21 de 606\n",
            "Batch 22 de 606\n",
            "Batch 23 de 606\n",
            "Batch 24 de 606\n",
            "Batch 25 de 606\n",
            "Batch 26 de 606\n",
            "Batch 27 de 606\n",
            "Batch 28 de 606\n",
            "Batch 29 de 606\n",
            "Batch 30 de 606\n",
            "Batch 31 de 606\n",
            "Batch 32 de 606\n",
            "Batch 33 de 606\n",
            "Batch 34 de 606\n",
            "Batch 35 de 606\n",
            "Batch 36 de 606\n",
            "Batch 37 de 606\n",
            "Batch 38 de 606\n",
            "Batch 39 de 606\n",
            "Batch 40 de 606\n",
            "Batch 41 de 606\n",
            "Batch 42 de 606\n",
            "Batch 43 de 606\n",
            "Batch 44 de 606\n",
            "Batch 45 de 606\n",
            "Batch 46 de 606\n",
            "Batch 47 de 606\n",
            "Batch 48 de 606\n",
            "Batch 49 de 606\n",
            "Batch 50 de 606\n",
            "Batch 51 de 606\n",
            "Batch 52 de 606\n",
            "Batch 53 de 606\n",
            "Batch 54 de 606\n",
            "Batch 55 de 606\n",
            "Batch 56 de 606\n",
            "Batch 57 de 606\n",
            "Batch 58 de 606\n",
            "Batch 59 de 606\n",
            "Batch 60 de 606\n",
            "Batch 61 de 606\n",
            "Batch 62 de 606\n",
            "Batch 63 de 606\n",
            "Batch 64 de 606\n",
            "Batch 65 de 606\n",
            "Batch 66 de 606\n",
            "Batch 67 de 606\n",
            "Batch 68 de 606\n",
            "Batch 69 de 606\n",
            "Batch 70 de 606\n",
            "Batch 71 de 606\n",
            "Batch 72 de 606\n",
            "Batch 73 de 606\n",
            "Batch 74 de 606\n",
            "Batch 75 de 606\n",
            "Batch 76 de 606\n",
            "Batch 77 de 606\n",
            "Batch 78 de 606\n",
            "Batch 79 de 606\n",
            "Batch 80 de 606\n",
            "Batch 81 de 606\n",
            "Batch 82 de 606\n",
            "Batch 83 de 606\n",
            "Batch 84 de 606\n",
            "Batch 85 de 606\n",
            "Batch 86 de 606\n",
            "Batch 87 de 606\n",
            "Batch 88 de 606\n",
            "Batch 89 de 606\n",
            "Batch 90 de 606\n",
            "Batch 91 de 606\n",
            "Batch 92 de 606\n",
            "Batch 93 de 606\n",
            "Batch 94 de 606\n",
            "Batch 95 de 606\n",
            "Batch 96 de 606\n",
            "Batch 97 de 606\n",
            "Batch 98 de 606\n",
            "Batch 99 de 606\n",
            "Batch 100 de 606\n",
            "Batch 101 de 606\n",
            "Batch 102 de 606\n",
            "Batch 103 de 606\n",
            "Batch 104 de 606\n",
            "Batch 105 de 606\n",
            "Batch 106 de 606\n",
            "Batch 107 de 606\n",
            "Batch 108 de 606\n",
            "Batch 109 de 606\n",
            "Batch 110 de 606\n",
            "Batch 111 de 606\n",
            "Batch 112 de 606\n",
            "Batch 113 de 606\n",
            "Batch 114 de 606\n",
            "Batch 115 de 606\n",
            "Batch 116 de 606\n",
            "Batch 117 de 606\n",
            "Batch 118 de 606\n",
            "Batch 119 de 606\n",
            "Batch 120 de 606\n",
            "Batch 121 de 606\n",
            "Batch 122 de 606\n",
            "Batch 123 de 606\n",
            "Batch 124 de 606\n",
            "Batch 125 de 606\n",
            "Batch 126 de 606\n",
            "Batch 127 de 606\n",
            "Batch 128 de 606\n",
            "Batch 129 de 606\n",
            "Batch 130 de 606\n",
            "Batch 131 de 606\n",
            "Batch 132 de 606\n",
            "Batch 133 de 606\n",
            "Batch 134 de 606\n",
            "Batch 135 de 606\n",
            "Batch 136 de 606\n",
            "Batch 137 de 606\n",
            "Batch 138 de 606\n",
            "Batch 139 de 606\n",
            "Batch 140 de 606\n",
            "Batch 141 de 606\n",
            "Batch 142 de 606\n",
            "Batch 143 de 606\n",
            "Batch 144 de 606\n",
            "Batch 145 de 606\n",
            "Batch 146 de 606\n",
            "Batch 147 de 606\n",
            "Batch 148 de 606\n",
            "Batch 149 de 606\n",
            "Batch 150 de 606\n",
            "Batch 151 de 606\n",
            "Batch 152 de 606\n",
            "Batch 153 de 606\n",
            "Batch 154 de 606\n",
            "Batch 155 de 606\n",
            "Batch 156 de 606\n",
            "Batch 157 de 606\n",
            "Batch 158 de 606\n",
            "Batch 159 de 606\n",
            "Batch 160 de 606\n",
            "Batch 161 de 606\n",
            "Batch 162 de 606\n",
            "Batch 163 de 606\n",
            "Batch 164 de 606\n",
            "Batch 165 de 606\n",
            "Batch 166 de 606\n",
            "Batch 167 de 606\n",
            "Batch 168 de 606\n",
            "Batch 169 de 606\n",
            "Batch 170 de 606\n",
            "Batch 171 de 606\n",
            "Batch 172 de 606\n",
            "Batch 173 de 606\n",
            "Batch 174 de 606\n",
            "Batch 175 de 606\n",
            "Batch 176 de 606\n",
            "Batch 177 de 606\n",
            "Batch 178 de 606\n",
            "Batch 179 de 606\n",
            "Batch 180 de 606\n",
            "Batch 181 de 606\n",
            "Batch 182 de 606\n",
            "Batch 183 de 606\n",
            "Batch 184 de 606\n",
            "Batch 185 de 606\n",
            "Batch 186 de 606\n",
            "Batch 187 de 606\n",
            "Batch 188 de 606\n",
            "Batch 189 de 606\n",
            "Batch 190 de 606\n",
            "Batch 191 de 606\n",
            "Batch 192 de 606\n",
            "Batch 193 de 606\n",
            "Batch 194 de 606\n",
            "Batch 195 de 606\n",
            "Batch 196 de 606\n",
            "Batch 197 de 606\n",
            "Batch 198 de 606\n",
            "Batch 199 de 606\n",
            "Batch 200 de 606\n",
            "Batch 201 de 606\n",
            "Batch 202 de 606\n",
            "Batch 203 de 606\n",
            "Batch 204 de 606\n",
            "Batch 205 de 606\n",
            "Batch 206 de 606\n",
            "Batch 207 de 606\n",
            "Batch 208 de 606\n",
            "Batch 209 de 606\n",
            "Batch 210 de 606\n",
            "Batch 211 de 606\n",
            "Batch 212 de 606\n",
            "Batch 213 de 606\n",
            "Batch 214 de 606\n",
            "Batch 215 de 606\n",
            "Batch 216 de 606\n",
            "Batch 217 de 606\n",
            "Batch 218 de 606\n",
            "Batch 219 de 606\n",
            "Batch 220 de 606\n",
            "Batch 221 de 606\n",
            "Batch 222 de 606\n",
            "Batch 223 de 606\n",
            "Batch 224 de 606\n",
            "Batch 225 de 606\n",
            "Batch 226 de 606\n",
            "Batch 227 de 606\n",
            "Batch 228 de 606\n",
            "Batch 229 de 606\n",
            "Batch 230 de 606\n",
            "Batch 231 de 606\n",
            "Batch 232 de 606\n",
            "Batch 233 de 606\n",
            "Batch 234 de 606\n",
            "Batch 235 de 606\n",
            "Batch 236 de 606\n",
            "Batch 237 de 606\n",
            "Batch 238 de 606\n",
            "Batch 239 de 606\n",
            "Batch 240 de 606\n",
            "Batch 241 de 606\n",
            "Batch 242 de 606\n",
            "Batch 243 de 606\n",
            "Batch 244 de 606\n",
            "Batch 245 de 606\n",
            "Batch 246 de 606\n",
            "Batch 247 de 606\n",
            "Batch 248 de 606\n",
            "Batch 249 de 606\n",
            "Batch 250 de 606\n",
            "Batch 251 de 606\n",
            "Batch 252 de 606\n",
            "Batch 253 de 606\n",
            "Batch 254 de 606\n",
            "Batch 255 de 606\n",
            "Batch 256 de 606\n",
            "Batch 257 de 606\n",
            "Batch 258 de 606\n",
            "Batch 259 de 606\n",
            "Batch 260 de 606\n",
            "Batch 261 de 606\n",
            "Batch 262 de 606\n",
            "Batch 263 de 606\n",
            "Batch 264 de 606\n",
            "Batch 265 de 606\n",
            "Batch 266 de 606\n",
            "Batch 267 de 606\n",
            "Batch 268 de 606\n",
            "Batch 269 de 606\n",
            "Batch 270 de 606\n",
            "Batch 271 de 606\n",
            "Batch 272 de 606\n",
            "Batch 273 de 606\n",
            "Batch 274 de 606\n",
            "Batch 275 de 606\n",
            "Batch 276 de 606\n",
            "Batch 277 de 606\n",
            "Batch 278 de 606\n",
            "Batch 279 de 606\n",
            "Batch 280 de 606\n",
            "Batch 281 de 606\n",
            "Batch 282 de 606\n",
            "Batch 283 de 606\n",
            "Batch 284 de 606\n",
            "Batch 285 de 606\n",
            "Batch 286 de 606\n",
            "Batch 287 de 606\n",
            "Batch 288 de 606\n",
            "Batch 289 de 606\n",
            "Batch 290 de 606\n",
            "Batch 291 de 606\n",
            "Batch 292 de 606\n",
            "Batch 293 de 606\n",
            "Batch 294 de 606\n",
            "Batch 295 de 606\n",
            "Batch 296 de 606\n",
            "Batch 297 de 606\n",
            "Batch 298 de 606\n",
            "Batch 299 de 606\n",
            "Batch 300 de 606\n",
            "Batch 301 de 606\n",
            "Batch 302 de 606\n",
            "Batch 303 de 606\n",
            "Batch 304 de 606\n",
            "Batch 305 de 606\n",
            "Batch 306 de 606\n",
            "Batch 307 de 606\n",
            "Batch 308 de 606\n",
            "Batch 309 de 606\n",
            "Batch 310 de 606\n",
            "Batch 311 de 606\n",
            "Batch 312 de 606\n",
            "Batch 313 de 606\n",
            "Batch 314 de 606\n",
            "Batch 315 de 606\n",
            "Batch 316 de 606\n",
            "Batch 317 de 606\n",
            "Batch 318 de 606\n",
            "Batch 319 de 606\n",
            "Batch 320 de 606\n",
            "Batch 321 de 606\n",
            "Batch 322 de 606\n",
            "Batch 323 de 606\n",
            "Batch 324 de 606\n",
            "Batch 325 de 606\n",
            "Batch 326 de 606\n",
            "Batch 327 de 606\n",
            "Batch 328 de 606\n",
            "Batch 329 de 606\n",
            "Batch 330 de 606\n",
            "Batch 331 de 606\n",
            "Batch 332 de 606\n",
            "Batch 333 de 606\n",
            "Batch 334 de 606\n",
            "Batch 335 de 606\n",
            "Batch 336 de 606\n",
            "Batch 337 de 606\n",
            "Batch 338 de 606\n",
            "Batch 339 de 606\n",
            "Batch 340 de 606\n",
            "Batch 341 de 606\n",
            "Batch 342 de 606\n",
            "Batch 343 de 606\n",
            "Batch 344 de 606\n",
            "Batch 345 de 606\n",
            "Batch 346 de 606\n",
            "Batch 347 de 606\n",
            "Batch 348 de 606\n",
            "Batch 349 de 606\n",
            "Batch 350 de 606\n",
            "Batch 351 de 606\n",
            "Batch 352 de 606\n",
            "Batch 353 de 606\n",
            "Batch 354 de 606\n",
            "Batch 355 de 606\n",
            "Batch 356 de 606\n",
            "Batch 357 de 606\n",
            "Batch 358 de 606\n",
            "Batch 359 de 606\n",
            "Batch 360 de 606\n",
            "Batch 361 de 606\n",
            "Batch 362 de 606\n",
            "Batch 363 de 606\n",
            "Batch 364 de 606\n",
            "Batch 365 de 606\n",
            "Batch 366 de 606\n",
            "Batch 367 de 606\n",
            "Batch 368 de 606\n",
            "Batch 369 de 606\n",
            "Batch 370 de 606\n",
            "Batch 371 de 606\n",
            "Batch 372 de 606\n",
            "Batch 373 de 606\n",
            "Batch 374 de 606\n",
            "Batch 375 de 606\n",
            "Batch 376 de 606\n",
            "Batch 377 de 606\n",
            "Batch 378 de 606\n",
            "Batch 379 de 606\n",
            "Batch 380 de 606\n",
            "Batch 381 de 606\n",
            "Batch 382 de 606\n",
            "Batch 383 de 606\n",
            "Batch 384 de 606\n",
            "Batch 385 de 606\n",
            "Batch 386 de 606\n",
            "Batch 387 de 606\n",
            "Batch 388 de 606\n",
            "Batch 389 de 606\n",
            "Batch 390 de 606\n",
            "Batch 391 de 606\n",
            "Batch 392 de 606\n",
            "Batch 393 de 606\n",
            "Batch 394 de 606\n",
            "Batch 395 de 606\n",
            "Batch 396 de 606\n",
            "Batch 397 de 606\n",
            "Batch 398 de 606\n",
            "Batch 399 de 606\n",
            "Batch 400 de 606\n",
            "Batch 401 de 606\n",
            "Batch 402 de 606\n",
            "Batch 403 de 606\n",
            "Batch 404 de 606\n",
            "Batch 405 de 606\n",
            "Batch 406 de 606\n",
            "Batch 407 de 606\n",
            "Batch 408 de 606\n",
            "Batch 409 de 606\n",
            "Batch 410 de 606\n",
            "Batch 411 de 606\n",
            "Batch 412 de 606\n",
            "Batch 413 de 606\n",
            "Batch 414 de 606\n",
            "Batch 415 de 606\n",
            "Batch 416 de 606\n",
            "Batch 417 de 606\n",
            "Batch 418 de 606\n",
            "Batch 419 de 606\n",
            "Batch 420 de 606\n",
            "Batch 421 de 606\n",
            "Batch 422 de 606\n",
            "Batch 423 de 606\n",
            "Batch 424 de 606\n",
            "Batch 425 de 606\n",
            "Batch 426 de 606\n",
            "Batch 427 de 606\n",
            "Batch 428 de 606\n",
            "Batch 429 de 606\n",
            "Batch 430 de 606\n",
            "Batch 431 de 606\n",
            "Batch 432 de 606\n",
            "Batch 433 de 606\n",
            "Batch 434 de 606\n",
            "Batch 435 de 606\n",
            "Batch 436 de 606\n",
            "Batch 437 de 606\n",
            "Batch 438 de 606\n",
            "Batch 439 de 606\n",
            "Batch 440 de 606\n",
            "Batch 441 de 606\n",
            "Batch 442 de 606\n",
            "Batch 443 de 606\n",
            "Batch 444 de 606\n",
            "Batch 445 de 606\n",
            "Batch 446 de 606\n",
            "Batch 447 de 606\n",
            "Batch 448 de 606\n",
            "Batch 449 de 606\n",
            "Batch 450 de 606\n",
            "Batch 451 de 606\n",
            "Batch 452 de 606\n",
            "Batch 453 de 606\n",
            "Batch 454 de 606\n",
            "Batch 455 de 606\n",
            "Batch 456 de 606\n",
            "Batch 457 de 606\n",
            "Batch 458 de 606\n",
            "Batch 459 de 606\n",
            "Batch 460 de 606\n",
            "Batch 461 de 606\n",
            "Batch 462 de 606\n",
            "Batch 463 de 606\n",
            "Batch 464 de 606\n",
            "Batch 465 de 606\n",
            "Batch 466 de 606\n",
            "Batch 467 de 606\n",
            "Batch 468 de 606\n",
            "Batch 469 de 606\n",
            "Batch 470 de 606\n",
            "Batch 471 de 606\n",
            "Batch 472 de 606\n",
            "Batch 473 de 606\n",
            "Batch 474 de 606\n",
            "Batch 475 de 606\n",
            "Batch 476 de 606\n",
            "Batch 477 de 606\n",
            "Batch 478 de 606\n",
            "Batch 479 de 606\n",
            "Batch 480 de 606\n",
            "Batch 481 de 606\n",
            "Batch 482 de 606\n",
            "Batch 483 de 606\n",
            "Batch 484 de 606\n",
            "Batch 485 de 606\n",
            "Batch 486 de 606\n",
            "Batch 487 de 606\n",
            "Batch 488 de 606\n",
            "Batch 489 de 606\n",
            "Batch 490 de 606\n",
            "Batch 491 de 606\n",
            "Batch 492 de 606\n",
            "Batch 493 de 606\n",
            "Batch 494 de 606\n",
            "Batch 495 de 606\n",
            "Batch 496 de 606\n",
            "Batch 497 de 606\n",
            "Batch 498 de 606\n",
            "Batch 499 de 606\n",
            "Batch 500 de 606\n",
            "Batch 501 de 606\n",
            "Batch 502 de 606\n",
            "Batch 503 de 606\n",
            "Batch 504 de 606\n",
            "Batch 505 de 606\n",
            "Batch 506 de 606\n",
            "Batch 507 de 606\n",
            "Batch 508 de 606\n",
            "Batch 509 de 606\n",
            "Batch 510 de 606\n",
            "Batch 511 de 606\n",
            "Batch 512 de 606\n",
            "Batch 513 de 606\n",
            "Batch 514 de 606\n",
            "Batch 515 de 606\n",
            "Batch 516 de 606\n",
            "Batch 517 de 606\n",
            "Batch 518 de 606\n",
            "Batch 519 de 606\n",
            "Batch 520 de 606\n",
            "Batch 521 de 606\n",
            "Batch 522 de 606\n",
            "Batch 523 de 606\n",
            "Batch 524 de 606\n",
            "Batch 525 de 606\n",
            "Batch 526 de 606\n",
            "Batch 527 de 606\n",
            "Batch 528 de 606\n",
            "Batch 529 de 606\n",
            "Batch 530 de 606\n",
            "Batch 531 de 606\n",
            "Batch 532 de 606\n",
            "Batch 533 de 606\n",
            "Batch 534 de 606\n",
            "Batch 535 de 606\n",
            "Batch 536 de 606\n",
            "Batch 537 de 606\n",
            "Batch 538 de 606\n",
            "Batch 539 de 606\n",
            "Batch 540 de 606\n",
            "Batch 541 de 606\n",
            "Batch 542 de 606\n",
            "Batch 543 de 606\n",
            "Batch 544 de 606\n",
            "Batch 545 de 606\n",
            "Batch 546 de 606\n",
            "Batch 547 de 606\n",
            "Batch 548 de 606\n",
            "Batch 549 de 606\n",
            "Batch 550 de 606\n",
            "Batch 551 de 606\n",
            "Batch 552 de 606\n",
            "Batch 553 de 606\n",
            "Batch 554 de 606\n",
            "Batch 555 de 606\n",
            "Batch 556 de 606\n",
            "Batch 557 de 606\n",
            "Batch 558 de 606\n",
            "Batch 559 de 606\n",
            "Batch 560 de 606\n",
            "Batch 561 de 606\n",
            "Batch 562 de 606\n",
            "Batch 563 de 606\n",
            "Batch 564 de 606\n",
            "Batch 565 de 606\n",
            "Batch 566 de 606\n",
            "Batch 567 de 606\n",
            "Batch 568 de 606\n",
            "Batch 569 de 606\n",
            "Batch 570 de 606\n",
            "Batch 571 de 606\n",
            "Batch 572 de 606\n",
            "Batch 573 de 606\n",
            "Batch 574 de 606\n",
            "Batch 575 de 606\n",
            "Batch 576 de 606\n",
            "Batch 577 de 606\n",
            "Batch 578 de 606\n",
            "Batch 579 de 606\n",
            "Batch 580 de 606\n",
            "Batch 581 de 606\n",
            "Batch 582 de 606\n",
            "Batch 583 de 606\n",
            "Batch 584 de 606\n",
            "Batch 585 de 606\n",
            "Batch 586 de 606\n",
            "Batch 587 de 606\n",
            "Batch 588 de 606\n",
            "Batch 589 de 606\n",
            "Batch 590 de 606\n",
            "Batch 591 de 606\n",
            "Batch 592 de 606\n",
            "Batch 593 de 606\n",
            "Batch 594 de 606\n",
            "Batch 595 de 606\n",
            "Batch 596 de 606\n",
            "Batch 597 de 606\n",
            "Batch 598 de 606\n",
            "Batch 599 de 606\n",
            "Batch 600 de 606\n",
            "Batch 601 de 606\n",
            "Batch 602 de 606\n",
            "Batch 603 de 606\n",
            "Batch 604 de 606\n",
            "Batch 605 de 606\n",
            "Accuracy Score = 0.7167131494680301\n",
            "F1 Score (Micro) = 0.7167131494680301\n",
            "F1 Score (Macro) = 0.41749150094768195\n",
            "Batch 0 de 606\n",
            "Batch 1 de 606\n",
            "Batch 2 de 606\n",
            "Batch 3 de 606\n",
            "Batch 4 de 606\n",
            "Batch 5 de 606\n",
            "Batch 6 de 606\n",
            "Batch 7 de 606\n",
            "Batch 8 de 606\n",
            "Batch 9 de 606\n",
            "Batch 10 de 606\n",
            "Batch 11 de 606\n",
            "Batch 12 de 606\n",
            "Batch 13 de 606\n",
            "Batch 14 de 606\n",
            "Batch 15 de 606\n",
            "Batch 16 de 606\n",
            "Batch 17 de 606\n",
            "Batch 18 de 606\n",
            "Batch 19 de 606\n",
            "Batch 20 de 606\n",
            "Batch 21 de 606\n",
            "Batch 22 de 606\n",
            "Batch 23 de 606\n",
            "Batch 24 de 606\n",
            "Batch 25 de 606\n",
            "Batch 26 de 606\n",
            "Batch 27 de 606\n",
            "Batch 28 de 606\n",
            "Batch 29 de 606\n",
            "Batch 30 de 606\n",
            "Batch 31 de 606\n",
            "Batch 32 de 606\n",
            "Batch 33 de 606\n",
            "Batch 34 de 606\n",
            "Batch 35 de 606\n",
            "Batch 36 de 606\n",
            "Batch 37 de 606\n",
            "Batch 38 de 606\n",
            "Batch 39 de 606\n",
            "Batch 40 de 606\n",
            "Batch 41 de 606\n",
            "Batch 42 de 606\n",
            "Batch 43 de 606\n",
            "Batch 44 de 606\n",
            "Batch 45 de 606\n",
            "Batch 46 de 606\n",
            "Batch 47 de 606\n",
            "Batch 48 de 606\n",
            "Batch 49 de 606\n",
            "Batch 50 de 606\n",
            "Batch 51 de 606\n",
            "Batch 52 de 606\n",
            "Batch 53 de 606\n",
            "Batch 54 de 606\n",
            "Batch 55 de 606\n",
            "Batch 56 de 606\n",
            "Batch 57 de 606\n",
            "Batch 58 de 606\n",
            "Batch 59 de 606\n",
            "Batch 60 de 606\n",
            "Batch 61 de 606\n",
            "Batch 62 de 606\n",
            "Batch 63 de 606\n",
            "Batch 64 de 606\n",
            "Batch 65 de 606\n",
            "Batch 66 de 606\n",
            "Batch 67 de 606\n",
            "Batch 68 de 606\n",
            "Batch 69 de 606\n",
            "Batch 70 de 606\n",
            "Batch 71 de 606\n",
            "Batch 72 de 606\n",
            "Batch 73 de 606\n",
            "Batch 74 de 606\n",
            "Batch 75 de 606\n",
            "Batch 76 de 606\n",
            "Batch 77 de 606\n",
            "Batch 78 de 606\n",
            "Batch 79 de 606\n",
            "Batch 80 de 606\n",
            "Batch 81 de 606\n",
            "Batch 82 de 606\n",
            "Batch 83 de 606\n",
            "Batch 84 de 606\n",
            "Batch 85 de 606\n",
            "Batch 86 de 606\n",
            "Batch 87 de 606\n",
            "Batch 88 de 606\n",
            "Batch 89 de 606\n",
            "Batch 90 de 606\n",
            "Batch 91 de 606\n",
            "Batch 92 de 606\n",
            "Batch 93 de 606\n",
            "Batch 94 de 606\n",
            "Batch 95 de 606\n",
            "Batch 96 de 606\n",
            "Batch 97 de 606\n",
            "Batch 98 de 606\n",
            "Batch 99 de 606\n",
            "Batch 100 de 606\n",
            "Batch 101 de 606\n",
            "Batch 102 de 606\n",
            "Batch 103 de 606\n",
            "Batch 104 de 606\n",
            "Batch 105 de 606\n",
            "Batch 106 de 606\n",
            "Batch 107 de 606\n",
            "Batch 108 de 606\n",
            "Batch 109 de 606\n",
            "Batch 110 de 606\n",
            "Batch 111 de 606\n",
            "Batch 112 de 606\n",
            "Batch 113 de 606\n",
            "Batch 114 de 606\n",
            "Batch 115 de 606\n",
            "Batch 116 de 606\n",
            "Batch 117 de 606\n",
            "Batch 118 de 606\n",
            "Batch 119 de 606\n",
            "Batch 120 de 606\n",
            "Batch 121 de 606\n",
            "Batch 122 de 606\n",
            "Batch 123 de 606\n",
            "Batch 124 de 606\n",
            "Batch 125 de 606\n",
            "Batch 126 de 606\n",
            "Batch 127 de 606\n",
            "Batch 128 de 606\n",
            "Batch 129 de 606\n",
            "Batch 130 de 606\n",
            "Batch 131 de 606\n",
            "Batch 132 de 606\n",
            "Batch 133 de 606\n",
            "Batch 134 de 606\n",
            "Batch 135 de 606\n",
            "Batch 136 de 606\n",
            "Batch 137 de 606\n",
            "Batch 138 de 606\n",
            "Batch 139 de 606\n",
            "Batch 140 de 606\n",
            "Batch 141 de 606\n",
            "Batch 142 de 606\n",
            "Batch 143 de 606\n",
            "Batch 144 de 606\n",
            "Batch 145 de 606\n",
            "Batch 146 de 606\n",
            "Batch 147 de 606\n",
            "Batch 148 de 606\n",
            "Batch 149 de 606\n",
            "Batch 150 de 606\n",
            "Batch 151 de 606\n",
            "Batch 152 de 606\n",
            "Batch 153 de 606\n",
            "Batch 154 de 606\n",
            "Batch 155 de 606\n",
            "Batch 156 de 606\n",
            "Batch 157 de 606\n",
            "Batch 158 de 606\n",
            "Batch 159 de 606\n",
            "Batch 160 de 606\n",
            "Batch 161 de 606\n",
            "Batch 162 de 606\n",
            "Batch 163 de 606\n",
            "Batch 164 de 606\n",
            "Batch 165 de 606\n",
            "Batch 166 de 606\n",
            "Batch 167 de 606\n",
            "Batch 168 de 606\n",
            "Batch 169 de 606\n",
            "Batch 170 de 606\n",
            "Batch 171 de 606\n",
            "Batch 172 de 606\n",
            "Batch 173 de 606\n",
            "Batch 174 de 606\n",
            "Batch 175 de 606\n",
            "Batch 176 de 606\n",
            "Batch 177 de 606\n",
            "Batch 178 de 606\n",
            "Batch 179 de 606\n",
            "Batch 180 de 606\n",
            "Batch 181 de 606\n",
            "Batch 182 de 606\n",
            "Batch 183 de 606\n",
            "Batch 184 de 606\n",
            "Batch 185 de 606\n",
            "Batch 186 de 606\n",
            "Batch 187 de 606\n",
            "Batch 188 de 606\n",
            "Batch 189 de 606\n",
            "Batch 190 de 606\n",
            "Batch 191 de 606\n",
            "Batch 192 de 606\n",
            "Batch 193 de 606\n",
            "Batch 194 de 606\n",
            "Batch 195 de 606\n",
            "Batch 196 de 606\n",
            "Batch 197 de 606\n",
            "Batch 198 de 606\n",
            "Batch 199 de 606\n",
            "Batch 200 de 606\n",
            "Batch 201 de 606\n",
            "Batch 202 de 606\n",
            "Batch 203 de 606\n",
            "Batch 204 de 606\n",
            "Batch 205 de 606\n",
            "Batch 206 de 606\n",
            "Batch 207 de 606\n",
            "Batch 208 de 606\n",
            "Batch 209 de 606\n",
            "Batch 210 de 606\n",
            "Batch 211 de 606\n",
            "Batch 212 de 606\n",
            "Batch 213 de 606\n",
            "Batch 214 de 606\n",
            "Batch 215 de 606\n",
            "Batch 216 de 606\n",
            "Batch 217 de 606\n",
            "Batch 218 de 606\n",
            "Batch 219 de 606\n",
            "Batch 220 de 606\n",
            "Batch 221 de 606\n",
            "Batch 222 de 606\n",
            "Batch 223 de 606\n",
            "Batch 224 de 606\n",
            "Batch 225 de 606\n",
            "Batch 226 de 606\n",
            "Batch 227 de 606\n",
            "Batch 228 de 606\n",
            "Batch 229 de 606\n",
            "Batch 230 de 606\n",
            "Batch 231 de 606\n",
            "Batch 232 de 606\n",
            "Batch 233 de 606\n",
            "Batch 234 de 606\n",
            "Batch 235 de 606\n",
            "Batch 236 de 606\n",
            "Batch 237 de 606\n",
            "Batch 238 de 606\n",
            "Batch 239 de 606\n",
            "Batch 240 de 606\n",
            "Batch 241 de 606\n",
            "Batch 242 de 606\n",
            "Batch 243 de 606\n",
            "Batch 244 de 606\n",
            "Batch 245 de 606\n",
            "Batch 246 de 606\n",
            "Batch 247 de 606\n",
            "Batch 248 de 606\n",
            "Batch 249 de 606\n",
            "Batch 250 de 606\n",
            "Batch 251 de 606\n",
            "Batch 252 de 606\n",
            "Batch 253 de 606\n",
            "Batch 254 de 606\n",
            "Batch 255 de 606\n",
            "Batch 256 de 606\n",
            "Batch 257 de 606\n",
            "Batch 258 de 606\n",
            "Batch 259 de 606\n",
            "Batch 260 de 606\n",
            "Batch 261 de 606\n",
            "Batch 262 de 606\n",
            "Batch 263 de 606\n",
            "Batch 264 de 606\n",
            "Batch 265 de 606\n",
            "Batch 266 de 606\n",
            "Batch 267 de 606\n",
            "Batch 268 de 606\n",
            "Batch 269 de 606\n",
            "Batch 270 de 606\n",
            "Batch 271 de 606\n",
            "Batch 272 de 606\n",
            "Batch 273 de 606\n",
            "Batch 274 de 606\n",
            "Batch 275 de 606\n",
            "Batch 276 de 606\n",
            "Batch 277 de 606\n",
            "Batch 278 de 606\n",
            "Batch 279 de 606\n",
            "Batch 280 de 606\n",
            "Batch 281 de 606\n",
            "Batch 282 de 606\n",
            "Batch 283 de 606\n",
            "Batch 284 de 606\n",
            "Batch 285 de 606\n",
            "Batch 286 de 606\n",
            "Batch 287 de 606\n",
            "Batch 288 de 606\n",
            "Batch 289 de 606\n",
            "Batch 290 de 606\n",
            "Batch 291 de 606\n",
            "Batch 292 de 606\n",
            "Batch 293 de 606\n",
            "Batch 294 de 606\n",
            "Batch 295 de 606\n",
            "Batch 296 de 606\n",
            "Batch 297 de 606\n",
            "Batch 298 de 606\n",
            "Batch 299 de 606\n",
            "Batch 300 de 606\n",
            "Batch 301 de 606\n",
            "Batch 302 de 606\n",
            "Batch 303 de 606\n",
            "Batch 304 de 606\n",
            "Batch 305 de 606\n",
            "Batch 306 de 606\n",
            "Batch 307 de 606\n",
            "Batch 308 de 606\n",
            "Batch 309 de 606\n",
            "Batch 310 de 606\n",
            "Batch 311 de 606\n",
            "Batch 312 de 606\n",
            "Batch 313 de 606\n",
            "Batch 314 de 606\n",
            "Batch 315 de 606\n",
            "Batch 316 de 606\n",
            "Batch 317 de 606\n",
            "Batch 318 de 606\n",
            "Batch 319 de 606\n",
            "Batch 320 de 606\n",
            "Batch 321 de 606\n",
            "Batch 322 de 606\n",
            "Batch 323 de 606\n",
            "Batch 324 de 606\n",
            "Batch 325 de 606\n",
            "Batch 326 de 606\n",
            "Batch 327 de 606\n",
            "Batch 328 de 606\n",
            "Batch 329 de 606\n",
            "Batch 330 de 606\n",
            "Batch 331 de 606\n",
            "Batch 332 de 606\n",
            "Batch 333 de 606\n",
            "Batch 334 de 606\n",
            "Batch 335 de 606\n",
            "Batch 336 de 606\n",
            "Batch 337 de 606\n",
            "Batch 338 de 606\n",
            "Batch 339 de 606\n",
            "Batch 340 de 606\n",
            "Batch 341 de 606\n",
            "Batch 342 de 606\n",
            "Batch 343 de 606\n",
            "Batch 344 de 606\n",
            "Batch 345 de 606\n",
            "Batch 346 de 606\n",
            "Batch 347 de 606\n",
            "Batch 348 de 606\n",
            "Batch 349 de 606\n",
            "Batch 350 de 606\n",
            "Batch 351 de 606\n",
            "Batch 352 de 606\n",
            "Batch 353 de 606\n",
            "Batch 354 de 606\n",
            "Batch 355 de 606\n",
            "Batch 356 de 606\n",
            "Batch 357 de 606\n",
            "Batch 358 de 606\n",
            "Batch 359 de 606\n",
            "Batch 360 de 606\n",
            "Batch 361 de 606\n",
            "Batch 362 de 606\n",
            "Batch 363 de 606\n",
            "Batch 364 de 606\n",
            "Batch 365 de 606\n",
            "Batch 366 de 606\n",
            "Batch 367 de 606\n",
            "Batch 368 de 606\n",
            "Batch 369 de 606\n",
            "Batch 370 de 606\n",
            "Batch 371 de 606\n",
            "Batch 372 de 606\n",
            "Batch 373 de 606\n",
            "Batch 374 de 606\n",
            "Batch 375 de 606\n",
            "Batch 376 de 606\n",
            "Batch 377 de 606\n",
            "Batch 378 de 606\n",
            "Batch 379 de 606\n",
            "Batch 380 de 606\n",
            "Batch 381 de 606\n",
            "Batch 382 de 606\n",
            "Batch 383 de 606\n",
            "Batch 384 de 606\n",
            "Batch 385 de 606\n",
            "Batch 386 de 606\n",
            "Batch 387 de 606\n",
            "Batch 388 de 606\n",
            "Batch 389 de 606\n",
            "Batch 390 de 606\n",
            "Batch 391 de 606\n",
            "Batch 392 de 606\n",
            "Batch 393 de 606\n",
            "Batch 394 de 606\n",
            "Batch 395 de 606\n",
            "Batch 396 de 606\n",
            "Batch 397 de 606\n",
            "Batch 398 de 606\n",
            "Batch 399 de 606\n",
            "Batch 400 de 606\n",
            "Batch 401 de 606\n",
            "Batch 402 de 606\n",
            "Batch 403 de 606\n",
            "Batch 404 de 606\n",
            "Batch 405 de 606\n",
            "Batch 406 de 606\n",
            "Batch 407 de 606\n",
            "Batch 408 de 606\n",
            "Batch 409 de 606\n",
            "Batch 410 de 606\n",
            "Batch 411 de 606\n",
            "Batch 412 de 606\n",
            "Batch 413 de 606\n",
            "Batch 414 de 606\n",
            "Batch 415 de 606\n",
            "Batch 416 de 606\n",
            "Batch 417 de 606\n",
            "Batch 418 de 606\n",
            "Batch 419 de 606\n",
            "Batch 420 de 606\n",
            "Batch 421 de 606\n",
            "Batch 422 de 606\n",
            "Batch 423 de 606\n",
            "Batch 424 de 606\n",
            "Batch 425 de 606\n",
            "Batch 426 de 606\n",
            "Batch 427 de 606\n",
            "Batch 428 de 606\n",
            "Batch 429 de 606\n",
            "Batch 430 de 606\n",
            "Batch 431 de 606\n",
            "Batch 432 de 606\n",
            "Batch 433 de 606\n",
            "Batch 434 de 606\n",
            "Batch 435 de 606\n",
            "Batch 436 de 606\n",
            "Batch 437 de 606\n",
            "Batch 438 de 606\n",
            "Batch 439 de 606\n",
            "Batch 440 de 606\n",
            "Batch 441 de 606\n",
            "Batch 442 de 606\n",
            "Batch 443 de 606\n",
            "Batch 444 de 606\n",
            "Batch 445 de 606\n",
            "Batch 446 de 606\n",
            "Batch 447 de 606\n",
            "Batch 448 de 606\n",
            "Batch 449 de 606\n",
            "Batch 450 de 606\n",
            "Batch 451 de 606\n",
            "Batch 452 de 606\n",
            "Batch 453 de 606\n",
            "Batch 454 de 606\n",
            "Batch 455 de 606\n",
            "Batch 456 de 606\n",
            "Batch 457 de 606\n",
            "Batch 458 de 606\n",
            "Batch 459 de 606\n",
            "Batch 460 de 606\n",
            "Batch 461 de 606\n",
            "Batch 462 de 606\n",
            "Batch 463 de 606\n",
            "Batch 464 de 606\n",
            "Batch 465 de 606\n",
            "Batch 466 de 606\n",
            "Batch 467 de 606\n",
            "Batch 468 de 606\n",
            "Batch 469 de 606\n",
            "Batch 470 de 606\n",
            "Batch 471 de 606\n",
            "Batch 472 de 606\n",
            "Batch 473 de 606\n",
            "Batch 474 de 606\n",
            "Batch 475 de 606\n",
            "Batch 476 de 606\n",
            "Batch 477 de 606\n",
            "Batch 478 de 606\n",
            "Batch 479 de 606\n",
            "Batch 480 de 606\n",
            "Batch 481 de 606\n",
            "Batch 482 de 606\n",
            "Batch 483 de 606\n",
            "Batch 484 de 606\n",
            "Batch 485 de 606\n",
            "Batch 486 de 606\n",
            "Batch 487 de 606\n",
            "Batch 488 de 606\n",
            "Batch 489 de 606\n",
            "Batch 490 de 606\n",
            "Batch 491 de 606\n",
            "Batch 492 de 606\n",
            "Batch 493 de 606\n",
            "Batch 494 de 606\n",
            "Batch 495 de 606\n",
            "Batch 496 de 606\n",
            "Batch 497 de 606\n",
            "Batch 498 de 606\n",
            "Batch 499 de 606\n",
            "Batch 500 de 606\n",
            "Batch 501 de 606\n",
            "Batch 502 de 606\n",
            "Batch 503 de 606\n",
            "Batch 504 de 606\n",
            "Batch 505 de 606\n",
            "Batch 506 de 606\n",
            "Batch 507 de 606\n",
            "Batch 508 de 606\n",
            "Batch 509 de 606\n",
            "Batch 510 de 606\n",
            "Batch 511 de 606\n",
            "Batch 512 de 606\n",
            "Batch 513 de 606\n",
            "Batch 514 de 606\n",
            "Batch 515 de 606\n",
            "Batch 516 de 606\n",
            "Batch 517 de 606\n",
            "Batch 518 de 606\n",
            "Batch 519 de 606\n",
            "Batch 520 de 606\n",
            "Batch 521 de 606\n",
            "Batch 522 de 606\n",
            "Batch 523 de 606\n",
            "Batch 524 de 606\n",
            "Batch 525 de 606\n",
            "Batch 526 de 606\n",
            "Batch 527 de 606\n",
            "Batch 528 de 606\n",
            "Batch 529 de 606\n",
            "Batch 530 de 606\n",
            "Batch 531 de 606\n",
            "Batch 532 de 606\n",
            "Batch 533 de 606\n",
            "Batch 534 de 606\n",
            "Batch 535 de 606\n",
            "Batch 536 de 606\n",
            "Batch 537 de 606\n",
            "Batch 538 de 606\n",
            "Batch 539 de 606\n",
            "Batch 540 de 606\n",
            "Batch 541 de 606\n",
            "Batch 542 de 606\n",
            "Batch 543 de 606\n",
            "Batch 544 de 606\n",
            "Batch 545 de 606\n",
            "Batch 546 de 606\n",
            "Batch 547 de 606\n",
            "Batch 548 de 606\n",
            "Batch 549 de 606\n",
            "Batch 550 de 606\n",
            "Batch 551 de 606\n",
            "Batch 552 de 606\n",
            "Batch 553 de 606\n",
            "Batch 554 de 606\n",
            "Batch 555 de 606\n",
            "Batch 556 de 606\n",
            "Batch 557 de 606\n",
            "Batch 558 de 606\n",
            "Batch 559 de 606\n",
            "Batch 560 de 606\n",
            "Batch 561 de 606\n",
            "Batch 562 de 606\n",
            "Batch 563 de 606\n",
            "Batch 564 de 606\n",
            "Batch 565 de 606\n",
            "Batch 566 de 606\n",
            "Batch 567 de 606\n",
            "Batch 568 de 606\n",
            "Batch 569 de 606\n",
            "Batch 570 de 606\n",
            "Batch 571 de 606\n",
            "Batch 572 de 606\n",
            "Batch 573 de 606\n",
            "Batch 574 de 606\n",
            "Batch 575 de 606\n",
            "Batch 576 de 606\n",
            "Batch 577 de 606\n",
            "Batch 578 de 606\n",
            "Batch 579 de 606\n",
            "Batch 580 de 606\n",
            "Batch 581 de 606\n",
            "Batch 582 de 606\n",
            "Batch 583 de 606\n",
            "Batch 584 de 606\n",
            "Batch 585 de 606\n",
            "Batch 586 de 606\n",
            "Batch 587 de 606\n",
            "Batch 588 de 606\n",
            "Batch 589 de 606\n",
            "Batch 590 de 606\n",
            "Batch 591 de 606\n",
            "Batch 592 de 606\n",
            "Batch 593 de 606\n",
            "Batch 594 de 606\n",
            "Batch 595 de 606\n",
            "Batch 596 de 606\n",
            "Batch 597 de 606\n",
            "Batch 598 de 606\n",
            "Batch 599 de 606\n",
            "Batch 600 de 606\n",
            "Batch 601 de 606\n",
            "Batch 602 de 606\n",
            "Batch 603 de 606\n",
            "Batch 604 de 606\n",
            "Batch 605 de 606\n",
            "Accuracy Score = 0.7167131494680301\n",
            "F1 Score (Micro) = 0.7167131494680301\n",
            "F1 Score (Macro) = 0.41749150094768195\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationBert(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "id": "uRgipb0wJkJy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvBbUoa3irJ_"
      },
      "source": [
        "##### Entrenamiento del modelo (80% de datos)"
      ],
      "id": "NvBbUoa3irJ_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-5\n",
        "- weight_decay=0.01\n",
        "- Dropout + Linear + Sigmoid"
      ],
      "metadata": {
        "id": "2_kGtSdHJSKE"
      },
      "id": "2_kGtSdHJSKE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68f88ee-d98f-4ebb-cd75-caf06fd25814",
        "id": "dy81zCZiirKE"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración; 0 de 7745, Loss: 0.05297529101371765\n",
            "Epoch: 0, iteración; 10 de 7745, Loss: 0.6039949417114258\n",
            "Epoch: 0, iteración; 20 de 7745, Loss: 0.5772326946258545\n",
            "Epoch: 0, iteración; 30 de 7745, Loss: 0.5921803951263428\n",
            "Epoch: 0, iteración; 40 de 7745, Loss: 0.5428352355957031\n",
            "Epoch: 0, iteración; 50 de 7745, Loss: 0.6100131034851074\n",
            "Epoch: 0, iteración; 60 de 7745, Loss: 0.6429983139038086\n",
            "Epoch: 0, iteración; 70 de 7745, Loss: 0.633080530166626\n",
            "Epoch: 0, iteración; 80 de 7745, Loss: 0.6191935062408447\n",
            "Epoch: 0, iteración; 90 de 7745, Loss: 0.5706310749053956\n",
            "Epoch: 0, iteración; 100 de 7745, Loss: 0.5942049980163574\n",
            "Epoch: 0, iteración; 110 de 7745, Loss: 0.5618804931640625\n",
            "Epoch: 0, iteración; 120 de 7745, Loss: 0.6414105415344238\n",
            "Epoch: 0, iteración; 130 de 7745, Loss: 0.5560259342193603\n",
            "Epoch: 0, iteración; 140 de 7745, Loss: 0.5813461303710937\n",
            "Epoch: 0, iteración; 150 de 7745, Loss: 0.5813619136810303\n",
            "Epoch: 0, iteración; 160 de 7745, Loss: 0.6667360782623291\n",
            "Epoch: 0, iteración; 170 de 7745, Loss: 0.5700974464416504\n",
            "Epoch: 0, iteración; 180 de 7745, Loss: 0.6230388641357422\n",
            "Epoch: 0, iteración; 190 de 7745, Loss: 0.5728838443756104\n",
            "Epoch: 0, iteración; 200 de 7745, Loss: 0.5976145744323731\n",
            "Epoch: 0, iteración; 210 de 7745, Loss: 0.6218945503234863\n",
            "Epoch: 0, iteración; 220 de 7745, Loss: 0.5781482219696045\n",
            "Epoch: 0, iteración; 230 de 7745, Loss: 0.572594404220581\n",
            "Epoch: 0, iteración; 240 de 7745, Loss: 0.660817003250122\n",
            "Epoch: 0, iteración; 250 de 7745, Loss: 0.630536413192749\n",
            "Epoch: 0, iteración; 260 de 7745, Loss: 0.6685995578765869\n",
            "Epoch: 0, iteración; 270 de 7745, Loss: 0.549217939376831\n",
            "Epoch: 0, iteración; 280 de 7745, Loss: 0.6151998043060303\n",
            "Epoch: 0, iteración; 290 de 7745, Loss: 0.5869847297668457\n",
            "Epoch: 0, iteración; 300 de 7745, Loss: 0.5529417514801025\n",
            "Epoch: 0, iteración; 310 de 7745, Loss: 0.47919931411743166\n",
            "Epoch: 0, iteración; 320 de 7745, Loss: 0.6337763786315918\n",
            "Epoch: 0, iteración; 330 de 7745, Loss: 0.6710148811340332\n",
            "Epoch: 0, iteración; 340 de 7745, Loss: 0.609926176071167\n",
            "Epoch: 0, iteración; 350 de 7745, Loss: 0.632954454421997\n",
            "Epoch: 0, iteración; 360 de 7745, Loss: 0.5839531898498536\n",
            "Epoch: 0, iteración; 370 de 7745, Loss: 0.6144436359405517\n",
            "Epoch: 0, iteración; 380 de 7745, Loss: 0.5574911117553711\n",
            "Epoch: 0, iteración; 390 de 7745, Loss: 0.6386708736419677\n",
            "Epoch: 0, iteración; 400 de 7745, Loss: 0.6016364097595215\n",
            "Epoch: 0, iteración; 410 de 7745, Loss: 0.5914598941802979\n",
            "Epoch: 0, iteración; 420 de 7745, Loss: 0.554680347442627\n",
            "Epoch: 0, iteración; 430 de 7745, Loss: 0.5856365203857422\n",
            "Epoch: 0, iteración; 440 de 7745, Loss: 0.5739336490631104\n",
            "Epoch: 0, iteración; 450 de 7745, Loss: 0.5703812122344971\n",
            "Epoch: 0, iteración; 460 de 7745, Loss: 0.6452223777770996\n",
            "Epoch: 0, iteración; 470 de 7745, Loss: 0.5495768070220948\n",
            "Epoch: 0, iteración; 480 de 7745, Loss: 0.6282917499542237\n",
            "Epoch: 0, iteración; 490 de 7745, Loss: 0.526972484588623\n",
            "Epoch: 0, iteración; 500 de 7745, Loss: 0.5868213653564454\n",
            "Epoch: 0, iteración; 510 de 7745, Loss: 0.5857892990112304\n",
            "Epoch: 0, iteración; 520 de 7745, Loss: 0.5429269313812256\n",
            "Epoch: 0, iteración; 530 de 7745, Loss: 0.5315333366394043\n",
            "Epoch: 0, iteración; 540 de 7745, Loss: 0.5820413589477539\n",
            "Epoch: 0, iteración; 550 de 7745, Loss: 0.533315372467041\n",
            "Epoch: 0, iteración; 560 de 7745, Loss: 0.594758939743042\n",
            "Epoch: 0, iteración; 570 de 7745, Loss: 0.5918758392333985\n",
            "Epoch: 0, iteración; 580 de 7745, Loss: 0.5710850715637207\n",
            "Epoch: 0, iteración; 590 de 7745, Loss: 0.6080373764038086\n",
            "Epoch: 0, iteración; 600 de 7745, Loss: 0.5942668437957763\n",
            "Epoch: 0, iteración; 610 de 7745, Loss: 0.6090369701385498\n",
            "Epoch: 0, iteración; 620 de 7745, Loss: 0.5818406105041504\n",
            "Epoch: 0, iteración; 630 de 7745, Loss: 0.5545724391937256\n",
            "Epoch: 0, iteración; 640 de 7745, Loss: 0.5355788230895996\n",
            "Epoch: 0, iteración; 650 de 7745, Loss: 0.5542296886444091\n",
            "Epoch: 0, iteración; 660 de 7745, Loss: 0.5901721477508545\n",
            "Epoch: 0, iteración; 670 de 7745, Loss: 0.5286712169647216\n",
            "Epoch: 0, iteración; 680 de 7745, Loss: 0.5666438102722168\n",
            "Epoch: 0, iteración; 690 de 7745, Loss: 0.5848074913024902\n",
            "Epoch: 0, iteración; 700 de 7745, Loss: 0.5686609268188476\n",
            "Epoch: 0, iteración; 710 de 7745, Loss: 0.5662358283996582\n",
            "Epoch: 0, iteración; 720 de 7745, Loss: 0.5505139827728271\n",
            "Epoch: 0, iteración; 730 de 7745, Loss: 0.5770929336547852\n",
            "Epoch: 0, iteración; 740 de 7745, Loss: 0.5929329872131348\n",
            "Epoch: 0, iteración; 750 de 7745, Loss: 0.5914834976196289\n",
            "Epoch: 0, iteración; 760 de 7745, Loss: 0.5623850345611572\n",
            "Epoch: 0, iteración; 770 de 7745, Loss: 0.5115040302276611\n",
            "Epoch: 0, iteración; 780 de 7745, Loss: 0.5308528900146484\n",
            "Epoch: 0, iteración; 790 de 7745, Loss: 0.5145195960998535\n",
            "Epoch: 0, iteración; 800 de 7745, Loss: 0.5395996570587158\n",
            "Epoch: 0, iteración; 810 de 7745, Loss: 0.5271316528320312\n",
            "Epoch: 0, iteración; 820 de 7745, Loss: 0.6051458358764649\n",
            "Epoch: 0, iteración; 830 de 7745, Loss: 0.5711028575897217\n",
            "Epoch: 0, iteración; 840 de 7745, Loss: 0.5062806606292725\n",
            "Epoch: 0, iteración; 850 de 7745, Loss: 0.5932320117950439\n",
            "Epoch: 0, iteración; 860 de 7745, Loss: 0.5327083110809326\n",
            "Epoch: 0, iteración; 870 de 7745, Loss: 0.5283015251159668\n",
            "Epoch: 0, iteración; 880 de 7745, Loss: 0.5009754180908204\n",
            "Epoch: 0, iteración; 890 de 7745, Loss: 0.5589926719665528\n",
            "Epoch: 0, iteración; 900 de 7745, Loss: 0.5477769851684571\n",
            "Epoch: 0, iteración; 910 de 7745, Loss: 0.6178861618041992\n",
            "Epoch: 0, iteración; 920 de 7745, Loss: 0.5129883766174317\n",
            "Epoch: 0, iteración; 930 de 7745, Loss: 0.5411543369293212\n",
            "Epoch: 0, iteración; 940 de 7745, Loss: 0.5942996501922607\n",
            "Epoch: 0, iteración; 950 de 7745, Loss: 0.5656109809875488\n",
            "Epoch: 0, iteración; 960 de 7745, Loss: 0.6181585311889648\n",
            "Epoch: 0, iteración; 970 de 7745, Loss: 0.5261399745941162\n",
            "Epoch: 0, iteración; 980 de 7745, Loss: 0.5540999412536621\n",
            "Epoch: 0, iteración; 990 de 7745, Loss: 0.6347470283508301\n",
            "Epoch: 0, iteración; 1000 de 7745, Loss: 0.5462688446044922\n",
            "Epoch: 0, iteración; 1010 de 7745, Loss: 0.5614016056060791\n",
            "Epoch: 0, iteración; 1020 de 7745, Loss: 0.5573558807373047\n",
            "Epoch: 0, iteración; 1030 de 7745, Loss: 0.5208573341369629\n",
            "Epoch: 0, iteración; 1040 de 7745, Loss: 0.6240230083465577\n",
            "Epoch: 0, iteración; 1050 de 7745, Loss: 0.6312044143676758\n",
            "Epoch: 0, iteración; 1060 de 7745, Loss: 0.5608058929443359\n",
            "Epoch: 0, iteración; 1070 de 7745, Loss: 0.5519857406616211\n",
            "Epoch: 0, iteración; 1080 de 7745, Loss: 0.6158133983612061\n",
            "Epoch: 0, iteración; 1090 de 7745, Loss: 0.500658655166626\n",
            "Epoch: 0, iteración; 1100 de 7745, Loss: 0.5666877746582031\n",
            "Epoch: 0, iteración; 1110 de 7745, Loss: 0.5819491386413574\n",
            "Epoch: 0, iteración; 1120 de 7745, Loss: 0.5889419555664063\n",
            "Epoch: 0, iteración; 1130 de 7745, Loss: 0.5690155029296875\n",
            "Epoch: 0, iteración; 1140 de 7745, Loss: 0.534273338317871\n",
            "Epoch: 0, iteración; 1150 de 7745, Loss: 0.48483619689941404\n",
            "Epoch: 0, iteración; 1160 de 7745, Loss: 0.572560453414917\n",
            "Epoch: 0, iteración; 1170 de 7745, Loss: 0.5353725910186767\n",
            "Epoch: 0, iteración; 1180 de 7745, Loss: 0.6418167114257812\n",
            "Epoch: 0, iteración; 1190 de 7745, Loss: 0.5885167121887207\n",
            "Epoch: 0, iteración; 1200 de 7745, Loss: 0.6339224815368653\n",
            "Epoch: 0, iteración; 1210 de 7745, Loss: 0.5349037170410156\n",
            "Epoch: 0, iteración; 1220 de 7745, Loss: 0.5624804973602295\n",
            "Epoch: 0, iteración; 1230 de 7745, Loss: 0.5502737522125244\n",
            "Epoch: 0, iteración; 1240 de 7745, Loss: 0.49926133155822755\n",
            "Epoch: 0, iteración; 1250 de 7745, Loss: 0.530250072479248\n",
            "Epoch: 0, iteración; 1260 de 7745, Loss: 0.5097144603729248\n",
            "Epoch: 0, iteración; 1270 de 7745, Loss: 0.6219366550445556\n",
            "Epoch: 0, iteración; 1280 de 7745, Loss: 0.5505010604858398\n",
            "Epoch: 0, iteración; 1290 de 7745, Loss: 0.5475143909454345\n",
            "Epoch: 0, iteración; 1300 de 7745, Loss: 0.5704171180725097\n",
            "Epoch: 0, iteración; 1310 de 7745, Loss: 0.6248577117919922\n",
            "Epoch: 0, iteración; 1320 de 7745, Loss: 0.6119664192199707\n",
            "Epoch: 0, iteración; 1330 de 7745, Loss: 0.5944869995117188\n",
            "Epoch: 0, iteración; 1340 de 7745, Loss: 0.5986212253570556\n",
            "Epoch: 0, iteración; 1350 de 7745, Loss: 0.5052550315856934\n",
            "Epoch: 0, iteración; 1360 de 7745, Loss: 0.5193862438201904\n",
            "Epoch: 0, iteración; 1370 de 7745, Loss: 0.5584744930267334\n",
            "Epoch: 0, iteración; 1380 de 7745, Loss: 0.5401161670684814\n",
            "Epoch: 0, iteración; 1390 de 7745, Loss: 0.46307663917541503\n",
            "Epoch: 0, iteración; 1400 de 7745, Loss: 0.5438825130462647\n",
            "Epoch: 0, iteración; 1410 de 7745, Loss: 0.6054295539855957\n",
            "Epoch: 0, iteración; 1420 de 7745, Loss: 0.5605944633483887\n",
            "Epoch: 0, iteración; 1430 de 7745, Loss: 0.5691227436065673\n",
            "Epoch: 0, iteración; 1440 de 7745, Loss: 0.5494711875915528\n",
            "Epoch: 0, iteración; 1450 de 7745, Loss: 0.557822322845459\n",
            "Epoch: 0, iteración; 1460 de 7745, Loss: 0.5268475532531738\n",
            "Epoch: 0, iteración; 1470 de 7745, Loss: 0.5078306674957276\n",
            "Epoch: 0, iteración; 1480 de 7745, Loss: 0.61782865524292\n",
            "Epoch: 0, iteración; 1490 de 7745, Loss: 0.5384096145629883\n",
            "Epoch: 0, iteración; 1500 de 7745, Loss: 0.5127943992614746\n",
            "Epoch: 0, iteración; 1510 de 7745, Loss: 0.539345645904541\n",
            "Epoch: 0, iteración; 1520 de 7745, Loss: 0.5341078281402588\n",
            "Epoch: 0, iteración; 1530 de 7745, Loss: 0.5853968620300293\n",
            "Epoch: 0, iteración; 1540 de 7745, Loss: 0.6364135265350341\n",
            "Epoch: 0, iteración; 1550 de 7745, Loss: 0.5788209915161133\n",
            "Epoch: 0, iteración; 1560 de 7745, Loss: 0.5937458515167237\n",
            "Epoch: 0, iteración; 1570 de 7745, Loss: 0.49572577476501467\n",
            "Epoch: 0, iteración; 1580 de 7745, Loss: 0.47073163986206057\n",
            "Epoch: 0, iteración; 1590 de 7745, Loss: 0.6205797672271729\n",
            "Epoch: 0, iteración; 1600 de 7745, Loss: 0.5524799346923828\n",
            "Epoch: 0, iteración; 1610 de 7745, Loss: 0.6028968334197998\n",
            "Epoch: 0, iteración; 1620 de 7745, Loss: 0.5693181991577149\n",
            "Epoch: 0, iteración; 1630 de 7745, Loss: 0.5936303615570069\n",
            "Epoch: 0, iteración; 1640 de 7745, Loss: 0.5689472198486328\n",
            "Epoch: 0, iteración; 1650 de 7745, Loss: 0.5538299083709717\n",
            "Epoch: 0, iteración; 1660 de 7745, Loss: 0.5036571502685547\n",
            "Epoch: 0, iteración; 1670 de 7745, Loss: 0.5068415641784668\n",
            "Epoch: 0, iteración; 1680 de 7745, Loss: 0.538694953918457\n",
            "Epoch: 0, iteración; 1690 de 7745, Loss: 0.5451102733612061\n",
            "Epoch: 0, iteración; 1700 de 7745, Loss: 0.5296030044555664\n",
            "Epoch: 0, iteración; 1710 de 7745, Loss: 0.54634108543396\n",
            "Epoch: 0, iteración; 1720 de 7745, Loss: 0.5688134670257569\n",
            "Epoch: 0, iteración; 1730 de 7745, Loss: 0.5455865859985352\n",
            "Epoch: 0, iteración; 1740 de 7745, Loss: 0.574657392501831\n",
            "Epoch: 0, iteración; 1750 de 7745, Loss: 0.6042056083679199\n",
            "Epoch: 0, iteración; 1760 de 7745, Loss: 0.5914961338043213\n",
            "Epoch: 0, iteración; 1770 de 7745, Loss: 0.5810925006866455\n",
            "Epoch: 0, iteración; 1780 de 7745, Loss: 0.5386370658874512\n",
            "Epoch: 0, iteración; 1790 de 7745, Loss: 0.5058356285095215\n",
            "Epoch: 0, iteración; 1800 de 7745, Loss: 0.5071534156799317\n",
            "Epoch: 0, iteración; 1810 de 7745, Loss: 0.6172916889190674\n",
            "Epoch: 0, iteración; 1820 de 7745, Loss: 0.5972812652587891\n",
            "Epoch: 0, iteración; 1830 de 7745, Loss: 0.5600471019744873\n",
            "Epoch: 0, iteración; 1840 de 7745, Loss: 0.5144946098327636\n",
            "Epoch: 0, iteración; 1850 de 7745, Loss: 0.5565061569213867\n",
            "Epoch: 0, iteración; 1860 de 7745, Loss: 0.5232844352722168\n",
            "Epoch: 0, iteración; 1870 de 7745, Loss: 0.5515241622924805\n",
            "Epoch: 0, iteración; 1880 de 7745, Loss: 0.5755616664886475\n",
            "Epoch: 0, iteración; 1890 de 7745, Loss: 0.5069136619567871\n",
            "Epoch: 0, iteración; 1900 de 7745, Loss: 0.5493451595306397\n",
            "Epoch: 0, iteración; 1910 de 7745, Loss: 0.5697862148284912\n",
            "Epoch: 0, iteración; 1920 de 7745, Loss: 0.5014010906219483\n",
            "Epoch: 0, iteración; 1930 de 7745, Loss: 0.6161245822906494\n",
            "Epoch: 0, iteración; 1940 de 7745, Loss: 0.5900231838226319\n",
            "Epoch: 0, iteración; 1950 de 7745, Loss: 0.5428413867950439\n",
            "Epoch: 0, iteración; 1960 de 7745, Loss: 0.5718332290649414\n",
            "Epoch: 0, iteración; 1970 de 7745, Loss: 0.5183009147644043\n",
            "Epoch: 0, iteración; 1980 de 7745, Loss: 0.5579923629760742\n",
            "Epoch: 0, iteración; 1990 de 7745, Loss: 0.540189266204834\n",
            "Epoch: 0, iteración; 2000 de 7745, Loss: 0.5919337272644043\n",
            "Epoch: 0, iteración; 2010 de 7745, Loss: 0.47797298431396484\n",
            "Epoch: 0, iteración; 2020 de 7745, Loss: 0.5449681758880616\n",
            "Epoch: 0, iteración; 2030 de 7745, Loss: 0.5084685325622559\n",
            "Epoch: 0, iteración; 2040 de 7745, Loss: 0.5981704711914062\n",
            "Epoch: 0, iteración; 2050 de 7745, Loss: 0.5750577926635743\n",
            "Epoch: 0, iteración; 2060 de 7745, Loss: 0.549930477142334\n",
            "Epoch: 0, iteración; 2070 de 7745, Loss: 0.5512573719024658\n",
            "Epoch: 0, iteración; 2080 de 7745, Loss: 0.5728049755096436\n",
            "Epoch: 0, iteración; 2090 de 7745, Loss: 0.4681265830993652\n",
            "Epoch: 0, iteración; 2100 de 7745, Loss: 0.48927812576293944\n",
            "Epoch: 0, iteración; 2110 de 7745, Loss: 0.5637170314788819\n",
            "Epoch: 0, iteración; 2120 de 7745, Loss: 0.538737678527832\n",
            "Epoch: 0, iteración; 2130 de 7745, Loss: 0.5657974243164062\n",
            "Epoch: 0, iteración; 2140 de 7745, Loss: 0.5331150531768799\n",
            "Epoch: 0, iteración; 2150 de 7745, Loss: 0.5623759269714356\n",
            "Epoch: 0, iteración; 2160 de 7745, Loss: 0.5440218925476075\n",
            "Epoch: 0, iteración; 2170 de 7745, Loss: 0.5782899856567383\n",
            "Epoch: 0, iteración; 2180 de 7745, Loss: 0.49935259819030764\n",
            "Epoch: 0, iteración; 2190 de 7745, Loss: 0.6017302989959716\n",
            "Epoch: 0, iteración; 2200 de 7745, Loss: 0.5772744178771972\n",
            "Epoch: 0, iteración; 2210 de 7745, Loss: 0.48807291984558104\n",
            "Epoch: 0, iteración; 2220 de 7745, Loss: 0.5444007873535156\n",
            "Epoch: 0, iteración; 2230 de 7745, Loss: 0.5819774627685547\n",
            "Epoch: 0, iteración; 2240 de 7745, Loss: 0.5464230537414551\n",
            "Epoch: 0, iteración; 2250 de 7745, Loss: 0.624713659286499\n",
            "Epoch: 0, iteración; 2260 de 7745, Loss: 0.5513018608093262\n",
            "Epoch: 0, iteración; 2270 de 7745, Loss: 0.48797264099121096\n",
            "Epoch: 0, iteración; 2280 de 7745, Loss: 0.563776683807373\n",
            "Epoch: 0, iteración; 2290 de 7745, Loss: 0.5405805587768555\n",
            "Epoch: 0, iteración; 2300 de 7745, Loss: 0.5693511962890625\n",
            "Epoch: 0, iteración; 2310 de 7745, Loss: 0.5247715950012207\n",
            "Epoch: 0, iteración; 2320 de 7745, Loss: 0.557441520690918\n",
            "Epoch: 0, iteración; 2330 de 7745, Loss: 0.5677894592285156\n",
            "Epoch: 0, iteración; 2340 de 7745, Loss: 0.5259995460510254\n",
            "Epoch: 0, iteración; 2350 de 7745, Loss: 0.5358343124389648\n",
            "Epoch: 0, iteración; 2360 de 7745, Loss: 0.5177334308624267\n",
            "Epoch: 0, iteración; 2370 de 7745, Loss: 0.5665359497070312\n",
            "Epoch: 0, iteración; 2380 de 7745, Loss: 0.5892626762390136\n",
            "Epoch: 0, iteración; 2390 de 7745, Loss: 0.5179585933685302\n",
            "Epoch: 0, iteración; 2400 de 7745, Loss: 0.5498978137969971\n",
            "Epoch: 0, iteración; 2410 de 7745, Loss: 0.5679962158203125\n",
            "Epoch: 0, iteración; 2420 de 7745, Loss: 0.5812001705169678\n",
            "Epoch: 0, iteración; 2430 de 7745, Loss: 0.5736902236938477\n",
            "Epoch: 0, iteración; 2440 de 7745, Loss: 0.5202527523040772\n",
            "Epoch: 0, iteración; 2450 de 7745, Loss: 0.5272378921508789\n",
            "Epoch: 0, iteración; 2460 de 7745, Loss: 0.5435588836669922\n",
            "Epoch: 0, iteración; 2470 de 7745, Loss: 0.5465072631835938\n",
            "Epoch: 0, iteración; 2480 de 7745, Loss: 0.5054319381713868\n",
            "Epoch: 0, iteración; 2490 de 7745, Loss: 0.5957255363464355\n",
            "Epoch: 0, iteración; 2500 de 7745, Loss: 0.5808382987976074\n",
            "Epoch: 0, iteración; 2510 de 7745, Loss: 0.5405697345733642\n",
            "Epoch: 0, iteración; 2520 de 7745, Loss: 0.5671325206756592\n",
            "Epoch: 0, iteración; 2530 de 7745, Loss: 0.5757625102996826\n",
            "Epoch: 0, iteración; 2540 de 7745, Loss: 0.6365542888641358\n",
            "Epoch: 0, iteración; 2550 de 7745, Loss: 0.5206521511077881\n",
            "Epoch: 0, iteración; 2560 de 7745, Loss: 0.5293674468994141\n",
            "Epoch: 0, iteración; 2570 de 7745, Loss: 0.5496049880981445\n",
            "Epoch: 0, iteración; 2580 de 7745, Loss: 0.5880205154418945\n",
            "Epoch: 0, iteración; 2590 de 7745, Loss: 0.5748866558074951\n",
            "Epoch: 0, iteración; 2600 de 7745, Loss: 0.5940632820129395\n",
            "Epoch: 0, iteración; 2610 de 7745, Loss: 0.5869010925292969\n",
            "Epoch: 0, iteración; 2620 de 7745, Loss: 0.5932074546813965\n",
            "Epoch: 0, iteración; 2630 de 7745, Loss: 0.5279733657836914\n",
            "Epoch: 0, iteración; 2640 de 7745, Loss: 0.4939438819885254\n",
            "Epoch: 0, iteración; 2650 de 7745, Loss: 0.6156923770904541\n",
            "Epoch: 0, iteración; 2660 de 7745, Loss: 0.5802128314971924\n",
            "Epoch: 0, iteración; 2670 de 7745, Loss: 0.5419317245483398\n",
            "Epoch: 0, iteración; 2680 de 7745, Loss: 0.5600693702697754\n",
            "Epoch: 0, iteración; 2690 de 7745, Loss: 0.5412126541137695\n",
            "Epoch: 0, iteración; 2700 de 7745, Loss: 0.6143652439117432\n",
            "Epoch: 0, iteración; 2710 de 7745, Loss: 0.4807192325592041\n",
            "Epoch: 0, iteración; 2720 de 7745, Loss: 0.5507969856262207\n",
            "Epoch: 0, iteración; 2730 de 7745, Loss: 0.5680265426635742\n",
            "Epoch: 0, iteración; 2740 de 7745, Loss: 0.4906031131744385\n",
            "Epoch: 0, iteración; 2750 de 7745, Loss: 0.5843807697296143\n",
            "Epoch: 0, iteración; 2760 de 7745, Loss: 0.6201602935791015\n",
            "Epoch: 0, iteración; 2770 de 7745, Loss: 0.5139751434326172\n",
            "Epoch: 0, iteración; 2780 de 7745, Loss: 0.5722816467285157\n",
            "Epoch: 0, iteración; 2790 de 7745, Loss: 0.5690191268920899\n",
            "Epoch: 0, iteración; 2800 de 7745, Loss: 0.608207893371582\n",
            "Epoch: 0, iteración; 2810 de 7745, Loss: 0.5367583274841309\n",
            "Epoch: 0, iteración; 2820 de 7745, Loss: 0.5301353454589843\n",
            "Epoch: 0, iteración; 2830 de 7745, Loss: 0.5476332187652588\n",
            "Epoch: 0, iteración; 2840 de 7745, Loss: 0.5347711563110351\n",
            "Epoch: 0, iteración; 2850 de 7745, Loss: 0.5193190097808837\n",
            "Epoch: 0, iteración; 2860 de 7745, Loss: 0.5685052394866943\n",
            "Epoch: 0, iteración; 2870 de 7745, Loss: 0.610534954071045\n",
            "Epoch: 0, iteración; 2880 de 7745, Loss: 0.5680297374725342\n",
            "Epoch: 0, iteración; 2890 de 7745, Loss: 0.5304512023925781\n",
            "Epoch: 0, iteración; 2900 de 7745, Loss: 0.5331674098968506\n",
            "Epoch: 0, iteración; 2910 de 7745, Loss: 0.5694793701171875\n",
            "Epoch: 0, iteración; 2920 de 7745, Loss: 0.559449577331543\n",
            "Epoch: 0, iteración; 2930 de 7745, Loss: 0.5498856544494629\n",
            "Epoch: 0, iteración; 2940 de 7745, Loss: 0.580834436416626\n",
            "Epoch: 0, iteración; 2950 de 7745, Loss: 0.5652747631072998\n",
            "Epoch: 0, iteración; 2960 de 7745, Loss: 0.508616590499878\n",
            "Epoch: 0, iteración; 2970 de 7745, Loss: 0.5391414642333985\n",
            "Epoch: 0, iteración; 2980 de 7745, Loss: 0.5473309993743897\n",
            "Epoch: 0, iteración; 2990 de 7745, Loss: 0.5286946296691895\n",
            "Epoch: 0, iteración; 3000 de 7745, Loss: 0.5658820629119873\n",
            "Epoch: 0, iteración; 3010 de 7745, Loss: 0.5271969318389893\n",
            "Epoch: 0, iteración; 3020 de 7745, Loss: 0.5748238563537598\n",
            "Epoch: 0, iteración; 3030 de 7745, Loss: 0.5001043319702149\n",
            "Epoch: 0, iteración; 3040 de 7745, Loss: 0.5400486469268799\n",
            "Epoch: 0, iteración; 3050 de 7745, Loss: 0.576580286026001\n",
            "Epoch: 0, iteración; 3060 de 7745, Loss: 0.5903959751129151\n",
            "Epoch: 0, iteración; 3070 de 7745, Loss: 0.5423545837402344\n",
            "Epoch: 0, iteración; 3080 de 7745, Loss: 0.492477560043335\n",
            "Epoch: 0, iteración; 3090 de 7745, Loss: 0.5655853271484375\n",
            "Epoch: 0, iteración; 3100 de 7745, Loss: 0.574595832824707\n",
            "Epoch: 0, iteración; 3110 de 7745, Loss: 0.5742388248443604\n",
            "Epoch: 0, iteración; 3120 de 7745, Loss: 0.5537555694580079\n",
            "Epoch: 0, iteración; 3130 de 7745, Loss: 0.5395113468170166\n",
            "Epoch: 0, iteración; 3140 de 7745, Loss: 0.5604854583740234\n",
            "Epoch: 0, iteración; 3150 de 7745, Loss: 0.5428454875946045\n",
            "Epoch: 0, iteración; 3160 de 7745, Loss: 0.5975782394409179\n",
            "Epoch: 0, iteración; 3170 de 7745, Loss: 0.5804026603698731\n",
            "Epoch: 0, iteración; 3180 de 7745, Loss: 0.5832194328308106\n",
            "Epoch: 0, iteración; 3190 de 7745, Loss: 0.6123955726623536\n",
            "Epoch: 0, iteración; 3200 de 7745, Loss: 0.5239189147949219\n",
            "Epoch: 0, iteración; 3210 de 7745, Loss: 0.5455273151397705\n",
            "Epoch: 0, iteración; 3220 de 7745, Loss: 0.554288101196289\n",
            "Epoch: 0, iteración; 3230 de 7745, Loss: 0.5308891773223877\n",
            "Epoch: 0, iteración; 3240 de 7745, Loss: 0.5886097908020019\n",
            "Epoch: 0, iteración; 3250 de 7745, Loss: 0.626304817199707\n",
            "Epoch: 0, iteración; 3260 de 7745, Loss: 0.5558795928955078\n",
            "Epoch: 0, iteración; 3270 de 7745, Loss: 0.5405721664428711\n",
            "Epoch: 0, iteración; 3280 de 7745, Loss: 0.573963212966919\n",
            "Epoch: 0, iteración; 3290 de 7745, Loss: 0.5226287364959716\n",
            "Epoch: 0, iteración; 3300 de 7745, Loss: 0.6474587440490722\n",
            "Epoch: 0, iteración; 3310 de 7745, Loss: 0.6093823909759521\n",
            "Epoch: 0, iteración; 3320 de 7745, Loss: 0.5932951927185058\n",
            "Epoch: 0, iteración; 3330 de 7745, Loss: 0.5522431373596192\n",
            "Epoch: 0, iteración; 3340 de 7745, Loss: 0.6098781585693359\n",
            "Epoch: 0, iteración; 3350 de 7745, Loss: 0.5918383598327637\n",
            "Epoch: 0, iteración; 3360 de 7745, Loss: 0.585994815826416\n",
            "Epoch: 0, iteración; 3370 de 7745, Loss: 0.5307101249694824\n",
            "Epoch: 0, iteración; 3380 de 7745, Loss: 0.5296716213226318\n",
            "Epoch: 0, iteración; 3390 de 7745, Loss: 0.5112149715423584\n",
            "Epoch: 0, iteración; 3400 de 7745, Loss: 0.5424058437347412\n",
            "Epoch: 0, iteración; 3410 de 7745, Loss: 0.5764998435974121\n",
            "Epoch: 0, iteración; 3420 de 7745, Loss: 0.5481344223022461\n",
            "Epoch: 0, iteración; 3430 de 7745, Loss: 0.4666563034057617\n",
            "Epoch: 0, iteración; 3440 de 7745, Loss: 0.5685095310211181\n",
            "Epoch: 0, iteración; 3450 de 7745, Loss: 0.5118605613708496\n",
            "Epoch: 0, iteración; 3460 de 7745, Loss: 0.49983062744140627\n",
            "Epoch: 0, iteración; 3470 de 7745, Loss: 0.5221170902252197\n",
            "Epoch: 0, iteración; 3480 de 7745, Loss: 0.6135051727294922\n",
            "Epoch: 0, iteración; 3490 de 7745, Loss: 0.5701962471008301\n",
            "Epoch: 0, iteración; 3500 de 7745, Loss: 0.5201001167297363\n",
            "Epoch: 0, iteración; 3510 de 7745, Loss: 0.5555259704589843\n",
            "Epoch: 0, iteración; 3520 de 7745, Loss: 0.599543285369873\n",
            "Epoch: 0, iteración; 3530 de 7745, Loss: 0.5507883548736572\n",
            "Epoch: 0, iteración; 3540 de 7745, Loss: 0.5924821853637695\n",
            "Epoch: 0, iteración; 3550 de 7745, Loss: 0.5676629066467285\n",
            "Epoch: 0, iteración; 3560 de 7745, Loss: 0.5284319400787354\n",
            "Epoch: 0, iteración; 3570 de 7745, Loss: 0.6019280433654786\n",
            "Epoch: 0, iteración; 3580 de 7745, Loss: 0.5469882488250732\n",
            "Epoch: 0, iteración; 3590 de 7745, Loss: 0.5918416976928711\n",
            "Epoch: 0, iteración; 3600 de 7745, Loss: 0.5854393482208252\n",
            "Epoch: 0, iteración; 3610 de 7745, Loss: 0.526957893371582\n",
            "Epoch: 0, iteración; 3620 de 7745, Loss: 0.541440200805664\n",
            "Epoch: 0, iteración; 3630 de 7745, Loss: 0.5119060039520263\n",
            "Epoch: 0, iteración; 3640 de 7745, Loss: 0.5580793380737304\n",
            "Epoch: 0, iteración; 3650 de 7745, Loss: 0.5370807647705078\n",
            "Epoch: 0, iteración; 3660 de 7745, Loss: 0.49663529396057127\n",
            "Epoch: 0, iteración; 3670 de 7745, Loss: 0.5048259258270263\n",
            "Epoch: 0, iteración; 3680 de 7745, Loss: 0.4535218715667725\n",
            "Epoch: 0, iteración; 3690 de 7745, Loss: 0.5216494560241699\n",
            "Epoch: 0, iteración; 3700 de 7745, Loss: 0.5682388305664062\n",
            "Epoch: 0, iteración; 3710 de 7745, Loss: 0.5701685428619385\n",
            "Epoch: 0, iteración; 3720 de 7745, Loss: 0.5658779621124268\n",
            "Epoch: 0, iteración; 3730 de 7745, Loss: 0.4718083381652832\n",
            "Epoch: 0, iteración; 3740 de 7745, Loss: 0.639097023010254\n",
            "Epoch: 0, iteración; 3750 de 7745, Loss: 0.5539068222045899\n",
            "Epoch: 0, iteración; 3760 de 7745, Loss: 0.5796623229980469\n",
            "Epoch: 0, iteración; 3770 de 7745, Loss: 0.5505870819091797\n",
            "Epoch: 0, iteración; 3780 de 7745, Loss: 0.6256528377532959\n",
            "Epoch: 0, iteración; 3790 de 7745, Loss: 0.5375164985656739\n",
            "Epoch: 0, iteración; 3800 de 7745, Loss: 0.5024548530578613\n",
            "Epoch: 0, iteración; 3810 de 7745, Loss: 0.5552516460418702\n",
            "Epoch: 0, iteración; 3820 de 7745, Loss: 0.5655136585235596\n",
            "Epoch: 0, iteración; 3830 de 7745, Loss: 0.5093326091766357\n",
            "Epoch: 0, iteración; 3840 de 7745, Loss: 0.5776732921600342\n",
            "Epoch: 0, iteración; 3850 de 7745, Loss: 0.49080696105957033\n",
            "Epoch: 0, iteración; 3860 de 7745, Loss: 0.5280651092529297\n",
            "Epoch: 0, iteración; 3870 de 7745, Loss: 0.6284479141235352\n",
            "Epoch: 0, iteración; 3880 de 7745, Loss: 0.576611328125\n",
            "Epoch: 0, iteración; 3890 de 7745, Loss: 0.6029056549072266\n",
            "Epoch: 0, iteración; 3900 de 7745, Loss: 0.5989286422729492\n",
            "Epoch: 0, iteración; 3910 de 7745, Loss: 0.5819921970367432\n",
            "Epoch: 0, iteración; 3920 de 7745, Loss: 0.5983977317810059\n",
            "Epoch: 0, iteración; 3930 de 7745, Loss: 0.5767481803894043\n",
            "Epoch: 0, iteración; 3940 de 7745, Loss: 0.5190474033355713\n",
            "Epoch: 0, iteración; 3950 de 7745, Loss: 0.5654065608978271\n",
            "Epoch: 0, iteración; 3960 de 7745, Loss: 0.5597066879272461\n",
            "Epoch: 0, iteración; 3970 de 7745, Loss: 0.5422618865966797\n",
            "Epoch: 0, iteración; 3980 de 7745, Loss: 0.5384625434875489\n",
            "Epoch: 0, iteración; 3990 de 7745, Loss: 0.5359439373016357\n",
            "Epoch: 0, iteración; 4000 de 7745, Loss: 0.5239546775817872\n",
            "Epoch: 0, iteración; 4010 de 7745, Loss: 0.5137028217315673\n",
            "Epoch: 0, iteración; 4020 de 7745, Loss: 0.5384675025939941\n",
            "Epoch: 0, iteración; 4030 de 7745, Loss: 0.5612248420715332\n",
            "Epoch: 0, iteración; 4040 de 7745, Loss: 0.5245282173156738\n",
            "Epoch: 0, iteración; 4050 de 7745, Loss: 0.548365592956543\n",
            "Epoch: 0, iteración; 4060 de 7745, Loss: 0.621064567565918\n",
            "Epoch: 0, iteración; 4070 de 7745, Loss: 0.6856877326965332\n",
            "Epoch: 0, iteración; 4080 de 7745, Loss: 0.6353431701660156\n",
            "Epoch: 0, iteración; 4090 de 7745, Loss: 0.5411629676818848\n",
            "Epoch: 0, iteración; 4100 de 7745, Loss: 0.4758411407470703\n",
            "Epoch: 0, iteración; 4110 de 7745, Loss: 0.6294060230255127\n",
            "Epoch: 0, iteración; 4120 de 7745, Loss: 0.608487319946289\n",
            "Epoch: 0, iteración; 4130 de 7745, Loss: 0.5845409870147705\n",
            "Epoch: 0, iteración; 4140 de 7745, Loss: 0.5479448318481446\n",
            "Epoch: 0, iteración; 4150 de 7745, Loss: 0.5494971752166748\n",
            "Epoch: 0, iteración; 4160 de 7745, Loss: 0.5623205661773681\n",
            "Epoch: 0, iteración; 4170 de 7745, Loss: 0.5560929775238037\n",
            "Epoch: 0, iteración; 4180 de 7745, Loss: 0.5188433647155761\n",
            "Epoch: 0, iteración; 4190 de 7745, Loss: 0.5530405044555664\n",
            "Epoch: 0, iteración; 4200 de 7745, Loss: 0.5169064998626709\n",
            "Epoch: 0, iteración; 4210 de 7745, Loss: 0.5962806701660156\n",
            "Epoch: 0, iteración; 4220 de 7745, Loss: 0.6242904186248779\n",
            "Epoch: 0, iteración; 4230 de 7745, Loss: 0.5185826301574707\n",
            "Epoch: 0, iteración; 4240 de 7745, Loss: 0.5153412818908691\n",
            "Epoch: 0, iteración; 4250 de 7745, Loss: 0.593705701828003\n",
            "Epoch: 0, iteración; 4260 de 7745, Loss: 0.5456440448760986\n",
            "Epoch: 0, iteración; 4270 de 7745, Loss: 0.5473915100097656\n",
            "Epoch: 0, iteración; 4280 de 7745, Loss: 0.5023167133331299\n",
            "Epoch: 0, iteración; 4290 de 7745, Loss: 0.5463969230651855\n",
            "Epoch: 0, iteración; 4300 de 7745, Loss: 0.556349229812622\n",
            "Epoch: 0, iteración; 4310 de 7745, Loss: 0.5441015243530274\n",
            "Epoch: 0, iteración; 4320 de 7745, Loss: 0.5140598297119141\n",
            "Epoch: 0, iteración; 4330 de 7745, Loss: 0.5479399681091308\n",
            "Epoch: 0, iteración; 4340 de 7745, Loss: 0.5493024826049805\n",
            "Epoch: 0, iteración; 4350 de 7745, Loss: 0.5438491821289062\n",
            "Epoch: 0, iteración; 4360 de 7745, Loss: 0.5939863204956055\n",
            "Epoch: 0, iteración; 4370 de 7745, Loss: 0.5605336189270019\n",
            "Epoch: 0, iteración; 4380 de 7745, Loss: 0.5267477989196777\n",
            "Epoch: 0, iteración; 4390 de 7745, Loss: 0.5490524291992187\n",
            "Epoch: 0, iteración; 4400 de 7745, Loss: 0.618379545211792\n",
            "Epoch: 0, iteración; 4410 de 7745, Loss: 0.5460961341857911\n",
            "Epoch: 0, iteración; 4420 de 7745, Loss: 0.5032208442687989\n",
            "Epoch: 0, iteración; 4430 de 7745, Loss: 0.6291266441345215\n",
            "Epoch: 0, iteración; 4440 de 7745, Loss: 0.6287988662719727\n",
            "Epoch: 0, iteración; 4450 de 7745, Loss: 0.5290202140808106\n",
            "Epoch: 0, iteración; 4460 de 7745, Loss: 0.565863037109375\n",
            "Epoch: 0, iteración; 4470 de 7745, Loss: 0.5650052547454834\n",
            "Epoch: 0, iteración; 4480 de 7745, Loss: 0.49212822914123533\n",
            "Epoch: 0, iteración; 4490 de 7745, Loss: 0.51756911277771\n",
            "Epoch: 0, iteración; 4500 de 7745, Loss: 0.5388866424560547\n",
            "Epoch: 0, iteración; 4510 de 7745, Loss: 0.5094112873077392\n",
            "Epoch: 0, iteración; 4520 de 7745, Loss: 0.47513551712036134\n",
            "Epoch: 0, iteración; 4530 de 7745, Loss: 0.5044864177703857\n",
            "Epoch: 0, iteración; 4540 de 7745, Loss: 0.5896400928497314\n",
            "Epoch: 0, iteración; 4550 de 7745, Loss: 0.5653633117675781\n",
            "Epoch: 0, iteración; 4560 de 7745, Loss: 0.6159034729003906\n",
            "Epoch: 0, iteración; 4570 de 7745, Loss: 0.6234023094177246\n",
            "Epoch: 0, iteración; 4580 de 7745, Loss: 0.5881199836730957\n",
            "Epoch: 0, iteración; 4590 de 7745, Loss: 0.5732083797454834\n",
            "Epoch: 0, iteración; 4600 de 7745, Loss: 0.4866739273071289\n",
            "Epoch: 0, iteración; 4610 de 7745, Loss: 0.5320050239562988\n",
            "Epoch: 0, iteración; 4620 de 7745, Loss: 0.6225392341613769\n",
            "Epoch: 0, iteración; 4630 de 7745, Loss: 0.45505542755126954\n",
            "Epoch: 0, iteración; 4640 de 7745, Loss: 0.5694705963134765\n",
            "Epoch: 0, iteración; 4650 de 7745, Loss: 0.567065954208374\n",
            "Epoch: 0, iteración; 4660 de 7745, Loss: 0.5481850624084472\n",
            "Epoch: 0, iteración; 4670 de 7745, Loss: 0.5276631832122802\n",
            "Epoch: 0, iteración; 4680 de 7745, Loss: 0.5809502601623535\n",
            "Epoch: 0, iteración; 4690 de 7745, Loss: 0.5429960250854492\n",
            "Epoch: 0, iteración; 4700 de 7745, Loss: 0.5120475769042969\n",
            "Epoch: 0, iteración; 4710 de 7745, Loss: 0.5588171005249023\n",
            "Epoch: 0, iteración; 4720 de 7745, Loss: 0.5549918174743652\n",
            "Epoch: 0, iteración; 4730 de 7745, Loss: 0.5029781341552735\n",
            "Epoch: 0, iteración; 4740 de 7745, Loss: 0.599216365814209\n",
            "Epoch: 0, iteración; 4750 de 7745, Loss: 0.5804007530212403\n",
            "Epoch: 0, iteración; 4760 de 7745, Loss: 0.596738338470459\n",
            "Epoch: 0, iteración; 4770 de 7745, Loss: 0.5298379898071289\n",
            "Epoch: 0, iteración; 4780 de 7745, Loss: 0.5434867382049561\n",
            "Epoch: 0, iteración; 4790 de 7745, Loss: 0.5563454627990723\n",
            "Epoch: 0, iteración; 4800 de 7745, Loss: 0.6289285659790039\n",
            "Epoch: 0, iteración; 4810 de 7745, Loss: 0.5707309722900391\n",
            "Epoch: 0, iteración; 4820 de 7745, Loss: 0.5848872661590576\n",
            "Epoch: 0, iteración; 4830 de 7745, Loss: 0.567531156539917\n",
            "Epoch: 0, iteración; 4840 de 7745, Loss: 0.500353479385376\n",
            "Epoch: 0, iteración; 4850 de 7745, Loss: 0.49231686592102053\n",
            "Epoch: 0, iteración; 4860 de 7745, Loss: 0.5932104110717773\n",
            "Epoch: 0, iteración; 4870 de 7745, Loss: 0.5907636165618897\n",
            "Epoch: 0, iteración; 4880 de 7745, Loss: 0.5993676662445069\n",
            "Epoch: 0, iteración; 4890 de 7745, Loss: 0.5709556102752685\n",
            "Epoch: 0, iteración; 4900 de 7745, Loss: 0.6314291954040527\n",
            "Epoch: 0, iteración; 4910 de 7745, Loss: 0.6275563716888428\n",
            "Epoch: 0, iteración; 4920 de 7745, Loss: 0.5566929817199707\n",
            "Epoch: 0, iteración; 4930 de 7745, Loss: 0.5823468208312989\n",
            "Epoch: 0, iteración; 4940 de 7745, Loss: 0.5368916034698487\n",
            "Epoch: 0, iteración; 4950 de 7745, Loss: 0.5713884353637695\n",
            "Epoch: 0, iteración; 4960 de 7745, Loss: 0.5955852031707763\n",
            "Epoch: 0, iteración; 4970 de 7745, Loss: 0.5716670989990235\n",
            "Epoch: 0, iteración; 4980 de 7745, Loss: 0.5861925601959228\n",
            "Epoch: 0, iteración; 4990 de 7745, Loss: 0.5675345420837402\n",
            "Epoch: 0, iteración; 5000 de 7745, Loss: 0.5831393241882324\n",
            "Epoch: 0, iteración; 5010 de 7745, Loss: 0.5229145050048828\n",
            "Epoch: 0, iteración; 5020 de 7745, Loss: 0.6167397022247314\n",
            "Epoch: 0, iteración; 5030 de 7745, Loss: 0.5931374549865722\n",
            "Epoch: 0, iteración; 5040 de 7745, Loss: 0.5339044570922852\n",
            "Epoch: 0, iteración; 5050 de 7745, Loss: 0.5705843925476074\n",
            "Epoch: 0, iteración; 5060 de 7745, Loss: 0.4781947135925293\n",
            "Epoch: 0, iteración; 5070 de 7745, Loss: 0.5080613613128662\n",
            "Epoch: 0, iteración; 5080 de 7745, Loss: 0.5855936050415039\n",
            "Epoch: 0, iteración; 5090 de 7745, Loss: 0.5357595443725586\n",
            "Epoch: 0, iteración; 5100 de 7745, Loss: 0.5406819343566894\n",
            "Epoch: 0, iteración; 5110 de 7745, Loss: 0.6450377941131592\n",
            "Epoch: 0, iteración; 5120 de 7745, Loss: 0.563677978515625\n",
            "Epoch: 0, iteración; 5130 de 7745, Loss: 0.5499448776245117\n",
            "Epoch: 0, iteración; 5140 de 7745, Loss: 0.5353175163269043\n",
            "Epoch: 0, iteración; 5150 de 7745, Loss: 0.5514245510101319\n",
            "Epoch: 0, iteración; 5160 de 7745, Loss: 0.5415265560150146\n",
            "Epoch: 0, iteración; 5170 de 7745, Loss: 0.5075442314147949\n",
            "Epoch: 0, iteración; 5180 de 7745, Loss: 0.5332094669342041\n",
            "Epoch: 0, iteración; 5190 de 7745, Loss: 0.5463570117950439\n",
            "Epoch: 0, iteración; 5200 de 7745, Loss: 0.5519328594207764\n",
            "Epoch: 0, iteración; 5210 de 7745, Loss: 0.5582403182983399\n",
            "Epoch: 0, iteración; 5220 de 7745, Loss: 0.5920790195465088\n",
            "Epoch: 0, iteración; 5230 de 7745, Loss: 0.5180416584014893\n",
            "Epoch: 0, iteración; 5240 de 7745, Loss: 0.5100313663482666\n",
            "Epoch: 0, iteración; 5250 de 7745, Loss: 0.5099891185760498\n",
            "Epoch: 0, iteración; 5260 de 7745, Loss: 0.524964427947998\n",
            "Epoch: 0, iteración; 5270 de 7745, Loss: 0.5141777515411377\n",
            "Epoch: 0, iteración; 5280 de 7745, Loss: 0.5713922500610351\n",
            "Epoch: 0, iteración; 5290 de 7745, Loss: 0.5049868583679199\n",
            "Epoch: 0, iteración; 5300 de 7745, Loss: 0.563086462020874\n",
            "Epoch: 0, iteración; 5310 de 7745, Loss: 0.5238248825073242\n",
            "Epoch: 0, iteración; 5320 de 7745, Loss: 0.48655409812927247\n",
            "Epoch: 0, iteración; 5330 de 7745, Loss: 0.5318024635314942\n",
            "Epoch: 0, iteración; 5340 de 7745, Loss: 0.5831681251525879\n",
            "Epoch: 0, iteración; 5350 de 7745, Loss: 0.5635233402252198\n",
            "Epoch: 0, iteración; 5360 de 7745, Loss: 0.5746653079986572\n",
            "Epoch: 0, iteración; 5370 de 7745, Loss: 0.5786727905273438\n",
            "Epoch: 0, iteración; 5380 de 7745, Loss: 0.5314557075500488\n",
            "Epoch: 0, iteración; 5390 de 7745, Loss: 0.6202179431915283\n",
            "Epoch: 0, iteración; 5400 de 7745, Loss: 0.5740102767944336\n",
            "Epoch: 0, iteración; 5410 de 7745, Loss: 0.5569612503051757\n",
            "Epoch: 0, iteración; 5420 de 7745, Loss: 0.5877294063568115\n",
            "Epoch: 0, iteración; 5430 de 7745, Loss: 0.5497629642486572\n",
            "Epoch: 0, iteración; 5440 de 7745, Loss: 0.596358060836792\n",
            "Epoch: 0, iteración; 5450 de 7745, Loss: 0.46681995391845704\n",
            "Epoch: 0, iteración; 5460 de 7745, Loss: 0.5239295482635498\n",
            "Epoch: 0, iteración; 5470 de 7745, Loss: 0.5762148380279541\n",
            "Epoch: 0, iteración; 5480 de 7745, Loss: 0.6048138618469239\n",
            "Epoch: 0, iteración; 5490 de 7745, Loss: 0.5427627086639404\n",
            "Epoch: 0, iteración; 5500 de 7745, Loss: 0.5835609436035156\n",
            "Epoch: 0, iteración; 5510 de 7745, Loss: 0.5595547676086425\n",
            "Epoch: 0, iteración; 5520 de 7745, Loss: 0.524862003326416\n",
            "Epoch: 0, iteración; 5530 de 7745, Loss: 0.5651956558227539\n",
            "Epoch: 0, iteración; 5540 de 7745, Loss: 0.48195643424987794\n",
            "Epoch: 0, iteración; 5550 de 7745, Loss: 0.5254980087280273\n",
            "Epoch: 0, iteración; 5560 de 7745, Loss: 0.6061038970947266\n",
            "Epoch: 0, iteración; 5570 de 7745, Loss: 0.5336046695709229\n",
            "Epoch: 0, iteración; 5580 de 7745, Loss: 0.5746020317077637\n",
            "Epoch: 0, iteración; 5590 de 7745, Loss: 0.5765791893005371\n",
            "Epoch: 0, iteración; 5600 de 7745, Loss: 0.5360904693603515\n",
            "Epoch: 0, iteración; 5610 de 7745, Loss: 0.45915422439575193\n",
            "Epoch: 0, iteración; 5620 de 7745, Loss: 0.5480927467346192\n",
            "Epoch: 0, iteración; 5630 de 7745, Loss: 0.49396800994873047\n",
            "Epoch: 0, iteración; 5640 de 7745, Loss: 0.5316321849822998\n",
            "Epoch: 0, iteración; 5650 de 7745, Loss: 0.5872071266174317\n",
            "Epoch: 0, iteración; 5660 de 7745, Loss: 0.5933535099029541\n",
            "Epoch: 0, iteración; 5670 de 7745, Loss: 0.5849669933319092\n",
            "Epoch: 0, iteración; 5680 de 7745, Loss: 0.5349061012268066\n",
            "Epoch: 0, iteración; 5690 de 7745, Loss: 0.5831347465515136\n",
            "Epoch: 0, iteración; 5700 de 7745, Loss: 0.566718864440918\n",
            "Epoch: 0, iteración; 5710 de 7745, Loss: 0.6023849010467529\n",
            "Epoch: 0, iteración; 5720 de 7745, Loss: 0.5539600372314453\n",
            "Epoch: 0, iteración; 5730 de 7745, Loss: 0.5516935348510742\n",
            "Epoch: 0, iteración; 5740 de 7745, Loss: 0.5480552196502686\n",
            "Epoch: 0, iteración; 5750 de 7745, Loss: 0.5732380390167237\n",
            "Epoch: 0, iteración; 5760 de 7745, Loss: 0.5650477409362793\n",
            "Epoch: 0, iteración; 5770 de 7745, Loss: 0.5925562381744385\n",
            "Epoch: 0, iteración; 5780 de 7745, Loss: 0.5952710151672364\n",
            "Epoch: 0, iteración; 5790 de 7745, Loss: 0.5256660938262939\n",
            "Epoch: 0, iteración; 5800 de 7745, Loss: 0.624225664138794\n",
            "Epoch: 0, iteración; 5810 de 7745, Loss: 0.5437820434570313\n",
            "Epoch: 0, iteración; 5820 de 7745, Loss: 0.5388918876647949\n",
            "Epoch: 0, iteración; 5830 de 7745, Loss: 0.5180760383605957\n",
            "Epoch: 0, iteración; 5840 de 7745, Loss: 0.5998402118682862\n",
            "Epoch: 0, iteración; 5850 de 7745, Loss: 0.459852409362793\n",
            "Epoch: 0, iteración; 5860 de 7745, Loss: 0.49654555320739746\n",
            "Epoch: 0, iteración; 5870 de 7745, Loss: 0.5223321437835693\n",
            "Epoch: 0, iteración; 5880 de 7745, Loss: 0.5950489997863769\n",
            "Epoch: 0, iteración; 5890 de 7745, Loss: 0.5532018184661865\n",
            "Epoch: 0, iteración; 5900 de 7745, Loss: 0.5093000411987305\n",
            "Epoch: 0, iteración; 5910 de 7745, Loss: 0.6088114261627198\n",
            "Epoch: 0, iteración; 5920 de 7745, Loss: 0.5088460445404053\n",
            "Epoch: 0, iteración; 5930 de 7745, Loss: 0.6023918151855469\n",
            "Epoch: 0, iteración; 5940 de 7745, Loss: 0.5464205741882324\n",
            "Epoch: 0, iteración; 5950 de 7745, Loss: 0.5118072032928467\n",
            "Epoch: 0, iteración; 5960 de 7745, Loss: 0.5886261940002442\n",
            "Epoch: 0, iteración; 5970 de 7745, Loss: 0.5306501865386963\n",
            "Epoch: 0, iteración; 5980 de 7745, Loss: 0.5881516456604003\n",
            "Epoch: 0, iteración; 5990 de 7745, Loss: 0.5239485740661621\n",
            "Epoch: 0, iteración; 6000 de 7745, Loss: 0.5653922080993652\n",
            "Epoch: 0, iteración; 6010 de 7745, Loss: 0.624672794342041\n",
            "Epoch: 0, iteración; 6020 de 7745, Loss: 0.6391961097717285\n",
            "Epoch: 0, iteración; 6030 de 7745, Loss: 0.5376993179321289\n",
            "Epoch: 0, iteración; 6040 de 7745, Loss: 0.5564877033233643\n",
            "Epoch: 0, iteración; 6050 de 7745, Loss: 0.5658793449401855\n",
            "Epoch: 0, iteración; 6060 de 7745, Loss: 0.573005199432373\n",
            "Epoch: 0, iteración; 6070 de 7745, Loss: 0.5616716861724853\n",
            "Epoch: 0, iteración; 6080 de 7745, Loss: 0.5850393295288085\n",
            "Epoch: 0, iteración; 6090 de 7745, Loss: 0.5924198627471924\n",
            "Epoch: 0, iteración; 6100 de 7745, Loss: 0.563637638092041\n",
            "Epoch: 0, iteración; 6110 de 7745, Loss: 0.584473991394043\n",
            "Epoch: 0, iteración; 6120 de 7745, Loss: 0.5818637847900391\n",
            "Epoch: 0, iteración; 6130 de 7745, Loss: 0.6079123497009278\n",
            "Epoch: 0, iteración; 6140 de 7745, Loss: 0.4808178424835205\n",
            "Epoch: 0, iteración; 6150 de 7745, Loss: 0.501185417175293\n",
            "Epoch: 0, iteración; 6160 de 7745, Loss: 0.5125815391540527\n",
            "Epoch: 0, iteración; 6170 de 7745, Loss: 0.4881254196166992\n",
            "Epoch: 0, iteración; 6180 de 7745, Loss: 0.5547034263610839\n",
            "Epoch: 0, iteración; 6190 de 7745, Loss: 0.5099211692810058\n",
            "Epoch: 0, iteración; 6200 de 7745, Loss: 0.5749503135681152\n",
            "Epoch: 0, iteración; 6210 de 7745, Loss: 0.5635761737823486\n",
            "Epoch: 0, iteración; 6220 de 7745, Loss: 0.5587356090545654\n",
            "Epoch: 0, iteración; 6230 de 7745, Loss: 0.5518959999084473\n",
            "Epoch: 0, iteración; 6240 de 7745, Loss: 0.5421031475067138\n",
            "Epoch: 0, iteración; 6250 de 7745, Loss: 0.5496662616729736\n",
            "Epoch: 0, iteración; 6260 de 7745, Loss: 0.5356008529663085\n",
            "Epoch: 0, iteración; 6270 de 7745, Loss: 0.5726132392883301\n",
            "Epoch: 0, iteración; 6280 de 7745, Loss: 0.5192476272583008\n",
            "Epoch: 0, iteración; 6290 de 7745, Loss: 0.5390830039978027\n",
            "Epoch: 0, iteración; 6300 de 7745, Loss: 0.5196243762969971\n",
            "Epoch: 0, iteración; 6310 de 7745, Loss: 0.564276123046875\n",
            "Epoch: 0, iteración; 6320 de 7745, Loss: 0.5931351661682129\n",
            "Epoch: 0, iteración; 6330 de 7745, Loss: 0.5614238739013672\n",
            "Epoch: 0, iteración; 6340 de 7745, Loss: 0.5425358295440674\n",
            "Epoch: 0, iteración; 6350 de 7745, Loss: 0.5196852684020996\n",
            "Epoch: 0, iteración; 6360 de 7745, Loss: 0.5407962799072266\n",
            "Epoch: 0, iteración; 6370 de 7745, Loss: 0.585181999206543\n",
            "Epoch: 0, iteración; 6380 de 7745, Loss: 0.5240963935852051\n",
            "Epoch: 0, iteración; 6390 de 7745, Loss: 0.568810510635376\n",
            "Epoch: 0, iteración; 6400 de 7745, Loss: 0.5917869567871094\n",
            "Epoch: 0, iteración; 6410 de 7745, Loss: 0.5394124031066895\n",
            "Epoch: 0, iteración; 6420 de 7745, Loss: 0.5227366924285889\n",
            "Epoch: 0, iteración; 6430 de 7745, Loss: 0.5358026027679443\n",
            "Epoch: 0, iteración; 6440 de 7745, Loss: 0.5729618549346924\n",
            "Epoch: 0, iteración; 6450 de 7745, Loss: 0.5268379211425781\n",
            "Epoch: 0, iteración; 6460 de 7745, Loss: 0.5816776752471924\n",
            "Epoch: 0, iteración; 6470 de 7745, Loss: 0.6455814361572265\n",
            "Epoch: 0, iteración; 6480 de 7745, Loss: 0.582177209854126\n",
            "Epoch: 0, iteración; 6490 de 7745, Loss: 0.5082841873168945\n",
            "Epoch: 0, iteración; 6500 de 7745, Loss: 0.4987334728240967\n",
            "Epoch: 0, iteración; 6510 de 7745, Loss: 0.5328762054443359\n",
            "Epoch: 0, iteración; 6520 de 7745, Loss: 0.5414279937744141\n",
            "Epoch: 0, iteración; 6530 de 7745, Loss: 0.5423445701599121\n",
            "Epoch: 0, iteración; 6540 de 7745, Loss: 0.5751270294189453\n",
            "Epoch: 0, iteración; 6550 de 7745, Loss: 0.5613740444183349\n",
            "Epoch: 0, iteración; 6560 de 7745, Loss: 0.5549792766571044\n",
            "Epoch: 0, iteración; 6570 de 7745, Loss: 0.5265542030334472\n",
            "Epoch: 0, iteración; 6580 de 7745, Loss: 0.5908065795898437\n",
            "Epoch: 0, iteración; 6590 de 7745, Loss: 0.4929788589477539\n",
            "Epoch: 0, iteración; 6600 de 7745, Loss: 0.5754850387573243\n",
            "Epoch: 0, iteración; 6610 de 7745, Loss: 0.49272680282592773\n",
            "Epoch: 0, iteración; 6620 de 7745, Loss: 0.5482365131378174\n",
            "Epoch: 0, iteración; 6630 de 7745, Loss: 0.5078880786895752\n",
            "Epoch: 0, iteración; 6640 de 7745, Loss: 0.5441858768463135\n",
            "Epoch: 0, iteración; 6650 de 7745, Loss: 0.5923016548156739\n",
            "Epoch: 0, iteración; 6660 de 7745, Loss: 0.5033014297485352\n",
            "Epoch: 0, iteración; 6670 de 7745, Loss: 0.5300490856170654\n",
            "Epoch: 0, iteración; 6680 de 7745, Loss: 0.587164306640625\n",
            "Epoch: 0, iteración; 6690 de 7745, Loss: 0.5273616790771485\n",
            "Epoch: 0, iteración; 6700 de 7745, Loss: 0.5938561916351318\n",
            "Epoch: 0, iteración; 6710 de 7745, Loss: 0.6157408237457276\n",
            "Epoch: 0, iteración; 6720 de 7745, Loss: 0.5933720588684082\n",
            "Epoch: 0, iteración; 6730 de 7745, Loss: 0.5506868362426758\n",
            "Epoch: 0, iteración; 6740 de 7745, Loss: 0.5656664371490479\n",
            "Epoch: 0, iteración; 6750 de 7745, Loss: 0.5654572010040283\n",
            "Epoch: 0, iteración; 6760 de 7745, Loss: 0.5817620277404785\n",
            "Epoch: 0, iteración; 6770 de 7745, Loss: 0.5482586860656739\n",
            "Epoch: 0, iteración; 6780 de 7745, Loss: 0.5880797863006592\n",
            "Epoch: 0, iteración; 6790 de 7745, Loss: 0.5485547542572021\n",
            "Epoch: 0, iteración; 6800 de 7745, Loss: 0.5699106693267822\n",
            "Epoch: 0, iteración; 6810 de 7745, Loss: 0.5460582733154297\n",
            "Epoch: 0, iteración; 6820 de 7745, Loss: 0.5588492393493653\n",
            "Epoch: 0, iteración; 6830 de 7745, Loss: 0.5115519523620605\n",
            "Epoch: 0, iteración; 6840 de 7745, Loss: 0.5703239917755127\n",
            "Epoch: 0, iteración; 6850 de 7745, Loss: 0.6012608051300049\n",
            "Epoch: 0, iteración; 6860 de 7745, Loss: 0.5826600074768067\n",
            "Epoch: 0, iteración; 6870 de 7745, Loss: 0.5805099010467529\n",
            "Epoch: 0, iteración; 6880 de 7745, Loss: 0.5813122272491456\n",
            "Epoch: 0, iteración; 6890 de 7745, Loss: 0.596068000793457\n",
            "Epoch: 0, iteración; 6900 de 7745, Loss: 0.5648459434509278\n",
            "Epoch: 0, iteración; 6910 de 7745, Loss: 0.5348459720611572\n",
            "Epoch: 0, iteración; 6920 de 7745, Loss: 0.6076361179351807\n",
            "Epoch: 0, iteración; 6930 de 7745, Loss: 0.5660526752471924\n",
            "Epoch: 0, iteración; 6940 de 7745, Loss: 0.5051844596862793\n",
            "Epoch: 0, iteración; 6950 de 7745, Loss: 0.517339038848877\n",
            "Epoch: 0, iteración; 6960 de 7745, Loss: 0.568767499923706\n",
            "Epoch: 0, iteración; 6970 de 7745, Loss: 0.5934571743011474\n",
            "Epoch: 0, iteración; 6980 de 7745, Loss: 0.5965511798858643\n",
            "Epoch: 0, iteración; 6990 de 7745, Loss: 0.5571117401123047\n",
            "Epoch: 0, iteración; 7000 de 7745, Loss: 0.5193497657775878\n",
            "Epoch: 0, iteración; 7010 de 7745, Loss: 0.49269990921020507\n",
            "Epoch: 0, iteración; 7020 de 7745, Loss: 0.5580962181091309\n",
            "Epoch: 0, iteración; 7030 de 7745, Loss: 0.587592887878418\n",
            "Epoch: 0, iteración; 7040 de 7745, Loss: 0.4778741359710693\n",
            "Epoch: 0, iteración; 7050 de 7745, Loss: 0.5063429355621338\n",
            "Epoch: 0, iteración; 7060 de 7745, Loss: 0.49436073303222655\n",
            "Epoch: 0, iteración; 7070 de 7745, Loss: 0.5264902114868164\n",
            "Epoch: 0, iteración; 7080 de 7745, Loss: 0.596349048614502\n",
            "Epoch: 0, iteración; 7090 de 7745, Loss: 0.6457668781280518\n",
            "Epoch: 0, iteración; 7100 de 7745, Loss: 0.5879059791564941\n",
            "Epoch: 0, iteración; 7110 de 7745, Loss: 0.5312328338623047\n",
            "Epoch: 0, iteración; 7120 de 7745, Loss: 0.5987814426422119\n",
            "Epoch: 0, iteración; 7130 de 7745, Loss: 0.5374974250793457\n",
            "Epoch: 0, iteración; 7140 de 7745, Loss: 0.5949534893035888\n",
            "Epoch: 0, iteración; 7150 de 7745, Loss: 0.531412410736084\n",
            "Epoch: 0, iteración; 7160 de 7745, Loss: 0.6128193855285644\n",
            "Epoch: 0, iteración; 7170 de 7745, Loss: 0.5324079990386963\n",
            "Epoch: 0, iteración; 7180 de 7745, Loss: 0.5710172176361084\n",
            "Epoch: 0, iteración; 7190 de 7745, Loss: 0.5390345573425293\n",
            "Epoch: 0, iteración; 7200 de 7745, Loss: 0.5588837623596191\n",
            "Epoch: 0, iteración; 7210 de 7745, Loss: 0.5956232070922851\n",
            "Epoch: 0, iteración; 7220 de 7745, Loss: 0.48475894927978513\n",
            "Epoch: 0, iteración; 7230 de 7745, Loss: 0.534332275390625\n",
            "Epoch: 0, iteración; 7240 de 7745, Loss: 0.541754674911499\n",
            "Epoch: 0, iteración; 7250 de 7745, Loss: 0.5924490928649903\n",
            "Epoch: 0, iteración; 7260 de 7745, Loss: 0.5332167148590088\n",
            "Epoch: 0, iteración; 7270 de 7745, Loss: 0.548042106628418\n",
            "Epoch: 0, iteración; 7280 de 7745, Loss: 0.5477355480194092\n",
            "Epoch: 0, iteración; 7290 de 7745, Loss: 0.5488639354705811\n",
            "Epoch: 0, iteración; 7300 de 7745, Loss: 0.6145381450653076\n",
            "Epoch: 0, iteración; 7310 de 7745, Loss: 0.5825125694274902\n",
            "Epoch: 0, iteración; 7320 de 7745, Loss: 0.6248317241668702\n",
            "Epoch: 0, iteración; 7330 de 7745, Loss: 0.5272663593292236\n",
            "Epoch: 0, iteración; 7340 de 7745, Loss: 0.6249454975128174\n",
            "Epoch: 0, iteración; 7350 de 7745, Loss: 0.5249257564544678\n",
            "Epoch: 0, iteración; 7360 de 7745, Loss: 0.546824836730957\n",
            "Epoch: 0, iteración; 7370 de 7745, Loss: 0.5905993461608887\n",
            "Epoch: 0, iteración; 7380 de 7745, Loss: 0.533789873123169\n",
            "Epoch: 0, iteración; 7390 de 7745, Loss: 0.6116920471191406\n",
            "Epoch: 0, iteración; 7400 de 7745, Loss: 0.5062742233276367\n",
            "Epoch: 0, iteración; 7410 de 7745, Loss: 0.5408421516418457\n",
            "Epoch: 0, iteración; 7420 de 7745, Loss: 0.5435440063476562\n",
            "Epoch: 0, iteración; 7430 de 7745, Loss: 0.6170440196990967\n",
            "Epoch: 0, iteración; 7440 de 7745, Loss: 0.5861982345581055\n",
            "Epoch: 0, iteración; 7450 de 7745, Loss: 0.5485536098480225\n",
            "Epoch: 0, iteración; 7460 de 7745, Loss: 0.6464333534240723\n",
            "Epoch: 0, iteración; 7470 de 7745, Loss: 0.5795609474182128\n",
            "Epoch: 0, iteración; 7480 de 7745, Loss: 0.5669264793395996\n",
            "Epoch: 0, iteración; 7490 de 7745, Loss: 0.6158747673034668\n",
            "Epoch: 0, iteración; 7500 de 7745, Loss: 0.5429023742675781\n",
            "Epoch: 0, iteración; 7510 de 7745, Loss: 0.5136395931243897\n",
            "Epoch: 0, iteración; 7520 de 7745, Loss: 0.6241785049438476\n",
            "Epoch: 0, iteración; 7530 de 7745, Loss: 0.5904770851135254\n",
            "Epoch: 0, iteración; 7540 de 7745, Loss: 0.5640695095062256\n",
            "Epoch: 0, iteración; 7550 de 7745, Loss: 0.547386884689331\n",
            "Epoch: 0, iteración; 7560 de 7745, Loss: 0.5064011096954346\n",
            "Epoch: 0, iteración; 7570 de 7745, Loss: 0.5349251747131347\n",
            "Epoch: 0, iteración; 7580 de 7745, Loss: 0.5371494770050049\n",
            "Epoch: 0, iteración; 7590 de 7745, Loss: 0.5283142566680908\n",
            "Epoch: 0, iteración; 7600 de 7745, Loss: 0.5753041744232178\n",
            "Epoch: 0, iteración; 7610 de 7745, Loss: 0.6036205768585206\n",
            "Epoch: 0, iteración; 7620 de 7745, Loss: 0.5065243244171143\n",
            "Epoch: 0, iteración; 7630 de 7745, Loss: 0.6053590774536133\n",
            "Epoch: 0, iteración; 7640 de 7745, Loss: 0.5324053764343262\n",
            "Epoch: 0, iteración; 7650 de 7745, Loss: 0.5220011234283447\n",
            "Epoch: 0, iteración; 7660 de 7745, Loss: 0.5787423610687256\n",
            "Epoch: 0, iteración; 7670 de 7745, Loss: 0.5725656032562256\n",
            "Epoch: 0, iteración; 7680 de 7745, Loss: 0.5286543846130372\n",
            "Epoch: 0, iteración; 7690 de 7745, Loss: 0.5065518856048584\n",
            "Epoch: 0, iteración; 7700 de 7745, Loss: 0.5658820629119873\n",
            "Epoch: 0, iteración; 7710 de 7745, Loss: 0.5782848834991455\n",
            "Epoch: 0, iteración; 7720 de 7745, Loss: 0.5173982620239258\n",
            "Epoch: 0, iteración; 7730 de 7745, Loss: 0.5663506984710693\n",
            "Epoch: 0, iteración; 7740 de 7745, Loss: 0.5550646781921387\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainBert(epoch)"
      ],
      "id": "dy81zCZiirKE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDIkX2n5irKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ae8722-d462-493a-aff1-3169a395613e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_80.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "id": "vDIkX2n5irKE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgejl67emCxQ"
      },
      "source": [
        "##### Evaluación del modelo"
      ],
      "id": "kgejl67emCxQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Yv9NZ5fmCxR"
      },
      "outputs": [],
      "source": [
        "def validationBert(epoch):\n",
        "  model.eval()\n",
        "  fin_targets=[]\n",
        "  fin_outputs=[]\n",
        "  num_iteraciones = len(testing_loader)\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testing_loader, 0):\n",
        "      ids = data['ids'].to(device)\n",
        "      mask = data['mask'].to(device)\n",
        "      token_type_ids = data['token_type_ids'].to(device)\n",
        "      targets = data['target'].to(device)\n",
        "\n",
        "      print(f\"Batch {i} de {num_iteraciones}\")\n",
        "\n",
        "      outputs = model(ids, mask, token_type_ids)\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "  return fin_outputs, fin_targets"
      ],
      "id": "-Yv9NZ5fmCxR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "UWH36eHSmCxR"
      },
      "id": "UWH36eHSmCxR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctDOkaMomCxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd2f9a3b-bb2e-4948-f192-83060dfe7478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado correctamente\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_80.pth\"):\n",
        "  model = BERTClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_80.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_80.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "id": "ctDOkaMomCxR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLNQXMz0mCxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d0cc27-10ea-4b0c-a289-7af3275cd663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 de 243\n",
            "Batch 1 de 243\n",
            "Batch 2 de 243\n",
            "Batch 3 de 243\n",
            "Batch 4 de 243\n",
            "Batch 5 de 243\n",
            "Batch 6 de 243\n",
            "Batch 7 de 243\n",
            "Batch 8 de 243\n",
            "Batch 9 de 243\n",
            "Batch 10 de 243\n",
            "Batch 11 de 243\n",
            "Batch 12 de 243\n",
            "Batch 13 de 243\n",
            "Batch 14 de 243\n",
            "Batch 15 de 243\n",
            "Batch 16 de 243\n",
            "Batch 17 de 243\n",
            "Batch 18 de 243\n",
            "Batch 19 de 243\n",
            "Batch 20 de 243\n",
            "Batch 21 de 243\n",
            "Batch 22 de 243\n",
            "Batch 23 de 243\n",
            "Batch 24 de 243\n",
            "Batch 25 de 243\n",
            "Batch 26 de 243\n",
            "Batch 27 de 243\n",
            "Batch 28 de 243\n",
            "Batch 29 de 243\n",
            "Batch 30 de 243\n",
            "Batch 31 de 243\n",
            "Batch 32 de 243\n",
            "Batch 33 de 243\n",
            "Batch 34 de 243\n",
            "Batch 35 de 243\n",
            "Batch 36 de 243\n",
            "Batch 37 de 243\n",
            "Batch 38 de 243\n",
            "Batch 39 de 243\n",
            "Batch 40 de 243\n",
            "Batch 41 de 243\n",
            "Batch 42 de 243\n",
            "Batch 43 de 243\n",
            "Batch 44 de 243\n",
            "Batch 45 de 243\n",
            "Batch 46 de 243\n",
            "Batch 47 de 243\n",
            "Batch 48 de 243\n",
            "Batch 49 de 243\n",
            "Batch 50 de 243\n",
            "Batch 51 de 243\n",
            "Batch 52 de 243\n",
            "Batch 53 de 243\n",
            "Batch 54 de 243\n",
            "Batch 55 de 243\n",
            "Batch 56 de 243\n",
            "Batch 57 de 243\n",
            "Batch 58 de 243\n",
            "Batch 59 de 243\n",
            "Batch 60 de 243\n",
            "Batch 61 de 243\n",
            "Batch 62 de 243\n",
            "Batch 63 de 243\n",
            "Batch 64 de 243\n",
            "Batch 65 de 243\n",
            "Batch 66 de 243\n",
            "Batch 67 de 243\n",
            "Batch 68 de 243\n",
            "Batch 69 de 243\n",
            "Batch 70 de 243\n",
            "Batch 71 de 243\n",
            "Batch 72 de 243\n",
            "Batch 73 de 243\n",
            "Batch 74 de 243\n",
            "Batch 75 de 243\n",
            "Batch 76 de 243\n",
            "Batch 77 de 243\n",
            "Batch 78 de 243\n",
            "Batch 79 de 243\n",
            "Batch 80 de 243\n",
            "Batch 81 de 243\n",
            "Batch 82 de 243\n",
            "Batch 83 de 243\n",
            "Batch 84 de 243\n",
            "Batch 85 de 243\n",
            "Batch 86 de 243\n",
            "Batch 87 de 243\n",
            "Batch 88 de 243\n",
            "Batch 89 de 243\n",
            "Batch 90 de 243\n",
            "Batch 91 de 243\n",
            "Batch 92 de 243\n",
            "Batch 93 de 243\n",
            "Batch 94 de 243\n",
            "Batch 95 de 243\n",
            "Batch 96 de 243\n",
            "Batch 97 de 243\n",
            "Batch 98 de 243\n",
            "Batch 99 de 243\n",
            "Batch 100 de 243\n",
            "Batch 101 de 243\n",
            "Batch 102 de 243\n",
            "Batch 103 de 243\n",
            "Batch 104 de 243\n",
            "Batch 105 de 243\n",
            "Batch 106 de 243\n",
            "Batch 107 de 243\n",
            "Batch 108 de 243\n",
            "Batch 109 de 243\n",
            "Batch 110 de 243\n",
            "Batch 111 de 243\n",
            "Batch 112 de 243\n",
            "Batch 113 de 243\n",
            "Batch 114 de 243\n",
            "Batch 115 de 243\n",
            "Batch 116 de 243\n",
            "Batch 117 de 243\n",
            "Batch 118 de 243\n",
            "Batch 119 de 243\n",
            "Batch 120 de 243\n",
            "Batch 121 de 243\n",
            "Batch 122 de 243\n",
            "Batch 123 de 243\n",
            "Batch 124 de 243\n",
            "Batch 125 de 243\n",
            "Batch 126 de 243\n",
            "Batch 127 de 243\n",
            "Batch 128 de 243\n",
            "Batch 129 de 243\n",
            "Batch 130 de 243\n",
            "Batch 131 de 243\n",
            "Batch 132 de 243\n",
            "Batch 133 de 243\n",
            "Batch 134 de 243\n",
            "Batch 135 de 243\n",
            "Batch 136 de 243\n",
            "Batch 137 de 243\n",
            "Batch 138 de 243\n",
            "Batch 139 de 243\n",
            "Batch 140 de 243\n",
            "Batch 141 de 243\n",
            "Batch 142 de 243\n",
            "Batch 143 de 243\n",
            "Batch 144 de 243\n",
            "Batch 145 de 243\n",
            "Batch 146 de 243\n",
            "Batch 147 de 243\n",
            "Batch 148 de 243\n",
            "Batch 149 de 243\n",
            "Batch 150 de 243\n",
            "Batch 151 de 243\n",
            "Batch 152 de 243\n",
            "Batch 153 de 243\n",
            "Batch 154 de 243\n",
            "Batch 155 de 243\n",
            "Batch 156 de 243\n",
            "Batch 157 de 243\n",
            "Batch 158 de 243\n",
            "Batch 159 de 243\n",
            "Batch 160 de 243\n",
            "Batch 161 de 243\n",
            "Batch 162 de 243\n",
            "Batch 163 de 243\n",
            "Batch 164 de 243\n",
            "Batch 165 de 243\n",
            "Batch 166 de 243\n",
            "Batch 167 de 243\n",
            "Batch 168 de 243\n",
            "Batch 169 de 243\n",
            "Batch 170 de 243\n",
            "Batch 171 de 243\n",
            "Batch 172 de 243\n",
            "Batch 173 de 243\n",
            "Batch 174 de 243\n",
            "Batch 175 de 243\n",
            "Batch 176 de 243\n",
            "Batch 177 de 243\n",
            "Batch 178 de 243\n",
            "Batch 179 de 243\n",
            "Batch 180 de 243\n",
            "Batch 181 de 243\n",
            "Batch 182 de 243\n",
            "Batch 183 de 243\n",
            "Batch 184 de 243\n",
            "Batch 185 de 243\n",
            "Batch 186 de 243\n",
            "Batch 187 de 243\n",
            "Batch 188 de 243\n",
            "Batch 189 de 243\n",
            "Batch 190 de 243\n",
            "Batch 191 de 243\n",
            "Batch 192 de 243\n",
            "Batch 193 de 243\n",
            "Batch 194 de 243\n",
            "Batch 195 de 243\n",
            "Batch 196 de 243\n",
            "Batch 197 de 243\n",
            "Batch 198 de 243\n",
            "Batch 199 de 243\n",
            "Batch 200 de 243\n",
            "Batch 201 de 243\n",
            "Batch 202 de 243\n",
            "Batch 203 de 243\n",
            "Batch 204 de 243\n",
            "Batch 205 de 243\n",
            "Batch 206 de 243\n",
            "Batch 207 de 243\n",
            "Batch 208 de 243\n",
            "Batch 209 de 243\n",
            "Batch 210 de 243\n",
            "Batch 211 de 243\n",
            "Batch 212 de 243\n",
            "Batch 213 de 243\n",
            "Batch 214 de 243\n",
            "Batch 215 de 243\n",
            "Batch 216 de 243\n",
            "Batch 217 de 243\n",
            "Batch 218 de 243\n",
            "Batch 219 de 243\n",
            "Batch 220 de 243\n",
            "Batch 221 de 243\n",
            "Batch 222 de 243\n",
            "Batch 223 de 243\n",
            "Batch 224 de 243\n",
            "Batch 225 de 243\n",
            "Batch 226 de 243\n",
            "Batch 227 de 243\n",
            "Batch 228 de 243\n",
            "Batch 229 de 243\n",
            "Batch 230 de 243\n",
            "Batch 231 de 243\n",
            "Batch 232 de 243\n",
            "Batch 233 de 243\n",
            "Batch 234 de 243\n",
            "Batch 235 de 243\n",
            "Batch 236 de 243\n",
            "Batch 237 de 243\n",
            "Batch 238 de 243\n",
            "Batch 239 de 243\n",
            "Batch 240 de 243\n",
            "Batch 241 de 243\n",
            "Batch 242 de 243\n",
            "Accuracy Score = 0.7166559070367979\n",
            "F1 Score (Micro) = 0.716655907036798\n",
            "F1 Score (Macro) = 0.4174720770185401\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationBert(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "\n",
        "  targets = np.array(targets).flatten().astype(int)\n",
        "\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "id": "fLNQXMz0mCxR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih3AZP8g-O1M"
      },
      "source": [
        "####2.4.4.3 Modelo 2: RoBERTa"
      ],
      "id": "ih3AZP8g-O1M"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfSNGdWuCoHp"
      },
      "source": [
        "##### Generación Dataset y Dataloader"
      ],
      "id": "mfSNGdWuCoHp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsZEY8vo-aSL",
        "outputId": "01f692f5-af7e-46ac-b73b-144c35a49466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset:(77448, 4)\n",
            "TRAIN Dataset: (61958, 4)\n",
            "TEST Dataset: (15490, 4)\n"
          ]
        }
      ],
      "source": [
        "training_loader, testing_loader = generate_loaders(datos, tokenizerRB,\n",
        "                                                   restaurantsDataset,\n",
        "                                                   DataCollatorRestaurant\n",
        "                                                   )"
      ],
      "id": "jsZEY8vo-aSL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHJCm_YGCuEA"
      },
      "source": [
        "##### Definición del modelo"
      ],
      "id": "PHJCm_YGCuEA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TOUkaucCv54",
        "outputId": "7f43f64f-a6ac-46c0-91d3-9713e125835d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaClass(\n",
              "  (l1): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l4): Dropout(p=0.2, inplace=False)\n",
              "  (l5): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (l6): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "class RobertaClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RobertaClass, self).__init__()\n",
        "        self.dropout = 0.2\n",
        "        self.hidden_embd = 768\n",
        "        self.output_layer = 1\n",
        "\n",
        "        # Layers\n",
        "        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        #self.l2 = torch.nn.Linear(self.hidden_embd, 256)\n",
        "        #self.l3 = torch.nn.Linear(256, 64)\n",
        "        self.l4 = torch.nn.Dropout(self.dropout)\n",
        "        # self.l5 = torch.nn.Linear(64, self.output_layer)\n",
        "        self.l5 = torch.nn.Linear(self.hidden_embd, self.output_layer)\n",
        "        self.l6 = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, output_1 = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
        "        #output_2 = self.l2(output_1)\n",
        "        #output_3 = self.l3(output_2)\n",
        "        output_4 = self.l4(output_1)\n",
        "        output = self.l5(output_4)\n",
        "        output = self.l6(output)\n",
        "        return output\n",
        "\n",
        "model = RobertaClass()\n",
        "model.to(device)"
      ],
      "id": "7TOUkaucCv54"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBG54im1DMBm",
        "outputId": "238f2141-d528-4da6-f2f8-bbd4103df7e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 1e-05\n",
              "    maximize: False\n",
              "    weight_decay: 0.01\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE,\n",
        "                             weight_decay=0.01)\n",
        "optimizer"
      ],
      "id": "xBG54im1DMBm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Función de entrenamiento"
      ],
      "metadata": {
        "id": "PrHK5EkTjdWo"
      },
      "id": "PrHK5EkTjdWo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gySeLFVDPkf"
      },
      "outputs": [],
      "source": [
        "def trainRoberta(epoch):\n",
        "  model.train()\n",
        "  loss_fn = torch.nn.BCELoss() #funcion perdida categorical cross entropy\n",
        "  num_iteraciones = len(training_loader)\n",
        "  sum_loss = 0\n",
        "\n",
        "  for iteracion,data in enumerate(training_loader, 0):\n",
        "    ids = data['ids'].to(device)\n",
        "    mask = data['mask'].to(device)\n",
        "    targets = data['target'].to(device)\n",
        "    token_type_ids = data[\"token_type_ids\"].to(device)\n",
        "\n",
        "    output = model(ids, mask, token_type_ids)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    perdida = loss_fn(output.squeeze(), targets)\n",
        "    with torch.no_grad():\n",
        "      sum_loss+=perdida\n",
        "      if iteracion % PASOS_POR_INTERVALO == 0:\n",
        "        print(f'Epoch: {epoch}, iteración; {iteracion:6} de {num_iteraciones}, Loss: {sum_loss.cpu().numpy()/PASOS_POR_INTERVALO}')\n",
        "        sum_loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    perdida.backward()\n",
        "    optimizer.step()"
      ],
      "id": "8gySeLFVDPkf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGSONSbKDNhm"
      },
      "source": [
        "##### Entrenamiento del modelo (30% de datos)"
      ],
      "id": "GGSONSbKDNhm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-5\n",
        "- weight_decay=0.01\n",
        "- Dropout + Linear + Sigmoid"
      ],
      "metadata": {
        "id": "EIeieR8lKFLf"
      },
      "id": "EIeieR8lKFLf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApO8MaCTDPfG",
        "outputId": "882b8d6f-fa3e-4b2a-febd-612243ab9696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración;      0 de 2905, Loss: 0.06860789060592651\n",
            "Epoch: 0, iteración;     10 de 2905, Loss: 0.6764469623565674\n",
            "Epoch: 0, iteración;     20 de 2905, Loss: 0.648057222366333\n",
            "Epoch: 0, iteración;     30 de 2905, Loss: 0.604004955291748\n",
            "Epoch: 0, iteración;     40 de 2905, Loss: 0.6138870716094971\n",
            "Epoch: 0, iteración;     50 de 2905, Loss: 0.68815598487854\n",
            "Epoch: 0, iteración;     60 de 2905, Loss: 0.6525362491607666\n",
            "Epoch: 0, iteración;     70 de 2905, Loss: 0.625678300857544\n",
            "Epoch: 0, iteración;     80 de 2905, Loss: 0.5612018585205079\n",
            "Epoch: 0, iteración;     90 de 2905, Loss: 0.5164202213287353\n",
            "Epoch: 0, iteración;    100 de 2905, Loss: 0.5604738712310791\n",
            "Epoch: 0, iteración;    110 de 2905, Loss: 0.5884951114654541\n",
            "Epoch: 0, iteración;    120 de 2905, Loss: 0.5894658088684082\n",
            "Epoch: 0, iteración;    130 de 2905, Loss: 0.6428716659545899\n",
            "Epoch: 0, iteración;    140 de 2905, Loss: 0.5927660465240479\n",
            "Epoch: 0, iteración;    150 de 2905, Loss: 0.5822919845581055\n",
            "Epoch: 0, iteración;    160 de 2905, Loss: 0.5679028511047364\n",
            "Epoch: 0, iteración;    170 de 2905, Loss: 0.4744142532348633\n",
            "Epoch: 0, iteración;    180 de 2905, Loss: 0.6536189079284668\n",
            "Epoch: 0, iteración;    190 de 2905, Loss: 0.5402970790863038\n",
            "Epoch: 0, iteración;    200 de 2905, Loss: 0.5795816898345947\n",
            "Epoch: 0, iteración;    210 de 2905, Loss: 0.5091442584991455\n",
            "Epoch: 0, iteración;    220 de 2905, Loss: 0.5579804897308349\n",
            "Epoch: 0, iteración;    230 de 2905, Loss: 0.5183543205261231\n",
            "Epoch: 0, iteración;    240 de 2905, Loss: 0.4646496295928955\n",
            "Epoch: 0, iteración;    250 de 2905, Loss: 0.5552947521209717\n",
            "Epoch: 0, iteración;    260 de 2905, Loss: 0.548057746887207\n",
            "Epoch: 0, iteración;    270 de 2905, Loss: 0.483155345916748\n",
            "Epoch: 0, iteración;    280 de 2905, Loss: 0.5889279842376709\n",
            "Epoch: 0, iteración;    290 de 2905, Loss: 0.5492311477661133\n",
            "Epoch: 0, iteración;    300 de 2905, Loss: 0.5153764724731446\n",
            "Epoch: 0, iteración;    310 de 2905, Loss: 0.48524131774902346\n",
            "Epoch: 0, iteración;    320 de 2905, Loss: 0.5354454040527343\n",
            "Epoch: 0, iteración;    330 de 2905, Loss: 0.5289440155029297\n",
            "Epoch: 0, iteración;    340 de 2905, Loss: 0.4356230735778809\n",
            "Epoch: 0, iteración;    350 de 2905, Loss: 0.5981632232666015\n",
            "Epoch: 0, iteración;    360 de 2905, Loss: 0.4798499584197998\n",
            "Epoch: 0, iteración;    370 de 2905, Loss: 0.5166641712188721\n",
            "Epoch: 0, iteración;    380 de 2905, Loss: 0.4939472198486328\n",
            "Epoch: 0, iteración;    390 de 2905, Loss: 0.4770171642303467\n",
            "Epoch: 0, iteración;    400 de 2905, Loss: 0.4626802921295166\n",
            "Epoch: 0, iteración;    410 de 2905, Loss: 0.6595474720001221\n",
            "Epoch: 0, iteración;    420 de 2905, Loss: 0.5831563472747803\n",
            "Epoch: 0, iteración;    430 de 2905, Loss: 0.5412928581237793\n",
            "Epoch: 0, iteración;    440 de 2905, Loss: 0.45711708068847656\n",
            "Epoch: 0, iteración;    450 de 2905, Loss: 0.6484690189361573\n",
            "Epoch: 0, iteración;    460 de 2905, Loss: 0.49408445358276365\n",
            "Epoch: 0, iteración;    470 de 2905, Loss: 0.46068830490112306\n",
            "Epoch: 0, iteración;    480 de 2905, Loss: 0.5068821907043457\n",
            "Epoch: 0, iteración;    490 de 2905, Loss: 0.4609020709991455\n",
            "Epoch: 0, iteración;    500 de 2905, Loss: 0.42536230087280275\n",
            "Epoch: 0, iteración;    510 de 2905, Loss: 0.5273959159851074\n",
            "Epoch: 0, iteración;    520 de 2905, Loss: 0.5672658443450928\n",
            "Epoch: 0, iteración;    530 de 2905, Loss: 0.5888210773468018\n",
            "Epoch: 0, iteración;    540 de 2905, Loss: 0.5754987716674804\n",
            "Epoch: 0, iteración;    550 de 2905, Loss: 0.5314594268798828\n",
            "Epoch: 0, iteración;    560 de 2905, Loss: 0.5084107875823974\n",
            "Epoch: 0, iteración;    570 de 2905, Loss: 0.4499979496002197\n",
            "Epoch: 0, iteración;    580 de 2905, Loss: 0.6529535770416259\n",
            "Epoch: 0, iteración;    590 de 2905, Loss: 0.5557613372802734\n",
            "Epoch: 0, iteración;    600 de 2905, Loss: 0.5884405136108398\n",
            "Epoch: 0, iteración;    610 de 2905, Loss: 0.5132441043853759\n",
            "Epoch: 0, iteración;    620 de 2905, Loss: 0.4710840225219727\n",
            "Epoch: 0, iteración;    630 de 2905, Loss: 0.6032763957977295\n",
            "Epoch: 0, iteración;    640 de 2905, Loss: 0.47344179153442384\n",
            "Epoch: 0, iteración;    650 de 2905, Loss: 0.4695366382598877\n",
            "Epoch: 0, iteración;    660 de 2905, Loss: 0.48563876152038576\n",
            "Epoch: 0, iteración;    670 de 2905, Loss: 0.4378504753112793\n",
            "Epoch: 0, iteración;    680 de 2905, Loss: 0.5552449703216553\n",
            "Epoch: 0, iteración;    690 de 2905, Loss: 0.5443707942962647\n",
            "Epoch: 0, iteración;    700 de 2905, Loss: 0.5183473110198975\n",
            "Epoch: 0, iteración;    710 de 2905, Loss: 0.5312070369720459\n",
            "Epoch: 0, iteración;    720 de 2905, Loss: 0.5620307922363281\n",
            "Epoch: 0, iteración;    730 de 2905, Loss: 0.5890505313873291\n",
            "Epoch: 0, iteración;    740 de 2905, Loss: 0.567050838470459\n",
            "Epoch: 0, iteración;    750 de 2905, Loss: 0.5578042507171631\n",
            "Epoch: 0, iteración;    760 de 2905, Loss: 0.5483538627624511\n",
            "Epoch: 0, iteración;    770 de 2905, Loss: 0.4679883480072021\n",
            "Epoch: 0, iteración;    780 de 2905, Loss: 0.601749324798584\n",
            "Epoch: 0, iteración;    790 de 2905, Loss: 0.5921293258666992\n",
            "Epoch: 0, iteración;    800 de 2905, Loss: 0.516435194015503\n",
            "Epoch: 0, iteración;    810 de 2905, Loss: 0.6348702907562256\n",
            "Epoch: 0, iteración;    820 de 2905, Loss: 0.607820987701416\n",
            "Epoch: 0, iteración;    830 de 2905, Loss: 0.5052762508392334\n",
            "Epoch: 0, iteración;    840 de 2905, Loss: 0.5542056083679199\n",
            "Epoch: 0, iteración;    850 de 2905, Loss: 0.6713580131530762\n",
            "Epoch: 0, iteración;    860 de 2905, Loss: 0.5070045471191407\n",
            "Epoch: 0, iteración;    870 de 2905, Loss: 0.3965125560760498\n",
            "Epoch: 0, iteración;    880 de 2905, Loss: 0.5382344722747803\n",
            "Epoch: 0, iteración;    890 de 2905, Loss: 0.5050743103027344\n",
            "Epoch: 0, iteración;    900 de 2905, Loss: 0.6035972118377686\n",
            "Epoch: 0, iteración;    910 de 2905, Loss: 0.5343949794769287\n",
            "Epoch: 0, iteración;    920 de 2905, Loss: 0.5646676540374755\n",
            "Epoch: 0, iteración;    930 de 2905, Loss: 0.4943855762481689\n",
            "Epoch: 0, iteración;    940 de 2905, Loss: 0.478636360168457\n",
            "Epoch: 0, iteración;    950 de 2905, Loss: 0.5263104915618897\n",
            "Epoch: 0, iteración;    960 de 2905, Loss: 0.5104311943054199\n",
            "Epoch: 0, iteración;    970 de 2905, Loss: 0.4676045417785645\n",
            "Epoch: 0, iteración;    980 de 2905, Loss: 0.5065353393554688\n",
            "Epoch: 0, iteración;    990 de 2905, Loss: 0.5320245742797851\n",
            "Epoch: 0, iteración;   1000 de 2905, Loss: 0.4385200023651123\n",
            "Epoch: 0, iteración;   1010 de 2905, Loss: 0.4277984619140625\n",
            "Epoch: 0, iteración;   1020 de 2905, Loss: 0.5751049518585205\n",
            "Epoch: 0, iteración;   1030 de 2905, Loss: 0.5314088821411133\n",
            "Epoch: 0, iteración;   1040 de 2905, Loss: 0.4478311538696289\n",
            "Epoch: 0, iteración;   1050 de 2905, Loss: 0.45831618309020994\n",
            "Epoch: 0, iteración;   1060 de 2905, Loss: 0.4786045551300049\n",
            "Epoch: 0, iteración;   1070 de 2905, Loss: 0.5280787467956543\n",
            "Epoch: 0, iteración;   1080 de 2905, Loss: 0.639638090133667\n",
            "Epoch: 0, iteración;   1090 de 2905, Loss: 0.522713041305542\n",
            "Epoch: 0, iteración;   1100 de 2905, Loss: 0.5349483966827393\n",
            "Epoch: 0, iteración;   1110 de 2905, Loss: 0.5880198001861572\n",
            "Epoch: 0, iteración;   1120 de 2905, Loss: 0.5355338096618653\n",
            "Epoch: 0, iteración;   1130 de 2905, Loss: 0.40752205848693845\n",
            "Epoch: 0, iteración;   1140 de 2905, Loss: 0.48642854690551757\n",
            "Epoch: 0, iteración;   1150 de 2905, Loss: 0.5339418888092041\n",
            "Epoch: 0, iteración;   1160 de 2905, Loss: 0.5576422691345215\n",
            "Epoch: 0, iteración;   1170 de 2905, Loss: 0.5395205974578857\n",
            "Epoch: 0, iteración;   1180 de 2905, Loss: 0.5238648891448975\n",
            "Epoch: 0, iteración;   1190 de 2905, Loss: 0.5673458576202393\n",
            "Epoch: 0, iteración;   1200 de 2905, Loss: 0.4812182903289795\n",
            "Epoch: 0, iteración;   1210 de 2905, Loss: 0.5832652091979981\n",
            "Epoch: 0, iteración;   1220 de 2905, Loss: 0.522197675704956\n",
            "Epoch: 0, iteración;   1230 de 2905, Loss: 0.5758211612701416\n",
            "Epoch: 0, iteración;   1240 de 2905, Loss: 0.4925676822662354\n",
            "Epoch: 0, iteración;   1250 de 2905, Loss: 0.38831362724304197\n",
            "Epoch: 0, iteración;   1260 de 2905, Loss: 0.6750547409057617\n",
            "Epoch: 0, iteración;   1270 de 2905, Loss: 0.5058379650115967\n",
            "Epoch: 0, iteración;   1280 de 2905, Loss: 0.6196603775024414\n",
            "Epoch: 0, iteración;   1290 de 2905, Loss: 0.463742733001709\n",
            "Epoch: 0, iteración;   1300 de 2905, Loss: 0.5190548419952392\n",
            "Epoch: 0, iteración;   1310 de 2905, Loss: 0.5355062484741211\n",
            "Epoch: 0, iteración;   1320 de 2905, Loss: 0.499370813369751\n",
            "Epoch: 0, iteración;   1330 de 2905, Loss: 0.4829899787902832\n",
            "Epoch: 0, iteración;   1340 de 2905, Loss: 0.4863423347473145\n",
            "Epoch: 0, iteración;   1350 de 2905, Loss: 0.5304040908813477\n",
            "Epoch: 0, iteración;   1360 de 2905, Loss: 0.447450590133667\n",
            "Epoch: 0, iteración;   1370 de 2905, Loss: 0.5835417747497559\n",
            "Epoch: 0, iteración;   1380 de 2905, Loss: 0.523097038269043\n",
            "Epoch: 0, iteración;   1390 de 2905, Loss: 0.477146577835083\n",
            "Epoch: 0, iteración;   1400 de 2905, Loss: 0.5165585041046142\n",
            "Epoch: 0, iteración;   1410 de 2905, Loss: 0.4734278678894043\n",
            "Epoch: 0, iteración;   1420 de 2905, Loss: 0.4244540214538574\n",
            "Epoch: 0, iteración;   1430 de 2905, Loss: 0.5887073040008545\n",
            "Epoch: 0, iteración;   1440 de 2905, Loss: 0.4877556324005127\n",
            "Epoch: 0, iteración;   1450 de 2905, Loss: 0.5314457893371582\n",
            "Epoch: 0, iteración;   1460 de 2905, Loss: 0.500907039642334\n",
            "Epoch: 0, iteración;   1470 de 2905, Loss: 0.6099196434020996\n",
            "Epoch: 0, iteración;   1480 de 2905, Loss: 0.5962874889373779\n",
            "Epoch: 0, iteración;   1490 de 2905, Loss: 0.4802410125732422\n",
            "Epoch: 0, iteración;   1500 de 2905, Loss: 0.5521981239318847\n",
            "Epoch: 0, iteración;   1510 de 2905, Loss: 0.5100613117218018\n",
            "Epoch: 0, iteración;   1520 de 2905, Loss: 0.41878280639648435\n",
            "Epoch: 0, iteración;   1530 de 2905, Loss: 0.5193243980407715\n",
            "Epoch: 0, iteración;   1540 de 2905, Loss: 0.4636554718017578\n",
            "Epoch: 0, iteración;   1550 de 2905, Loss: 0.5000975608825684\n",
            "Epoch: 0, iteración;   1560 de 2905, Loss: 0.5417973041534424\n",
            "Epoch: 0, iteración;   1570 de 2905, Loss: 0.5136825561523437\n",
            "Epoch: 0, iteración;   1580 de 2905, Loss: 0.44330925941467286\n",
            "Epoch: 0, iteración;   1590 de 2905, Loss: 0.6692395687103272\n",
            "Epoch: 0, iteración;   1600 de 2905, Loss: 0.5061184406280518\n",
            "Epoch: 0, iteración;   1610 de 2905, Loss: 0.6153977870941162\n",
            "Epoch: 0, iteración;   1620 de 2905, Loss: 0.5442405700683594\n",
            "Epoch: 0, iteración;   1630 de 2905, Loss: 0.5485422134399414\n",
            "Epoch: 0, iteración;   1640 de 2905, Loss: 0.49657015800476073\n",
            "Epoch: 0, iteración;   1650 de 2905, Loss: 0.6001305103302002\n",
            "Epoch: 0, iteración;   1660 de 2905, Loss: 0.4584663867950439\n",
            "Epoch: 0, iteración;   1670 de 2905, Loss: 0.5057813644409179\n",
            "Epoch: 0, iteración;   1680 de 2905, Loss: 0.45319929122924807\n",
            "Epoch: 0, iteración;   1690 de 2905, Loss: 0.423037052154541\n",
            "Epoch: 0, iteración;   1700 de 2905, Loss: 0.5656126499176025\n",
            "Epoch: 0, iteración;   1710 de 2905, Loss: 0.5673306465148926\n",
            "Epoch: 0, iteración;   1720 de 2905, Loss: 0.4811758518218994\n",
            "Epoch: 0, iteración;   1730 de 2905, Loss: 0.5768060207366943\n",
            "Epoch: 0, iteración;   1740 de 2905, Loss: 0.6744735240936279\n",
            "Epoch: 0, iteración;   1750 de 2905, Loss: 0.5263455390930176\n",
            "Epoch: 0, iteración;   1760 de 2905, Loss: 0.5594638824462891\n",
            "Epoch: 0, iteración;   1770 de 2905, Loss: 0.5524452686309814\n",
            "Epoch: 0, iteración;   1780 de 2905, Loss: 0.5462935447692872\n",
            "Epoch: 0, iteración;   1790 de 2905, Loss: 0.48018832206726075\n",
            "Epoch: 0, iteración;   1800 de 2905, Loss: 0.4814199924468994\n",
            "Epoch: 0, iteración;   1810 de 2905, Loss: 0.537221097946167\n",
            "Epoch: 0, iteración;   1820 de 2905, Loss: 0.4844204902648926\n",
            "Epoch: 0, iteración;   1830 de 2905, Loss: 0.4497769832611084\n",
            "Epoch: 0, iteración;   1840 de 2905, Loss: 0.514066219329834\n",
            "Epoch: 0, iteración;   1850 de 2905, Loss: 0.539824104309082\n",
            "Epoch: 0, iteración;   1860 de 2905, Loss: 0.5097191333770752\n",
            "Epoch: 0, iteración;   1870 de 2905, Loss: 0.47307529449462893\n",
            "Epoch: 0, iteración;   1880 de 2905, Loss: 0.4702712059020996\n",
            "Epoch: 0, iteración;   1890 de 2905, Loss: 0.5089820861816406\n",
            "Epoch: 0, iteración;   1900 de 2905, Loss: 0.47610297203063967\n",
            "Epoch: 0, iteración;   1910 de 2905, Loss: 0.48799781799316405\n",
            "Epoch: 0, iteración;   1920 de 2905, Loss: 0.49022660255432127\n",
            "Epoch: 0, iteración;   1930 de 2905, Loss: 0.5043508529663085\n",
            "Epoch: 0, iteración;   1940 de 2905, Loss: 0.5565050125122071\n",
            "Epoch: 0, iteración;   1950 de 2905, Loss: 0.46744279861450194\n",
            "Epoch: 0, iteración;   1960 de 2905, Loss: 0.5357714653015136\n",
            "Epoch: 0, iteración;   1970 de 2905, Loss: 0.5934885501861572\n",
            "Epoch: 0, iteración;   1980 de 2905, Loss: 0.48149681091308594\n",
            "Epoch: 0, iteración;   1990 de 2905, Loss: 0.49835729598999023\n",
            "Epoch: 0, iteración;   2000 de 2905, Loss: 0.5005804538726807\n",
            "Epoch: 0, iteración;   2010 de 2905, Loss: 0.46794700622558594\n",
            "Epoch: 0, iteración;   2020 de 2905, Loss: 0.469866943359375\n",
            "Epoch: 0, iteración;   2030 de 2905, Loss: 0.5752139091491699\n",
            "Epoch: 0, iteración;   2040 de 2905, Loss: 0.31645917892456055\n",
            "Epoch: 0, iteración;   2050 de 2905, Loss: 0.5617711544036865\n",
            "Epoch: 0, iteración;   2060 de 2905, Loss: 0.5147462844848633\n",
            "Epoch: 0, iteración;   2070 de 2905, Loss: 0.5595844268798829\n",
            "Epoch: 0, iteración;   2080 de 2905, Loss: 0.5811902523040772\n",
            "Epoch: 0, iteración;   2090 de 2905, Loss: 0.5081979751586914\n",
            "Epoch: 0, iteración;   2100 de 2905, Loss: 0.49533929824829104\n",
            "Epoch: 0, iteración;   2110 de 2905, Loss: 0.4366917610168457\n",
            "Epoch: 0, iteración;   2120 de 2905, Loss: 0.5253059387207031\n",
            "Epoch: 0, iteración;   2130 de 2905, Loss: 0.5691958904266358\n",
            "Epoch: 0, iteración;   2140 de 2905, Loss: 0.5068361759185791\n",
            "Epoch: 0, iteración;   2150 de 2905, Loss: 0.6345421314239502\n",
            "Epoch: 0, iteración;   2160 de 2905, Loss: 0.5507773876190185\n",
            "Epoch: 0, iteración;   2170 de 2905, Loss: 0.503534984588623\n",
            "Epoch: 0, iteración;   2180 de 2905, Loss: 0.48316030502319335\n",
            "Epoch: 0, iteración;   2190 de 2905, Loss: 0.4732337474822998\n",
            "Epoch: 0, iteración;   2200 de 2905, Loss: 0.38471829891204834\n",
            "Epoch: 0, iteración;   2210 de 2905, Loss: 0.5198296070098877\n",
            "Epoch: 0, iteración;   2220 de 2905, Loss: 0.40192174911499023\n",
            "Epoch: 0, iteración;   2230 de 2905, Loss: 0.42679762840270996\n",
            "Epoch: 0, iteración;   2240 de 2905, Loss: 0.5745598316192627\n",
            "Epoch: 0, iteración;   2250 de 2905, Loss: 0.5134719371795654\n",
            "Epoch: 0, iteración;   2260 de 2905, Loss: 0.39691505432128904\n",
            "Epoch: 0, iteración;   2270 de 2905, Loss: 0.6297784805297851\n",
            "Epoch: 0, iteración;   2280 de 2905, Loss: 0.5664411067962647\n",
            "Epoch: 0, iteración;   2290 de 2905, Loss: 0.4711338996887207\n",
            "Epoch: 0, iteración;   2300 de 2905, Loss: 0.5389016151428223\n",
            "Epoch: 0, iteración;   2310 de 2905, Loss: 0.5180897235870361\n",
            "Epoch: 0, iteración;   2320 de 2905, Loss: 0.4951800346374512\n",
            "Epoch: 0, iteración;   2330 de 2905, Loss: 0.4983685493469238\n",
            "Epoch: 0, iteración;   2340 de 2905, Loss: 0.5803813457489013\n",
            "Epoch: 0, iteración;   2350 de 2905, Loss: 0.4899207592010498\n",
            "Epoch: 0, iteración;   2360 de 2905, Loss: 0.5471270561218262\n",
            "Epoch: 0, iteración;   2370 de 2905, Loss: 0.43339171409606936\n",
            "Epoch: 0, iteración;   2380 de 2905, Loss: 0.5230607032775879\n",
            "Epoch: 0, iteración;   2390 de 2905, Loss: 0.4624619007110596\n",
            "Epoch: 0, iteración;   2400 de 2905, Loss: 0.5475590229034424\n",
            "Epoch: 0, iteración;   2410 de 2905, Loss: 0.5256717205047607\n",
            "Epoch: 0, iteración;   2420 de 2905, Loss: 0.5137417793273926\n",
            "Epoch: 0, iteración;   2430 de 2905, Loss: 0.5782567501068115\n",
            "Epoch: 0, iteración;   2440 de 2905, Loss: 0.561390495300293\n",
            "Epoch: 0, iteración;   2450 de 2905, Loss: 0.523744010925293\n",
            "Epoch: 0, iteración;   2460 de 2905, Loss: 0.4956141471862793\n",
            "Epoch: 0, iteración;   2470 de 2905, Loss: 0.5495802879333496\n",
            "Epoch: 0, iteración;   2480 de 2905, Loss: 0.5372981548309326\n",
            "Epoch: 0, iteración;   2490 de 2905, Loss: 0.4450679779052734\n",
            "Epoch: 0, iteración;   2500 de 2905, Loss: 0.4864034652709961\n",
            "Epoch: 0, iteración;   2510 de 2905, Loss: 0.5019754409790039\n",
            "Epoch: 0, iteración;   2520 de 2905, Loss: 0.4723259925842285\n",
            "Epoch: 0, iteración;   2530 de 2905, Loss: 0.4985059261322021\n",
            "Epoch: 0, iteración;   2540 de 2905, Loss: 0.572111177444458\n",
            "Epoch: 0, iteración;   2550 de 2905, Loss: 0.5700058460235595\n",
            "Epoch: 0, iteración;   2560 de 2905, Loss: 0.5077664375305175\n",
            "Epoch: 0, iteración;   2570 de 2905, Loss: 0.4778746604919434\n",
            "Epoch: 0, iteración;   2580 de 2905, Loss: 0.6040639877319336\n",
            "Epoch: 0, iteración;   2590 de 2905, Loss: 0.5812659740447998\n",
            "Epoch: 0, iteración;   2600 de 2905, Loss: 0.5495541095733643\n",
            "Epoch: 0, iteración;   2610 de 2905, Loss: 0.5352039813995362\n",
            "Epoch: 0, iteración;   2620 de 2905, Loss: 0.5631875038146973\n",
            "Epoch: 0, iteración;   2630 de 2905, Loss: 0.5356598377227784\n",
            "Epoch: 0, iteración;   2640 de 2905, Loss: 0.44359712600708007\n",
            "Epoch: 0, iteración;   2650 de 2905, Loss: 0.48604278564453124\n",
            "Epoch: 0, iteración;   2660 de 2905, Loss: 0.4997879505157471\n",
            "Epoch: 0, iteración;   2670 de 2905, Loss: 0.5786463260650635\n",
            "Epoch: 0, iteración;   2680 de 2905, Loss: 0.44202895164489747\n",
            "Epoch: 0, iteración;   2690 de 2905, Loss: 0.5308842182159423\n",
            "Epoch: 0, iteración;   2700 de 2905, Loss: 0.500818395614624\n",
            "Epoch: 0, iteración;   2710 de 2905, Loss: 0.5285273551940918\n",
            "Epoch: 0, iteración;   2720 de 2905, Loss: 0.4788831233978271\n",
            "Epoch: 0, iteración;   2730 de 2905, Loss: 0.5526613235473633\n",
            "Epoch: 0, iteración;   2740 de 2905, Loss: 0.3976409912109375\n",
            "Epoch: 0, iteración;   2750 de 2905, Loss: 0.46170268058776853\n",
            "Epoch: 0, iteración;   2760 de 2905, Loss: 0.513167142868042\n",
            "Epoch: 0, iteración;   2770 de 2905, Loss: 0.4464585304260254\n",
            "Epoch: 0, iteración;   2780 de 2905, Loss: 0.47712979316711424\n",
            "Epoch: 0, iteración;   2790 de 2905, Loss: 0.4996541976928711\n",
            "Epoch: 0, iteración;   2800 de 2905, Loss: 0.5041015625\n",
            "Epoch: 0, iteración;   2810 de 2905, Loss: 0.5413052558898925\n",
            "Epoch: 0, iteración;   2820 de 2905, Loss: 0.5017236709594727\n",
            "Epoch: 0, iteración;   2830 de 2905, Loss: 0.46141719818115234\n",
            "Epoch: 0, iteración;   2840 de 2905, Loss: 0.6055031776428222\n",
            "Epoch: 0, iteración;   2850 de 2905, Loss: 0.5411431789398193\n",
            "Epoch: 0, iteración;   2860 de 2905, Loss: 0.4868333339691162\n",
            "Epoch: 0, iteración;   2870 de 2905, Loss: 0.5217618465423584\n",
            "Epoch: 0, iteración;   2880 de 2905, Loss: 0.5770486354827881\n",
            "Epoch: 0, iteración;   2890 de 2905, Loss: 0.39745972156524656\n",
            "Epoch: 0, iteración;   2900 de 2905, Loss: 0.46775007247924805\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainRoberta(epoch)"
      ],
      "id": "ApO8MaCTDPfG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iV85STlFUFXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "380ac4c4-09d4-4478-afa1-eefd2d6ce172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_30.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "id": "iV85STlFUFXl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Wu1EO7Dnnz"
      },
      "source": [
        "##### Evaluación del modelo"
      ],
      "id": "R0Wu1EO7Dnnz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-R_ECp-DPbe"
      },
      "outputs": [],
      "source": [
        "def validationRoberta(epoch):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    num_iteraciones = len(testing_loader)\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device)\n",
        "            mask = data['mask'].to(device)\n",
        "            token_type_ids = data['token_type_ids'].to(device)\n",
        "            targets = data['target'].to(device)\n",
        "\n",
        "            print(f\"Iteración: {i:6} de {num_iteraciones}\")\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "id": "L-R_ECp-DPbe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "UGIUz-ouPbOx"
      },
      "id": "UGIUz-ouPbOx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnuFD6mBbYse"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_30.pth\"):\n",
        "  model = RobertaClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_30.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_30.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "id": "DnuFD6mBbYse"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSV1zqwmDPYu",
        "outputId": "a6dd5f28-11b9-4282-cf97-502e83e811fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración:      0 de 848\n",
            "Iteración:      1 de 848\n",
            "Iteración:      2 de 848\n",
            "Iteración:      3 de 848\n",
            "Iteración:      4 de 848\n",
            "Iteración:      5 de 848\n",
            "Iteración:      6 de 848\n",
            "Iteración:      7 de 848\n",
            "Iteración:      8 de 848\n",
            "Iteración:      9 de 848\n",
            "Iteración:     10 de 848\n",
            "Iteración:     11 de 848\n",
            "Iteración:     12 de 848\n",
            "Iteración:     13 de 848\n",
            "Iteración:     14 de 848\n",
            "Iteración:     15 de 848\n",
            "Iteración:     16 de 848\n",
            "Iteración:     17 de 848\n",
            "Iteración:     18 de 848\n",
            "Iteración:     19 de 848\n",
            "Iteración:     20 de 848\n",
            "Iteración:     21 de 848\n",
            "Iteración:     22 de 848\n",
            "Iteración:     23 de 848\n",
            "Iteración:     24 de 848\n",
            "Iteración:     25 de 848\n",
            "Iteración:     26 de 848\n",
            "Iteración:     27 de 848\n",
            "Iteración:     28 de 848\n",
            "Iteración:     29 de 848\n",
            "Iteración:     30 de 848\n",
            "Iteración:     31 de 848\n",
            "Iteración:     32 de 848\n",
            "Iteración:     33 de 848\n",
            "Iteración:     34 de 848\n",
            "Iteración:     35 de 848\n",
            "Iteración:     36 de 848\n",
            "Iteración:     37 de 848\n",
            "Iteración:     38 de 848\n",
            "Iteración:     39 de 848\n",
            "Iteración:     40 de 848\n",
            "Iteración:     41 de 848\n",
            "Iteración:     42 de 848\n",
            "Iteración:     43 de 848\n",
            "Iteración:     44 de 848\n",
            "Iteración:     45 de 848\n",
            "Iteración:     46 de 848\n",
            "Iteración:     47 de 848\n",
            "Iteración:     48 de 848\n",
            "Iteración:     49 de 848\n",
            "Iteración:     50 de 848\n",
            "Iteración:     51 de 848\n",
            "Iteración:     52 de 848\n",
            "Iteración:     53 de 848\n",
            "Iteración:     54 de 848\n",
            "Iteración:     55 de 848\n",
            "Iteración:     56 de 848\n",
            "Iteración:     57 de 848\n",
            "Iteración:     58 de 848\n",
            "Iteración:     59 de 848\n",
            "Iteración:     60 de 848\n",
            "Iteración:     61 de 848\n",
            "Iteración:     62 de 848\n",
            "Iteración:     63 de 848\n",
            "Iteración:     64 de 848\n",
            "Iteración:     65 de 848\n",
            "Iteración:     66 de 848\n",
            "Iteración:     67 de 848\n",
            "Iteración:     68 de 848\n",
            "Iteración:     69 de 848\n",
            "Iteración:     70 de 848\n",
            "Iteración:     71 de 848\n",
            "Iteración:     72 de 848\n",
            "Iteración:     73 de 848\n",
            "Iteración:     74 de 848\n",
            "Iteración:     75 de 848\n",
            "Iteración:     76 de 848\n",
            "Iteración:     77 de 848\n",
            "Iteración:     78 de 848\n",
            "Iteración:     79 de 848\n",
            "Iteración:     80 de 848\n",
            "Iteración:     81 de 848\n",
            "Iteración:     82 de 848\n",
            "Iteración:     83 de 848\n",
            "Iteración:     84 de 848\n",
            "Iteración:     85 de 848\n",
            "Iteración:     86 de 848\n",
            "Iteración:     87 de 848\n",
            "Iteración:     88 de 848\n",
            "Iteración:     89 de 848\n",
            "Iteración:     90 de 848\n",
            "Iteración:     91 de 848\n",
            "Iteración:     92 de 848\n",
            "Iteración:     93 de 848\n",
            "Iteración:     94 de 848\n",
            "Iteración:     95 de 848\n",
            "Iteración:     96 de 848\n",
            "Iteración:     97 de 848\n",
            "Iteración:     98 de 848\n",
            "Iteración:     99 de 848\n",
            "Iteración:    100 de 848\n",
            "Iteración:    101 de 848\n",
            "Iteración:    102 de 848\n",
            "Iteración:    103 de 848\n",
            "Iteración:    104 de 848\n",
            "Iteración:    105 de 848\n",
            "Iteración:    106 de 848\n",
            "Iteración:    107 de 848\n",
            "Iteración:    108 de 848\n",
            "Iteración:    109 de 848\n",
            "Iteración:    110 de 848\n",
            "Iteración:    111 de 848\n",
            "Iteración:    112 de 848\n",
            "Iteración:    113 de 848\n",
            "Iteración:    114 de 848\n",
            "Iteración:    115 de 848\n",
            "Iteración:    116 de 848\n",
            "Iteración:    117 de 848\n",
            "Iteración:    118 de 848\n",
            "Iteración:    119 de 848\n",
            "Iteración:    120 de 848\n",
            "Iteración:    121 de 848\n",
            "Iteración:    122 de 848\n",
            "Iteración:    123 de 848\n",
            "Iteración:    124 de 848\n",
            "Iteración:    125 de 848\n",
            "Iteración:    126 de 848\n",
            "Iteración:    127 de 848\n",
            "Iteración:    128 de 848\n",
            "Iteración:    129 de 848\n",
            "Iteración:    130 de 848\n",
            "Iteración:    131 de 848\n",
            "Iteración:    132 de 848\n",
            "Iteración:    133 de 848\n",
            "Iteración:    134 de 848\n",
            "Iteración:    135 de 848\n",
            "Iteración:    136 de 848\n",
            "Iteración:    137 de 848\n",
            "Iteración:    138 de 848\n",
            "Iteración:    139 de 848\n",
            "Iteración:    140 de 848\n",
            "Iteración:    141 de 848\n",
            "Iteración:    142 de 848\n",
            "Iteración:    143 de 848\n",
            "Iteración:    144 de 848\n",
            "Iteración:    145 de 848\n",
            "Iteración:    146 de 848\n",
            "Iteración:    147 de 848\n",
            "Iteración:    148 de 848\n",
            "Iteración:    149 de 848\n",
            "Iteración:    150 de 848\n",
            "Iteración:    151 de 848\n",
            "Iteración:    152 de 848\n",
            "Iteración:    153 de 848\n",
            "Iteración:    154 de 848\n",
            "Iteración:    155 de 848\n",
            "Iteración:    156 de 848\n",
            "Iteración:    157 de 848\n",
            "Iteración:    158 de 848\n",
            "Iteración:    159 de 848\n",
            "Iteración:    160 de 848\n",
            "Iteración:    161 de 848\n",
            "Iteración:    162 de 848\n",
            "Iteración:    163 de 848\n",
            "Iteración:    164 de 848\n",
            "Iteración:    165 de 848\n",
            "Iteración:    166 de 848\n",
            "Iteración:    167 de 848\n",
            "Iteración:    168 de 848\n",
            "Iteración:    169 de 848\n",
            "Iteración:    170 de 848\n",
            "Iteración:    171 de 848\n",
            "Iteración:    172 de 848\n",
            "Iteración:    173 de 848\n",
            "Iteración:    174 de 848\n",
            "Iteración:    175 de 848\n",
            "Iteración:    176 de 848\n",
            "Iteración:    177 de 848\n",
            "Iteración:    178 de 848\n",
            "Iteración:    179 de 848\n",
            "Iteración:    180 de 848\n",
            "Iteración:    181 de 848\n",
            "Iteración:    182 de 848\n",
            "Iteración:    183 de 848\n",
            "Iteración:    184 de 848\n",
            "Iteración:    185 de 848\n",
            "Iteración:    186 de 848\n",
            "Iteración:    187 de 848\n",
            "Iteración:    188 de 848\n",
            "Iteración:    189 de 848\n",
            "Iteración:    190 de 848\n",
            "Iteración:    191 de 848\n",
            "Iteración:    192 de 848\n",
            "Iteración:    193 de 848\n",
            "Iteración:    194 de 848\n",
            "Iteración:    195 de 848\n",
            "Iteración:    196 de 848\n",
            "Iteración:    197 de 848\n",
            "Iteración:    198 de 848\n",
            "Iteración:    199 de 848\n",
            "Iteración:    200 de 848\n",
            "Iteración:    201 de 848\n",
            "Iteración:    202 de 848\n",
            "Iteración:    203 de 848\n",
            "Iteración:    204 de 848\n",
            "Iteración:    205 de 848\n",
            "Iteración:    206 de 848\n",
            "Iteración:    207 de 848\n",
            "Iteración:    208 de 848\n",
            "Iteración:    209 de 848\n",
            "Iteración:    210 de 848\n",
            "Iteración:    211 de 848\n",
            "Iteración:    212 de 848\n",
            "Iteración:    213 de 848\n",
            "Iteración:    214 de 848\n",
            "Iteración:    215 de 848\n",
            "Iteración:    216 de 848\n",
            "Iteración:    217 de 848\n",
            "Iteración:    218 de 848\n",
            "Iteración:    219 de 848\n",
            "Iteración:    220 de 848\n",
            "Iteración:    221 de 848\n",
            "Iteración:    222 de 848\n",
            "Iteración:    223 de 848\n",
            "Iteración:    224 de 848\n",
            "Iteración:    225 de 848\n",
            "Iteración:    226 de 848\n",
            "Iteración:    227 de 848\n",
            "Iteración:    228 de 848\n",
            "Iteración:    229 de 848\n",
            "Iteración:    230 de 848\n",
            "Iteración:    231 de 848\n",
            "Iteración:    232 de 848\n",
            "Iteración:    233 de 848\n",
            "Iteración:    234 de 848\n",
            "Iteración:    235 de 848\n",
            "Iteración:    236 de 848\n",
            "Iteración:    237 de 848\n",
            "Iteración:    238 de 848\n",
            "Iteración:    239 de 848\n",
            "Iteración:    240 de 848\n",
            "Iteración:    241 de 848\n",
            "Iteración:    242 de 848\n",
            "Iteración:    243 de 848\n",
            "Iteración:    244 de 848\n",
            "Iteración:    245 de 848\n",
            "Iteración:    246 de 848\n",
            "Iteración:    247 de 848\n",
            "Iteración:    248 de 848\n",
            "Iteración:    249 de 848\n",
            "Iteración:    250 de 848\n",
            "Iteración:    251 de 848\n",
            "Iteración:    252 de 848\n",
            "Iteración:    253 de 848\n",
            "Iteración:    254 de 848\n",
            "Iteración:    255 de 848\n",
            "Iteración:    256 de 848\n",
            "Iteración:    257 de 848\n",
            "Iteración:    258 de 848\n",
            "Iteración:    259 de 848\n",
            "Iteración:    260 de 848\n",
            "Iteración:    261 de 848\n",
            "Iteración:    262 de 848\n",
            "Iteración:    263 de 848\n",
            "Iteración:    264 de 848\n",
            "Iteración:    265 de 848\n",
            "Iteración:    266 de 848\n",
            "Iteración:    267 de 848\n",
            "Iteración:    268 de 848\n",
            "Iteración:    269 de 848\n",
            "Iteración:    270 de 848\n",
            "Iteración:    271 de 848\n",
            "Iteración:    272 de 848\n",
            "Iteración:    273 de 848\n",
            "Iteración:    274 de 848\n",
            "Iteración:    275 de 848\n",
            "Iteración:    276 de 848\n",
            "Iteración:    277 de 848\n",
            "Iteración:    278 de 848\n",
            "Iteración:    279 de 848\n",
            "Iteración:    280 de 848\n",
            "Iteración:    281 de 848\n",
            "Iteración:    282 de 848\n",
            "Iteración:    283 de 848\n",
            "Iteración:    284 de 848\n",
            "Iteración:    285 de 848\n",
            "Iteración:    286 de 848\n",
            "Iteración:    287 de 848\n",
            "Iteración:    288 de 848\n",
            "Iteración:    289 de 848\n",
            "Iteración:    290 de 848\n",
            "Iteración:    291 de 848\n",
            "Iteración:    292 de 848\n",
            "Iteración:    293 de 848\n",
            "Iteración:    294 de 848\n",
            "Iteración:    295 de 848\n",
            "Iteración:    296 de 848\n",
            "Iteración:    297 de 848\n",
            "Iteración:    298 de 848\n",
            "Iteración:    299 de 848\n",
            "Iteración:    300 de 848\n",
            "Iteración:    301 de 848\n",
            "Iteración:    302 de 848\n",
            "Iteración:    303 de 848\n",
            "Iteración:    304 de 848\n",
            "Iteración:    305 de 848\n",
            "Iteración:    306 de 848\n",
            "Iteración:    307 de 848\n",
            "Iteración:    308 de 848\n",
            "Iteración:    309 de 848\n",
            "Iteración:    310 de 848\n",
            "Iteración:    311 de 848\n",
            "Iteración:    312 de 848\n",
            "Iteración:    313 de 848\n",
            "Iteración:    314 de 848\n",
            "Iteración:    315 de 848\n",
            "Iteración:    316 de 848\n",
            "Iteración:    317 de 848\n",
            "Iteración:    318 de 848\n",
            "Iteración:    319 de 848\n",
            "Iteración:    320 de 848\n",
            "Iteración:    321 de 848\n",
            "Iteración:    322 de 848\n",
            "Iteración:    323 de 848\n",
            "Iteración:    324 de 848\n",
            "Iteración:    325 de 848\n",
            "Iteración:    326 de 848\n",
            "Iteración:    327 de 848\n",
            "Iteración:    328 de 848\n",
            "Iteración:    329 de 848\n",
            "Iteración:    330 de 848\n",
            "Iteración:    331 de 848\n",
            "Iteración:    332 de 848\n",
            "Iteración:    333 de 848\n",
            "Iteración:    334 de 848\n",
            "Iteración:    335 de 848\n",
            "Iteración:    336 de 848\n",
            "Iteración:    337 de 848\n",
            "Iteración:    338 de 848\n",
            "Iteración:    339 de 848\n",
            "Iteración:    340 de 848\n",
            "Iteración:    341 de 848\n",
            "Iteración:    342 de 848\n",
            "Iteración:    343 de 848\n",
            "Iteración:    344 de 848\n",
            "Iteración:    345 de 848\n",
            "Iteración:    346 de 848\n",
            "Iteración:    347 de 848\n",
            "Iteración:    348 de 848\n",
            "Iteración:    349 de 848\n",
            "Iteración:    350 de 848\n",
            "Iteración:    351 de 848\n",
            "Iteración:    352 de 848\n",
            "Iteración:    353 de 848\n",
            "Iteración:    354 de 848\n",
            "Iteración:    355 de 848\n",
            "Iteración:    356 de 848\n",
            "Iteración:    357 de 848\n",
            "Iteración:    358 de 848\n",
            "Iteración:    359 de 848\n",
            "Iteración:    360 de 848\n",
            "Iteración:    361 de 848\n",
            "Iteración:    362 de 848\n",
            "Iteración:    363 de 848\n",
            "Iteración:    364 de 848\n",
            "Iteración:    365 de 848\n",
            "Iteración:    366 de 848\n",
            "Iteración:    367 de 848\n",
            "Iteración:    368 de 848\n",
            "Iteración:    369 de 848\n",
            "Iteración:    370 de 848\n",
            "Iteración:    371 de 848\n",
            "Iteración:    372 de 848\n",
            "Iteración:    373 de 848\n",
            "Iteración:    374 de 848\n",
            "Iteración:    375 de 848\n",
            "Iteración:    376 de 848\n",
            "Iteración:    377 de 848\n",
            "Iteración:    378 de 848\n",
            "Iteración:    379 de 848\n",
            "Iteración:    380 de 848\n",
            "Iteración:    381 de 848\n",
            "Iteración:    382 de 848\n",
            "Iteración:    383 de 848\n",
            "Iteración:    384 de 848\n",
            "Iteración:    385 de 848\n",
            "Iteración:    386 de 848\n",
            "Iteración:    387 de 848\n",
            "Iteración:    388 de 848\n",
            "Iteración:    389 de 848\n",
            "Iteración:    390 de 848\n",
            "Iteración:    391 de 848\n",
            "Iteración:    392 de 848\n",
            "Iteración:    393 de 848\n",
            "Iteración:    394 de 848\n",
            "Iteración:    395 de 848\n",
            "Iteración:    396 de 848\n",
            "Iteración:    397 de 848\n",
            "Iteración:    398 de 848\n",
            "Iteración:    399 de 848\n",
            "Iteración:    400 de 848\n",
            "Iteración:    401 de 848\n",
            "Iteración:    402 de 848\n",
            "Iteración:    403 de 848\n",
            "Iteración:    404 de 848\n",
            "Iteración:    405 de 848\n",
            "Iteración:    406 de 848\n",
            "Iteración:    407 de 848\n",
            "Iteración:    408 de 848\n",
            "Iteración:    409 de 848\n",
            "Iteración:    410 de 848\n",
            "Iteración:    411 de 848\n",
            "Iteración:    412 de 848\n",
            "Iteración:    413 de 848\n",
            "Iteración:    414 de 848\n",
            "Iteración:    415 de 848\n",
            "Iteración:    416 de 848\n",
            "Iteración:    417 de 848\n",
            "Iteración:    418 de 848\n",
            "Iteración:    419 de 848\n",
            "Iteración:    420 de 848\n",
            "Iteración:    421 de 848\n",
            "Iteración:    422 de 848\n",
            "Iteración:    423 de 848\n",
            "Iteración:    424 de 848\n",
            "Iteración:    425 de 848\n",
            "Iteración:    426 de 848\n",
            "Iteración:    427 de 848\n",
            "Iteración:    428 de 848\n",
            "Iteración:    429 de 848\n",
            "Iteración:    430 de 848\n",
            "Iteración:    431 de 848\n",
            "Iteración:    432 de 848\n",
            "Iteración:    433 de 848\n",
            "Iteración:    434 de 848\n",
            "Iteración:    435 de 848\n",
            "Iteración:    436 de 848\n",
            "Iteración:    437 de 848\n",
            "Iteración:    438 de 848\n",
            "Iteración:    439 de 848\n",
            "Iteración:    440 de 848\n",
            "Iteración:    441 de 848\n",
            "Iteración:    442 de 848\n",
            "Iteración:    443 de 848\n",
            "Iteración:    444 de 848\n",
            "Iteración:    445 de 848\n",
            "Iteración:    446 de 848\n",
            "Iteración:    447 de 848\n",
            "Iteración:    448 de 848\n",
            "Iteración:    449 de 848\n",
            "Iteración:    450 de 848\n",
            "Iteración:    451 de 848\n",
            "Iteración:    452 de 848\n",
            "Iteración:    453 de 848\n",
            "Iteración:    454 de 848\n",
            "Iteración:    455 de 848\n",
            "Iteración:    456 de 848\n",
            "Iteración:    457 de 848\n",
            "Iteración:    458 de 848\n",
            "Iteración:    459 de 848\n",
            "Iteración:    460 de 848\n",
            "Iteración:    461 de 848\n",
            "Iteración:    462 de 848\n",
            "Iteración:    463 de 848\n",
            "Iteración:    464 de 848\n",
            "Iteración:    465 de 848\n",
            "Iteración:    466 de 848\n",
            "Iteración:    467 de 848\n",
            "Iteración:    468 de 848\n",
            "Iteración:    469 de 848\n",
            "Iteración:    470 de 848\n",
            "Iteración:    471 de 848\n",
            "Iteración:    472 de 848\n",
            "Iteración:    473 de 848\n",
            "Iteración:    474 de 848\n",
            "Iteración:    475 de 848\n",
            "Iteración:    476 de 848\n",
            "Iteración:    477 de 848\n",
            "Iteración:    478 de 848\n",
            "Iteración:    479 de 848\n",
            "Iteración:    480 de 848\n",
            "Iteración:    481 de 848\n",
            "Iteración:    482 de 848\n",
            "Iteración:    483 de 848\n",
            "Iteración:    484 de 848\n",
            "Iteración:    485 de 848\n",
            "Iteración:    486 de 848\n",
            "Iteración:    487 de 848\n",
            "Iteración:    488 de 848\n",
            "Iteración:    489 de 848\n",
            "Iteración:    490 de 848\n",
            "Iteración:    491 de 848\n",
            "Iteración:    492 de 848\n",
            "Iteración:    493 de 848\n",
            "Iteración:    494 de 848\n",
            "Iteración:    495 de 848\n",
            "Iteración:    496 de 848\n",
            "Iteración:    497 de 848\n",
            "Iteración:    498 de 848\n",
            "Iteración:    499 de 848\n",
            "Iteración:    500 de 848\n",
            "Iteración:    501 de 848\n",
            "Iteración:    502 de 848\n",
            "Iteración:    503 de 848\n",
            "Iteración:    504 de 848\n",
            "Iteración:    505 de 848\n",
            "Iteración:    506 de 848\n",
            "Iteración:    507 de 848\n",
            "Iteración:    508 de 848\n",
            "Iteración:    509 de 848\n",
            "Iteración:    510 de 848\n",
            "Iteración:    511 de 848\n",
            "Iteración:    512 de 848\n",
            "Iteración:    513 de 848\n",
            "Iteración:    514 de 848\n",
            "Iteración:    515 de 848\n",
            "Iteración:    516 de 848\n",
            "Iteración:    517 de 848\n",
            "Iteración:    518 de 848\n",
            "Iteración:    519 de 848\n",
            "Iteración:    520 de 848\n",
            "Iteración:    521 de 848\n",
            "Iteración:    522 de 848\n",
            "Iteración:    523 de 848\n",
            "Iteración:    524 de 848\n",
            "Iteración:    525 de 848\n",
            "Iteración:    526 de 848\n",
            "Iteración:    527 de 848\n",
            "Iteración:    528 de 848\n",
            "Iteración:    529 de 848\n",
            "Iteración:    530 de 848\n",
            "Iteración:    531 de 848\n",
            "Iteración:    532 de 848\n",
            "Iteración:    533 de 848\n",
            "Iteración:    534 de 848\n",
            "Iteración:    535 de 848\n",
            "Iteración:    536 de 848\n",
            "Iteración:    537 de 848\n",
            "Iteración:    538 de 848\n",
            "Iteración:    539 de 848\n",
            "Iteración:    540 de 848\n",
            "Iteración:    541 de 848\n",
            "Iteración:    542 de 848\n",
            "Iteración:    543 de 848\n",
            "Iteración:    544 de 848\n",
            "Iteración:    545 de 848\n",
            "Iteración:    546 de 848\n",
            "Iteración:    547 de 848\n",
            "Iteración:    548 de 848\n",
            "Iteración:    549 de 848\n",
            "Iteración:    550 de 848\n",
            "Iteración:    551 de 848\n",
            "Iteración:    552 de 848\n",
            "Iteración:    553 de 848\n",
            "Iteración:    554 de 848\n",
            "Iteración:    555 de 848\n",
            "Iteración:    556 de 848\n",
            "Iteración:    557 de 848\n",
            "Iteración:    558 de 848\n",
            "Iteración:    559 de 848\n",
            "Iteración:    560 de 848\n",
            "Iteración:    561 de 848\n",
            "Iteración:    562 de 848\n",
            "Iteración:    563 de 848\n",
            "Iteración:    564 de 848\n",
            "Iteración:    565 de 848\n",
            "Iteración:    566 de 848\n",
            "Iteración:    567 de 848\n",
            "Iteración:    568 de 848\n",
            "Iteración:    569 de 848\n",
            "Iteración:    570 de 848\n",
            "Iteración:    571 de 848\n",
            "Iteración:    572 de 848\n",
            "Iteración:    573 de 848\n",
            "Iteración:    574 de 848\n",
            "Iteración:    575 de 848\n",
            "Iteración:    576 de 848\n",
            "Iteración:    577 de 848\n",
            "Iteración:    578 de 848\n",
            "Iteración:    579 de 848\n",
            "Iteración:    580 de 848\n",
            "Iteración:    581 de 848\n",
            "Iteración:    582 de 848\n",
            "Iteración:    583 de 848\n",
            "Iteración:    584 de 848\n",
            "Iteración:    585 de 848\n",
            "Iteración:    586 de 848\n",
            "Iteración:    587 de 848\n",
            "Iteración:    588 de 848\n",
            "Iteración:    589 de 848\n",
            "Iteración:    590 de 848\n",
            "Iteración:    591 de 848\n",
            "Iteración:    592 de 848\n",
            "Iteración:    593 de 848\n",
            "Iteración:    594 de 848\n",
            "Iteración:    595 de 848\n",
            "Iteración:    596 de 848\n",
            "Iteración:    597 de 848\n",
            "Iteración:    598 de 848\n",
            "Iteración:    599 de 848\n",
            "Iteración:    600 de 848\n",
            "Iteración:    601 de 848\n",
            "Iteración:    602 de 848\n",
            "Iteración:    603 de 848\n",
            "Iteración:    604 de 848\n",
            "Iteración:    605 de 848\n",
            "Iteración:    606 de 848\n",
            "Iteración:    607 de 848\n",
            "Iteración:    608 de 848\n",
            "Iteración:    609 de 848\n",
            "Iteración:    610 de 848\n",
            "Iteración:    611 de 848\n",
            "Iteración:    612 de 848\n",
            "Iteración:    613 de 848\n",
            "Iteración:    614 de 848\n",
            "Iteración:    615 de 848\n",
            "Iteración:    616 de 848\n",
            "Iteración:    617 de 848\n",
            "Iteración:    618 de 848\n",
            "Iteración:    619 de 848\n",
            "Iteración:    620 de 848\n",
            "Iteración:    621 de 848\n",
            "Iteración:    622 de 848\n",
            "Iteración:    623 de 848\n",
            "Iteración:    624 de 848\n",
            "Iteración:    625 de 848\n",
            "Iteración:    626 de 848\n",
            "Iteración:    627 de 848\n",
            "Iteración:    628 de 848\n",
            "Iteración:    629 de 848\n",
            "Iteración:    630 de 848\n",
            "Iteración:    631 de 848\n",
            "Iteración:    632 de 848\n",
            "Iteración:    633 de 848\n",
            "Iteración:    634 de 848\n",
            "Iteración:    635 de 848\n",
            "Iteración:    636 de 848\n",
            "Iteración:    637 de 848\n",
            "Iteración:    638 de 848\n",
            "Iteración:    639 de 848\n",
            "Iteración:    640 de 848\n",
            "Iteración:    641 de 848\n",
            "Iteración:    642 de 848\n",
            "Iteración:    643 de 848\n",
            "Iteración:    644 de 848\n",
            "Iteración:    645 de 848\n",
            "Iteración:    646 de 848\n",
            "Iteración:    647 de 848\n",
            "Iteración:    648 de 848\n",
            "Iteración:    649 de 848\n",
            "Iteración:    650 de 848\n",
            "Iteración:    651 de 848\n",
            "Iteración:    652 de 848\n",
            "Iteración:    653 de 848\n",
            "Iteración:    654 de 848\n",
            "Iteración:    655 de 848\n",
            "Iteración:    656 de 848\n",
            "Iteración:    657 de 848\n",
            "Iteración:    658 de 848\n",
            "Iteración:    659 de 848\n",
            "Iteración:    660 de 848\n",
            "Iteración:    661 de 848\n",
            "Iteración:    662 de 848\n",
            "Iteración:    663 de 848\n",
            "Iteración:    664 de 848\n",
            "Iteración:    665 de 848\n",
            "Iteración:    666 de 848\n",
            "Iteración:    667 de 848\n",
            "Iteración:    668 de 848\n",
            "Iteración:    669 de 848\n",
            "Iteración:    670 de 848\n",
            "Iteración:    671 de 848\n",
            "Iteración:    672 de 848\n",
            "Iteración:    673 de 848\n",
            "Iteración:    674 de 848\n",
            "Iteración:    675 de 848\n",
            "Iteración:    676 de 848\n",
            "Iteración:    677 de 848\n",
            "Iteración:    678 de 848\n",
            "Iteración:    679 de 848\n",
            "Iteración:    680 de 848\n",
            "Iteración:    681 de 848\n",
            "Iteración:    682 de 848\n",
            "Iteración:    683 de 848\n",
            "Iteración:    684 de 848\n",
            "Iteración:    685 de 848\n",
            "Iteración:    686 de 848\n",
            "Iteración:    687 de 848\n",
            "Iteración:    688 de 848\n",
            "Iteración:    689 de 848\n",
            "Iteración:    690 de 848\n",
            "Iteración:    691 de 848\n",
            "Iteración:    692 de 848\n",
            "Iteración:    693 de 848\n",
            "Iteración:    694 de 848\n",
            "Iteración:    695 de 848\n",
            "Iteración:    696 de 848\n",
            "Iteración:    697 de 848\n",
            "Iteración:    698 de 848\n",
            "Iteración:    699 de 848\n",
            "Iteración:    700 de 848\n",
            "Iteración:    701 de 848\n",
            "Iteración:    702 de 848\n",
            "Iteración:    703 de 848\n",
            "Iteración:    704 de 848\n",
            "Iteración:    705 de 848\n",
            "Iteración:    706 de 848\n",
            "Iteración:    707 de 848\n",
            "Iteración:    708 de 848\n",
            "Iteración:    709 de 848\n",
            "Iteración:    710 de 848\n",
            "Iteración:    711 de 848\n",
            "Iteración:    712 de 848\n",
            "Iteración:    713 de 848\n",
            "Iteración:    714 de 848\n",
            "Iteración:    715 de 848\n",
            "Iteración:    716 de 848\n",
            "Iteración:    717 de 848\n",
            "Iteración:    718 de 848\n",
            "Iteración:    719 de 848\n",
            "Iteración:    720 de 848\n",
            "Iteración:    721 de 848\n",
            "Iteración:    722 de 848\n",
            "Iteración:    723 de 848\n",
            "Iteración:    724 de 848\n",
            "Iteración:    725 de 848\n",
            "Iteración:    726 de 848\n",
            "Iteración:    727 de 848\n",
            "Iteración:    728 de 848\n",
            "Iteración:    729 de 848\n",
            "Iteración:    730 de 848\n",
            "Iteración:    731 de 848\n",
            "Iteración:    732 de 848\n",
            "Iteración:    733 de 848\n",
            "Iteración:    734 de 848\n",
            "Iteración:    735 de 848\n",
            "Iteración:    736 de 848\n",
            "Iteración:    737 de 848\n",
            "Iteración:    738 de 848\n",
            "Iteración:    739 de 848\n",
            "Iteración:    740 de 848\n",
            "Iteración:    741 de 848\n",
            "Iteración:    742 de 848\n",
            "Iteración:    743 de 848\n",
            "Iteración:    744 de 848\n",
            "Iteración:    745 de 848\n",
            "Iteración:    746 de 848\n",
            "Iteración:    747 de 848\n",
            "Iteración:    748 de 848\n",
            "Iteración:    749 de 848\n",
            "Iteración:    750 de 848\n",
            "Iteración:    751 de 848\n",
            "Iteración:    752 de 848\n",
            "Iteración:    753 de 848\n",
            "Iteración:    754 de 848\n",
            "Iteración:    755 de 848\n",
            "Iteración:    756 de 848\n",
            "Iteración:    757 de 848\n",
            "Iteración:    758 de 848\n",
            "Iteración:    759 de 848\n",
            "Iteración:    760 de 848\n",
            "Iteración:    761 de 848\n",
            "Iteración:    762 de 848\n",
            "Iteración:    763 de 848\n",
            "Iteración:    764 de 848\n",
            "Iteración:    765 de 848\n",
            "Iteración:    766 de 848\n",
            "Iteración:    767 de 848\n",
            "Iteración:    768 de 848\n",
            "Iteración:    769 de 848\n",
            "Iteración:    770 de 848\n",
            "Iteración:    771 de 848\n",
            "Iteración:    772 de 848\n",
            "Iteración:    773 de 848\n",
            "Iteración:    774 de 848\n",
            "Iteración:    775 de 848\n",
            "Iteración:    776 de 848\n",
            "Iteración:    777 de 848\n",
            "Iteración:    778 de 848\n",
            "Iteración:    779 de 848\n",
            "Iteración:    780 de 848\n",
            "Iteración:    781 de 848\n",
            "Iteración:    782 de 848\n",
            "Iteración:    783 de 848\n",
            "Iteración:    784 de 848\n",
            "Iteración:    785 de 848\n",
            "Iteración:    786 de 848\n",
            "Iteración:    787 de 848\n",
            "Iteración:    788 de 848\n",
            "Iteración:    789 de 848\n",
            "Iteración:    790 de 848\n",
            "Iteración:    791 de 848\n",
            "Iteración:    792 de 848\n",
            "Iteración:    793 de 848\n",
            "Iteración:    794 de 848\n",
            "Iteración:    795 de 848\n",
            "Iteración:    796 de 848\n",
            "Iteración:    797 de 848\n",
            "Iteración:    798 de 848\n",
            "Iteración:    799 de 848\n",
            "Iteración:    800 de 848\n",
            "Iteración:    801 de 848\n",
            "Iteración:    802 de 848\n",
            "Iteración:    803 de 848\n",
            "Iteración:    804 de 848\n",
            "Iteración:    805 de 848\n",
            "Iteración:    806 de 848\n",
            "Iteración:    807 de 848\n",
            "Iteración:    808 de 848\n",
            "Iteración:    809 de 848\n",
            "Iteración:    810 de 848\n",
            "Iteración:    811 de 848\n",
            "Iteración:    812 de 848\n",
            "Iteración:    813 de 848\n",
            "Iteración:    814 de 848\n",
            "Iteración:    815 de 848\n",
            "Iteración:    816 de 848\n",
            "Iteración:    817 de 848\n",
            "Iteración:    818 de 848\n",
            "Iteración:    819 de 848\n",
            "Iteración:    820 de 848\n",
            "Iteración:    821 de 848\n",
            "Iteración:    822 de 848\n",
            "Iteración:    823 de 848\n",
            "Iteración:    824 de 848\n",
            "Iteración:    825 de 848\n",
            "Iteración:    826 de 848\n",
            "Iteración:    827 de 848\n",
            "Iteración:    828 de 848\n",
            "Iteración:    829 de 848\n",
            "Iteración:    830 de 848\n",
            "Iteración:    831 de 848\n",
            "Iteración:    832 de 848\n",
            "Iteración:    833 de 848\n",
            "Iteración:    834 de 848\n",
            "Iteración:    835 de 848\n",
            "Iteración:    836 de 848\n",
            "Iteración:    837 de 848\n",
            "Iteración:    838 de 848\n",
            "Iteración:    839 de 848\n",
            "Iteración:    840 de 848\n",
            "Iteración:    841 de 848\n",
            "Iteración:    842 de 848\n",
            "Iteración:    843 de 848\n",
            "Iteración:    844 de 848\n",
            "Iteración:    845 de 848\n",
            "Iteración:    846 de 848\n",
            "Iteración:    847 de 848\n",
            "Accuracy Score = 0.7164385583059726\n",
            "F1 Score (Micro) = 0.7164385583059726\n",
            "F1 Score (Macro) = 0.4173983128257482\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationRoberta(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "id": "eSV1zqwmDPYu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gKLmkw9i-Js"
      },
      "source": [
        "##### Entrenamiento del modelo (50% de datos)"
      ],
      "id": "9gKLmkw9i-Js"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-5\n",
        "- weight_decay=0.01\n",
        "- Dropout + Linear + Sigmoid"
      ],
      "metadata": {
        "id": "xNSP-YH3KRiD"
      },
      "id": "xNSP-YH3KRiD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83948e80-caa7-44ac-e8c1-7bb988961051",
        "id": "KTpV94vti-Jy"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración;      0 de 4841, Loss: 0.0690148115158081\n",
            "Epoch: 0, iteración;     10 de 4841, Loss: 0.6695529460906983\n",
            "Epoch: 0, iteración;     20 de 4841, Loss: 0.6651931285858155\n",
            "Epoch: 0, iteración;     30 de 4841, Loss: 0.6305753707885742\n",
            "Epoch: 0, iteración;     40 de 4841, Loss: 0.6418673038482666\n",
            "Epoch: 0, iteración;     50 de 4841, Loss: 0.667976188659668\n",
            "Epoch: 0, iteración;     60 de 4841, Loss: 0.6516317367553711\n",
            "Epoch: 0, iteración;     70 de 4841, Loss: 0.6127129554748535\n",
            "Epoch: 0, iteración;     80 de 4841, Loss: 0.6398096084594727\n",
            "Epoch: 0, iteración;     90 de 4841, Loss: 0.6491200447082519\n",
            "Epoch: 0, iteración;    100 de 4841, Loss: 0.6119801998138428\n",
            "Epoch: 0, iteración;    110 de 4841, Loss: 0.5749374866485596\n",
            "Epoch: 0, iteración;    120 de 4841, Loss: 0.5183465480804443\n",
            "Epoch: 0, iteración;    130 de 4841, Loss: 0.5098889350891114\n",
            "Epoch: 0, iteración;    140 de 4841, Loss: 0.5941874504089355\n",
            "Epoch: 0, iteración;    150 de 4841, Loss: 0.4488194465637207\n",
            "Epoch: 0, iteración;    160 de 4841, Loss: 0.5137249946594238\n",
            "Epoch: 0, iteración;    170 de 4841, Loss: 0.662013578414917\n",
            "Epoch: 0, iteración;    180 de 4841, Loss: 0.6086583614349366\n",
            "Epoch: 0, iteración;    190 de 4841, Loss: 0.5757638931274414\n",
            "Epoch: 0, iteración;    200 de 4841, Loss: 0.6187149524688721\n",
            "Epoch: 0, iteración;    210 de 4841, Loss: 0.563752269744873\n",
            "Epoch: 0, iteración;    220 de 4841, Loss: 0.5024037837982178\n",
            "Epoch: 0, iteración;    230 de 4841, Loss: 0.6050149917602539\n",
            "Epoch: 0, iteración;    240 de 4841, Loss: 0.5366775512695312\n",
            "Epoch: 0, iteración;    250 de 4841, Loss: 0.5229480743408204\n",
            "Epoch: 0, iteración;    260 de 4841, Loss: 0.5466042995452881\n",
            "Epoch: 0, iteración;    270 de 4841, Loss: 0.4959277153015137\n",
            "Epoch: 0, iteración;    280 de 4841, Loss: 0.5415647029876709\n",
            "Epoch: 0, iteración;    290 de 4841, Loss: 0.5597411155700683\n",
            "Epoch: 0, iteración;    300 de 4841, Loss: 0.5334623336791993\n",
            "Epoch: 0, iteración;    310 de 4841, Loss: 0.5173798561096191\n",
            "Epoch: 0, iteración;    320 de 4841, Loss: 0.6103026390075683\n",
            "Epoch: 0, iteración;    330 de 4841, Loss: 0.5499355316162109\n",
            "Epoch: 0, iteración;    340 de 4841, Loss: 0.43509368896484374\n",
            "Epoch: 0, iteración;    350 de 4841, Loss: 0.5107490539550781\n",
            "Epoch: 0, iteración;    360 de 4841, Loss: 0.5312732219696045\n",
            "Epoch: 0, iteración;    370 de 4841, Loss: 0.5548702239990234\n",
            "Epoch: 0, iteración;    380 de 4841, Loss: 0.5415633201599122\n",
            "Epoch: 0, iteración;    390 de 4841, Loss: 0.5529940128326416\n",
            "Epoch: 0, iteración;    400 de 4841, Loss: 0.5582894325256348\n",
            "Epoch: 0, iteración;    410 de 4841, Loss: 0.4862683773040771\n",
            "Epoch: 0, iteración;    420 de 4841, Loss: 0.590270709991455\n",
            "Epoch: 0, iteración;    430 de 4841, Loss: 0.4704787254333496\n",
            "Epoch: 0, iteración;    440 de 4841, Loss: 0.5775683879852295\n",
            "Epoch: 0, iteración;    450 de 4841, Loss: 0.4848348140716553\n",
            "Epoch: 0, iteración;    460 de 4841, Loss: 0.48558816909790037\n",
            "Epoch: 0, iteración;    470 de 4841, Loss: 0.5943253040313721\n",
            "Epoch: 0, iteración;    480 de 4841, Loss: 0.5016016483306884\n",
            "Epoch: 0, iteración;    490 de 4841, Loss: 0.4956578254699707\n",
            "Epoch: 0, iteración;    500 de 4841, Loss: 0.44344472885131836\n",
            "Epoch: 0, iteración;    510 de 4841, Loss: 0.5762300491333008\n",
            "Epoch: 0, iteración;    520 de 4841, Loss: 0.6396794795989991\n",
            "Epoch: 0, iteración;    530 de 4841, Loss: 0.5126788139343261\n",
            "Epoch: 0, iteración;    540 de 4841, Loss: 0.46000056266784667\n",
            "Epoch: 0, iteración;    550 de 4841, Loss: 0.5179378509521484\n",
            "Epoch: 0, iteración;    560 de 4841, Loss: 0.46797380447387693\n",
            "Epoch: 0, iteración;    570 de 4841, Loss: 0.4626119136810303\n",
            "Epoch: 0, iteración;    580 de 4841, Loss: 0.48227629661560056\n",
            "Epoch: 0, iteración;    590 de 4841, Loss: 0.656745719909668\n",
            "Epoch: 0, iteración;    600 de 4841, Loss: 0.6139667510986329\n",
            "Epoch: 0, iteración;    610 de 4841, Loss: 0.5618888854980468\n",
            "Epoch: 0, iteración;    620 de 4841, Loss: 0.488189697265625\n",
            "Epoch: 0, iteración;    630 de 4841, Loss: 0.5348499774932861\n",
            "Epoch: 0, iteración;    640 de 4841, Loss: 0.4279774188995361\n",
            "Epoch: 0, iteración;    650 de 4841, Loss: 0.6264997005462647\n",
            "Epoch: 0, iteración;    660 de 4841, Loss: 0.48868398666381835\n",
            "Epoch: 0, iteración;    670 de 4841, Loss: 0.45778522491455076\n",
            "Epoch: 0, iteración;    680 de 4841, Loss: 0.47036399841308596\n",
            "Epoch: 0, iteración;    690 de 4841, Loss: 0.4737229347229004\n",
            "Epoch: 0, iteración;    700 de 4841, Loss: 0.4093317031860352\n",
            "Epoch: 0, iteración;    710 de 4841, Loss: 0.4072596549987793\n",
            "Epoch: 0, iteración;    720 de 4841, Loss: 0.6003611087799072\n",
            "Epoch: 0, iteración;    730 de 4841, Loss: 0.5077394485473633\n",
            "Epoch: 0, iteración;    740 de 4841, Loss: 0.45175681114196775\n",
            "Epoch: 0, iteración;    750 de 4841, Loss: 0.6555424213409424\n",
            "Epoch: 0, iteración;    760 de 4841, Loss: 0.4745979309082031\n",
            "Epoch: 0, iteración;    770 de 4841, Loss: 0.4807331085205078\n",
            "Epoch: 0, iteración;    780 de 4841, Loss: 0.4707810401916504\n",
            "Epoch: 0, iteración;    790 de 4841, Loss: 0.5628467082977295\n",
            "Epoch: 0, iteración;    800 de 4841, Loss: 0.5736227035522461\n",
            "Epoch: 0, iteración;    810 de 4841, Loss: 0.5351505756378174\n",
            "Epoch: 0, iteración;    820 de 4841, Loss: 0.6418601989746093\n",
            "Epoch: 0, iteración;    830 de 4841, Loss: 0.5248782634735107\n",
            "Epoch: 0, iteración;    840 de 4841, Loss: 0.4863927364349365\n",
            "Epoch: 0, iteración;    850 de 4841, Loss: 0.6451375484466553\n",
            "Epoch: 0, iteración;    860 de 4841, Loss: 0.41262197494506836\n",
            "Epoch: 0, iteración;    870 de 4841, Loss: 0.48598394393920896\n",
            "Epoch: 0, iteración;    880 de 4841, Loss: 0.5660428524017334\n",
            "Epoch: 0, iteración;    890 de 4841, Loss: 0.5272644996643067\n",
            "Epoch: 0, iteración;    900 de 4841, Loss: 0.5467774868011475\n",
            "Epoch: 0, iteración;    910 de 4841, Loss: 0.5054018497467041\n",
            "Epoch: 0, iteración;    920 de 4841, Loss: 0.5145857334136963\n",
            "Epoch: 0, iteración;    930 de 4841, Loss: 0.6081053733825683\n",
            "Epoch: 0, iteración;    940 de 4841, Loss: 0.5286373615264892\n",
            "Epoch: 0, iteración;    950 de 4841, Loss: 0.5154189586639404\n",
            "Epoch: 0, iteración;    960 de 4841, Loss: 0.500689697265625\n",
            "Epoch: 0, iteración;    970 de 4841, Loss: 0.4834605693817139\n",
            "Epoch: 0, iteración;    980 de 4841, Loss: 0.43735613822937014\n",
            "Epoch: 0, iteración;    990 de 4841, Loss: 0.511675214767456\n",
            "Epoch: 0, iteración;   1000 de 4841, Loss: 0.49138898849487306\n",
            "Epoch: 0, iteración;   1010 de 4841, Loss: 0.5549540042877197\n",
            "Epoch: 0, iteración;   1020 de 4841, Loss: 0.4027651309967041\n",
            "Epoch: 0, iteración;   1030 de 4841, Loss: 0.613683032989502\n",
            "Epoch: 0, iteración;   1040 de 4841, Loss: 0.45165128707885743\n",
            "Epoch: 0, iteración;   1050 de 4841, Loss: 0.4158872127532959\n",
            "Epoch: 0, iteración;   1060 de 4841, Loss: 0.5636778831481933\n",
            "Epoch: 0, iteración;   1070 de 4841, Loss: 0.47907323837280275\n",
            "Epoch: 0, iteración;   1080 de 4841, Loss: 0.4395695686340332\n",
            "Epoch: 0, iteración;   1090 de 4841, Loss: 0.5799405097961425\n",
            "Epoch: 0, iteración;   1100 de 4841, Loss: 0.5198815345764161\n",
            "Epoch: 0, iteración;   1110 de 4841, Loss: 0.44840121269226074\n",
            "Epoch: 0, iteración;   1120 de 4841, Loss: 0.4771461009979248\n",
            "Epoch: 0, iteración;   1130 de 4841, Loss: 0.43158783912658694\n",
            "Epoch: 0, iteración;   1140 de 4841, Loss: 0.5488825798034668\n",
            "Epoch: 0, iteración;   1150 de 4841, Loss: 0.400893497467041\n",
            "Epoch: 0, iteración;   1160 de 4841, Loss: 0.5742091655731201\n",
            "Epoch: 0, iteración;   1170 de 4841, Loss: 0.4976010322570801\n",
            "Epoch: 0, iteración;   1180 de 4841, Loss: 0.5897914886474609\n",
            "Epoch: 0, iteración;   1190 de 4841, Loss: 0.46349635124206545\n",
            "Epoch: 0, iteración;   1200 de 4841, Loss: 0.4121302604675293\n",
            "Epoch: 0, iteración;   1210 de 4841, Loss: 0.48510117530822755\n",
            "Epoch: 0, iteración;   1220 de 4841, Loss: 0.6545634269714355\n",
            "Epoch: 0, iteración;   1230 de 4841, Loss: 0.5259088516235352\n",
            "Epoch: 0, iteración;   1240 de 4841, Loss: 0.5388055801391601\n",
            "Epoch: 0, iteración;   1250 de 4841, Loss: 0.48201794624328614\n",
            "Epoch: 0, iteración;   1260 de 4841, Loss: 0.5295506954193115\n",
            "Epoch: 0, iteración;   1270 de 4841, Loss: 0.45157313346862793\n",
            "Epoch: 0, iteración;   1280 de 4841, Loss: 0.4757666110992432\n",
            "Epoch: 0, iteración;   1290 de 4841, Loss: 0.536841630935669\n",
            "Epoch: 0, iteración;   1300 de 4841, Loss: 0.465102481842041\n",
            "Epoch: 0, iteración;   1310 de 4841, Loss: 0.5084356307983399\n",
            "Epoch: 0, iteración;   1320 de 4841, Loss: 0.5062827587127685\n",
            "Epoch: 0, iteración;   1330 de 4841, Loss: 0.6057480812072754\n",
            "Epoch: 0, iteración;   1340 de 4841, Loss: 0.5591836929321289\n",
            "Epoch: 0, iteración;   1350 de 4841, Loss: 0.46317324638366697\n",
            "Epoch: 0, iteración;   1360 de 4841, Loss: 0.49886322021484375\n",
            "Epoch: 0, iteración;   1370 de 4841, Loss: 0.5040196895599365\n",
            "Epoch: 0, iteración;   1380 de 4841, Loss: 0.5827739715576172\n",
            "Epoch: 0, iteración;   1390 de 4841, Loss: 0.46601428985595705\n",
            "Epoch: 0, iteración;   1400 de 4841, Loss: 0.5412535667419434\n",
            "Epoch: 0, iteración;   1410 de 4841, Loss: 0.5780381202697754\n",
            "Epoch: 0, iteración;   1420 de 4841, Loss: 0.5414849758148194\n",
            "Epoch: 0, iteración;   1430 de 4841, Loss: 0.44644722938537595\n",
            "Epoch: 0, iteración;   1440 de 4841, Loss: 0.5951055526733399\n",
            "Epoch: 0, iteración;   1450 de 4841, Loss: 0.5536427021026611\n",
            "Epoch: 0, iteración;   1460 de 4841, Loss: 0.5672667503356934\n",
            "Epoch: 0, iteración;   1470 de 4841, Loss: 0.5803245544433594\n",
            "Epoch: 0, iteración;   1480 de 4841, Loss: 0.56451416015625\n",
            "Epoch: 0, iteración;   1490 de 4841, Loss: 0.5237836837768555\n",
            "Epoch: 0, iteración;   1500 de 4841, Loss: 0.46534037590026855\n",
            "Epoch: 0, iteración;   1510 de 4841, Loss: 0.6134925842285156\n",
            "Epoch: 0, iteración;   1520 de 4841, Loss: 0.5227019309997558\n",
            "Epoch: 0, iteración;   1530 de 4841, Loss: 0.552614402770996\n",
            "Epoch: 0, iteración;   1540 de 4841, Loss: 0.5117040634155273\n",
            "Epoch: 0, iteración;   1550 de 4841, Loss: 0.5916239738464355\n",
            "Epoch: 0, iteración;   1560 de 4841, Loss: 0.4900151252746582\n",
            "Epoch: 0, iteración;   1570 de 4841, Loss: 0.5008128166198731\n",
            "Epoch: 0, iteración;   1580 de 4841, Loss: 0.48946633338928225\n",
            "Epoch: 0, iteración;   1590 de 4841, Loss: 0.4921877384185791\n",
            "Epoch: 0, iteración;   1600 de 4841, Loss: 0.5129448413848877\n",
            "Epoch: 0, iteración;   1610 de 4841, Loss: 0.5816380977630615\n",
            "Epoch: 0, iteración;   1620 de 4841, Loss: 0.5421219348907471\n",
            "Epoch: 0, iteración;   1630 de 4841, Loss: 0.5281688690185546\n",
            "Epoch: 0, iteración;   1640 de 4841, Loss: 0.4471557140350342\n",
            "Epoch: 0, iteración;   1650 de 4841, Loss: 0.40268640518188475\n",
            "Epoch: 0, iteración;   1660 de 4841, Loss: 0.4890486240386963\n",
            "Epoch: 0, iteración;   1670 de 4841, Loss: 0.5219810485839844\n",
            "Epoch: 0, iteración;   1680 de 4841, Loss: 0.3902677059173584\n",
            "Epoch: 0, iteración;   1690 de 4841, Loss: 0.41930475234985354\n",
            "Epoch: 0, iteración;   1700 de 4841, Loss: 0.5924801349639892\n",
            "Epoch: 0, iteración;   1710 de 4841, Loss: 0.4836221218109131\n",
            "Epoch: 0, iteración;   1720 de 4841, Loss: 0.5796812057495118\n",
            "Epoch: 0, iteración;   1730 de 4841, Loss: 0.5263258457183838\n",
            "Epoch: 0, iteración;   1740 de 4841, Loss: 0.6408470630645752\n",
            "Epoch: 0, iteración;   1750 de 4841, Loss: 0.5368001937866211\n",
            "Epoch: 0, iteración;   1760 de 4841, Loss: 0.5156590938568115\n",
            "Epoch: 0, iteración;   1770 de 4841, Loss: 0.4646193504333496\n",
            "Epoch: 0, iteración;   1780 de 4841, Loss: 0.4854270935058594\n",
            "Epoch: 0, iteración;   1790 de 4841, Loss: 0.4907670974731445\n",
            "Epoch: 0, iteración;   1800 de 4841, Loss: 0.4718714714050293\n",
            "Epoch: 0, iteración;   1810 de 4841, Loss: 0.5850025177001953\n",
            "Epoch: 0, iteración;   1820 de 4841, Loss: 0.6058730125427246\n",
            "Epoch: 0, iteración;   1830 de 4841, Loss: 0.5196033954620362\n",
            "Epoch: 0, iteración;   1840 de 4841, Loss: 0.5321052074432373\n",
            "Epoch: 0, iteración;   1850 de 4841, Loss: 0.5026691913604736\n",
            "Epoch: 0, iteración;   1860 de 4841, Loss: 0.5043747425079346\n",
            "Epoch: 0, iteración;   1870 de 4841, Loss: 0.5554111480712891\n",
            "Epoch: 0, iteración;   1880 de 4841, Loss: 0.4382274627685547\n",
            "Epoch: 0, iteración;   1890 de 4841, Loss: 0.5536291122436523\n",
            "Epoch: 0, iteración;   1900 de 4841, Loss: 0.5025047779083252\n",
            "Epoch: 0, iteración;   1910 de 4841, Loss: 0.5256060600280762\n",
            "Epoch: 0, iteración;   1920 de 4841, Loss: 0.5498865604400635\n",
            "Epoch: 0, iteración;   1930 de 4841, Loss: 0.47441930770874025\n",
            "Epoch: 0, iteración;   1940 de 4841, Loss: 0.5439795017242431\n",
            "Epoch: 0, iteración;   1950 de 4841, Loss: 0.5251220703125\n",
            "Epoch: 0, iteración;   1960 de 4841, Loss: 0.5021398544311524\n",
            "Epoch: 0, iteración;   1970 de 4841, Loss: 0.51907320022583\n",
            "Epoch: 0, iteración;   1980 de 4841, Loss: 0.4947244167327881\n",
            "Epoch: 0, iteración;   1990 de 4841, Loss: 0.5058303356170655\n",
            "Epoch: 0, iteración;   2000 de 4841, Loss: 0.5366244316101074\n",
            "Epoch: 0, iteración;   2010 de 4841, Loss: 0.5031853199005127\n",
            "Epoch: 0, iteración;   2020 de 4841, Loss: 0.4931803703308105\n",
            "Epoch: 0, iteración;   2030 de 4841, Loss: 0.5034046649932862\n",
            "Epoch: 0, iteración;   2040 de 4841, Loss: 0.47933025360107423\n",
            "Epoch: 0, iteración;   2050 de 4841, Loss: 0.520108413696289\n",
            "Epoch: 0, iteración;   2060 de 4841, Loss: 0.5379586696624756\n",
            "Epoch: 0, iteración;   2070 de 4841, Loss: 0.533269739151001\n",
            "Epoch: 0, iteración;   2080 de 4841, Loss: 0.5248448371887207\n",
            "Epoch: 0, iteración;   2090 de 4841, Loss: 0.5272344589233399\n",
            "Epoch: 0, iteración;   2100 de 4841, Loss: 0.45502004623413084\n",
            "Epoch: 0, iteración;   2110 de 4841, Loss: 0.4995689392089844\n",
            "Epoch: 0, iteración;   2120 de 4841, Loss: 0.49879989624023435\n",
            "Epoch: 0, iteración;   2130 de 4841, Loss: 0.5671498298645019\n",
            "Epoch: 0, iteración;   2140 de 4841, Loss: 0.6091177940368653\n",
            "Epoch: 0, iteración;   2150 de 4841, Loss: 0.5037737846374511\n",
            "Epoch: 0, iteración;   2160 de 4841, Loss: 0.5725156307220459\n",
            "Epoch: 0, iteración;   2170 de 4841, Loss: 0.4194685935974121\n",
            "Epoch: 0, iteración;   2180 de 4841, Loss: 0.5042447090148926\n",
            "Epoch: 0, iteración;   2190 de 4841, Loss: 0.4672394752502441\n",
            "Epoch: 0, iteración;   2200 de 4841, Loss: 0.5524363040924072\n",
            "Epoch: 0, iteración;   2210 de 4841, Loss: 0.478786563873291\n",
            "Epoch: 0, iteración;   2220 de 4841, Loss: 0.5444733142852783\n",
            "Epoch: 0, iteración;   2230 de 4841, Loss: 0.5623940467834473\n",
            "Epoch: 0, iteración;   2240 de 4841, Loss: 0.4778815746307373\n",
            "Epoch: 0, iteración;   2250 de 4841, Loss: 0.5857088088989257\n",
            "Epoch: 0, iteración;   2260 de 4841, Loss: 0.482270336151123\n",
            "Epoch: 0, iteración;   2270 de 4841, Loss: 0.4649941921234131\n",
            "Epoch: 0, iteración;   2280 de 4841, Loss: 0.45383291244506835\n",
            "Epoch: 0, iteración;   2290 de 4841, Loss: 0.5260015487670898\n",
            "Epoch: 0, iteración;   2300 de 4841, Loss: 0.523134422302246\n",
            "Epoch: 0, iteración;   2310 de 4841, Loss: 0.5466810703277588\n",
            "Epoch: 0, iteración;   2320 de 4841, Loss: 0.47441649436950684\n",
            "Epoch: 0, iteración;   2330 de 4841, Loss: 0.5319408416748047\n",
            "Epoch: 0, iteración;   2340 de 4841, Loss: 0.5491230010986328\n",
            "Epoch: 0, iteración;   2350 de 4841, Loss: 0.4652519702911377\n",
            "Epoch: 0, iteración;   2360 de 4841, Loss: 0.5577141761779785\n",
            "Epoch: 0, iteración;   2370 de 4841, Loss: 0.47420344352722166\n",
            "Epoch: 0, iteración;   2380 de 4841, Loss: 0.5213930130004882\n",
            "Epoch: 0, iteración;   2390 de 4841, Loss: 0.48351202011108396\n",
            "Epoch: 0, iteración;   2400 de 4841, Loss: 0.4746049404144287\n",
            "Epoch: 0, iteración;   2410 de 4841, Loss: 0.47087559700012205\n",
            "Epoch: 0, iteración;   2420 de 4841, Loss: 0.36594333648681643\n",
            "Epoch: 0, iteración;   2430 de 4841, Loss: 0.6271459102630615\n",
            "Epoch: 0, iteración;   2440 de 4841, Loss: 0.6154226303100586\n",
            "Epoch: 0, iteración;   2450 de 4841, Loss: 0.6320206642150878\n",
            "Epoch: 0, iteración;   2460 de 4841, Loss: 0.5139538764953613\n",
            "Epoch: 0, iteración;   2470 de 4841, Loss: 0.5186805725097656\n",
            "Epoch: 0, iteración;   2480 de 4841, Loss: 0.48131427764892576\n",
            "Epoch: 0, iteración;   2490 de 4841, Loss: 0.48056755065917967\n",
            "Epoch: 0, iteración;   2500 de 4841, Loss: 0.6369248390197754\n",
            "Epoch: 0, iteración;   2510 de 4841, Loss: 0.48472042083740235\n",
            "Epoch: 0, iteración;   2520 de 4841, Loss: 0.4848517417907715\n",
            "Epoch: 0, iteración;   2530 de 4841, Loss: 0.42592105865478513\n",
            "Epoch: 0, iteración;   2540 de 4841, Loss: 0.6155405044555664\n",
            "Epoch: 0, iteración;   2550 de 4841, Loss: 0.5532735824584961\n",
            "Epoch: 0, iteración;   2560 de 4841, Loss: 0.5329781532287597\n",
            "Epoch: 0, iteración;   2570 de 4841, Loss: 0.4798872947692871\n",
            "Epoch: 0, iteración;   2580 de 4841, Loss: 0.48711504936218264\n",
            "Epoch: 0, iteración;   2590 de 4841, Loss: 0.5553785800933838\n",
            "Epoch: 0, iteración;   2600 de 4841, Loss: 0.6058351039886475\n",
            "Epoch: 0, iteración;   2610 de 4841, Loss: 0.5041136741638184\n",
            "Epoch: 0, iteración;   2620 de 4841, Loss: 0.4490915298461914\n",
            "Epoch: 0, iteración;   2630 de 4841, Loss: 0.5036312103271484\n",
            "Epoch: 0, iteración;   2640 de 4841, Loss: 0.5028119087219238\n",
            "Epoch: 0, iteración;   2650 de 4841, Loss: 0.4869367599487305\n",
            "Epoch: 0, iteración;   2660 de 4841, Loss: 0.5736952781677246\n",
            "Epoch: 0, iteración;   2670 de 4841, Loss: 0.49752440452575686\n",
            "Epoch: 0, iteración;   2680 de 4841, Loss: 0.5352514266967774\n",
            "Epoch: 0, iteración;   2690 de 4841, Loss: 0.5146747589111328\n",
            "Epoch: 0, iteración;   2700 de 4841, Loss: 0.49974961280822755\n",
            "Epoch: 0, iteración;   2710 de 4841, Loss: 0.46123218536376953\n",
            "Epoch: 0, iteración;   2720 de 4841, Loss: 0.49145984649658203\n",
            "Epoch: 0, iteración;   2730 de 4841, Loss: 0.5531715869903564\n",
            "Epoch: 0, iteración;   2740 de 4841, Loss: 0.5286221027374267\n",
            "Epoch: 0, iteración;   2750 de 4841, Loss: 0.472005558013916\n",
            "Epoch: 0, iteración;   2760 de 4841, Loss: 0.6141889572143555\n",
            "Epoch: 0, iteración;   2770 de 4841, Loss: 0.4536187171936035\n",
            "Epoch: 0, iteración;   2780 de 4841, Loss: 0.37911243438720704\n",
            "Epoch: 0, iteración;   2790 de 4841, Loss: 0.41960740089416504\n",
            "Epoch: 0, iteración;   2800 de 4841, Loss: 0.6483264446258545\n",
            "Epoch: 0, iteración;   2810 de 4841, Loss: 0.44889678955078127\n",
            "Epoch: 0, iteración;   2820 de 4841, Loss: 0.5087194442749023\n",
            "Epoch: 0, iteración;   2830 de 4841, Loss: 0.49747323989868164\n",
            "Epoch: 0, iteración;   2840 de 4841, Loss: 0.4871941089630127\n",
            "Epoch: 0, iteración;   2850 de 4841, Loss: 0.5696530342102051\n",
            "Epoch: 0, iteración;   2860 de 4841, Loss: 0.45970783233642576\n",
            "Epoch: 0, iteración;   2870 de 4841, Loss: 0.5924076080322266\n",
            "Epoch: 0, iteración;   2880 de 4841, Loss: 0.560642147064209\n",
            "Epoch: 0, iteración;   2890 de 4841, Loss: 0.5540731906890869\n",
            "Epoch: 0, iteración;   2900 de 4841, Loss: 0.6256640911102295\n",
            "Epoch: 0, iteración;   2910 de 4841, Loss: 0.5544791221618652\n",
            "Epoch: 0, iteración;   2920 de 4841, Loss: 0.5082909107208252\n",
            "Epoch: 0, iteración;   2930 de 4841, Loss: 0.540633249282837\n",
            "Epoch: 0, iteración;   2940 de 4841, Loss: 0.48052515983581545\n",
            "Epoch: 0, iteración;   2950 de 4841, Loss: 0.538690710067749\n",
            "Epoch: 0, iteración;   2960 de 4841, Loss: 0.44968390464782715\n",
            "Epoch: 0, iteración;   2970 de 4841, Loss: 0.4934981346130371\n",
            "Epoch: 0, iteración;   2980 de 4841, Loss: 0.5547124862670898\n",
            "Epoch: 0, iteración;   2990 de 4841, Loss: 0.5173673629760742\n",
            "Epoch: 0, iteración;   3000 de 4841, Loss: 0.4625981330871582\n",
            "Epoch: 0, iteración;   3010 de 4841, Loss: 0.5898256778717041\n",
            "Epoch: 0, iteración;   3020 de 4841, Loss: 0.4590324878692627\n",
            "Epoch: 0, iteración;   3030 de 4841, Loss: 0.5303123950958252\n",
            "Epoch: 0, iteración;   3040 de 4841, Loss: 0.4434354782104492\n",
            "Epoch: 0, iteración;   3050 de 4841, Loss: 0.529693603515625\n",
            "Epoch: 0, iteración;   3060 de 4841, Loss: 0.5286443710327149\n",
            "Epoch: 0, iteración;   3070 de 4841, Loss: 0.5334603786468506\n",
            "Epoch: 0, iteración;   3080 de 4841, Loss: 0.6046286582946777\n",
            "Epoch: 0, iteración;   3090 de 4841, Loss: 0.40694708824157716\n",
            "Epoch: 0, iteración;   3100 de 4841, Loss: 0.5077407360076904\n",
            "Epoch: 0, iteración;   3110 de 4841, Loss: 0.5814267158508301\n",
            "Epoch: 0, iteración;   3120 de 4841, Loss: 0.5604620933532715\n",
            "Epoch: 0, iteración;   3130 de 4841, Loss: 0.42938804626464844\n",
            "Epoch: 0, iteración;   3140 de 4841, Loss: 0.5990504264831543\n",
            "Epoch: 0, iteración;   3150 de 4841, Loss: 0.4637748718261719\n",
            "Epoch: 0, iteración;   3160 de 4841, Loss: 0.5088580131530762\n",
            "Epoch: 0, iteración;   3170 de 4841, Loss: 0.5171665191650391\n",
            "Epoch: 0, iteración;   3180 de 4841, Loss: 0.4495443820953369\n",
            "Epoch: 0, iteración;   3190 de 4841, Loss: 0.5507388114929199\n",
            "Epoch: 0, iteración;   3200 de 4841, Loss: 0.5332341670989991\n",
            "Epoch: 0, iteración;   3210 de 4841, Loss: 0.5115398406982422\n",
            "Epoch: 0, iteración;   3220 de 4841, Loss: 0.5099455833435058\n",
            "Epoch: 0, iteración;   3230 de 4841, Loss: 0.48328819274902346\n",
            "Epoch: 0, iteración;   3240 de 4841, Loss: 0.5812222480773925\n",
            "Epoch: 0, iteración;   3250 de 4841, Loss: 0.48961515426635743\n",
            "Epoch: 0, iteración;   3260 de 4841, Loss: 0.560850715637207\n",
            "Epoch: 0, iteración;   3270 de 4841, Loss: 0.4848941802978516\n",
            "Epoch: 0, iteración;   3280 de 4841, Loss: 0.5321893692016602\n",
            "Epoch: 0, iteración;   3290 de 4841, Loss: 0.5273810863494873\n",
            "Epoch: 0, iteración;   3300 de 4841, Loss: 0.4985476493835449\n",
            "Epoch: 0, iteración;   3310 de 4841, Loss: 0.44227824211120603\n",
            "Epoch: 0, iteración;   3320 de 4841, Loss: 0.5128547191619873\n",
            "Epoch: 0, iteración;   3330 de 4841, Loss: 0.4440929412841797\n",
            "Epoch: 0, iteración;   3340 de 4841, Loss: 0.4589231491088867\n",
            "Epoch: 0, iteración;   3350 de 4841, Loss: 0.5763191223144531\n",
            "Epoch: 0, iteración;   3360 de 4841, Loss: 0.47682619094848633\n",
            "Epoch: 0, iteración;   3370 de 4841, Loss: 0.5462065219879151\n",
            "Epoch: 0, iteración;   3380 de 4841, Loss: 0.5180390357971192\n",
            "Epoch: 0, iteración;   3390 de 4841, Loss: 0.4582991123199463\n",
            "Epoch: 0, iteración;   3400 de 4841, Loss: 0.536736011505127\n",
            "Epoch: 0, iteración;   3410 de 4841, Loss: 0.4550317287445068\n",
            "Epoch: 0, iteración;   3420 de 4841, Loss: 0.3885010242462158\n",
            "Epoch: 0, iteración;   3430 de 4841, Loss: 0.4521807670593262\n",
            "Epoch: 0, iteración;   3440 de 4841, Loss: 0.5975332260131836\n",
            "Epoch: 0, iteración;   3450 de 4841, Loss: 0.5104993343353271\n",
            "Epoch: 0, iteración;   3460 de 4841, Loss: 0.4130237579345703\n",
            "Epoch: 0, iteración;   3470 de 4841, Loss: 0.524223804473877\n",
            "Epoch: 0, iteración;   3480 de 4841, Loss: 0.5028075695037841\n",
            "Epoch: 0, iteración;   3490 de 4841, Loss: 0.6081377983093261\n",
            "Epoch: 0, iteración;   3500 de 4841, Loss: 0.5517526149749756\n",
            "Epoch: 0, iteración;   3510 de 4841, Loss: 0.4611047744750977\n",
            "Epoch: 0, iteración;   3520 de 4841, Loss: 0.5658047199249268\n",
            "Epoch: 0, iteración;   3530 de 4841, Loss: 0.4557043075561523\n",
            "Epoch: 0, iteración;   3540 de 4841, Loss: 0.5588209152221679\n",
            "Epoch: 0, iteración;   3550 de 4841, Loss: 0.47346343994140627\n",
            "Epoch: 0, iteración;   3560 de 4841, Loss: 0.5660140991210938\n",
            "Epoch: 0, iteración;   3570 de 4841, Loss: 0.4817052364349365\n",
            "Epoch: 0, iteración;   3580 de 4841, Loss: 0.5067373275756836\n",
            "Epoch: 0, iteración;   3590 de 4841, Loss: 0.45511713027954104\n",
            "Epoch: 0, iteración;   3600 de 4841, Loss: 0.5026046752929687\n",
            "Epoch: 0, iteración;   3610 de 4841, Loss: 0.44602327346801757\n",
            "Epoch: 0, iteración;   3620 de 4841, Loss: 0.36887321472167967\n",
            "Epoch: 0, iteración;   3630 de 4841, Loss: 0.5983857154846192\n",
            "Epoch: 0, iteración;   3640 de 4841, Loss: 0.48140363693237304\n",
            "Epoch: 0, iteración;   3650 de 4841, Loss: 0.4981218338012695\n",
            "Epoch: 0, iteración;   3660 de 4841, Loss: 0.4636483669281006\n",
            "Epoch: 0, iteración;   3670 de 4841, Loss: 0.5588675498962402\n",
            "Epoch: 0, iteración;   3680 de 4841, Loss: 0.35870611667633057\n",
            "Epoch: 0, iteración;   3690 de 4841, Loss: 0.47606582641601564\n",
            "Epoch: 0, iteración;   3700 de 4841, Loss: 0.5970879077911377\n",
            "Epoch: 0, iteración;   3710 de 4841, Loss: 0.5121690273284912\n",
            "Epoch: 0, iteración;   3720 de 4841, Loss: 0.5271536827087402\n",
            "Epoch: 0, iteración;   3730 de 4841, Loss: 0.6722286224365235\n",
            "Epoch: 0, iteración;   3740 de 4841, Loss: 0.5418827533721924\n",
            "Epoch: 0, iteración;   3750 de 4841, Loss: 0.6149338245391845\n",
            "Epoch: 0, iteración;   3760 de 4841, Loss: 0.35573978424072267\n",
            "Epoch: 0, iteración;   3770 de 4841, Loss: 0.46648297309875486\n",
            "Epoch: 0, iteración;   3780 de 4841, Loss: 0.502254581451416\n",
            "Epoch: 0, iteración;   3790 de 4841, Loss: 0.4941847801208496\n",
            "Epoch: 0, iteración;   3800 de 4841, Loss: 0.522715950012207\n",
            "Epoch: 0, iteración;   3810 de 4841, Loss: 0.5429515838623047\n",
            "Epoch: 0, iteración;   3820 de 4841, Loss: 0.43469867706298826\n",
            "Epoch: 0, iteración;   3830 de 4841, Loss: 0.4992256164550781\n",
            "Epoch: 0, iteración;   3840 de 4841, Loss: 0.3980658292770386\n",
            "Epoch: 0, iteración;   3850 de 4841, Loss: 0.5603465080261231\n",
            "Epoch: 0, iteración;   3860 de 4841, Loss: 0.5071851730346679\n",
            "Epoch: 0, iteración;   3870 de 4841, Loss: 0.5488404750823974\n",
            "Epoch: 0, iteración;   3880 de 4841, Loss: 0.5387999534606933\n",
            "Epoch: 0, iteración;   3890 de 4841, Loss: 0.5430981636047363\n",
            "Epoch: 0, iteración;   3900 de 4841, Loss: 0.47652425765991213\n",
            "Epoch: 0, iteración;   3910 de 4841, Loss: 0.5062978744506836\n",
            "Epoch: 0, iteración;   3920 de 4841, Loss: 0.47643752098083497\n",
            "Epoch: 0, iteración;   3930 de 4841, Loss: 0.49668178558349607\n",
            "Epoch: 0, iteración;   3940 de 4841, Loss: 0.4140183925628662\n",
            "Epoch: 0, iteración;   3950 de 4841, Loss: 0.53555908203125\n",
            "Epoch: 0, iteración;   3960 de 4841, Loss: 0.5802999973297119\n",
            "Epoch: 0, iteración;   3970 de 4841, Loss: 0.5725040435791016\n",
            "Epoch: 0, iteración;   3980 de 4841, Loss: 0.55882568359375\n",
            "Epoch: 0, iteración;   3990 de 4841, Loss: 0.4359935760498047\n",
            "Epoch: 0, iteración;   4000 de 4841, Loss: 0.48768272399902346\n",
            "Epoch: 0, iteración;   4010 de 4841, Loss: 0.5690852642059326\n",
            "Epoch: 0, iteración;   4020 de 4841, Loss: 0.5781705856323243\n",
            "Epoch: 0, iteración;   4030 de 4841, Loss: 0.5528031349182129\n",
            "Epoch: 0, iteración;   4040 de 4841, Loss: 0.4422883987426758\n",
            "Epoch: 0, iteración;   4050 de 4841, Loss: 0.46292963027954104\n",
            "Epoch: 0, iteración;   4060 de 4841, Loss: 0.5864992141723633\n",
            "Epoch: 0, iteración;   4070 de 4841, Loss: 0.5893960952758789\n",
            "Epoch: 0, iteración;   4080 de 4841, Loss: 0.5107083797454834\n",
            "Epoch: 0, iteración;   4090 de 4841, Loss: 0.45899667739868166\n",
            "Epoch: 0, iteración;   4100 de 4841, Loss: 0.5758914947509766\n",
            "Epoch: 0, iteración;   4110 de 4841, Loss: 0.5519098281860352\n",
            "Epoch: 0, iteración;   4120 de 4841, Loss: 0.3737258195877075\n",
            "Epoch: 0, iteración;   4130 de 4841, Loss: 0.5623634338378907\n",
            "Epoch: 0, iteración;   4140 de 4841, Loss: 0.5106569290161133\n",
            "Epoch: 0, iteración;   4150 de 4841, Loss: 0.5987041473388672\n",
            "Epoch: 0, iteración;   4160 de 4841, Loss: 0.4676237106323242\n",
            "Epoch: 0, iteración;   4170 de 4841, Loss: 0.49077301025390624\n",
            "Epoch: 0, iteración;   4180 de 4841, Loss: 0.5444884300231934\n",
            "Epoch: 0, iteración;   4190 de 4841, Loss: 0.5246736526489257\n",
            "Epoch: 0, iteración;   4200 de 4841, Loss: 0.6181424617767334\n",
            "Epoch: 0, iteración;   4210 de 4841, Loss: 0.5535847187042237\n",
            "Epoch: 0, iteración;   4220 de 4841, Loss: 0.4873387336730957\n",
            "Epoch: 0, iteración;   4230 de 4841, Loss: 0.49962239265441893\n",
            "Epoch: 0, iteración;   4240 de 4841, Loss: 0.5323610782623291\n",
            "Epoch: 0, iteración;   4250 de 4841, Loss: 0.472580623626709\n",
            "Epoch: 0, iteración;   4260 de 4841, Loss: 0.40204696655273436\n",
            "Epoch: 0, iteración;   4270 de 4841, Loss: 0.46253294944763185\n",
            "Epoch: 0, iteración;   4280 de 4841, Loss: 0.6396516323089599\n",
            "Epoch: 0, iteración;   4290 de 4841, Loss: 0.4388916015625\n",
            "Epoch: 0, iteración;   4300 de 4841, Loss: 0.4310065746307373\n",
            "Epoch: 0, iteración;   4310 de 4841, Loss: 0.6398262500762939\n",
            "Epoch: 0, iteración;   4320 de 4841, Loss: 0.568348503112793\n",
            "Epoch: 0, iteración;   4330 de 4841, Loss: 0.5562798500061035\n",
            "Epoch: 0, iteración;   4340 de 4841, Loss: 0.5280468463897705\n",
            "Epoch: 0, iteración;   4350 de 4841, Loss: 0.47941083908081056\n",
            "Epoch: 0, iteración;   4360 de 4841, Loss: 0.5352866649627686\n",
            "Epoch: 0, iteración;   4370 de 4841, Loss: 0.5212924957275391\n",
            "Epoch: 0, iteración;   4380 de 4841, Loss: 0.5462267398834229\n",
            "Epoch: 0, iteración;   4390 de 4841, Loss: 0.45763602256774905\n",
            "Epoch: 0, iteración;   4400 de 4841, Loss: 0.5251797199249267\n",
            "Epoch: 0, iteración;   4410 de 4841, Loss: 0.5267980575561524\n",
            "Epoch: 0, iteración;   4420 de 4841, Loss: 0.4673642635345459\n",
            "Epoch: 0, iteración;   4430 de 4841, Loss: 0.5545721054077148\n",
            "Epoch: 0, iteración;   4440 de 4841, Loss: 0.6492340564727783\n",
            "Epoch: 0, iteración;   4450 de 4841, Loss: 0.5391041755676269\n",
            "Epoch: 0, iteración;   4460 de 4841, Loss: 0.5217620849609375\n",
            "Epoch: 0, iteración;   4470 de 4841, Loss: 0.5339578628540039\n",
            "Epoch: 0, iteración;   4480 de 4841, Loss: 0.635676097869873\n",
            "Epoch: 0, iteración;   4490 de 4841, Loss: 0.5515021800994873\n",
            "Epoch: 0, iteración;   4500 de 4841, Loss: 0.5341884136199951\n",
            "Epoch: 0, iteración;   4510 de 4841, Loss: 0.584046459197998\n",
            "Epoch: 0, iteración;   4520 de 4841, Loss: 0.5094285488128663\n",
            "Epoch: 0, iteración;   4530 de 4841, Loss: 0.6015946865081787\n",
            "Epoch: 0, iteración;   4540 de 4841, Loss: 0.5568852424621582\n",
            "Epoch: 0, iteración;   4550 de 4841, Loss: 0.5733438491821289\n",
            "Epoch: 0, iteración;   4560 de 4841, Loss: 0.474229621887207\n",
            "Epoch: 0, iteración;   4570 de 4841, Loss: 0.516165828704834\n",
            "Epoch: 0, iteración;   4580 de 4841, Loss: 0.5552096366882324\n",
            "Epoch: 0, iteración;   4590 de 4841, Loss: 0.43927836418151855\n",
            "Epoch: 0, iteración;   4600 de 4841, Loss: 0.5632494926452637\n",
            "Epoch: 0, iteración;   4610 de 4841, Loss: 0.44226608276367185\n",
            "Epoch: 0, iteración;   4620 de 4841, Loss: 0.5485270500183106\n",
            "Epoch: 0, iteración;   4630 de 4841, Loss: 0.48406076431274414\n",
            "Epoch: 0, iteración;   4640 de 4841, Loss: 0.47563767433166504\n",
            "Epoch: 0, iteración;   4650 de 4841, Loss: 0.6395057201385498\n",
            "Epoch: 0, iteración;   4660 de 4841, Loss: 0.4884284496307373\n",
            "Epoch: 0, iteración;   4670 de 4841, Loss: 0.46572151184082033\n",
            "Epoch: 0, iteración;   4680 de 4841, Loss: 0.5641854763031006\n",
            "Epoch: 0, iteración;   4690 de 4841, Loss: 0.5115007400512696\n",
            "Epoch: 0, iteración;   4700 de 4841, Loss: 0.5293826103210449\n",
            "Epoch: 0, iteración;   4710 de 4841, Loss: 0.6213300704956055\n",
            "Epoch: 0, iteración;   4720 de 4841, Loss: 0.5903090000152588\n",
            "Epoch: 0, iteración;   4730 de 4841, Loss: 0.561713981628418\n",
            "Epoch: 0, iteración;   4740 de 4841, Loss: 0.550281572341919\n",
            "Epoch: 0, iteración;   4750 de 4841, Loss: 0.5510732650756835\n",
            "Epoch: 0, iteración;   4760 de 4841, Loss: 0.5892329216003418\n",
            "Epoch: 0, iteración;   4770 de 4841, Loss: 0.5248397350311279\n",
            "Epoch: 0, iteración;   4780 de 4841, Loss: 0.6190890312194824\n",
            "Epoch: 0, iteración;   4790 de 4841, Loss: 0.45404949188232424\n",
            "Epoch: 0, iteración;   4800 de 4841, Loss: 0.535916519165039\n",
            "Epoch: 0, iteración;   4810 de 4841, Loss: 0.46120271682739256\n",
            "Epoch: 0, iteración;   4820 de 4841, Loss: 0.5598329544067383\n",
            "Epoch: 0, iteración;   4830 de 4841, Loss: 0.5061042785644532\n",
            "Epoch: 0, iteración;   4840 de 4841, Loss: 0.4662198543548584\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainRoberta(epoch)"
      ],
      "id": "KTpV94vti-Jy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwpOQ7O1i-Jy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ff472d-fbf9-41c3-c0ff-9c6cab9d9f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_50.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "id": "VwpOQ7O1i-Jy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAdJhxHcjLc8"
      },
      "source": [
        "##### Evaluación del modelo"
      ],
      "id": "aAdJhxHcjLc8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv5Y0SmqjLdB"
      },
      "outputs": [],
      "source": [
        "def validationRoberta(epoch):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    num_iteraciones = len(testing_loader)\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device)\n",
        "            mask = data['mask'].to(device)\n",
        "            token_type_ids = data['token_type_ids'].to(device)\n",
        "            targets = data['target'].to(device)\n",
        "\n",
        "            print(f\"Iteración: {i:6} de {num_iteraciones}\")\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "id": "tv5Y0SmqjLdB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "hHgiO8ubjLdB"
      },
      "id": "hHgiO8ubjLdB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkxMsu31jLdB"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_50.pth\"):\n",
        "  model = RobertaClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_50.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_50.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "id": "FkxMsu31jLdB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61fdb123-e702-4dd7-fcab-42d20d23e37b",
        "id": "97u7oW6ejLdC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración:      0 de 606\n",
            "Iteración:      1 de 606\n",
            "Iteración:      2 de 606\n",
            "Iteración:      3 de 606\n",
            "Iteración:      4 de 606\n",
            "Iteración:      5 de 606\n",
            "Iteración:      6 de 606\n",
            "Iteración:      7 de 606\n",
            "Iteración:      8 de 606\n",
            "Iteración:      9 de 606\n",
            "Iteración:     10 de 606\n",
            "Iteración:     11 de 606\n",
            "Iteración:     12 de 606\n",
            "Iteración:     13 de 606\n",
            "Iteración:     14 de 606\n",
            "Iteración:     15 de 606\n",
            "Iteración:     16 de 606\n",
            "Iteración:     17 de 606\n",
            "Iteración:     18 de 606\n",
            "Iteración:     19 de 606\n",
            "Iteración:     20 de 606\n",
            "Iteración:     21 de 606\n",
            "Iteración:     22 de 606\n",
            "Iteración:     23 de 606\n",
            "Iteración:     24 de 606\n",
            "Iteración:     25 de 606\n",
            "Iteración:     26 de 606\n",
            "Iteración:     27 de 606\n",
            "Iteración:     28 de 606\n",
            "Iteración:     29 de 606\n",
            "Iteración:     30 de 606\n",
            "Iteración:     31 de 606\n",
            "Iteración:     32 de 606\n",
            "Iteración:     33 de 606\n",
            "Iteración:     34 de 606\n",
            "Iteración:     35 de 606\n",
            "Iteración:     36 de 606\n",
            "Iteración:     37 de 606\n",
            "Iteración:     38 de 606\n",
            "Iteración:     39 de 606\n",
            "Iteración:     40 de 606\n",
            "Iteración:     41 de 606\n",
            "Iteración:     42 de 606\n",
            "Iteración:     43 de 606\n",
            "Iteración:     44 de 606\n",
            "Iteración:     45 de 606\n",
            "Iteración:     46 de 606\n",
            "Iteración:     47 de 606\n",
            "Iteración:     48 de 606\n",
            "Iteración:     49 de 606\n",
            "Iteración:     50 de 606\n",
            "Iteración:     51 de 606\n",
            "Iteración:     52 de 606\n",
            "Iteración:     53 de 606\n",
            "Iteración:     54 de 606\n",
            "Iteración:     55 de 606\n",
            "Iteración:     56 de 606\n",
            "Iteración:     57 de 606\n",
            "Iteración:     58 de 606\n",
            "Iteración:     59 de 606\n",
            "Iteración:     60 de 606\n",
            "Iteración:     61 de 606\n",
            "Iteración:     62 de 606\n",
            "Iteración:     63 de 606\n",
            "Iteración:     64 de 606\n",
            "Iteración:     65 de 606\n",
            "Iteración:     66 de 606\n",
            "Iteración:     67 de 606\n",
            "Iteración:     68 de 606\n",
            "Iteración:     69 de 606\n",
            "Iteración:     70 de 606\n",
            "Iteración:     71 de 606\n",
            "Iteración:     72 de 606\n",
            "Iteración:     73 de 606\n",
            "Iteración:     74 de 606\n",
            "Iteración:     75 de 606\n",
            "Iteración:     76 de 606\n",
            "Iteración:     77 de 606\n",
            "Iteración:     78 de 606\n",
            "Iteración:     79 de 606\n",
            "Iteración:     80 de 606\n",
            "Iteración:     81 de 606\n",
            "Iteración:     82 de 606\n",
            "Iteración:     83 de 606\n",
            "Iteración:     84 de 606\n",
            "Iteración:     85 de 606\n",
            "Iteración:     86 de 606\n",
            "Iteración:     87 de 606\n",
            "Iteración:     88 de 606\n",
            "Iteración:     89 de 606\n",
            "Iteración:     90 de 606\n",
            "Iteración:     91 de 606\n",
            "Iteración:     92 de 606\n",
            "Iteración:     93 de 606\n",
            "Iteración:     94 de 606\n",
            "Iteración:     95 de 606\n",
            "Iteración:     96 de 606\n",
            "Iteración:     97 de 606\n",
            "Iteración:     98 de 606\n",
            "Iteración:     99 de 606\n",
            "Iteración:    100 de 606\n",
            "Iteración:    101 de 606\n",
            "Iteración:    102 de 606\n",
            "Iteración:    103 de 606\n",
            "Iteración:    104 de 606\n",
            "Iteración:    105 de 606\n",
            "Iteración:    106 de 606\n",
            "Iteración:    107 de 606\n",
            "Iteración:    108 de 606\n",
            "Iteración:    109 de 606\n",
            "Iteración:    110 de 606\n",
            "Iteración:    111 de 606\n",
            "Iteración:    112 de 606\n",
            "Iteración:    113 de 606\n",
            "Iteración:    114 de 606\n",
            "Iteración:    115 de 606\n",
            "Iteración:    116 de 606\n",
            "Iteración:    117 de 606\n",
            "Iteración:    118 de 606\n",
            "Iteración:    119 de 606\n",
            "Iteración:    120 de 606\n",
            "Iteración:    121 de 606\n",
            "Iteración:    122 de 606\n",
            "Iteración:    123 de 606\n",
            "Iteración:    124 de 606\n",
            "Iteración:    125 de 606\n",
            "Iteración:    126 de 606\n",
            "Iteración:    127 de 606\n",
            "Iteración:    128 de 606\n",
            "Iteración:    129 de 606\n",
            "Iteración:    130 de 606\n",
            "Iteración:    131 de 606\n",
            "Iteración:    132 de 606\n",
            "Iteración:    133 de 606\n",
            "Iteración:    134 de 606\n",
            "Iteración:    135 de 606\n",
            "Iteración:    136 de 606\n",
            "Iteración:    137 de 606\n",
            "Iteración:    138 de 606\n",
            "Iteración:    139 de 606\n",
            "Iteración:    140 de 606\n",
            "Iteración:    141 de 606\n",
            "Iteración:    142 de 606\n",
            "Iteración:    143 de 606\n",
            "Iteración:    144 de 606\n",
            "Iteración:    145 de 606\n",
            "Iteración:    146 de 606\n",
            "Iteración:    147 de 606\n",
            "Iteración:    148 de 606\n",
            "Iteración:    149 de 606\n",
            "Iteración:    150 de 606\n",
            "Iteración:    151 de 606\n",
            "Iteración:    152 de 606\n",
            "Iteración:    153 de 606\n",
            "Iteración:    154 de 606\n",
            "Iteración:    155 de 606\n",
            "Iteración:    156 de 606\n",
            "Iteración:    157 de 606\n",
            "Iteración:    158 de 606\n",
            "Iteración:    159 de 606\n",
            "Iteración:    160 de 606\n",
            "Iteración:    161 de 606\n",
            "Iteración:    162 de 606\n",
            "Iteración:    163 de 606\n",
            "Iteración:    164 de 606\n",
            "Iteración:    165 de 606\n",
            "Iteración:    166 de 606\n",
            "Iteración:    167 de 606\n",
            "Iteración:    168 de 606\n",
            "Iteración:    169 de 606\n",
            "Iteración:    170 de 606\n",
            "Iteración:    171 de 606\n",
            "Iteración:    172 de 606\n",
            "Iteración:    173 de 606\n",
            "Iteración:    174 de 606\n",
            "Iteración:    175 de 606\n",
            "Iteración:    176 de 606\n",
            "Iteración:    177 de 606\n",
            "Iteración:    178 de 606\n",
            "Iteración:    179 de 606\n",
            "Iteración:    180 de 606\n",
            "Iteración:    181 de 606\n",
            "Iteración:    182 de 606\n",
            "Iteración:    183 de 606\n",
            "Iteración:    184 de 606\n",
            "Iteración:    185 de 606\n",
            "Iteración:    186 de 606\n",
            "Iteración:    187 de 606\n",
            "Iteración:    188 de 606\n",
            "Iteración:    189 de 606\n",
            "Iteración:    190 de 606\n",
            "Iteración:    191 de 606\n",
            "Iteración:    192 de 606\n",
            "Iteración:    193 de 606\n",
            "Iteración:    194 de 606\n",
            "Iteración:    195 de 606\n",
            "Iteración:    196 de 606\n",
            "Iteración:    197 de 606\n",
            "Iteración:    198 de 606\n",
            "Iteración:    199 de 606\n",
            "Iteración:    200 de 606\n",
            "Iteración:    201 de 606\n",
            "Iteración:    202 de 606\n",
            "Iteración:    203 de 606\n",
            "Iteración:    204 de 606\n",
            "Iteración:    205 de 606\n",
            "Iteración:    206 de 606\n",
            "Iteración:    207 de 606\n",
            "Iteración:    208 de 606\n",
            "Iteración:    209 de 606\n",
            "Iteración:    210 de 606\n",
            "Iteración:    211 de 606\n",
            "Iteración:    212 de 606\n",
            "Iteración:    213 de 606\n",
            "Iteración:    214 de 606\n",
            "Iteración:    215 de 606\n",
            "Iteración:    216 de 606\n",
            "Iteración:    217 de 606\n",
            "Iteración:    218 de 606\n",
            "Iteración:    219 de 606\n",
            "Iteración:    220 de 606\n",
            "Iteración:    221 de 606\n",
            "Iteración:    222 de 606\n",
            "Iteración:    223 de 606\n",
            "Iteración:    224 de 606\n",
            "Iteración:    225 de 606\n",
            "Iteración:    226 de 606\n",
            "Iteración:    227 de 606\n",
            "Iteración:    228 de 606\n",
            "Iteración:    229 de 606\n",
            "Iteración:    230 de 606\n",
            "Iteración:    231 de 606\n",
            "Iteración:    232 de 606\n",
            "Iteración:    233 de 606\n",
            "Iteración:    234 de 606\n",
            "Iteración:    235 de 606\n",
            "Iteración:    236 de 606\n",
            "Iteración:    237 de 606\n",
            "Iteración:    238 de 606\n",
            "Iteración:    239 de 606\n",
            "Iteración:    240 de 606\n",
            "Iteración:    241 de 606\n",
            "Iteración:    242 de 606\n",
            "Iteración:    243 de 606\n",
            "Iteración:    244 de 606\n",
            "Iteración:    245 de 606\n",
            "Iteración:    246 de 606\n",
            "Iteración:    247 de 606\n",
            "Iteración:    248 de 606\n",
            "Iteración:    249 de 606\n",
            "Iteración:    250 de 606\n",
            "Iteración:    251 de 606\n",
            "Iteración:    252 de 606\n",
            "Iteración:    253 de 606\n",
            "Iteración:    254 de 606\n",
            "Iteración:    255 de 606\n",
            "Iteración:    256 de 606\n",
            "Iteración:    257 de 606\n",
            "Iteración:    258 de 606\n",
            "Iteración:    259 de 606\n",
            "Iteración:    260 de 606\n",
            "Iteración:    261 de 606\n",
            "Iteración:    262 de 606\n",
            "Iteración:    263 de 606\n",
            "Iteración:    264 de 606\n",
            "Iteración:    265 de 606\n",
            "Iteración:    266 de 606\n",
            "Iteración:    267 de 606\n",
            "Iteración:    268 de 606\n",
            "Iteración:    269 de 606\n",
            "Iteración:    270 de 606\n",
            "Iteración:    271 de 606\n",
            "Iteración:    272 de 606\n",
            "Iteración:    273 de 606\n",
            "Iteración:    274 de 606\n",
            "Iteración:    275 de 606\n",
            "Iteración:    276 de 606\n",
            "Iteración:    277 de 606\n",
            "Iteración:    278 de 606\n",
            "Iteración:    279 de 606\n",
            "Iteración:    280 de 606\n",
            "Iteración:    281 de 606\n",
            "Iteración:    282 de 606\n",
            "Iteración:    283 de 606\n",
            "Iteración:    284 de 606\n",
            "Iteración:    285 de 606\n",
            "Iteración:    286 de 606\n",
            "Iteración:    287 de 606\n",
            "Iteración:    288 de 606\n",
            "Iteración:    289 de 606\n",
            "Iteración:    290 de 606\n",
            "Iteración:    291 de 606\n",
            "Iteración:    292 de 606\n",
            "Iteración:    293 de 606\n",
            "Iteración:    294 de 606\n",
            "Iteración:    295 de 606\n",
            "Iteración:    296 de 606\n",
            "Iteración:    297 de 606\n",
            "Iteración:    298 de 606\n",
            "Iteración:    299 de 606\n",
            "Iteración:    300 de 606\n",
            "Iteración:    301 de 606\n",
            "Iteración:    302 de 606\n",
            "Iteración:    303 de 606\n",
            "Iteración:    304 de 606\n",
            "Iteración:    305 de 606\n",
            "Iteración:    306 de 606\n",
            "Iteración:    307 de 606\n",
            "Iteración:    308 de 606\n",
            "Iteración:    309 de 606\n",
            "Iteración:    310 de 606\n",
            "Iteración:    311 de 606\n",
            "Iteración:    312 de 606\n",
            "Iteración:    313 de 606\n",
            "Iteración:    314 de 606\n",
            "Iteración:    315 de 606\n",
            "Iteración:    316 de 606\n",
            "Iteración:    317 de 606\n",
            "Iteración:    318 de 606\n",
            "Iteración:    319 de 606\n",
            "Iteración:    320 de 606\n",
            "Iteración:    321 de 606\n",
            "Iteración:    322 de 606\n",
            "Iteración:    323 de 606\n",
            "Iteración:    324 de 606\n",
            "Iteración:    325 de 606\n",
            "Iteración:    326 de 606\n",
            "Iteración:    327 de 606\n",
            "Iteración:    328 de 606\n",
            "Iteración:    329 de 606\n",
            "Iteración:    330 de 606\n",
            "Iteración:    331 de 606\n",
            "Iteración:    332 de 606\n",
            "Iteración:    333 de 606\n",
            "Iteración:    334 de 606\n",
            "Iteración:    335 de 606\n",
            "Iteración:    336 de 606\n",
            "Iteración:    337 de 606\n",
            "Iteración:    338 de 606\n",
            "Iteración:    339 de 606\n",
            "Iteración:    340 de 606\n",
            "Iteración:    341 de 606\n",
            "Iteración:    342 de 606\n",
            "Iteración:    343 de 606\n",
            "Iteración:    344 de 606\n",
            "Iteración:    345 de 606\n",
            "Iteración:    346 de 606\n",
            "Iteración:    347 de 606\n",
            "Iteración:    348 de 606\n",
            "Iteración:    349 de 606\n",
            "Iteración:    350 de 606\n",
            "Iteración:    351 de 606\n",
            "Iteración:    352 de 606\n",
            "Iteración:    353 de 606\n",
            "Iteración:    354 de 606\n",
            "Iteración:    355 de 606\n",
            "Iteración:    356 de 606\n",
            "Iteración:    357 de 606\n",
            "Iteración:    358 de 606\n",
            "Iteración:    359 de 606\n",
            "Iteración:    360 de 606\n",
            "Iteración:    361 de 606\n",
            "Iteración:    362 de 606\n",
            "Iteración:    363 de 606\n",
            "Iteración:    364 de 606\n",
            "Iteración:    365 de 606\n",
            "Iteración:    366 de 606\n",
            "Iteración:    367 de 606\n",
            "Iteración:    368 de 606\n",
            "Iteración:    369 de 606\n",
            "Iteración:    370 de 606\n",
            "Iteración:    371 de 606\n",
            "Iteración:    372 de 606\n",
            "Iteración:    373 de 606\n",
            "Iteración:    374 de 606\n",
            "Iteración:    375 de 606\n",
            "Iteración:    376 de 606\n",
            "Iteración:    377 de 606\n",
            "Iteración:    378 de 606\n",
            "Iteración:    379 de 606\n",
            "Iteración:    380 de 606\n",
            "Iteración:    381 de 606\n",
            "Iteración:    382 de 606\n",
            "Iteración:    383 de 606\n",
            "Iteración:    384 de 606\n",
            "Iteración:    385 de 606\n",
            "Iteración:    386 de 606\n",
            "Iteración:    387 de 606\n",
            "Iteración:    388 de 606\n",
            "Iteración:    389 de 606\n",
            "Iteración:    390 de 606\n",
            "Iteración:    391 de 606\n",
            "Iteración:    392 de 606\n",
            "Iteración:    393 de 606\n",
            "Iteración:    394 de 606\n",
            "Iteración:    395 de 606\n",
            "Iteración:    396 de 606\n",
            "Iteración:    397 de 606\n",
            "Iteración:    398 de 606\n",
            "Iteración:    399 de 606\n",
            "Iteración:    400 de 606\n",
            "Iteración:    401 de 606\n",
            "Iteración:    402 de 606\n",
            "Iteración:    403 de 606\n",
            "Iteración:    404 de 606\n",
            "Iteración:    405 de 606\n",
            "Iteración:    406 de 606\n",
            "Iteración:    407 de 606\n",
            "Iteración:    408 de 606\n",
            "Iteración:    409 de 606\n",
            "Iteración:    410 de 606\n",
            "Iteración:    411 de 606\n",
            "Iteración:    412 de 606\n",
            "Iteración:    413 de 606\n",
            "Iteración:    414 de 606\n",
            "Iteración:    415 de 606\n",
            "Iteración:    416 de 606\n",
            "Iteración:    417 de 606\n",
            "Iteración:    418 de 606\n",
            "Iteración:    419 de 606\n",
            "Iteración:    420 de 606\n",
            "Iteración:    421 de 606\n",
            "Iteración:    422 de 606\n",
            "Iteración:    423 de 606\n",
            "Iteración:    424 de 606\n",
            "Iteración:    425 de 606\n",
            "Iteración:    426 de 606\n",
            "Iteración:    427 de 606\n",
            "Iteración:    428 de 606\n",
            "Iteración:    429 de 606\n",
            "Iteración:    430 de 606\n",
            "Iteración:    431 de 606\n",
            "Iteración:    432 de 606\n",
            "Iteración:    433 de 606\n",
            "Iteración:    434 de 606\n",
            "Iteración:    435 de 606\n",
            "Iteración:    436 de 606\n",
            "Iteración:    437 de 606\n",
            "Iteración:    438 de 606\n",
            "Iteración:    439 de 606\n",
            "Iteración:    440 de 606\n",
            "Iteración:    441 de 606\n",
            "Iteración:    442 de 606\n",
            "Iteración:    443 de 606\n",
            "Iteración:    444 de 606\n",
            "Iteración:    445 de 606\n",
            "Iteración:    446 de 606\n",
            "Iteración:    447 de 606\n",
            "Iteración:    448 de 606\n",
            "Iteración:    449 de 606\n",
            "Iteración:    450 de 606\n",
            "Iteración:    451 de 606\n",
            "Iteración:    452 de 606\n",
            "Iteración:    453 de 606\n",
            "Iteración:    454 de 606\n",
            "Iteración:    455 de 606\n",
            "Iteración:    456 de 606\n",
            "Iteración:    457 de 606\n",
            "Iteración:    458 de 606\n",
            "Iteración:    459 de 606\n",
            "Iteración:    460 de 606\n",
            "Iteración:    461 de 606\n",
            "Iteración:    462 de 606\n",
            "Iteración:    463 de 606\n",
            "Iteración:    464 de 606\n",
            "Iteración:    465 de 606\n",
            "Iteración:    466 de 606\n",
            "Iteración:    467 de 606\n",
            "Iteración:    468 de 606\n",
            "Iteración:    469 de 606\n",
            "Iteración:    470 de 606\n",
            "Iteración:    471 de 606\n",
            "Iteración:    472 de 606\n",
            "Iteración:    473 de 606\n",
            "Iteración:    474 de 606\n",
            "Iteración:    475 de 606\n",
            "Iteración:    476 de 606\n",
            "Iteración:    477 de 606\n",
            "Iteración:    478 de 606\n",
            "Iteración:    479 de 606\n",
            "Iteración:    480 de 606\n",
            "Iteración:    481 de 606\n",
            "Iteración:    482 de 606\n",
            "Iteración:    483 de 606\n",
            "Iteración:    484 de 606\n",
            "Iteración:    485 de 606\n",
            "Iteración:    486 de 606\n",
            "Iteración:    487 de 606\n",
            "Iteración:    488 de 606\n",
            "Iteración:    489 de 606\n",
            "Iteración:    490 de 606\n",
            "Iteración:    491 de 606\n",
            "Iteración:    492 de 606\n",
            "Iteración:    493 de 606\n",
            "Iteración:    494 de 606\n",
            "Iteración:    495 de 606\n",
            "Iteración:    496 de 606\n",
            "Iteración:    497 de 606\n",
            "Iteración:    498 de 606\n",
            "Iteración:    499 de 606\n",
            "Iteración:    500 de 606\n",
            "Iteración:    501 de 606\n",
            "Iteración:    502 de 606\n",
            "Iteración:    503 de 606\n",
            "Iteración:    504 de 606\n",
            "Iteración:    505 de 606\n",
            "Iteración:    506 de 606\n",
            "Iteración:    507 de 606\n",
            "Iteración:    508 de 606\n",
            "Iteración:    509 de 606\n",
            "Iteración:    510 de 606\n",
            "Iteración:    511 de 606\n",
            "Iteración:    512 de 606\n",
            "Iteración:    513 de 606\n",
            "Iteración:    514 de 606\n",
            "Iteración:    515 de 606\n",
            "Iteración:    516 de 606\n",
            "Iteración:    517 de 606\n",
            "Iteración:    518 de 606\n",
            "Iteración:    519 de 606\n",
            "Iteración:    520 de 606\n",
            "Iteración:    521 de 606\n",
            "Iteración:    522 de 606\n",
            "Iteración:    523 de 606\n",
            "Iteración:    524 de 606\n",
            "Iteración:    525 de 606\n",
            "Iteración:    526 de 606\n",
            "Iteración:    527 de 606\n",
            "Iteración:    528 de 606\n",
            "Iteración:    529 de 606\n",
            "Iteración:    530 de 606\n",
            "Iteración:    531 de 606\n",
            "Iteración:    532 de 606\n",
            "Iteración:    533 de 606\n",
            "Iteración:    534 de 606\n",
            "Iteración:    535 de 606\n",
            "Iteración:    536 de 606\n",
            "Iteración:    537 de 606\n",
            "Iteración:    538 de 606\n",
            "Iteración:    539 de 606\n",
            "Iteración:    540 de 606\n",
            "Iteración:    541 de 606\n",
            "Iteración:    542 de 606\n",
            "Iteración:    543 de 606\n",
            "Iteración:    544 de 606\n",
            "Iteración:    545 de 606\n",
            "Iteración:    546 de 606\n",
            "Iteración:    547 de 606\n",
            "Iteración:    548 de 606\n",
            "Iteración:    549 de 606\n",
            "Iteración:    550 de 606\n",
            "Iteración:    551 de 606\n",
            "Iteración:    552 de 606\n",
            "Iteración:    553 de 606\n",
            "Iteración:    554 de 606\n",
            "Iteración:    555 de 606\n",
            "Iteración:    556 de 606\n",
            "Iteración:    557 de 606\n",
            "Iteración:    558 de 606\n",
            "Iteración:    559 de 606\n",
            "Iteración:    560 de 606\n",
            "Iteración:    561 de 606\n",
            "Iteración:    562 de 606\n",
            "Iteración:    563 de 606\n",
            "Iteración:    564 de 606\n",
            "Iteración:    565 de 606\n",
            "Iteración:    566 de 606\n",
            "Iteración:    567 de 606\n",
            "Iteración:    568 de 606\n",
            "Iteración:    569 de 606\n",
            "Iteración:    570 de 606\n",
            "Iteración:    571 de 606\n",
            "Iteración:    572 de 606\n",
            "Iteración:    573 de 606\n",
            "Iteración:    574 de 606\n",
            "Iteración:    575 de 606\n",
            "Iteración:    576 de 606\n",
            "Iteración:    577 de 606\n",
            "Iteración:    578 de 606\n",
            "Iteración:    579 de 606\n",
            "Iteración:    580 de 606\n",
            "Iteración:    581 de 606\n",
            "Iteración:    582 de 606\n",
            "Iteración:    583 de 606\n",
            "Iteración:    584 de 606\n",
            "Iteración:    585 de 606\n",
            "Iteración:    586 de 606\n",
            "Iteración:    587 de 606\n",
            "Iteración:    588 de 606\n",
            "Iteración:    589 de 606\n",
            "Iteración:    590 de 606\n",
            "Iteración:    591 de 606\n",
            "Iteración:    592 de 606\n",
            "Iteración:    593 de 606\n",
            "Iteración:    594 de 606\n",
            "Iteración:    595 de 606\n",
            "Iteración:    596 de 606\n",
            "Iteración:    597 de 606\n",
            "Iteración:    598 de 606\n",
            "Iteración:    599 de 606\n",
            "Iteración:    600 de 606\n",
            "Iteración:    601 de 606\n",
            "Iteración:    602 de 606\n",
            "Iteración:    603 de 606\n",
            "Iteración:    604 de 606\n",
            "Iteración:    605 de 606\n",
            "Accuracy Score = 0.7167131494680301\n",
            "F1 Score (Micro) = 0.7167131494680301\n",
            "F1 Score (Macro) = 0.41749150094768195\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationRoberta(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "id": "97u7oW6ejLdC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETOGNCt0jv_g"
      },
      "source": [
        "##### Entrenamiento del modelo (80% de datos)"
      ],
      "id": "ETOGNCt0jv_g"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-5\n",
        "- weight_decay=0.01\n",
        "- Dropout + Linear + Sigmoid"
      ],
      "metadata": {
        "id": "13rMvu3EKXzr"
      },
      "id": "13rMvu3EKXzr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbbbb60d-6b96-4a12-ec62-4f8480a8305e",
        "id": "AqDWniyrjv_h"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración;      0 de 7745, Loss: 0.07203119993209839\n",
            "Epoch: 0, iteración;     10 de 7745, Loss: 0.6863770961761475\n",
            "Epoch: 0, iteración;     20 de 7745, Loss: 0.6773520946502686\n",
            "Epoch: 0, iteración;     30 de 7745, Loss: 0.6759041309356689\n",
            "Epoch: 0, iteración;     40 de 7745, Loss: 0.6124179363250732\n",
            "Epoch: 0, iteración;     50 de 7745, Loss: 0.6373193740844727\n",
            "Epoch: 0, iteración;     60 de 7745, Loss: 0.5993459701538086\n",
            "Epoch: 0, iteración;     70 de 7745, Loss: 0.5959677219390869\n",
            "Epoch: 0, iteración;     80 de 7745, Loss: 0.5703641414642334\n",
            "Epoch: 0, iteración;     90 de 7745, Loss: 0.5545778274536133\n",
            "Epoch: 0, iteración;    100 de 7745, Loss: 0.5832770347595215\n",
            "Epoch: 0, iteración;    110 de 7745, Loss: 0.5973462104797364\n",
            "Epoch: 0, iteración;    120 de 7745, Loss: 0.6187351226806641\n",
            "Epoch: 0, iteración;    130 de 7745, Loss: 0.5685255050659179\n",
            "Epoch: 0, iteración;    140 de 7745, Loss: 0.5912712574005127\n",
            "Epoch: 0, iteración;    150 de 7745, Loss: 0.5497786521911621\n",
            "Epoch: 0, iteración;    160 de 7745, Loss: 0.6246935844421386\n",
            "Epoch: 0, iteración;    170 de 7745, Loss: 0.6490622997283936\n",
            "Epoch: 0, iteración;    180 de 7745, Loss: 0.5955237865447998\n",
            "Epoch: 0, iteración;    190 de 7745, Loss: 0.5124438285827637\n",
            "Epoch: 0, iteración;    200 de 7745, Loss: 0.6214601516723632\n",
            "Epoch: 0, iteración;    210 de 7745, Loss: 0.6143192291259766\n",
            "Epoch: 0, iteración;    220 de 7745, Loss: 0.6225995063781739\n",
            "Epoch: 0, iteración;    230 de 7745, Loss: 0.521424674987793\n",
            "Epoch: 0, iteración;    240 de 7745, Loss: 0.588899564743042\n",
            "Epoch: 0, iteración;    250 de 7745, Loss: 0.591573429107666\n",
            "Epoch: 0, iteración;    260 de 7745, Loss: 0.6318131923675537\n",
            "Epoch: 0, iteración;    270 de 7745, Loss: 0.5364442825317383\n",
            "Epoch: 0, iteración;    280 de 7745, Loss: 0.46899662017822263\n",
            "Epoch: 0, iteración;    290 de 7745, Loss: 0.6014810562133789\n",
            "Epoch: 0, iteración;    300 de 7745, Loss: 0.5470241069793701\n",
            "Epoch: 0, iteración;    310 de 7745, Loss: 0.5537284851074219\n",
            "Epoch: 0, iteración;    320 de 7745, Loss: 0.46270089149475097\n",
            "Epoch: 0, iteración;    330 de 7745, Loss: 0.47940874099731445\n",
            "Epoch: 0, iteración;    340 de 7745, Loss: 0.5516275882720947\n",
            "Epoch: 0, iteración;    350 de 7745, Loss: 0.6088208198547364\n",
            "Epoch: 0, iteración;    360 de 7745, Loss: 0.5456879615783692\n",
            "Epoch: 0, iteración;    370 de 7745, Loss: 0.567485761642456\n",
            "Epoch: 0, iteración;    380 de 7745, Loss: 0.5407250404357911\n",
            "Epoch: 0, iteración;    390 de 7745, Loss: 0.4943558216094971\n",
            "Epoch: 0, iteración;    400 de 7745, Loss: 0.47418460845947263\n",
            "Epoch: 0, iteración;    410 de 7745, Loss: 0.5291439533233643\n",
            "Epoch: 0, iteración;    420 de 7745, Loss: 0.4809859275817871\n",
            "Epoch: 0, iteración;    430 de 7745, Loss: 0.4853334426879883\n",
            "Epoch: 0, iteración;    440 de 7745, Loss: 0.3390201568603516\n",
            "Epoch: 0, iteración;    450 de 7745, Loss: 0.42343506813049314\n",
            "Epoch: 0, iteración;    460 de 7745, Loss: 0.5246951103210449\n",
            "Epoch: 0, iteración;    470 de 7745, Loss: 0.5759894847869873\n",
            "Epoch: 0, iteración;    480 de 7745, Loss: 0.5154609203338623\n",
            "Epoch: 0, iteración;    490 de 7745, Loss: 0.4865857124328613\n",
            "Epoch: 0, iteración;    500 de 7745, Loss: 0.5242437362670899\n",
            "Epoch: 0, iteración;    510 de 7745, Loss: 0.5447305679321289\n",
            "Epoch: 0, iteración;    520 de 7745, Loss: 0.5615365028381347\n",
            "Epoch: 0, iteración;    530 de 7745, Loss: 0.49459142684936525\n",
            "Epoch: 0, iteración;    540 de 7745, Loss: 0.515726375579834\n",
            "Epoch: 0, iteración;    550 de 7745, Loss: 0.4672762393951416\n",
            "Epoch: 0, iteración;    560 de 7745, Loss: 0.39023828506469727\n",
            "Epoch: 0, iteración;    570 de 7745, Loss: 0.667637300491333\n",
            "Epoch: 0, iteración;    580 de 7745, Loss: 0.5749313354492187\n",
            "Epoch: 0, iteración;    590 de 7745, Loss: 0.5389220714569092\n",
            "Epoch: 0, iteración;    600 de 7745, Loss: 0.5164229393005371\n",
            "Epoch: 0, iteración;    610 de 7745, Loss: 0.5131623268127441\n",
            "Epoch: 0, iteración;    620 de 7745, Loss: 0.5786960124969482\n",
            "Epoch: 0, iteración;    630 de 7745, Loss: 0.48178739547729493\n",
            "Epoch: 0, iteración;    640 de 7745, Loss: 0.5704694271087647\n",
            "Epoch: 0, iteración;    650 de 7745, Loss: 0.5818687438964844\n",
            "Epoch: 0, iteración;    660 de 7745, Loss: 0.5328074932098389\n",
            "Epoch: 0, iteración;    670 de 7745, Loss: 0.45907068252563477\n",
            "Epoch: 0, iteración;    680 de 7745, Loss: 0.562589168548584\n",
            "Epoch: 0, iteración;    690 de 7745, Loss: 0.48207430839538573\n",
            "Epoch: 0, iteración;    700 de 7745, Loss: 0.43245768547058105\n",
            "Epoch: 0, iteración;    710 de 7745, Loss: 0.533294677734375\n",
            "Epoch: 0, iteración;    720 de 7745, Loss: 0.5575502872467041\n",
            "Epoch: 0, iteración;    730 de 7745, Loss: 0.5371209144592285\n",
            "Epoch: 0, iteración;    740 de 7745, Loss: 0.4667477607727051\n",
            "Epoch: 0, iteración;    750 de 7745, Loss: 0.5409327030181885\n",
            "Epoch: 0, iteración;    760 de 7745, Loss: 0.4987627983093262\n",
            "Epoch: 0, iteración;    770 de 7745, Loss: 0.5702553749084472\n",
            "Epoch: 0, iteración;    780 de 7745, Loss: 0.5350177764892579\n",
            "Epoch: 0, iteración;    790 de 7745, Loss: 0.4712395668029785\n",
            "Epoch: 0, iteración;    800 de 7745, Loss: 0.5007954597473144\n",
            "Epoch: 0, iteración;    810 de 7745, Loss: 0.6598362445831298\n",
            "Epoch: 0, iteración;    820 de 7745, Loss: 0.4885259628295898\n",
            "Epoch: 0, iteración;    830 de 7745, Loss: 0.46540632247924807\n",
            "Epoch: 0, iteración;    840 de 7745, Loss: 0.648177194595337\n",
            "Epoch: 0, iteración;    850 de 7745, Loss: 0.5116424083709716\n",
            "Epoch: 0, iteración;    860 de 7745, Loss: 0.5270827770233154\n",
            "Epoch: 0, iteración;    870 de 7745, Loss: 0.55972900390625\n",
            "Epoch: 0, iteración;    880 de 7745, Loss: 0.47016339302062987\n",
            "Epoch: 0, iteración;    890 de 7745, Loss: 0.47234325408935546\n",
            "Epoch: 0, iteración;    900 de 7745, Loss: 0.405405330657959\n",
            "Epoch: 0, iteración;    910 de 7745, Loss: 0.4931379795074463\n",
            "Epoch: 0, iteración;    920 de 7745, Loss: 0.6387186050415039\n",
            "Epoch: 0, iteración;    930 de 7745, Loss: 0.562241792678833\n",
            "Epoch: 0, iteración;    940 de 7745, Loss: 0.4865267276763916\n",
            "Epoch: 0, iteración;    950 de 7745, Loss: 0.4993912220001221\n",
            "Epoch: 0, iteración;    960 de 7745, Loss: 0.5340729713439941\n",
            "Epoch: 0, iteración;    970 de 7745, Loss: 0.45232210159301756\n",
            "Epoch: 0, iteración;    980 de 7745, Loss: 0.5387922763824463\n",
            "Epoch: 0, iteración;    990 de 7745, Loss: 0.5182745933532715\n",
            "Epoch: 0, iteración;   1000 de 7745, Loss: 0.4226179599761963\n",
            "Epoch: 0, iteración;   1010 de 7745, Loss: 0.571713924407959\n",
            "Epoch: 0, iteración;   1020 de 7745, Loss: 0.46810159683227537\n",
            "Epoch: 0, iteración;   1030 de 7745, Loss: 0.5212527751922608\n",
            "Epoch: 0, iteración;   1040 de 7745, Loss: 0.5082637786865234\n",
            "Epoch: 0, iteración;   1050 de 7745, Loss: 0.5074337959289551\n",
            "Epoch: 0, iteración;   1060 de 7745, Loss: 0.40826873779296874\n",
            "Epoch: 0, iteración;   1070 de 7745, Loss: 0.6557391166687012\n",
            "Epoch: 0, iteración;   1080 de 7745, Loss: 0.5604645729064941\n",
            "Epoch: 0, iteración;   1090 de 7745, Loss: 0.48651928901672364\n",
            "Epoch: 0, iteración;   1100 de 7745, Loss: 0.4387000560760498\n",
            "Epoch: 0, iteración;   1110 de 7745, Loss: 0.6503601551055909\n",
            "Epoch: 0, iteración;   1120 de 7745, Loss: 0.494933557510376\n",
            "Epoch: 0, iteración;   1130 de 7745, Loss: 0.5495969772338867\n",
            "Epoch: 0, iteración;   1140 de 7745, Loss: 0.508294677734375\n",
            "Epoch: 0, iteración;   1150 de 7745, Loss: 0.49706220626831055\n",
            "Epoch: 0, iteración;   1160 de 7745, Loss: 0.5964527606964112\n",
            "Epoch: 0, iteración;   1170 de 7745, Loss: 0.46808757781982424\n",
            "Epoch: 0, iteración;   1180 de 7745, Loss: 0.6041903495788574\n",
            "Epoch: 0, iteración;   1190 de 7745, Loss: 0.42834038734436036\n",
            "Epoch: 0, iteración;   1200 de 7745, Loss: 0.42521204948425295\n",
            "Epoch: 0, iteración;   1210 de 7745, Loss: 0.5841898918151855\n",
            "Epoch: 0, iteración;   1220 de 7745, Loss: 0.5023374080657959\n",
            "Epoch: 0, iteración;   1230 de 7745, Loss: 0.539035701751709\n",
            "Epoch: 0, iteración;   1240 de 7745, Loss: 0.4959737777709961\n",
            "Epoch: 0, iteración;   1250 de 7745, Loss: 0.5577487468719482\n",
            "Epoch: 0, iteración;   1260 de 7745, Loss: 0.413740873336792\n",
            "Epoch: 0, iteración;   1270 de 7745, Loss: 0.4355774879455566\n",
            "Epoch: 0, iteración;   1280 de 7745, Loss: 0.5394773960113526\n",
            "Epoch: 0, iteración;   1290 de 7745, Loss: 0.539413595199585\n",
            "Epoch: 0, iteración;   1300 de 7745, Loss: 0.5887710571289062\n",
            "Epoch: 0, iteración;   1310 de 7745, Loss: 0.5353454113006592\n",
            "Epoch: 0, iteración;   1320 de 7745, Loss: 0.4453925132751465\n",
            "Epoch: 0, iteración;   1330 de 7745, Loss: 0.5358092308044433\n",
            "Epoch: 0, iteración;   1340 de 7745, Loss: 0.5083078384399414\n",
            "Epoch: 0, iteración;   1350 de 7745, Loss: 0.42346649169921874\n",
            "Epoch: 0, iteración;   1360 de 7745, Loss: 0.6530492305755615\n",
            "Epoch: 0, iteración;   1370 de 7745, Loss: 0.4566316604614258\n",
            "Epoch: 0, iteración;   1380 de 7745, Loss: 0.5148600578308106\n",
            "Epoch: 0, iteración;   1390 de 7745, Loss: 0.5933189392089844\n",
            "Epoch: 0, iteración;   1400 de 7745, Loss: 0.49552226066589355\n",
            "Epoch: 0, iteración;   1410 de 7745, Loss: 0.49921379089355467\n",
            "Epoch: 0, iteración;   1420 de 7745, Loss: 0.4756143569946289\n",
            "Epoch: 0, iteración;   1430 de 7745, Loss: 0.3637979507446289\n",
            "Epoch: 0, iteración;   1440 de 7745, Loss: 0.48966641426086427\n",
            "Epoch: 0, iteración;   1450 de 7745, Loss: 0.44439969062805174\n",
            "Epoch: 0, iteración;   1460 de 7745, Loss: 0.41991825103759767\n",
            "Epoch: 0, iteración;   1470 de 7745, Loss: 0.509638786315918\n",
            "Epoch: 0, iteración;   1480 de 7745, Loss: 0.4748837947845459\n",
            "Epoch: 0, iteración;   1490 de 7745, Loss: 0.6096199035644532\n",
            "Epoch: 0, iteración;   1500 de 7745, Loss: 0.5903378009796143\n",
            "Epoch: 0, iteración;   1510 de 7745, Loss: 0.5286150932312011\n",
            "Epoch: 0, iteración;   1520 de 7745, Loss: 0.5156128883361817\n",
            "Epoch: 0, iteración;   1530 de 7745, Loss: 0.5783105850219726\n",
            "Epoch: 0, iteración;   1540 de 7745, Loss: 0.5414002418518067\n",
            "Epoch: 0, iteración;   1550 de 7745, Loss: 0.5410675048828125\n",
            "Epoch: 0, iteración;   1560 de 7745, Loss: 0.41904640197753906\n",
            "Epoch: 0, iteración;   1570 de 7745, Loss: 0.5281376838684082\n",
            "Epoch: 0, iteración;   1580 de 7745, Loss: 0.4103137493133545\n",
            "Epoch: 0, iteración;   1590 de 7745, Loss: 0.5667299747467041\n",
            "Epoch: 0, iteración;   1600 de 7745, Loss: 0.4592584609985352\n",
            "Epoch: 0, iteración;   1610 de 7745, Loss: 0.5420662879943847\n",
            "Epoch: 0, iteración;   1620 de 7745, Loss: 0.5389545440673829\n",
            "Epoch: 0, iteración;   1630 de 7745, Loss: 0.47459564208984373\n",
            "Epoch: 0, iteración;   1640 de 7745, Loss: 0.5716992378234863\n",
            "Epoch: 0, iteración;   1650 de 7745, Loss: 0.5936482429504395\n",
            "Epoch: 0, iteración;   1660 de 7745, Loss: 0.5219821453094482\n",
            "Epoch: 0, iteración;   1670 de 7745, Loss: 0.5468223094940186\n",
            "Epoch: 0, iteración;   1680 de 7745, Loss: 0.45178699493408203\n",
            "Epoch: 0, iteración;   1690 de 7745, Loss: 0.5809337139129639\n",
            "Epoch: 0, iteración;   1700 de 7745, Loss: 0.4630412578582764\n",
            "Epoch: 0, iteración;   1710 de 7745, Loss: 0.48230791091918945\n",
            "Epoch: 0, iteración;   1720 de 7745, Loss: 0.5139944076538085\n",
            "Epoch: 0, iteración;   1730 de 7745, Loss: 0.4891840934753418\n",
            "Epoch: 0, iteración;   1740 de 7745, Loss: 0.4840237617492676\n",
            "Epoch: 0, iteración;   1750 de 7745, Loss: 0.4559463024139404\n",
            "Epoch: 0, iteración;   1760 de 7745, Loss: 0.45876712799072267\n",
            "Epoch: 0, iteración;   1770 de 7745, Loss: 0.45576977729797363\n",
            "Epoch: 0, iteración;   1780 de 7745, Loss: 0.414765739440918\n",
            "Epoch: 0, iteración;   1790 de 7745, Loss: 0.4022879123687744\n",
            "Epoch: 0, iteración;   1800 de 7745, Loss: 0.7130801677703857\n",
            "Epoch: 0, iteración;   1810 de 7745, Loss: 0.5533183574676513\n",
            "Epoch: 0, iteración;   1820 de 7745, Loss: 0.4658674240112305\n",
            "Epoch: 0, iteración;   1830 de 7745, Loss: 0.47978920936584474\n",
            "Epoch: 0, iteración;   1840 de 7745, Loss: 0.43343477249145507\n",
            "Epoch: 0, iteración;   1850 de 7745, Loss: 0.45727243423461916\n",
            "Epoch: 0, iteración;   1860 de 7745, Loss: 0.3867689847946167\n",
            "Epoch: 0, iteración;   1870 de 7745, Loss: 0.4994767665863037\n",
            "Epoch: 0, iteración;   1880 de 7745, Loss: 0.6184206485748291\n",
            "Epoch: 0, iteración;   1890 de 7745, Loss: 0.5096694946289062\n",
            "Epoch: 0, iteración;   1900 de 7745, Loss: 0.45542593002319337\n",
            "Epoch: 0, iteración;   1910 de 7745, Loss: 0.44869675636291506\n",
            "Epoch: 0, iteración;   1920 de 7745, Loss: 0.40089950561523435\n",
            "Epoch: 0, iteración;   1930 de 7745, Loss: 0.4902051448822021\n",
            "Epoch: 0, iteración;   1940 de 7745, Loss: 0.5629880428314209\n",
            "Epoch: 0, iteración;   1950 de 7745, Loss: 0.5661214351654053\n",
            "Epoch: 0, iteración;   1960 de 7745, Loss: 0.6595511436462402\n",
            "Epoch: 0, iteración;   1970 de 7745, Loss: 0.5045760154724122\n",
            "Epoch: 0, iteración;   1980 de 7745, Loss: 0.5417550563812256\n",
            "Epoch: 0, iteración;   1990 de 7745, Loss: 0.3933082342147827\n",
            "Epoch: 0, iteración;   2000 de 7745, Loss: 0.6154287815093994\n",
            "Epoch: 0, iteración;   2010 de 7745, Loss: 0.5432976722717285\n",
            "Epoch: 0, iteración;   2020 de 7745, Loss: 0.5173389434814453\n",
            "Epoch: 0, iteración;   2030 de 7745, Loss: 0.4618824481964111\n",
            "Epoch: 0, iteración;   2040 de 7745, Loss: 0.48934273719787597\n",
            "Epoch: 0, iteración;   2050 de 7745, Loss: 0.47062835693359373\n",
            "Epoch: 0, iteración;   2060 de 7745, Loss: 0.49475626945495604\n",
            "Epoch: 0, iteración;   2070 de 7745, Loss: 0.5313337326049805\n",
            "Epoch: 0, iteración;   2080 de 7745, Loss: 0.46286807060241697\n",
            "Epoch: 0, iteración;   2090 de 7745, Loss: 0.5246463775634765\n",
            "Epoch: 0, iteración;   2100 de 7745, Loss: 0.5043814659118653\n",
            "Epoch: 0, iteración;   2110 de 7745, Loss: 0.5405667304992676\n",
            "Epoch: 0, iteración;   2120 de 7745, Loss: 0.4740017890930176\n",
            "Epoch: 0, iteración;   2130 de 7745, Loss: 0.47615675926208495\n",
            "Epoch: 0, iteración;   2140 de 7745, Loss: 0.42136058807373045\n",
            "Epoch: 0, iteración;   2150 de 7745, Loss: 0.49109816551208496\n",
            "Epoch: 0, iteración;   2160 de 7745, Loss: 0.4449188709259033\n",
            "Epoch: 0, iteración;   2170 de 7745, Loss: 0.3041469812393188\n",
            "Epoch: 0, iteración;   2180 de 7745, Loss: 0.36976304054260256\n",
            "Epoch: 0, iteración;   2190 de 7745, Loss: 0.706274938583374\n",
            "Epoch: 0, iteración;   2200 de 7745, Loss: 0.6131118774414063\n",
            "Epoch: 0, iteración;   2210 de 7745, Loss: 0.5587142944335938\n",
            "Epoch: 0, iteración;   2220 de 7745, Loss: 0.46136107444763186\n",
            "Epoch: 0, iteración;   2230 de 7745, Loss: 0.5057559967041015\n",
            "Epoch: 0, iteración;   2240 de 7745, Loss: 0.5650667190551758\n",
            "Epoch: 0, iteración;   2250 de 7745, Loss: 0.5132748126983643\n",
            "Epoch: 0, iteración;   2260 de 7745, Loss: 0.5577466487884521\n",
            "Epoch: 0, iteración;   2270 de 7745, Loss: 0.4752358913421631\n",
            "Epoch: 0, iteración;   2280 de 7745, Loss: 0.4627274513244629\n",
            "Epoch: 0, iteración;   2290 de 7745, Loss: 0.46475954055786134\n",
            "Epoch: 0, iteración;   2300 de 7745, Loss: 0.4663239479064941\n",
            "Epoch: 0, iteración;   2310 de 7745, Loss: 0.5020227432250977\n",
            "Epoch: 0, iteración;   2320 de 7745, Loss: 0.5532599449157715\n",
            "Epoch: 0, iteración;   2330 de 7745, Loss: 0.508462381362915\n",
            "Epoch: 0, iteración;   2340 de 7745, Loss: 0.4624336719512939\n",
            "Epoch: 0, iteración;   2350 de 7745, Loss: 0.48899378776550295\n",
            "Epoch: 0, iteración;   2360 de 7745, Loss: 0.45078153610229493\n",
            "Epoch: 0, iteración;   2370 de 7745, Loss: 0.6755352020263672\n",
            "Epoch: 0, iteración;   2380 de 7745, Loss: 0.5856592655181885\n",
            "Epoch: 0, iteración;   2390 de 7745, Loss: 0.5565438747406006\n",
            "Epoch: 0, iteración;   2400 de 7745, Loss: 0.5922744750976563\n",
            "Epoch: 0, iteración;   2410 de 7745, Loss: 0.46703391075134276\n",
            "Epoch: 0, iteración;   2420 de 7745, Loss: 0.5420197010040283\n",
            "Epoch: 0, iteración;   2430 de 7745, Loss: 0.5131381988525391\n",
            "Epoch: 0, iteración;   2440 de 7745, Loss: 0.5286957263946533\n",
            "Epoch: 0, iteración;   2450 de 7745, Loss: 0.5080077171325683\n",
            "Epoch: 0, iteración;   2460 de 7745, Loss: 0.566152286529541\n",
            "Epoch: 0, iteración;   2470 de 7745, Loss: 0.5331096172332763\n",
            "Epoch: 0, iteración;   2480 de 7745, Loss: 0.4877147197723389\n",
            "Epoch: 0, iteración;   2490 de 7745, Loss: 0.5267128467559814\n",
            "Epoch: 0, iteración;   2500 de 7745, Loss: 0.3910261392593384\n",
            "Epoch: 0, iteración;   2510 de 7745, Loss: 0.38051207065582277\n",
            "Epoch: 0, iteración;   2520 de 7745, Loss: 0.5638082504272461\n",
            "Epoch: 0, iteración;   2530 de 7745, Loss: 0.5105412483215332\n",
            "Epoch: 0, iteración;   2540 de 7745, Loss: 0.4597804546356201\n",
            "Epoch: 0, iteración;   2550 de 7745, Loss: 0.5259029388427734\n",
            "Epoch: 0, iteración;   2560 de 7745, Loss: 0.48235340118408204\n",
            "Epoch: 0, iteración;   2570 de 7745, Loss: 0.5413288116455078\n",
            "Epoch: 0, iteración;   2580 de 7745, Loss: 0.4623570442199707\n",
            "Epoch: 0, iteración;   2590 de 7745, Loss: 0.42261381149291993\n",
            "Epoch: 0, iteración;   2600 de 7745, Loss: 0.5617879867553711\n",
            "Epoch: 0, iteración;   2610 de 7745, Loss: 0.5230175018310547\n",
            "Epoch: 0, iteración;   2620 de 7745, Loss: 0.5126978397369385\n",
            "Epoch: 0, iteración;   2630 de 7745, Loss: 0.5781462669372559\n",
            "Epoch: 0, iteración;   2640 de 7745, Loss: 0.47205328941345215\n",
            "Epoch: 0, iteración;   2650 de 7745, Loss: 0.5415228843688965\n",
            "Epoch: 0, iteración;   2660 de 7745, Loss: 0.46224374771118165\n",
            "Epoch: 0, iteración;   2670 de 7745, Loss: 0.5788134098052978\n",
            "Epoch: 0, iteración;   2680 de 7745, Loss: 0.47815423011779784\n",
            "Epoch: 0, iteración;   2690 de 7745, Loss: 0.4806560516357422\n",
            "Epoch: 0, iteración;   2700 de 7745, Loss: 0.5928354740142823\n",
            "Epoch: 0, iteración;   2710 de 7745, Loss: 0.38089861869812014\n",
            "Epoch: 0, iteración;   2720 de 7745, Loss: 0.5111637115478516\n",
            "Epoch: 0, iteración;   2730 de 7745, Loss: 0.5395065784454346\n",
            "Epoch: 0, iteración;   2740 de 7745, Loss: 0.5372573375701905\n",
            "Epoch: 0, iteración;   2750 de 7745, Loss: 0.5384880065917969\n",
            "Epoch: 0, iteración;   2760 de 7745, Loss: 0.5028398036956787\n",
            "Epoch: 0, iteración;   2770 de 7745, Loss: 0.5312231063842774\n",
            "Epoch: 0, iteración;   2780 de 7745, Loss: 0.4520692825317383\n",
            "Epoch: 0, iteración;   2790 de 7745, Loss: 0.5936033725738525\n",
            "Epoch: 0, iteración;   2800 de 7745, Loss: 0.48717041015625\n",
            "Epoch: 0, iteración;   2810 de 7745, Loss: 0.4645251274108887\n",
            "Epoch: 0, iteración;   2820 de 7745, Loss: 0.4375598907470703\n",
            "Epoch: 0, iteración;   2830 de 7745, Loss: 0.4661897659301758\n",
            "Epoch: 0, iteración;   2840 de 7745, Loss: 0.5722373962402344\n",
            "Epoch: 0, iteración;   2850 de 7745, Loss: 0.4217127799987793\n",
            "Epoch: 0, iteración;   2860 de 7745, Loss: 0.4191134452819824\n",
            "Epoch: 0, iteración;   2870 de 7745, Loss: 0.5580991744995117\n",
            "Epoch: 0, iteración;   2880 de 7745, Loss: 0.5199277400970459\n",
            "Epoch: 0, iteración;   2890 de 7745, Loss: 0.3926578998565674\n",
            "Epoch: 0, iteración;   2900 de 7745, Loss: 0.5054812431335449\n",
            "Epoch: 0, iteración;   2910 de 7745, Loss: 0.622825813293457\n",
            "Epoch: 0, iteración;   2920 de 7745, Loss: 0.4360322952270508\n",
            "Epoch: 0, iteración;   2930 de 7745, Loss: 0.5994218826293946\n",
            "Epoch: 0, iteración;   2940 de 7745, Loss: 0.5053012371063232\n",
            "Epoch: 0, iteración;   2950 de 7745, Loss: 0.6662224769592285\n",
            "Epoch: 0, iteración;   2960 de 7745, Loss: 0.5466012477874755\n",
            "Epoch: 0, iteración;   2970 de 7745, Loss: 0.5158402442932128\n",
            "Epoch: 0, iteración;   2980 de 7745, Loss: 0.5499054431915283\n",
            "Epoch: 0, iteración;   2990 de 7745, Loss: 0.4705200672149658\n",
            "Epoch: 0, iteración;   3000 de 7745, Loss: 0.4214629173278809\n",
            "Epoch: 0, iteración;   3010 de 7745, Loss: 0.501923656463623\n",
            "Epoch: 0, iteración;   3020 de 7745, Loss: 0.47715225219726565\n",
            "Epoch: 0, iteración;   3030 de 7745, Loss: 0.4687808036804199\n",
            "Epoch: 0, iteración;   3040 de 7745, Loss: 0.47933597564697267\n",
            "Epoch: 0, iteración;   3050 de 7745, Loss: 0.48087358474731445\n",
            "Epoch: 0, iteración;   3060 de 7745, Loss: 0.5436174869537354\n",
            "Epoch: 0, iteración;   3070 de 7745, Loss: 0.5234487056732178\n",
            "Epoch: 0, iteración;   3080 de 7745, Loss: 0.4802103042602539\n",
            "Epoch: 0, iteración;   3090 de 7745, Loss: 0.5048205852508545\n",
            "Epoch: 0, iteración;   3100 de 7745, Loss: 0.4944176197052002\n",
            "Epoch: 0, iteración;   3110 de 7745, Loss: 0.5645742893218995\n",
            "Epoch: 0, iteración;   3120 de 7745, Loss: 0.5954416751861572\n",
            "Epoch: 0, iteración;   3130 de 7745, Loss: 0.47648916244506834\n",
            "Epoch: 0, iteración;   3140 de 7745, Loss: 0.506834888458252\n",
            "Epoch: 0, iteración;   3150 de 7745, Loss: 0.5548175811767578\n",
            "Epoch: 0, iteración;   3160 de 7745, Loss: 0.5182963371276855\n",
            "Epoch: 0, iteración;   3170 de 7745, Loss: 0.45067596435546875\n",
            "Epoch: 0, iteración;   3180 de 7745, Loss: 0.5931129455566406\n",
            "Epoch: 0, iteración;   3190 de 7745, Loss: 0.627522325515747\n",
            "Epoch: 0, iteración;   3200 de 7745, Loss: 0.5104503631591797\n",
            "Epoch: 0, iteración;   3210 de 7745, Loss: 0.4712634563446045\n",
            "Epoch: 0, iteración;   3220 de 7745, Loss: 0.5290488719940185\n",
            "Epoch: 0, iteración;   3230 de 7745, Loss: 0.45923004150390623\n",
            "Epoch: 0, iteración;   3240 de 7745, Loss: 0.40802969932556155\n",
            "Epoch: 0, iteración;   3250 de 7745, Loss: 0.4053187370300293\n",
            "Epoch: 0, iteración;   3260 de 7745, Loss: 0.5596517562866211\n",
            "Epoch: 0, iteración;   3270 de 7745, Loss: 0.4496142387390137\n",
            "Epoch: 0, iteración;   3280 de 7745, Loss: 0.4623504638671875\n",
            "Epoch: 0, iteración;   3290 de 7745, Loss: 0.5555693626403808\n",
            "Epoch: 0, iteración;   3300 de 7745, Loss: 0.5225155353546143\n",
            "Epoch: 0, iteración;   3310 de 7745, Loss: 0.5127463340759277\n",
            "Epoch: 0, iteración;   3320 de 7745, Loss: 0.6059837818145752\n",
            "Epoch: 0, iteración;   3330 de 7745, Loss: 0.5292800426483154\n",
            "Epoch: 0, iteración;   3340 de 7745, Loss: 0.5418047428131103\n",
            "Epoch: 0, iteración;   3350 de 7745, Loss: 0.5683075904846191\n",
            "Epoch: 0, iteración;   3360 de 7745, Loss: 0.4382468700408936\n",
            "Epoch: 0, iteración;   3370 de 7745, Loss: 0.4329056739807129\n",
            "Epoch: 0, iteración;   3380 de 7745, Loss: 0.4765148162841797\n",
            "Epoch: 0, iteración;   3390 de 7745, Loss: 0.45635390281677246\n",
            "Epoch: 0, iteración;   3400 de 7745, Loss: 0.6143052577972412\n",
            "Epoch: 0, iteración;   3410 de 7745, Loss: 0.4771583557128906\n",
            "Epoch: 0, iteración;   3420 de 7745, Loss: 0.5579376697540284\n",
            "Epoch: 0, iteración;   3430 de 7745, Loss: 0.514299726486206\n",
            "Epoch: 0, iteración;   3440 de 7745, Loss: 0.43622894287109376\n",
            "Epoch: 0, iteración;   3450 de 7745, Loss: 0.464566707611084\n",
            "Epoch: 0, iteración;   3460 de 7745, Loss: 0.44426493644714354\n",
            "Epoch: 0, iteración;   3470 de 7745, Loss: 0.4569092750549316\n",
            "Epoch: 0, iteración;   3480 de 7745, Loss: 0.6754971027374268\n",
            "Epoch: 0, iteración;   3490 de 7745, Loss: 0.5283708572387695\n",
            "Epoch: 0, iteración;   3500 de 7745, Loss: 0.5256377220153808\n",
            "Epoch: 0, iteración;   3510 de 7745, Loss: 0.4548630237579346\n",
            "Epoch: 0, iteración;   3520 de 7745, Loss: 0.511803674697876\n",
            "Epoch: 0, iteración;   3530 de 7745, Loss: 0.5711227893829346\n",
            "Epoch: 0, iteración;   3540 de 7745, Loss: 0.5411813259124756\n",
            "Epoch: 0, iteración;   3550 de 7745, Loss: 0.6205446243286132\n",
            "Epoch: 0, iteración;   3560 de 7745, Loss: 0.4027611255645752\n",
            "Epoch: 0, iteración;   3570 de 7745, Loss: 0.5494577407836914\n",
            "Epoch: 0, iteración;   3580 de 7745, Loss: 0.514939260482788\n",
            "Epoch: 0, iteración;   3590 de 7745, Loss: 0.4730010986328125\n",
            "Epoch: 0, iteración;   3600 de 7745, Loss: 0.5838426113128662\n",
            "Epoch: 0, iteración;   3610 de 7745, Loss: 0.5206913948059082\n",
            "Epoch: 0, iteración;   3620 de 7745, Loss: 0.4490043163299561\n",
            "Epoch: 0, iteración;   3630 de 7745, Loss: 0.5723947048187256\n",
            "Epoch: 0, iteración;   3640 de 7745, Loss: 0.4499797344207764\n",
            "Epoch: 0, iteración;   3650 de 7745, Loss: 0.5750591278076171\n",
            "Epoch: 0, iteración;   3660 de 7745, Loss: 0.4288750648498535\n",
            "Epoch: 0, iteración;   3670 de 7745, Loss: 0.5080804824829102\n",
            "Epoch: 0, iteración;   3680 de 7745, Loss: 0.4962620258331299\n",
            "Epoch: 0, iteración;   3690 de 7745, Loss: 0.4708423137664795\n",
            "Epoch: 0, iteración;   3700 de 7745, Loss: 0.5292820930480957\n",
            "Epoch: 0, iteración;   3710 de 7745, Loss: 0.554832124710083\n",
            "Epoch: 0, iteración;   3720 de 7745, Loss: 0.44086246490478515\n",
            "Epoch: 0, iteración;   3730 de 7745, Loss: 0.41583571434020994\n",
            "Epoch: 0, iteración;   3740 de 7745, Loss: 0.4852872371673584\n",
            "Epoch: 0, iteración;   3750 de 7745, Loss: 0.4265298843383789\n",
            "Epoch: 0, iteración;   3760 de 7745, Loss: 0.5417331695556641\n",
            "Epoch: 0, iteración;   3770 de 7745, Loss: 0.5147431850433349\n",
            "Epoch: 0, iteración;   3780 de 7745, Loss: 0.5117880821228027\n",
            "Epoch: 0, iteración;   3790 de 7745, Loss: 0.5315237522125245\n",
            "Epoch: 0, iteración;   3800 de 7745, Loss: 0.5371055603027344\n",
            "Epoch: 0, iteración;   3810 de 7745, Loss: 0.544105052947998\n",
            "Epoch: 0, iteración;   3820 de 7745, Loss: 0.5157113552093506\n",
            "Epoch: 0, iteración;   3830 de 7745, Loss: 0.5333938598632812\n",
            "Epoch: 0, iteración;   3840 de 7745, Loss: 0.5670862674713135\n",
            "Epoch: 0, iteración;   3850 de 7745, Loss: 0.41918792724609377\n",
            "Epoch: 0, iteración;   3860 de 7745, Loss: 0.5392744064331054\n",
            "Epoch: 0, iteración;   3870 de 7745, Loss: 0.4255338668823242\n",
            "Epoch: 0, iteración;   3880 de 7745, Loss: 0.5204569816589355\n",
            "Epoch: 0, iteración;   3890 de 7745, Loss: 0.49872307777404784\n",
            "Epoch: 0, iteración;   3900 de 7745, Loss: 0.49448118209838865\n",
            "Epoch: 0, iteración;   3910 de 7745, Loss: 0.5329164981842041\n",
            "Epoch: 0, iteración;   3920 de 7745, Loss: 0.473650598526001\n",
            "Epoch: 0, iteración;   3930 de 7745, Loss: 0.5242366790771484\n",
            "Epoch: 0, iteración;   3940 de 7745, Loss: 0.5371061325073242\n",
            "Epoch: 0, iteración;   3950 de 7745, Loss: 0.6208463191986084\n",
            "Epoch: 0, iteración;   3960 de 7745, Loss: 0.502559232711792\n",
            "Epoch: 0, iteración;   3970 de 7745, Loss: 0.5690652370452881\n",
            "Epoch: 0, iteración;   3980 de 7745, Loss: 0.45831003189086916\n",
            "Epoch: 0, iteración;   3990 de 7745, Loss: 0.6356736183166504\n",
            "Epoch: 0, iteración;   4000 de 7745, Loss: 0.43516125679016116\n",
            "Epoch: 0, iteración;   4010 de 7745, Loss: 0.4416797161102295\n",
            "Epoch: 0, iteración;   4020 de 7745, Loss: 0.504246711730957\n",
            "Epoch: 0, iteración;   4030 de 7745, Loss: 0.5550922393798828\n",
            "Epoch: 0, iteración;   4040 de 7745, Loss: 0.6032284736633301\n",
            "Epoch: 0, iteración;   4050 de 7745, Loss: 0.4803328990936279\n",
            "Epoch: 0, iteración;   4060 de 7745, Loss: 0.5463285446166992\n",
            "Epoch: 0, iteración;   4070 de 7745, Loss: 0.44690351486206054\n",
            "Epoch: 0, iteración;   4080 de 7745, Loss: 0.5386953830718995\n",
            "Epoch: 0, iteración;   4090 de 7745, Loss: 0.5178863048553467\n",
            "Epoch: 0, iteración;   4100 de 7745, Loss: 0.43998193740844727\n",
            "Epoch: 0, iteración;   4110 de 7745, Loss: 0.4265045166015625\n",
            "Epoch: 0, iteración;   4120 de 7745, Loss: 0.5092663764953613\n",
            "Epoch: 0, iteración;   4130 de 7745, Loss: 0.3426738023757935\n",
            "Epoch: 0, iteración;   4140 de 7745, Loss: 0.45547075271606446\n",
            "Epoch: 0, iteración;   4150 de 7745, Loss: 0.6144459247589111\n",
            "Epoch: 0, iteración;   4160 de 7745, Loss: 0.46436333656311035\n",
            "Epoch: 0, iteración;   4170 de 7745, Loss: 0.5532373905181884\n",
            "Epoch: 0, iteración;   4180 de 7745, Loss: 0.5371758460998535\n",
            "Epoch: 0, iteración;   4190 de 7745, Loss: 0.39314219951629636\n",
            "Epoch: 0, iteración;   4200 de 7745, Loss: 0.6193119049072265\n",
            "Epoch: 0, iteración;   4210 de 7745, Loss: 0.5126180648803711\n",
            "Epoch: 0, iteración;   4220 de 7745, Loss: 0.5497892379760743\n",
            "Epoch: 0, iteración;   4230 de 7745, Loss: 0.5166879653930664\n",
            "Epoch: 0, iteración;   4240 de 7745, Loss: 0.4844083786010742\n",
            "Epoch: 0, iteración;   4250 de 7745, Loss: 0.5466176033020019\n",
            "Epoch: 0, iteración;   4260 de 7745, Loss: 0.4459789276123047\n",
            "Epoch: 0, iteración;   4270 de 7745, Loss: 0.5759096145629883\n",
            "Epoch: 0, iteración;   4280 de 7745, Loss: 0.44307565689086914\n",
            "Epoch: 0, iteración;   4290 de 7745, Loss: 0.4335069179534912\n",
            "Epoch: 0, iteración;   4300 de 7745, Loss: 0.47322721481323243\n",
            "Epoch: 0, iteración;   4310 de 7745, Loss: 0.5230402946472168\n",
            "Epoch: 0, iteración;   4320 de 7745, Loss: 0.5470329284667969\n",
            "Epoch: 0, iteración;   4330 de 7745, Loss: 0.5140544891357421\n",
            "Epoch: 0, iteración;   4340 de 7745, Loss: 0.5744186401367187\n",
            "Epoch: 0, iteración;   4350 de 7745, Loss: 0.5496655464172363\n",
            "Epoch: 0, iteración;   4360 de 7745, Loss: 0.4424309730529785\n",
            "Epoch: 0, iteración;   4370 de 7745, Loss: 0.47252817153930665\n",
            "Epoch: 0, iteración;   4380 de 7745, Loss: 0.5403779506683349\n",
            "Epoch: 0, iteración;   4390 de 7745, Loss: 0.5979765892028809\n",
            "Epoch: 0, iteración;   4400 de 7745, Loss: 0.5481545448303222\n",
            "Epoch: 0, iteración;   4410 de 7745, Loss: 0.6077797889709473\n",
            "Epoch: 0, iteración;   4420 de 7745, Loss: 0.5112149238586425\n",
            "Epoch: 0, iteración;   4430 de 7745, Loss: 0.5607614517211914\n",
            "Epoch: 0, iteración;   4440 de 7745, Loss: 0.5033030986785889\n",
            "Epoch: 0, iteración;   4450 de 7745, Loss: 0.4418745994567871\n",
            "Epoch: 0, iteración;   4460 de 7745, Loss: 0.48731188774108886\n",
            "Epoch: 0, iteración;   4470 de 7745, Loss: 0.5145511150360107\n",
            "Epoch: 0, iteración;   4480 de 7745, Loss: 0.4685369491577148\n",
            "Epoch: 0, iteración;   4490 de 7745, Loss: 0.7042632102966309\n",
            "Epoch: 0, iteración;   4500 de 7745, Loss: 0.6112573146820068\n",
            "Epoch: 0, iteración;   4510 de 7745, Loss: 0.4525935173034668\n",
            "Epoch: 0, iteración;   4520 de 7745, Loss: 0.5347323417663574\n",
            "Epoch: 0, iteración;   4530 de 7745, Loss: 0.5925281524658204\n",
            "Epoch: 0, iteración;   4540 de 7745, Loss: 0.5397245407104492\n",
            "Epoch: 0, iteración;   4550 de 7745, Loss: 0.5830343246459961\n",
            "Epoch: 0, iteración;   4560 de 7745, Loss: 0.5832637310028076\n",
            "Epoch: 0, iteración;   4570 de 7745, Loss: 0.4906118392944336\n",
            "Epoch: 0, iteración;   4580 de 7745, Loss: 0.4516860008239746\n",
            "Epoch: 0, iteración;   4590 de 7745, Loss: 0.5450015068054199\n",
            "Epoch: 0, iteración;   4600 de 7745, Loss: 0.4725622653961182\n",
            "Epoch: 0, iteración;   4610 de 7745, Loss: 0.49129066467285154\n",
            "Epoch: 0, iteración;   4620 de 7745, Loss: 0.6133792400360107\n",
            "Epoch: 0, iteración;   4630 de 7745, Loss: 0.48645601272583006\n",
            "Epoch: 0, iteración;   4640 de 7745, Loss: 0.42821617126464845\n",
            "Epoch: 0, iteración;   4650 de 7745, Loss: 0.5835664749145508\n",
            "Epoch: 0, iteración;   4660 de 7745, Loss: 0.4652981758117676\n",
            "Epoch: 0, iteración;   4670 de 7745, Loss: 0.49698476791381835\n",
            "Epoch: 0, iteración;   4680 de 7745, Loss: 0.4835451602935791\n",
            "Epoch: 0, iteración;   4690 de 7745, Loss: 0.4536628246307373\n",
            "Epoch: 0, iteración;   4700 de 7745, Loss: 0.45599923133850095\n",
            "Epoch: 0, iteración;   4710 de 7745, Loss: 0.5006849288940429\n",
            "Epoch: 0, iteración;   4720 de 7745, Loss: 0.6132245063781738\n",
            "Epoch: 0, iteración;   4730 de 7745, Loss: 0.41767268180847167\n",
            "Epoch: 0, iteración;   4740 de 7745, Loss: 0.5762056827545166\n",
            "Epoch: 0, iteración;   4750 de 7745, Loss: 0.5085324764251709\n",
            "Epoch: 0, iteración;   4760 de 7745, Loss: 0.475267219543457\n",
            "Epoch: 0, iteración;   4770 de 7745, Loss: 0.5043764114379883\n",
            "Epoch: 0, iteración;   4780 de 7745, Loss: 0.5072061061859131\n",
            "Epoch: 0, iteración;   4790 de 7745, Loss: 0.538653039932251\n",
            "Epoch: 0, iteración;   4800 de 7745, Loss: 0.49676761627197263\n",
            "Epoch: 0, iteración;   4810 de 7745, Loss: 0.4893059730529785\n",
            "Epoch: 0, iteración;   4820 de 7745, Loss: 0.5594232082366943\n",
            "Epoch: 0, iteración;   4830 de 7745, Loss: 0.5239320278167725\n",
            "Epoch: 0, iteración;   4840 de 7745, Loss: 0.4212672233581543\n",
            "Epoch: 0, iteración;   4850 de 7745, Loss: 0.5267877578735352\n",
            "Epoch: 0, iteración;   4860 de 7745, Loss: 0.5295618534088135\n",
            "Epoch: 0, iteración;   4870 de 7745, Loss: 0.4893461227416992\n",
            "Epoch: 0, iteración;   4880 de 7745, Loss: 0.4633542537689209\n",
            "Epoch: 0, iteración;   4890 de 7745, Loss: 0.4519513607025146\n",
            "Epoch: 0, iteración;   4900 de 7745, Loss: 0.44384188652038575\n",
            "Epoch: 0, iteración;   4910 de 7745, Loss: 0.54934720993042\n",
            "Epoch: 0, iteración;   4920 de 7745, Loss: 0.5957838535308838\n",
            "Epoch: 0, iteración;   4930 de 7745, Loss: 0.6422450542449951\n",
            "Epoch: 0, iteración;   4940 de 7745, Loss: 0.5546032905578613\n",
            "Epoch: 0, iteración;   4950 de 7745, Loss: 0.5350184440612793\n",
            "Epoch: 0, iteración;   4960 de 7745, Loss: 0.5691184520721435\n",
            "Epoch: 0, iteración;   4970 de 7745, Loss: 0.6080397605895996\n",
            "Epoch: 0, iteración;   4980 de 7745, Loss: 0.5437310695648193\n",
            "Epoch: 0, iteración;   4990 de 7745, Loss: 0.5001685142517089\n",
            "Epoch: 0, iteración;   5000 de 7745, Loss: 0.5256802558898925\n",
            "Epoch: 0, iteración;   5010 de 7745, Loss: 0.5350324630737304\n",
            "Epoch: 0, iteración;   5020 de 7745, Loss: 0.4620809555053711\n",
            "Epoch: 0, iteración;   5030 de 7745, Loss: 0.5347896099090577\n",
            "Epoch: 0, iteración;   5040 de 7745, Loss: 0.5622179985046387\n",
            "Epoch: 0, iteración;   5050 de 7745, Loss: 0.5339527130126953\n",
            "Epoch: 0, iteración;   5060 de 7745, Loss: 0.5119351863861084\n",
            "Epoch: 0, iteración;   5070 de 7745, Loss: 0.553514051437378\n",
            "Epoch: 0, iteración;   5080 de 7745, Loss: 0.4407991886138916\n",
            "Epoch: 0, iteración;   5090 de 7745, Loss: 0.526006555557251\n",
            "Epoch: 0, iteración;   5100 de 7745, Loss: 0.5756858348846435\n",
            "Epoch: 0, iteración;   5110 de 7745, Loss: 0.4780423641204834\n",
            "Epoch: 0, iteración;   5120 de 7745, Loss: 0.4499800205230713\n",
            "Epoch: 0, iteración;   5130 de 7745, Loss: 0.6471621513366699\n",
            "Epoch: 0, iteración;   5140 de 7745, Loss: 0.5709727764129638\n",
            "Epoch: 0, iteración;   5150 de 7745, Loss: 0.5919069766998291\n",
            "Epoch: 0, iteración;   5160 de 7745, Loss: 0.5485401630401612\n",
            "Epoch: 0, iteración;   5170 de 7745, Loss: 0.5584149360656738\n",
            "Epoch: 0, iteración;   5180 de 7745, Loss: 0.4700023174285889\n",
            "Epoch: 0, iteración;   5190 de 7745, Loss: 0.5363780498504639\n",
            "Epoch: 0, iteración;   5200 de 7745, Loss: 0.42174839973449707\n",
            "Epoch: 0, iteración;   5210 de 7745, Loss: 0.4281937122344971\n",
            "Epoch: 0, iteración;   5220 de 7745, Loss: 0.4907833576202393\n",
            "Epoch: 0, iteración;   5230 de 7745, Loss: 0.5479629516601563\n",
            "Epoch: 0, iteración;   5240 de 7745, Loss: 0.510774803161621\n",
            "Epoch: 0, iteración;   5250 de 7745, Loss: 0.46828451156616213\n",
            "Epoch: 0, iteración;   5260 de 7745, Loss: 0.6138802528381347\n",
            "Epoch: 0, iteración;   5270 de 7745, Loss: 0.5733316898345947\n",
            "Epoch: 0, iteración;   5280 de 7745, Loss: 0.5264901638031005\n",
            "Epoch: 0, iteración;   5290 de 7745, Loss: 0.514055871963501\n",
            "Epoch: 0, iteración;   5300 de 7745, Loss: 0.5769569396972656\n",
            "Epoch: 0, iteración;   5310 de 7745, Loss: 0.6007944107055664\n",
            "Epoch: 0, iteración;   5320 de 7745, Loss: 0.5085795879364013\n",
            "Epoch: 0, iteración;   5330 de 7745, Loss: 0.49277329444885254\n",
            "Epoch: 0, iteración;   5340 de 7745, Loss: 0.5608854293823242\n",
            "Epoch: 0, iteración;   5350 de 7745, Loss: 0.5153966903686523\n",
            "Epoch: 0, iteración;   5360 de 7745, Loss: 0.5472702503204345\n",
            "Epoch: 0, iteración;   5370 de 7745, Loss: 0.5978551864624023\n",
            "Epoch: 0, iteración;   5380 de 7745, Loss: 0.42339448928833007\n",
            "Epoch: 0, iteración;   5390 de 7745, Loss: 0.46459202766418456\n",
            "Epoch: 0, iteración;   5400 de 7745, Loss: 0.6667290687561035\n",
            "Epoch: 0, iteración;   5410 de 7745, Loss: 0.513459300994873\n",
            "Epoch: 0, iteración;   5420 de 7745, Loss: 0.5547823905944824\n",
            "Epoch: 0, iteración;   5430 de 7745, Loss: 0.49318609237670896\n",
            "Epoch: 0, iteración;   5440 de 7745, Loss: 0.48102340698242185\n",
            "Epoch: 0, iteración;   5450 de 7745, Loss: 0.5056098937988281\n",
            "Epoch: 0, iteración;   5460 de 7745, Loss: 0.5146856784820557\n",
            "Epoch: 0, iteración;   5470 de 7745, Loss: 0.46381316184997556\n",
            "Epoch: 0, iteración;   5480 de 7745, Loss: 0.37424654960632325\n",
            "Epoch: 0, iteración;   5490 de 7745, Loss: 0.6250359535217285\n",
            "Epoch: 0, iteración;   5500 de 7745, Loss: 0.44933300018310546\n",
            "Epoch: 0, iteración;   5510 de 7745, Loss: 0.5680088043212891\n",
            "Epoch: 0, iteración;   5520 de 7745, Loss: 0.5182089805603027\n",
            "Epoch: 0, iteración;   5530 de 7745, Loss: 0.5315413475036621\n",
            "Epoch: 0, iteración;   5540 de 7745, Loss: 0.49203829765319823\n",
            "Epoch: 0, iteración;   5550 de 7745, Loss: 0.5352256774902344\n",
            "Epoch: 0, iteración;   5560 de 7745, Loss: 0.5279110431671142\n",
            "Epoch: 0, iteración;   5570 de 7745, Loss: 0.47476940155029296\n",
            "Epoch: 0, iteración;   5580 de 7745, Loss: 0.5537266731262207\n",
            "Epoch: 0, iteración;   5590 de 7745, Loss: 0.5441409111022949\n",
            "Epoch: 0, iteración;   5600 de 7745, Loss: 0.5452918529510498\n",
            "Epoch: 0, iteración;   5610 de 7745, Loss: 0.4739189624786377\n",
            "Epoch: 0, iteración;   5620 de 7745, Loss: 0.7067197799682617\n",
            "Epoch: 0, iteración;   5630 de 7745, Loss: 0.48923306465148925\n",
            "Epoch: 0, iteración;   5640 de 7745, Loss: 0.5575367927551269\n",
            "Epoch: 0, iteración;   5650 de 7745, Loss: 0.5247230052947998\n",
            "Epoch: 0, iteración;   5660 de 7745, Loss: 0.5449110984802246\n",
            "Epoch: 0, iteración;   5670 de 7745, Loss: 0.48868570327758787\n",
            "Epoch: 0, iteración;   5680 de 7745, Loss: 0.45404815673828125\n",
            "Epoch: 0, iteración;   5690 de 7745, Loss: 0.7153586387634278\n",
            "Epoch: 0, iteración;   5700 de 7745, Loss: 0.4872274398803711\n",
            "Epoch: 0, iteración;   5710 de 7745, Loss: 0.48665628433227537\n",
            "Epoch: 0, iteración;   5720 de 7745, Loss: 0.45403203964233396\n",
            "Epoch: 0, iteración;   5730 de 7745, Loss: 0.5808645248413086\n",
            "Epoch: 0, iteración;   5740 de 7745, Loss: 0.4656227588653564\n",
            "Epoch: 0, iteración;   5750 de 7745, Loss: 0.5381300449371338\n",
            "Epoch: 0, iteración;   5760 de 7745, Loss: 0.5799808502197266\n",
            "Epoch: 0, iteración;   5770 de 7745, Loss: 0.49460363388061523\n",
            "Epoch: 0, iteración;   5780 de 7745, Loss: 0.5331990242004394\n",
            "Epoch: 0, iteración;   5790 de 7745, Loss: 0.5503865242004394\n",
            "Epoch: 0, iteración;   5800 de 7745, Loss: 0.490233039855957\n",
            "Epoch: 0, iteración;   5810 de 7745, Loss: 0.531858253479004\n",
            "Epoch: 0, iteración;   5820 de 7745, Loss: 0.48876171112060546\n",
            "Epoch: 0, iteración;   5830 de 7745, Loss: 0.4939265727996826\n",
            "Epoch: 0, iteración;   5840 de 7745, Loss: 0.5096148014068603\n",
            "Epoch: 0, iteración;   5850 de 7745, Loss: 0.662201976776123\n",
            "Epoch: 0, iteración;   5860 de 7745, Loss: 0.5962659835815429\n",
            "Epoch: 0, iteración;   5870 de 7745, Loss: 0.5086066246032714\n",
            "Epoch: 0, iteración;   5880 de 7745, Loss: 0.4016765594482422\n",
            "Epoch: 0, iteración;   5890 de 7745, Loss: 0.5923705101013184\n",
            "Epoch: 0, iteración;   5900 de 7745, Loss: 0.5491484642028809\n",
            "Epoch: 0, iteración;   5910 de 7745, Loss: 0.4667685508728027\n",
            "Epoch: 0, iteración;   5920 de 7745, Loss: 0.5109431743621826\n",
            "Epoch: 0, iteración;   5930 de 7745, Loss: 0.6452739715576172\n",
            "Epoch: 0, iteración;   5940 de 7745, Loss: 0.502783203125\n",
            "Epoch: 0, iteración;   5950 de 7745, Loss: 0.4827573776245117\n",
            "Epoch: 0, iteración;   5960 de 7745, Loss: 0.5773133754730224\n",
            "Epoch: 0, iteración;   5970 de 7745, Loss: 0.6182573318481446\n",
            "Epoch: 0, iteración;   5980 de 7745, Loss: 0.5579025745391846\n",
            "Epoch: 0, iteración;   5990 de 7745, Loss: 0.47395906448364256\n",
            "Epoch: 0, iteración;   6000 de 7745, Loss: 0.5309502124786377\n",
            "Epoch: 0, iteración;   6010 de 7745, Loss: 0.4458878993988037\n",
            "Epoch: 0, iteración;   6020 de 7745, Loss: 0.6039858341217041\n",
            "Epoch: 0, iteración;   6030 de 7745, Loss: 0.5833929061889649\n",
            "Epoch: 0, iteración;   6040 de 7745, Loss: 0.5638684749603271\n",
            "Epoch: 0, iteración;   6050 de 7745, Loss: 0.4787005424499512\n",
            "Epoch: 0, iteración;   6060 de 7745, Loss: 0.4948867321014404\n",
            "Epoch: 0, iteración;   6070 de 7745, Loss: 0.49689149856567383\n",
            "Epoch: 0, iteración;   6080 de 7745, Loss: 0.5292027950286865\n",
            "Epoch: 0, iteración;   6090 de 7745, Loss: 0.6343543529510498\n",
            "Epoch: 0, iteración;   6100 de 7745, Loss: 0.46111440658569336\n",
            "Epoch: 0, iteración;   6110 de 7745, Loss: 0.5841158866882324\n",
            "Epoch: 0, iteración;   6120 de 7745, Loss: 0.5284010887145996\n",
            "Epoch: 0, iteración;   6130 de 7745, Loss: 0.549463415145874\n",
            "Epoch: 0, iteración;   6140 de 7745, Loss: 0.49389400482177737\n",
            "Epoch: 0, iteración;   6150 de 7745, Loss: 0.5100874423980712\n",
            "Epoch: 0, iteración;   6160 de 7745, Loss: 0.5288373947143554\n",
            "Epoch: 0, iteración;   6170 de 7745, Loss: 0.5822057723999023\n",
            "Epoch: 0, iteración;   6180 de 7745, Loss: 0.48408236503601076\n",
            "Epoch: 0, iteración;   6190 de 7745, Loss: 0.511223316192627\n",
            "Epoch: 0, iteración;   6200 de 7745, Loss: 0.5789173126220704\n",
            "Epoch: 0, iteración;   6210 de 7745, Loss: 0.5558239936828613\n",
            "Epoch: 0, iteración;   6220 de 7745, Loss: 0.5154154777526856\n",
            "Epoch: 0, iteración;   6230 de 7745, Loss: 0.5770536422729492\n",
            "Epoch: 0, iteración;   6240 de 7745, Loss: 0.5684834003448487\n",
            "Epoch: 0, iteración;   6250 de 7745, Loss: 0.5485603332519531\n",
            "Epoch: 0, iteración;   6260 de 7745, Loss: 0.5761224746704101\n",
            "Epoch: 0, iteración;   6270 de 7745, Loss: 0.5635302543640137\n",
            "Epoch: 0, iteración;   6280 de 7745, Loss: 0.5119718074798584\n",
            "Epoch: 0, iteración;   6290 de 7745, Loss: 0.39851562976837157\n",
            "Epoch: 0, iteración;   6300 de 7745, Loss: 0.5367324829101563\n",
            "Epoch: 0, iteración;   6310 de 7745, Loss: 0.48728628158569337\n",
            "Epoch: 0, iteración;   6320 de 7745, Loss: 0.5907758235931396\n",
            "Epoch: 0, iteración;   6330 de 7745, Loss: 0.5754238128662109\n",
            "Epoch: 0, iteración;   6340 de 7745, Loss: 0.5729952335357666\n",
            "Epoch: 0, iteración;   6350 de 7745, Loss: 0.48209681510925295\n",
            "Epoch: 0, iteración;   6360 de 7745, Loss: 0.517707633972168\n",
            "Epoch: 0, iteración;   6370 de 7745, Loss: 0.45201797485351564\n",
            "Epoch: 0, iteración;   6380 de 7745, Loss: 0.5207996368408203\n",
            "Epoch: 0, iteración;   6390 de 7745, Loss: 0.606078052520752\n",
            "Epoch: 0, iteración;   6400 de 7745, Loss: 0.5244611263275146\n",
            "Epoch: 0, iteración;   6410 de 7745, Loss: 0.4988986015319824\n",
            "Epoch: 0, iteración;   6420 de 7745, Loss: 0.5224554538726807\n",
            "Epoch: 0, iteración;   6430 de 7745, Loss: 0.5046539783477784\n",
            "Epoch: 0, iteración;   6440 de 7745, Loss: 0.48053774833679197\n",
            "Epoch: 0, iteración;   6450 de 7745, Loss: 0.45708513259887695\n",
            "Epoch: 0, iteración;   6460 de 7745, Loss: 0.5411995887756348\n",
            "Epoch: 0, iteración;   6470 de 7745, Loss: 0.6124299049377442\n",
            "Epoch: 0, iteración;   6480 de 7745, Loss: 0.5480492115020752\n",
            "Epoch: 0, iteración;   6490 de 7745, Loss: 0.48506779670715333\n",
            "Epoch: 0, iteración;   6500 de 7745, Loss: 0.4753128528594971\n",
            "Epoch: 0, iteración;   6510 de 7745, Loss: 0.5129603862762451\n",
            "Epoch: 0, iteración;   6520 de 7745, Loss: 0.5835155963897705\n",
            "Epoch: 0, iteración;   6530 de 7745, Loss: 0.5270195007324219\n",
            "Epoch: 0, iteración;   6540 de 7745, Loss: 0.5697691440582275\n",
            "Epoch: 0, iteración;   6550 de 7745, Loss: 0.4530289649963379\n",
            "Epoch: 0, iteración;   6560 de 7745, Loss: 0.4214653015136719\n",
            "Epoch: 0, iteración;   6570 de 7745, Loss: 0.5048591613769531\n",
            "Epoch: 0, iteración;   6580 de 7745, Loss: 0.47614364624023436\n",
            "Epoch: 0, iteración;   6590 de 7745, Loss: 0.5161029815673828\n",
            "Epoch: 0, iteración;   6600 de 7745, Loss: 0.5571527004241943\n",
            "Epoch: 0, iteración;   6610 de 7745, Loss: 0.47597203254699705\n",
            "Epoch: 0, iteración;   6620 de 7745, Loss: 0.4977259159088135\n",
            "Epoch: 0, iteración;   6630 de 7745, Loss: 0.5035462379455566\n",
            "Epoch: 0, iteración;   6640 de 7745, Loss: 0.5485724449157715\n",
            "Epoch: 0, iteración;   6650 de 7745, Loss: 0.5277477264404297\n",
            "Epoch: 0, iteración;   6660 de 7745, Loss: 0.5383918762207032\n",
            "Epoch: 0, iteración;   6670 de 7745, Loss: 0.46456260681152345\n",
            "Epoch: 0, iteración;   6680 de 7745, Loss: 0.5616859436035156\n",
            "Epoch: 0, iteración;   6690 de 7745, Loss: 0.5455131530761719\n",
            "Epoch: 0, iteración;   6700 de 7745, Loss: 0.6183398246765137\n",
            "Epoch: 0, iteración;   6710 de 7745, Loss: 0.4553221702575684\n",
            "Epoch: 0, iteración;   6720 de 7745, Loss: 0.5562061309814453\n",
            "Epoch: 0, iteración;   6730 de 7745, Loss: 0.4358846187591553\n",
            "Epoch: 0, iteración;   6740 de 7745, Loss: 0.643888282775879\n",
            "Epoch: 0, iteración;   6750 de 7745, Loss: 0.5121711730957031\n",
            "Epoch: 0, iteración;   6760 de 7745, Loss: 0.6338912963867187\n",
            "Epoch: 0, iteración;   6770 de 7745, Loss: 0.4918232440948486\n",
            "Epoch: 0, iteración;   6780 de 7745, Loss: 0.5605457782745361\n",
            "Epoch: 0, iteración;   6790 de 7745, Loss: 0.645639705657959\n",
            "Epoch: 0, iteración;   6800 de 7745, Loss: 0.4645551204681396\n",
            "Epoch: 0, iteración;   6810 de 7745, Loss: 0.5683973789215088\n",
            "Epoch: 0, iteración;   6820 de 7745, Loss: 0.5160553455352783\n",
            "Epoch: 0, iteración;   6830 de 7745, Loss: 0.5171799659729004\n",
            "Epoch: 0, iteración;   6840 de 7745, Loss: 0.5719165802001953\n",
            "Epoch: 0, iteración;   6850 de 7745, Loss: 0.5270113468170166\n",
            "Epoch: 0, iteración;   6860 de 7745, Loss: 0.572389793395996\n",
            "Epoch: 0, iteración;   6870 de 7745, Loss: 0.4706662654876709\n",
            "Epoch: 0, iteración;   6880 de 7745, Loss: 0.4513216972351074\n",
            "Epoch: 0, iteración;   6890 de 7745, Loss: 0.555180025100708\n",
            "Epoch: 0, iteración;   6900 de 7745, Loss: 0.6485669136047363\n",
            "Epoch: 0, iteración;   6910 de 7745, Loss: 0.5323302745819092\n",
            "Epoch: 0, iteración;   6920 de 7745, Loss: 0.5115894317626953\n",
            "Epoch: 0, iteración;   6930 de 7745, Loss: 0.46240234375\n",
            "Epoch: 0, iteración;   6940 de 7745, Loss: 0.5656049728393555\n",
            "Epoch: 0, iteración;   6950 de 7745, Loss: 0.5547864437103271\n",
            "Epoch: 0, iteración;   6960 de 7745, Loss: 0.5173011779785156\n",
            "Epoch: 0, iteración;   6970 de 7745, Loss: 0.6410309314727783\n",
            "Epoch: 0, iteración;   6980 de 7745, Loss: 0.544337797164917\n",
            "Epoch: 0, iteración;   6990 de 7745, Loss: 0.5788050174713135\n",
            "Epoch: 0, iteración;   7000 de 7745, Loss: 0.6564161300659179\n",
            "Epoch: 0, iteración;   7010 de 7745, Loss: 0.5179189682006836\n",
            "Epoch: 0, iteración;   7020 de 7745, Loss: 0.5010685920715332\n",
            "Epoch: 0, iteración;   7030 de 7745, Loss: 0.5540835857391357\n",
            "Epoch: 0, iteración;   7040 de 7745, Loss: 0.4674886703491211\n",
            "Epoch: 0, iteración;   7050 de 7745, Loss: 0.7256260871887207\n",
            "Epoch: 0, iteración;   7060 de 7745, Loss: 0.5146040916442871\n",
            "Epoch: 0, iteración;   7070 de 7745, Loss: 0.5786751747131348\n",
            "Epoch: 0, iteración;   7080 de 7745, Loss: 0.5748728275299072\n",
            "Epoch: 0, iteración;   7090 de 7745, Loss: 0.5024335384368896\n",
            "Epoch: 0, iteración;   7100 de 7745, Loss: 0.40763168334960936\n",
            "Epoch: 0, iteración;   7110 de 7745, Loss: 0.5893539428710938\n",
            "Epoch: 0, iteración;   7120 de 7745, Loss: 0.47626485824584963\n",
            "Epoch: 0, iteración;   7130 de 7745, Loss: 0.5412574291229248\n",
            "Epoch: 0, iteración;   7140 de 7745, Loss: 0.48763790130615237\n",
            "Epoch: 0, iteración;   7150 de 7745, Loss: 0.6252970218658447\n",
            "Epoch: 0, iteración;   7160 de 7745, Loss: 0.5758895874023438\n",
            "Epoch: 0, iteración;   7170 de 7745, Loss: 0.5316134452819824\n",
            "Epoch: 0, iteración;   7180 de 7745, Loss: 0.36060500144958496\n",
            "Epoch: 0, iteración;   7190 de 7745, Loss: 0.5669110774993896\n",
            "Epoch: 0, iteración;   7200 de 7745, Loss: 0.5394117355346679\n",
            "Epoch: 0, iteración;   7210 de 7745, Loss: 0.5076828002929688\n",
            "Epoch: 0, iteración;   7220 de 7745, Loss: 0.4562234878540039\n",
            "Epoch: 0, iteración;   7230 de 7745, Loss: 0.5123898983001709\n",
            "Epoch: 0, iteración;   7240 de 7745, Loss: 0.46390690803527834\n",
            "Epoch: 0, iteración;   7250 de 7745, Loss: 0.5784254550933838\n",
            "Epoch: 0, iteración;   7260 de 7745, Loss: 0.5647166728973388\n",
            "Epoch: 0, iteración;   7270 de 7745, Loss: 0.5187940120697021\n",
            "Epoch: 0, iteración;   7280 de 7745, Loss: 0.5008797168731689\n",
            "Epoch: 0, iteración;   7290 de 7745, Loss: 0.6294540882110595\n",
            "Epoch: 0, iteración;   7300 de 7745, Loss: 0.5332674026489258\n",
            "Epoch: 0, iteración;   7310 de 7745, Loss: 0.44127597808837893\n",
            "Epoch: 0, iteración;   7320 de 7745, Loss: 0.5033422470092773\n",
            "Epoch: 0, iteración;   7330 de 7745, Loss: 0.5270850658416748\n",
            "Epoch: 0, iteración;   7340 de 7745, Loss: 0.5059899806976318\n",
            "Epoch: 0, iteración;   7350 de 7745, Loss: 0.5290750026702881\n",
            "Epoch: 0, iteración;   7360 de 7745, Loss: 0.5599407196044922\n",
            "Epoch: 0, iteración;   7370 de 7745, Loss: 0.41678271293640134\n",
            "Epoch: 0, iteración;   7380 de 7745, Loss: 0.5281618595123291\n",
            "Epoch: 0, iteración;   7390 de 7745, Loss: 0.45396084785461427\n",
            "Epoch: 0, iteración;   7400 de 7745, Loss: 0.5983119010925293\n",
            "Epoch: 0, iteración;   7410 de 7745, Loss: 0.5414943218231201\n",
            "Epoch: 0, iteración;   7420 de 7745, Loss: 0.613769817352295\n",
            "Epoch: 0, iteración;   7430 de 7745, Loss: 0.5840281486511231\n",
            "Epoch: 0, iteración;   7440 de 7745, Loss: 0.5740112781524658\n",
            "Epoch: 0, iteración;   7450 de 7745, Loss: 0.5104681968688964\n",
            "Epoch: 0, iteración;   7460 de 7745, Loss: 0.5622767448425293\n",
            "Epoch: 0, iteración;   7470 de 7745, Loss: 0.4352989196777344\n",
            "Epoch: 0, iteración;   7480 de 7745, Loss: 0.6100756645202636\n",
            "Epoch: 0, iteración;   7490 de 7745, Loss: 0.5805740356445312\n",
            "Epoch: 0, iteración;   7500 de 7745, Loss: 0.5182511806488037\n",
            "Epoch: 0, iteración;   7510 de 7745, Loss: 0.5867616176605225\n",
            "Epoch: 0, iteración;   7520 de 7745, Loss: 0.4793053150177002\n",
            "Epoch: 0, iteración;   7530 de 7745, Loss: 0.4583254814147949\n",
            "Epoch: 0, iteración;   7540 de 7745, Loss: 0.4635061740875244\n",
            "Epoch: 0, iteración;   7550 de 7745, Loss: 0.469144868850708\n",
            "Epoch: 0, iteración;   7560 de 7745, Loss: 0.45660600662231443\n",
            "Epoch: 0, iteración;   7570 de 7745, Loss: 0.5900537014007569\n",
            "Epoch: 0, iteración;   7580 de 7745, Loss: 0.5154536247253418\n",
            "Epoch: 0, iteración;   7590 de 7745, Loss: 0.556118106842041\n",
            "Epoch: 0, iteración;   7600 de 7745, Loss: 0.5229254722595215\n",
            "Epoch: 0, iteración;   7610 de 7745, Loss: 0.4501189231872559\n",
            "Epoch: 0, iteración;   7620 de 7745, Loss: 0.3657487392425537\n",
            "Epoch: 0, iteración;   7630 de 7745, Loss: 0.45827488899230956\n",
            "Epoch: 0, iteración;   7640 de 7745, Loss: 0.5962297439575195\n",
            "Epoch: 0, iteración;   7650 de 7745, Loss: 0.5316993236541748\n",
            "Epoch: 0, iteración;   7660 de 7745, Loss: 0.5246943473815918\n",
            "Epoch: 0, iteración;   7670 de 7745, Loss: 0.6280618667602539\n",
            "Epoch: 0, iteración;   7680 de 7745, Loss: 0.5828886508941651\n",
            "Epoch: 0, iteración;   7690 de 7745, Loss: 0.5943568229675293\n",
            "Epoch: 0, iteración;   7700 de 7745, Loss: 0.5385196685791016\n",
            "Epoch: 0, iteración;   7710 de 7745, Loss: 0.5592916488647461\n",
            "Epoch: 0, iteración;   7720 de 7745, Loss: 0.5206255912780762\n",
            "Epoch: 0, iteración;   7730 de 7745, Loss: 0.4688680648803711\n",
            "Epoch: 0, iteración;   7740 de 7745, Loss: 0.4075779914855957\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainRoberta(epoch)"
      ],
      "id": "AqDWniyrjv_h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7GJKEaCjv_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba783a04-c1eb-44b4-e1d6-9beae1f8958f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_80.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "id": "b7GJKEaCjv_h"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLa8eXRZj0Hi"
      },
      "source": [
        "##### Evaluación del modelo"
      ],
      "id": "iLa8eXRZj0Hi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEF8rxp_j0Hj"
      },
      "outputs": [],
      "source": [
        "def validationRoberta(epoch):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    num_iteraciones = len(testing_loader)\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device)\n",
        "            mask = data['mask'].to(device)\n",
        "            token_type_ids = data['token_type_ids'].to(device)\n",
        "            targets = data['target'].to(device)\n",
        "\n",
        "            print(f\"Iteración: {i:6} de {num_iteraciones}\")\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "id": "oEF8rxp_j0Hj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "Vg4UBEwKj0Hj"
      },
      "id": "Vg4UBEwKj0Hj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbvE14p0j0Hj"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_80.pth\"):\n",
        "  model = RobertaClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_80.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_80.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "id": "jbvE14p0j0Hj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97c9f69-a2a3-4bb0-e8e0-aeab42aa2d21",
        "id": "bjfaIc9ij0Hj"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración:      0 de 243\n",
            "Iteración:      1 de 243\n",
            "Iteración:      2 de 243\n",
            "Iteración:      3 de 243\n",
            "Iteración:      4 de 243\n",
            "Iteración:      5 de 243\n",
            "Iteración:      6 de 243\n",
            "Iteración:      7 de 243\n",
            "Iteración:      8 de 243\n",
            "Iteración:      9 de 243\n",
            "Iteración:     10 de 243\n",
            "Iteración:     11 de 243\n",
            "Iteración:     12 de 243\n",
            "Iteración:     13 de 243\n",
            "Iteración:     14 de 243\n",
            "Iteración:     15 de 243\n",
            "Iteración:     16 de 243\n",
            "Iteración:     17 de 243\n",
            "Iteración:     18 de 243\n",
            "Iteración:     19 de 243\n",
            "Iteración:     20 de 243\n",
            "Iteración:     21 de 243\n",
            "Iteración:     22 de 243\n",
            "Iteración:     23 de 243\n",
            "Iteración:     24 de 243\n",
            "Iteración:     25 de 243\n",
            "Iteración:     26 de 243\n",
            "Iteración:     27 de 243\n",
            "Iteración:     28 de 243\n",
            "Iteración:     29 de 243\n",
            "Iteración:     30 de 243\n",
            "Iteración:     31 de 243\n",
            "Iteración:     32 de 243\n",
            "Iteración:     33 de 243\n",
            "Iteración:     34 de 243\n",
            "Iteración:     35 de 243\n",
            "Iteración:     36 de 243\n",
            "Iteración:     37 de 243\n",
            "Iteración:     38 de 243\n",
            "Iteración:     39 de 243\n",
            "Iteración:     40 de 243\n",
            "Iteración:     41 de 243\n",
            "Iteración:     42 de 243\n",
            "Iteración:     43 de 243\n",
            "Iteración:     44 de 243\n",
            "Iteración:     45 de 243\n",
            "Iteración:     46 de 243\n",
            "Iteración:     47 de 243\n",
            "Iteración:     48 de 243\n",
            "Iteración:     49 de 243\n",
            "Iteración:     50 de 243\n",
            "Iteración:     51 de 243\n",
            "Iteración:     52 de 243\n",
            "Iteración:     53 de 243\n",
            "Iteración:     54 de 243\n",
            "Iteración:     55 de 243\n",
            "Iteración:     56 de 243\n",
            "Iteración:     57 de 243\n",
            "Iteración:     58 de 243\n",
            "Iteración:     59 de 243\n",
            "Iteración:     60 de 243\n",
            "Iteración:     61 de 243\n",
            "Iteración:     62 de 243\n",
            "Iteración:     63 de 243\n",
            "Iteración:     64 de 243\n",
            "Iteración:     65 de 243\n",
            "Iteración:     66 de 243\n",
            "Iteración:     67 de 243\n",
            "Iteración:     68 de 243\n",
            "Iteración:     69 de 243\n",
            "Iteración:     70 de 243\n",
            "Iteración:     71 de 243\n",
            "Iteración:     72 de 243\n",
            "Iteración:     73 de 243\n",
            "Iteración:     74 de 243\n",
            "Iteración:     75 de 243\n",
            "Iteración:     76 de 243\n",
            "Iteración:     77 de 243\n",
            "Iteración:     78 de 243\n",
            "Iteración:     79 de 243\n",
            "Iteración:     80 de 243\n",
            "Iteración:     81 de 243\n",
            "Iteración:     82 de 243\n",
            "Iteración:     83 de 243\n",
            "Iteración:     84 de 243\n",
            "Iteración:     85 de 243\n",
            "Iteración:     86 de 243\n",
            "Iteración:     87 de 243\n",
            "Iteración:     88 de 243\n",
            "Iteración:     89 de 243\n",
            "Iteración:     90 de 243\n",
            "Iteración:     91 de 243\n",
            "Iteración:     92 de 243\n",
            "Iteración:     93 de 243\n",
            "Iteración:     94 de 243\n",
            "Iteración:     95 de 243\n",
            "Iteración:     96 de 243\n",
            "Iteración:     97 de 243\n",
            "Iteración:     98 de 243\n",
            "Iteración:     99 de 243\n",
            "Iteración:    100 de 243\n",
            "Iteración:    101 de 243\n",
            "Iteración:    102 de 243\n",
            "Iteración:    103 de 243\n",
            "Iteración:    104 de 243\n",
            "Iteración:    105 de 243\n",
            "Iteración:    106 de 243\n",
            "Iteración:    107 de 243\n",
            "Iteración:    108 de 243\n",
            "Iteración:    109 de 243\n",
            "Iteración:    110 de 243\n",
            "Iteración:    111 de 243\n",
            "Iteración:    112 de 243\n",
            "Iteración:    113 de 243\n",
            "Iteración:    114 de 243\n",
            "Iteración:    115 de 243\n",
            "Iteración:    116 de 243\n",
            "Iteración:    117 de 243\n",
            "Iteración:    118 de 243\n",
            "Iteración:    119 de 243\n",
            "Iteración:    120 de 243\n",
            "Iteración:    121 de 243\n",
            "Iteración:    122 de 243\n",
            "Iteración:    123 de 243\n",
            "Iteración:    124 de 243\n",
            "Iteración:    125 de 243\n",
            "Iteración:    126 de 243\n",
            "Iteración:    127 de 243\n",
            "Iteración:    128 de 243\n",
            "Iteración:    129 de 243\n",
            "Iteración:    130 de 243\n",
            "Iteración:    131 de 243\n",
            "Iteración:    132 de 243\n",
            "Iteración:    133 de 243\n",
            "Iteración:    134 de 243\n",
            "Iteración:    135 de 243\n",
            "Iteración:    136 de 243\n",
            "Iteración:    137 de 243\n",
            "Iteración:    138 de 243\n",
            "Iteración:    139 de 243\n",
            "Iteración:    140 de 243\n",
            "Iteración:    141 de 243\n",
            "Iteración:    142 de 243\n",
            "Iteración:    143 de 243\n",
            "Iteración:    144 de 243\n",
            "Iteración:    145 de 243\n",
            "Iteración:    146 de 243\n",
            "Iteración:    147 de 243\n",
            "Iteración:    148 de 243\n",
            "Iteración:    149 de 243\n",
            "Iteración:    150 de 243\n",
            "Iteración:    151 de 243\n",
            "Iteración:    152 de 243\n",
            "Iteración:    153 de 243\n",
            "Iteración:    154 de 243\n",
            "Iteración:    155 de 243\n",
            "Iteración:    156 de 243\n",
            "Iteración:    157 de 243\n",
            "Iteración:    158 de 243\n",
            "Iteración:    159 de 243\n",
            "Iteración:    160 de 243\n",
            "Iteración:    161 de 243\n",
            "Iteración:    162 de 243\n",
            "Iteración:    163 de 243\n",
            "Iteración:    164 de 243\n",
            "Iteración:    165 de 243\n",
            "Iteración:    166 de 243\n",
            "Iteración:    167 de 243\n",
            "Iteración:    168 de 243\n",
            "Iteración:    169 de 243\n",
            "Iteración:    170 de 243\n",
            "Iteración:    171 de 243\n",
            "Iteración:    172 de 243\n",
            "Iteración:    173 de 243\n",
            "Iteración:    174 de 243\n",
            "Iteración:    175 de 243\n",
            "Iteración:    176 de 243\n",
            "Iteración:    177 de 243\n",
            "Iteración:    178 de 243\n",
            "Iteración:    179 de 243\n",
            "Iteración:    180 de 243\n",
            "Iteración:    181 de 243\n",
            "Iteración:    182 de 243\n",
            "Iteración:    183 de 243\n",
            "Iteración:    184 de 243\n",
            "Iteración:    185 de 243\n",
            "Iteración:    186 de 243\n",
            "Iteración:    187 de 243\n",
            "Iteración:    188 de 243\n",
            "Iteración:    189 de 243\n",
            "Iteración:    190 de 243\n",
            "Iteración:    191 de 243\n",
            "Iteración:    192 de 243\n",
            "Iteración:    193 de 243\n",
            "Iteración:    194 de 243\n",
            "Iteración:    195 de 243\n",
            "Iteración:    196 de 243\n",
            "Iteración:    197 de 243\n",
            "Iteración:    198 de 243\n",
            "Iteración:    199 de 243\n",
            "Iteración:    200 de 243\n",
            "Iteración:    201 de 243\n",
            "Iteración:    202 de 243\n",
            "Iteración:    203 de 243\n",
            "Iteración:    204 de 243\n",
            "Iteración:    205 de 243\n",
            "Iteración:    206 de 243\n",
            "Iteración:    207 de 243\n",
            "Iteración:    208 de 243\n",
            "Iteración:    209 de 243\n",
            "Iteración:    210 de 243\n",
            "Iteración:    211 de 243\n",
            "Iteración:    212 de 243\n",
            "Iteración:    213 de 243\n",
            "Iteración:    214 de 243\n",
            "Iteración:    215 de 243\n",
            "Iteración:    216 de 243\n",
            "Iteración:    217 de 243\n",
            "Iteración:    218 de 243\n",
            "Iteración:    219 de 243\n",
            "Iteración:    220 de 243\n",
            "Iteración:    221 de 243\n",
            "Iteración:    222 de 243\n",
            "Iteración:    223 de 243\n",
            "Iteración:    224 de 243\n",
            "Iteración:    225 de 243\n",
            "Iteración:    226 de 243\n",
            "Iteración:    227 de 243\n",
            "Iteración:    228 de 243\n",
            "Iteración:    229 de 243\n",
            "Iteración:    230 de 243\n",
            "Iteración:    231 de 243\n",
            "Iteración:    232 de 243\n",
            "Iteración:    233 de 243\n",
            "Iteración:    234 de 243\n",
            "Iteración:    235 de 243\n",
            "Iteración:    236 de 243\n",
            "Iteración:    237 de 243\n",
            "Iteración:    238 de 243\n",
            "Iteración:    239 de 243\n",
            "Iteración:    240 de 243\n",
            "Iteración:    241 de 243\n",
            "Iteración:    242 de 243\n",
            "Accuracy Score = 0.7166559070367979\n",
            "F1 Score (Micro) = 0.716655907036798\n",
            "F1 Score (Macro) = 0.4174720770185401\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationRoberta(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "id": "bjfaIc9ij0Hj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "212fd36f-aaf2-4231-ab08-22ecc241a444"
      },
      "source": [
        "##2.5 Aproximación 2: Separando las dos reviews de cada restaurante\n"
      ],
      "id": "212fd36f-aaf2-4231-ab08-22ecc241a444"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta aproximación, se volverán a realizar los pasos de la sección 2.4, pero esta vez, haciendo uso de una cantidad considerablemente mayor del conjunto de los datos."
      ],
      "metadata": {
        "id": "4jzlpVqVcBRJ"
      },
      "id": "4jzlpVqVcBRJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.5.1 Carga de datos"
      ],
      "metadata": {
        "id": "uxRYSHGBd1xR"
      },
      "id": "uxRYSHGBd1xR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este paso, se cargan los datos preprocesados de la sección 1.2 Datos divididos."
      ],
      "metadata": {
        "id": "SgSqMgfAnOok"
      },
      "id": "SgSqMgfAnOok"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3GPI-m_fcui",
        "outputId": "032e1708-1c49-4ce1-e5a8-9a8685a80a75"
      },
      "id": "Z3GPI-m_fcui",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87977dde-5bd1-47f0-b709-08587ed36558",
        "outputId": "0a3b0d1f-43f6-4788-e31b-0bd5b248ae68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Reviews  Sentimiento\n",
              "0                                 A most friendly welcome            1\n",
              "1                                              Nice treat            0\n",
              "2       Lovely interior design', \"Don't let the lack o...            1\n",
              "3                              Nice Food and Good Service            1\n",
              "4                                                 Just ok            0\n",
              "...                                                   ...          ...\n",
              "142763                                 Great Chinese food            0\n",
              "142764                    Take a detour off the main drag            1\n",
              "142765                                       Good Burrito            1\n",
              "142766                                         Super Rude            0\n",
              "142767                                          Nice food            1\n",
              "\n",
              "[142768 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-231bcf23-01ab-4134-921b-12f05c663cca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A most friendly welcome</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nice treat</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lovely interior design', \"Don't let the lack o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nice Food and Good Service</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Just ok</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142763</th>\n",
              "      <td>Great Chinese food</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142764</th>\n",
              "      <td>Take a detour off the main drag</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142765</th>\n",
              "      <td>Good Burrito</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142766</th>\n",
              "      <td>Super Rude</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142767</th>\n",
              "      <td>Nice food</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>142768 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-231bcf23-01ab-4134-921b-12f05c663cca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-231bcf23-01ab-4134-921b-12f05c663cca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-231bcf23-01ab-4134-921b-12f05c663cca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5a75076d-ef14-427c-8c6e-25e1e2e5bd55\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a75076d-ef14-427c-8c6e-25e1e2e5bd55')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5a75076d-ef14-427c-8c6e-25e1e2e5bd55 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "datos = pd.read_feather(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/valoraciones_Separados_train.feather\")\n",
        "datos"
      ],
      "id": "87977dde-5bd1-47f0-b709-08587ed36558"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN98yOU8eACw"
      },
      "source": [
        "###2.5.2 Definición tokenizadores y modelos"
      ],
      "id": "qN98yOU8eACw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhX1FccpeACw"
      },
      "outputs": [],
      "source": [
        "tokenizerB = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "modelB = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "configB = AutoConfig.from_pretrained(\"bert-base-uncased\")"
      ],
      "id": "uhX1FccpeACw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_I-Fbh99eACx"
      },
      "outputs": [],
      "source": [
        "tokenizerRB = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "modelRB = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "configRB = AutoConfig.from_pretrained(\"roberta-base\")"
      ],
      "id": "_I-Fbh99eACx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.5.3 Función de generación de conjuntos de train y test: DataLoaders"
      ],
      "metadata": {
        "id": "TzhTX-s-ejQf"
      },
      "id": "TzhTX-s-ejQf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjScJHWtejQg"
      },
      "outputs": [],
      "source": [
        "def generate_loaders(dataframe, tokenizer, dataset, collator):\n",
        "  train_dataset = dataframe.sample(frac=TRAIN_SIZE, random_state=0)\n",
        "  test_dataset = dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
        "  train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "  print(f\"FULL Dataset:{dataframe.shape}\")\n",
        "  print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
        "  print(f\"TEST Dataset: {test_dataset.shape}\")\n",
        "\n",
        "  training_set = dataset(train_dataset, MAX_LEN)\n",
        "  testing_set = dataset(test_dataset, MAX_LEN)\n",
        "  dc = collator(tokenizer, MAX_LEN)\n",
        "\n",
        "\n",
        "  train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                  'shuffle': True,\n",
        "                  'num_workers': 0,\n",
        "                  'collate_fn': dc\n",
        "                  }\n",
        "\n",
        "  test_params = { 'batch_size': VALID_BATCH_SIZE,\n",
        "                  'shuffle': True,\n",
        "                  'num_workers': 0,\n",
        "                  'collate_fn': dc\n",
        "                }\n",
        "\n",
        "  training_loader = DataLoader(training_set, **train_params)\n",
        "  testing_loader = DataLoader(testing_set, **test_params)\n",
        "  return training_loader, testing_loader"
      ],
      "id": "gjScJHWtejQg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.5.4 Definición restaurantsDataset y DataCollatorRestaurant"
      ],
      "metadata": {
        "id": "wHWQqYES30Gg"
      },
      "id": "wHWQqYES30Gg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta clase es la encargada de elaborar las muestras con las que van a entrenar los modelos.\n",
        "\n",
        "Cada muestra consiste en:\n",
        "- La etiqueta *sentimiento*, que representa el valor de la columna `Sentimineto` de los datos, es decir, si el sentimiento es positivo o negativo.\n",
        "- `Reviews`, comentarios que se utilizan para entrenar el modelo.\n",
        "\n",
        "En esta aproximación se busca generar el *embedding* de las reseñas sobre cada *review*."
      ],
      "metadata": {
        "id": "Ar9OzGhy30Gl"
      },
      "id": "Ar9OzGhy30Gl"
    },
    {
      "cell_type": "code",
      "source": [
        "type(datos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4deb05c-c8fb-412b-ba76-61fccaae83ec",
        "id": "XCWU4nIW30Gl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "id": "XCWU4nIW30Gl"
    },
    {
      "cell_type": "code",
      "source": [
        "datos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5985549d-88cc-4295-d4d9-5cae2cb69dab",
        "id": "V_lfV6fv30Gm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Reviews  Sentimiento\n",
              "0                                 A most friendly welcome            1\n",
              "1                                              Nice treat            0\n",
              "2       Lovely interior design', \"Don't let the lack o...            1\n",
              "3                              Nice Food and Good Service            1\n",
              "4                                                 Just ok            0\n",
              "...                                                   ...          ...\n",
              "142763                                 Great Chinese food            0\n",
              "142764                    Take a detour off the main drag            1\n",
              "142765                                       Good Burrito            1\n",
              "142766                                         Super Rude            0\n",
              "142767                                          Nice food            1\n",
              "\n",
              "[142768 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-282a8f1d-5ed8-48ac-b569-a658ccd37678\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A most friendly welcome</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nice treat</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lovely interior design', \"Don't let the lack o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nice Food and Good Service</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Just ok</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142763</th>\n",
              "      <td>Great Chinese food</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142764</th>\n",
              "      <td>Take a detour off the main drag</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142765</th>\n",
              "      <td>Good Burrito</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142766</th>\n",
              "      <td>Super Rude</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142767</th>\n",
              "      <td>Nice food</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>142768 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-282a8f1d-5ed8-48ac-b569-a658ccd37678')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-282a8f1d-5ed8-48ac-b569-a658ccd37678 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-282a8f1d-5ed8-48ac-b569-a658ccd37678');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c0c9031f-cf17-468f-b4cf-083fde32426f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0c9031f-cf17-468f-b4cf-083fde32426f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c0c9031f-cf17-468f-b4cf-083fde32426f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "id": "V_lfV6fv30Gm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTE8YPx730Gm"
      },
      "outputs": [],
      "source": [
        "class restaurantsDataset(Dataset):\n",
        "  def __init__(self, dataframe, max_len):\n",
        "    self.data = dataframe\n",
        "    self.comentario = dataframe.Reviews\n",
        "    self.targets = self.data.Sentimiento\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.comentario)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    comment = self.comentario[index]\n",
        "    target = self.targets[index]\n",
        "\n",
        "    return {\n",
        "        \"comentario\": comment,\n",
        "        \"target\": target\n",
        "    }"
      ],
      "id": "vTE8YPx730Gm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eefd004-d51e-4278-dd90-ad8838c0c603",
        "id": "PM810U4E30Gm"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'comentario': 'A most friendly welcome', 'target': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "datasetRestaurants = restaurantsDataset(datos, MAX_LEN)\n",
        "salida = datasetRestaurants.__getitem__(0)\n",
        "salida"
      ],
      "id": "PM810U4E30Gm"
    },
    {
      "cell_type": "code",
      "source": [
        "aux = encoder_input = tokenizerB(\n",
        "          salida[\"comentario\"],\n",
        "          None,\n",
        "          add_special_tokens=True,\n",
        "          truncation=True,\n",
        "          max_length=MAX_LEN,\n",
        "          pad_to_max_length=True,\n",
        "          return_tensors = \"pt\",\n",
        "          return_token_type_ids=True\n",
        "          )\n",
        "aux[\"input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa7046f-23fb-46ae-bc1b-82503f554c8a",
        "id": "45zrfN6L30Gm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 101, 1037, 2087, 5379, 6160,  102,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "id": "45zrfN6L30Gm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HR63p8X30Gm"
      },
      "outputs": [],
      "source": [
        "class DataCollatorRestaurant:\n",
        "    def __init__(self, tokenizer, max_len=512):\n",
        "      self.tokenizer = tokenizer\n",
        "      self.max_len = max_len\n",
        "\n",
        "    def __call__(self, input_batch):\n",
        "      data_frame = pd.DataFrame(input_batch)\n",
        "      batch_dict = {column: data_frame[column].tolist() for column in data_frame}\n",
        "\n",
        "      encoder_input = self.tokenizer(\n",
        "          batch_dict[\"comentario\"],\n",
        "          None,\n",
        "          add_special_tokens=True,\n",
        "          truncation=True,\n",
        "          max_length=self.max_len,\n",
        "          pad_to_max_length=True,\n",
        "          return_tensors = \"pt\",\n",
        "          return_token_type_ids=True\n",
        "          )\n",
        "\n",
        "      return {\n",
        "      'ids': encoder_input[\"input_ids\"],\n",
        "      'mask': encoder_input[\"attention_mask\"],\n",
        "      \"target\": torch.Tensor(batch_dict[\"target\"]),\n",
        "      \"token_type_ids\": encoder_input[\"token_type_ids\"]\n",
        "    }"
      ],
      "id": "6HR63p8X30Gm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XUnO2ag4nZT"
      },
      "source": [
        "###2.5.5 Modelo 1: BERT"
      ],
      "id": "8XUnO2ag4nZT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGIkFYqC4nZY"
      },
      "source": [
        "##### Definición Dataset y Dataloader"
      ],
      "id": "FGIkFYqC4nZY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empleando la función anteriormente desarrollada, podemos generar los *loaders* sin tener que especificar nada más que el *tokenizer* concreto y el *Dataset* y el *DataCollator*."
      ],
      "metadata": {
        "id": "8KBQ3mzV4nZY"
      },
      "id": "8KBQ3mzV4nZY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cc4d21f-a395-4d81-fb6b-af55b885fbf3",
        "id": "98r7ZULj4nZY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset:(142768, 2)\n",
            "TRAIN Dataset: (114214, 2)\n",
            "TEST Dataset: (28554, 2)\n"
          ]
        }
      ],
      "source": [
        "training_loader, testing_loader = generate_loaders(datos,\n",
        "                                                   tokenizerB,\n",
        "                                                   restaurantsDataset,\n",
        "                                                   DataCollatorRestaurant\n",
        "                                                   )"
      ],
      "id": "98r7ZULj4nZY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJSrbOrY4nZY"
      },
      "source": [
        "##### Definición del modelo"
      ],
      "id": "SJSrbOrY4nZY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0762952c-055b-43d3-a7dd-84c4c2fb2a6d",
        "id": "jcyhmiEU4nZY"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l4): Dropout(p=0.2, inplace=False)\n",
              "  (l5): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (l6): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.dropout = 0.2\n",
        "        self.hidden_embd = 768\n",
        "        self.output_layer = 1\n",
        "\n",
        "        # Layers\n",
        "        self.l1 = BertModel.from_pretrained('bert-base-uncased')\n",
        "        #self.l2 = torch.nn.Linear(self.hidden_embd, 256)\n",
        "        #self.l3 = torch.nn.Linear(256, 64)\n",
        "        self.l4 = torch.nn.Dropout(self.dropout)\n",
        "        # self.l5 = torch.nn.Linear(64, self.output_layer)\n",
        "        self.l5 = torch.nn.Linear(self.hidden_embd, self.output_layer)\n",
        "        self.l6 = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, output_1 = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
        "        #output_2 = self.l2(output_1)\n",
        "        #output_3 = self.l3(output_2)\n",
        "        output_4 = self.l4(output_1)\n",
        "        output_5 = self.l5(output_4)\n",
        "        output = self.l6(output_5)\n",
        "        return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ],
      "id": "jcyhmiEU4nZY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e6f8b7-2743-4c4e-c21d-78c92f0a297b",
        "id": "yh3Wlaim4nZY"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 0.01\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE,\n",
        "                             weight_decay=0.01)\n",
        "optimizer"
      ],
      "id": "yh3Wlaim4nZY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Función de entrenamiento\n"
      ],
      "metadata": {
        "id": "uxGFgrja4nZY"
      },
      "id": "uxGFgrja4nZY"
    },
    {
      "cell_type": "code",
      "source": [
        "def trainBert(epoch):\n",
        "  model.train()\n",
        "  loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "  num_iteraciones = len(training_loader)\n",
        "  sum_loss = 0\n",
        "\n",
        "  for iteracion, data in enumerate(training_loader, 0):\n",
        "    ids = data['ids'].to(device)\n",
        "    mask = data['mask'].to(device)\n",
        "    targets = data['target'].to(device)\n",
        "    token_type_ids = data[\"token_type_ids\"].to(device)\n",
        "\n",
        "    output = model(ids, mask, token_type_ids)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    perdida = loss_fn(output.squeeze(), targets)\n",
        "    with torch.no_grad():\n",
        "      sum_loss+=perdida\n",
        "      if iteracion % PASOS_POR_INTERVALO ==0:\n",
        "        print(f'Epoch: {epoch}, iteración; {iteracion} de {num_iteraciones}, Loss: {sum_loss.cpu().numpy()/PASOS_POR_INTERVALO}')\n",
        "        sum_loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    perdida.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "PRVImVL-4nZY"
      },
      "execution_count": null,
      "outputs": [],
      "id": "PRVImVL-4nZY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLBKOi734nZZ"
      },
      "source": [
        "##### Entrenamiento del modelo (30% de datos)"
      ],
      "id": "qLBKOi734nZZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-5\n",
        "- weight_decay=0.01\n",
        "- Dropout + Linear + Sigmoid"
      ],
      "metadata": {
        "id": "6gqstBu5O2Tv"
      },
      "id": "6gqstBu5O2Tv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f58dd1dc-87bb-4036-bff6-cda670e1b8ac",
        "id": "SQF5Ds6_4nZZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración; 0 de 5354, Loss: 0.06584186553955078\n",
            "Epoch: 0, iteración; 10 de 5354, Loss: 0.5883976936340332\n",
            "Epoch: 0, iteración; 20 de 5354, Loss: 0.632751178741455\n",
            "Epoch: 0, iteración; 30 de 5354, Loss: 0.6096447944641114\n",
            "Epoch: 0, iteración; 40 de 5354, Loss: 0.5748745918273925\n",
            "Epoch: 0, iteración; 50 de 5354, Loss: 0.5510220050811767\n",
            "Epoch: 0, iteración; 60 de 5354, Loss: 0.617931318283081\n",
            "Epoch: 0, iteración; 70 de 5354, Loss: 0.5796681404113769\n",
            "Epoch: 0, iteración; 80 de 5354, Loss: 0.5210927963256836\n",
            "Epoch: 0, iteración; 90 de 5354, Loss: 0.6179694175720215\n",
            "Epoch: 0, iteración; 100 de 5354, Loss: 0.6450166702270508\n",
            "Epoch: 0, iteración; 110 de 5354, Loss: 0.5910777091979981\n",
            "Epoch: 0, iteración; 120 de 5354, Loss: 0.5932302474975586\n",
            "Epoch: 0, iteración; 130 de 5354, Loss: 0.5541589260101318\n",
            "Epoch: 0, iteración; 140 de 5354, Loss: 0.5372121810913086\n",
            "Epoch: 0, iteración; 150 de 5354, Loss: 0.646149730682373\n",
            "Epoch: 0, iteración; 160 de 5354, Loss: 0.6178732872009277\n",
            "Epoch: 0, iteración; 170 de 5354, Loss: 0.5926121711730957\n",
            "Epoch: 0, iteración; 180 de 5354, Loss: 0.5739500045776367\n",
            "Epoch: 0, iteración; 190 de 5354, Loss: 0.5614375591278076\n",
            "Epoch: 0, iteración; 200 de 5354, Loss: 0.6019528388977051\n",
            "Epoch: 0, iteración; 210 de 5354, Loss: 0.5586428642272949\n",
            "Epoch: 0, iteración; 220 de 5354, Loss: 0.6088304042816162\n",
            "Epoch: 0, iteración; 230 de 5354, Loss: 0.5785681247711182\n",
            "Epoch: 0, iteración; 240 de 5354, Loss: 0.5583100318908691\n",
            "Epoch: 0, iteración; 250 de 5354, Loss: 0.5566245555877686\n",
            "Epoch: 0, iteración; 260 de 5354, Loss: 0.5902825832366944\n",
            "Epoch: 0, iteración; 270 de 5354, Loss: 0.6577141761779786\n",
            "Epoch: 0, iteración; 280 de 5354, Loss: 0.5691727638244629\n",
            "Epoch: 0, iteración; 290 de 5354, Loss: 0.5709714412689209\n",
            "Epoch: 0, iteración; 300 de 5354, Loss: 0.5917733192443848\n",
            "Epoch: 0, iteración; 310 de 5354, Loss: 0.5751674175262451\n",
            "Epoch: 0, iteración; 320 de 5354, Loss: 0.6450293064117432\n",
            "Epoch: 0, iteración; 330 de 5354, Loss: 0.6095703125\n",
            "Epoch: 0, iteración; 340 de 5354, Loss: 0.5467427253723145\n",
            "Epoch: 0, iteración; 350 de 5354, Loss: 0.531000804901123\n",
            "Epoch: 0, iteración; 360 de 5354, Loss: 0.5733895778656006\n",
            "Epoch: 0, iteración; 370 de 5354, Loss: 0.5883548259735107\n",
            "Epoch: 0, iteración; 380 de 5354, Loss: 0.5275114059448243\n",
            "Epoch: 0, iteración; 390 de 5354, Loss: 0.5973153591156006\n",
            "Epoch: 0, iteración; 400 de 5354, Loss: 0.6383896827697754\n",
            "Epoch: 0, iteración; 410 de 5354, Loss: 0.4858078479766846\n",
            "Epoch: 0, iteración; 420 de 5354, Loss: 0.6298655986785888\n",
            "Epoch: 0, iteración; 430 de 5354, Loss: 0.6189753532409668\n",
            "Epoch: 0, iteración; 440 de 5354, Loss: 0.5742088317871094\n",
            "Epoch: 0, iteración; 450 de 5354, Loss: 0.5315299510955811\n",
            "Epoch: 0, iteración; 460 de 5354, Loss: 0.5772957324981689\n",
            "Epoch: 0, iteración; 470 de 5354, Loss: 0.6243786334991455\n",
            "Epoch: 0, iteración; 480 de 5354, Loss: 0.5824824810028076\n",
            "Epoch: 0, iteración; 490 de 5354, Loss: 0.5492693901062011\n",
            "Epoch: 0, iteración; 500 de 5354, Loss: 0.6720788478851318\n",
            "Epoch: 0, iteración; 510 de 5354, Loss: 0.611146354675293\n",
            "Epoch: 0, iteración; 520 de 5354, Loss: 0.5554098606109619\n",
            "Epoch: 0, iteración; 530 de 5354, Loss: 0.5088118553161621\n",
            "Epoch: 0, iteración; 540 de 5354, Loss: 0.520659351348877\n",
            "Epoch: 0, iteración; 550 de 5354, Loss: 0.6383398532867431\n",
            "Epoch: 0, iteración; 560 de 5354, Loss: 0.48973727226257324\n",
            "Epoch: 0, iteración; 570 de 5354, Loss: 0.5479139804840087\n",
            "Epoch: 0, iteración; 580 de 5354, Loss: 0.5776524066925048\n",
            "Epoch: 0, iteración; 590 de 5354, Loss: 0.5234053611755372\n",
            "Epoch: 0, iteración; 600 de 5354, Loss: 0.5460511684417725\n",
            "Epoch: 0, iteración; 610 de 5354, Loss: 0.5177833080291748\n",
            "Epoch: 0, iteración; 620 de 5354, Loss: 0.5587213039398193\n",
            "Epoch: 0, iteración; 630 de 5354, Loss: 0.5538896560668946\n",
            "Epoch: 0, iteración; 640 de 5354, Loss: 0.6328578948974609\n",
            "Epoch: 0, iteración; 650 de 5354, Loss: 0.5472121715545655\n",
            "Epoch: 0, iteración; 660 de 5354, Loss: 0.5482637882232666\n",
            "Epoch: 0, iteración; 670 de 5354, Loss: 0.6543888568878173\n",
            "Epoch: 0, iteración; 680 de 5354, Loss: 0.5470363616943359\n",
            "Epoch: 0, iteración; 690 de 5354, Loss: 0.5773543834686279\n",
            "Epoch: 0, iteración; 700 de 5354, Loss: 0.6034220218658447\n",
            "Epoch: 0, iteración; 710 de 5354, Loss: 0.5822217464447021\n",
            "Epoch: 0, iteración; 720 de 5354, Loss: 0.5618306636810303\n",
            "Epoch: 0, iteración; 730 de 5354, Loss: 0.540753173828125\n",
            "Epoch: 0, iteración; 740 de 5354, Loss: 0.5536765098571778\n",
            "Epoch: 0, iteración; 750 de 5354, Loss: 0.49408512115478515\n",
            "Epoch: 0, iteración; 760 de 5354, Loss: 0.6002708435058594\n",
            "Epoch: 0, iteración; 770 de 5354, Loss: 0.5832668781280518\n",
            "Epoch: 0, iteración; 780 de 5354, Loss: 0.6175453186035156\n",
            "Epoch: 0, iteración; 790 de 5354, Loss: 0.5206602573394775\n",
            "Epoch: 0, iteración; 800 de 5354, Loss: 0.5633854866027832\n",
            "Epoch: 0, iteración; 810 de 5354, Loss: 0.5797560691833497\n",
            "Epoch: 0, iteración; 820 de 5354, Loss: 0.5304594516754151\n",
            "Epoch: 0, iteración; 830 de 5354, Loss: 0.5507705211639404\n",
            "Epoch: 0, iteración; 840 de 5354, Loss: 0.49997859001159667\n",
            "Epoch: 0, iteración; 850 de 5354, Loss: 0.5975651741027832\n",
            "Epoch: 0, iteración; 860 de 5354, Loss: 0.5992979049682617\n",
            "Epoch: 0, iteración; 870 de 5354, Loss: 0.607420015335083\n",
            "Epoch: 0, iteración; 880 de 5354, Loss: 0.5462110042572021\n",
            "Epoch: 0, iteración; 890 de 5354, Loss: 0.6377810955047607\n",
            "Epoch: 0, iteración; 900 de 5354, Loss: 0.568084716796875\n",
            "Epoch: 0, iteración; 910 de 5354, Loss: 0.6052274703979492\n",
            "Epoch: 0, iteración; 920 de 5354, Loss: 0.5975695610046386\n",
            "Epoch: 0, iteración; 930 de 5354, Loss: 0.5363975524902344\n",
            "Epoch: 0, iteración; 940 de 5354, Loss: 0.5590357780456543\n",
            "Epoch: 0, iteración; 950 de 5354, Loss: 0.6089594841003418\n",
            "Epoch: 0, iteración; 960 de 5354, Loss: 0.5880247592926026\n",
            "Epoch: 0, iteración; 970 de 5354, Loss: 0.5810091495513916\n",
            "Epoch: 0, iteración; 980 de 5354, Loss: 0.602704381942749\n",
            "Epoch: 0, iteración; 990 de 5354, Loss: 0.5628169536590576\n",
            "Epoch: 0, iteración; 1000 de 5354, Loss: 0.5513765811920166\n",
            "Epoch: 0, iteración; 1010 de 5354, Loss: 0.5205636978149414\n",
            "Epoch: 0, iteración; 1020 de 5354, Loss: 0.6011350631713868\n",
            "Epoch: 0, iteración; 1030 de 5354, Loss: 0.5486659049987793\n",
            "Epoch: 0, iteración; 1040 de 5354, Loss: 0.5390060424804688\n",
            "Epoch: 0, iteración; 1050 de 5354, Loss: 0.6234652519226074\n",
            "Epoch: 0, iteración; 1060 de 5354, Loss: 0.6201358318328858\n",
            "Epoch: 0, iteración; 1070 de 5354, Loss: 0.5595383167266845\n",
            "Epoch: 0, iteración; 1080 de 5354, Loss: 0.48387818336486815\n",
            "Epoch: 0, iteración; 1090 de 5354, Loss: 0.5091958999633789\n",
            "Epoch: 0, iteración; 1100 de 5354, Loss: 0.5385267257690429\n",
            "Epoch: 0, iteración; 1110 de 5354, Loss: 0.5678798675537109\n",
            "Epoch: 0, iteración; 1120 de 5354, Loss: 0.5461640357971191\n",
            "Epoch: 0, iteración; 1130 de 5354, Loss: 0.5358601570129394\n",
            "Epoch: 0, iteración; 1140 de 5354, Loss: 0.6012332916259766\n",
            "Epoch: 0, iteración; 1150 de 5354, Loss: 0.5361392021179199\n",
            "Epoch: 0, iteración; 1160 de 5354, Loss: 0.5271206855773926\n",
            "Epoch: 0, iteración; 1170 de 5354, Loss: 0.5663991451263428\n",
            "Epoch: 0, iteración; 1180 de 5354, Loss: 0.5699963092803955\n",
            "Epoch: 0, iteración; 1190 de 5354, Loss: 0.5711378574371337\n",
            "Epoch: 0, iteración; 1200 de 5354, Loss: 0.5508710861206054\n",
            "Epoch: 0, iteración; 1210 de 5354, Loss: 0.5243640899658203\n",
            "Epoch: 0, iteración; 1220 de 5354, Loss: 0.5712025165557861\n",
            "Epoch: 0, iteración; 1230 de 5354, Loss: 0.5962837219238282\n",
            "Epoch: 0, iteración; 1240 de 5354, Loss: 0.5897170066833496\n",
            "Epoch: 0, iteración; 1250 de 5354, Loss: 0.5964499473571777\n",
            "Epoch: 0, iteración; 1260 de 5354, Loss: 0.48908090591430664\n",
            "Epoch: 0, iteración; 1270 de 5354, Loss: 0.5555097579956054\n",
            "Epoch: 0, iteración; 1280 de 5354, Loss: 0.5736971855163574\n",
            "Epoch: 0, iteración; 1290 de 5354, Loss: 0.5476795673370362\n",
            "Epoch: 0, iteración; 1300 de 5354, Loss: 0.5266836643218994\n",
            "Epoch: 0, iteración; 1310 de 5354, Loss: 0.5274524211883544\n",
            "Epoch: 0, iteración; 1320 de 5354, Loss: 0.5908254623413086\n",
            "Epoch: 0, iteración; 1330 de 5354, Loss: 0.5317355632781983\n",
            "Epoch: 0, iteración; 1340 de 5354, Loss: 0.5424388408660888\n",
            "Epoch: 0, iteración; 1350 de 5354, Loss: 0.5670224189758301\n",
            "Epoch: 0, iteración; 1360 de 5354, Loss: 0.5576436519622803\n",
            "Epoch: 0, iteración; 1370 de 5354, Loss: 0.554839038848877\n",
            "Epoch: 0, iteración; 1380 de 5354, Loss: 0.5256519317626953\n",
            "Epoch: 0, iteración; 1390 de 5354, Loss: 0.5678229331970215\n",
            "Epoch: 0, iteración; 1400 de 5354, Loss: 0.5642669677734375\n",
            "Epoch: 0, iteración; 1410 de 5354, Loss: 0.5508661270141602\n",
            "Epoch: 0, iteración; 1420 de 5354, Loss: 0.5185245990753173\n",
            "Epoch: 0, iteración; 1430 de 5354, Loss: 0.5828157901763916\n",
            "Epoch: 0, iteración; 1440 de 5354, Loss: 0.5988352298736572\n",
            "Epoch: 0, iteración; 1450 de 5354, Loss: 0.5135897636413574\n",
            "Epoch: 0, iteración; 1460 de 5354, Loss: 0.5172964572906494\n",
            "Epoch: 0, iteración; 1470 de 5354, Loss: 0.5415201187133789\n",
            "Epoch: 0, iteración; 1480 de 5354, Loss: 0.5825857162475586\n",
            "Epoch: 0, iteración; 1490 de 5354, Loss: 0.5636118888854981\n",
            "Epoch: 0, iteración; 1500 de 5354, Loss: 0.4683687210083008\n",
            "Epoch: 0, iteración; 1510 de 5354, Loss: 0.5720377922058105\n",
            "Epoch: 0, iteración; 1520 de 5354, Loss: 0.5631231307983399\n",
            "Epoch: 0, iteración; 1530 de 5354, Loss: 0.5624575138092041\n",
            "Epoch: 0, iteración; 1540 de 5354, Loss: 0.4894065856933594\n",
            "Epoch: 0, iteración; 1550 de 5354, Loss: 0.5138172149658203\n",
            "Epoch: 0, iteración; 1560 de 5354, Loss: 0.5756432056427002\n",
            "Epoch: 0, iteración; 1570 de 5354, Loss: 0.5919076442718506\n",
            "Epoch: 0, iteración; 1580 de 5354, Loss: 0.5817503452301025\n",
            "Epoch: 0, iteración; 1590 de 5354, Loss: 0.5010880470275879\n",
            "Epoch: 0, iteración; 1600 de 5354, Loss: 0.5165990352630615\n",
            "Epoch: 0, iteración; 1610 de 5354, Loss: 0.5807628154754638\n",
            "Epoch: 0, iteración; 1620 de 5354, Loss: 0.5316161632537841\n",
            "Epoch: 0, iteración; 1630 de 5354, Loss: 0.5180349826812745\n",
            "Epoch: 0, iteración; 1640 de 5354, Loss: 0.5807106971740723\n",
            "Epoch: 0, iteración; 1650 de 5354, Loss: 0.521815299987793\n",
            "Epoch: 0, iteración; 1660 de 5354, Loss: 0.547540807723999\n",
            "Epoch: 0, iteración; 1670 de 5354, Loss: 0.49840307235717773\n",
            "Epoch: 0, iteración; 1680 de 5354, Loss: 0.561286449432373\n",
            "Epoch: 0, iteración; 1690 de 5354, Loss: 0.530329418182373\n",
            "Epoch: 0, iteración; 1700 de 5354, Loss: 0.6076560020446777\n",
            "Epoch: 0, iteración; 1710 de 5354, Loss: 0.5891878128051757\n",
            "Epoch: 0, iteración; 1720 de 5354, Loss: 0.5836697578430176\n",
            "Epoch: 0, iteración; 1730 de 5354, Loss: 0.5418008327484131\n",
            "Epoch: 0, iteración; 1740 de 5354, Loss: 0.6388339996337891\n",
            "Epoch: 0, iteración; 1750 de 5354, Loss: 0.5993030071258545\n",
            "Epoch: 0, iteración; 1760 de 5354, Loss: 0.6257325649261475\n",
            "Epoch: 0, iteración; 1770 de 5354, Loss: 0.6099061489105224\n",
            "Epoch: 0, iteración; 1780 de 5354, Loss: 0.5771028995513916\n",
            "Epoch: 0, iteración; 1790 de 5354, Loss: 0.5295861244201661\n",
            "Epoch: 0, iteración; 1800 de 5354, Loss: 0.5588325023651123\n",
            "Epoch: 0, iteración; 1810 de 5354, Loss: 0.5669230937957763\n",
            "Epoch: 0, iteración; 1820 de 5354, Loss: 0.5857313632965088\n",
            "Epoch: 0, iteración; 1830 de 5354, Loss: 0.6508503913879394\n",
            "Epoch: 0, iteración; 1840 de 5354, Loss: 0.5819522857666015\n",
            "Epoch: 0, iteración; 1850 de 5354, Loss: 0.5618454933166503\n",
            "Epoch: 0, iteración; 1860 de 5354, Loss: 0.5652613162994384\n",
            "Epoch: 0, iteración; 1870 de 5354, Loss: 0.5167682647705079\n",
            "Epoch: 0, iteración; 1880 de 5354, Loss: 0.5554088115692138\n",
            "Epoch: 0, iteración; 1890 de 5354, Loss: 0.6056431770324707\n",
            "Epoch: 0, iteración; 1900 de 5354, Loss: 0.5133559703826904\n",
            "Epoch: 0, iteración; 1910 de 5354, Loss: 0.5819949150085449\n",
            "Epoch: 0, iteración; 1920 de 5354, Loss: 0.6324504852294922\n",
            "Epoch: 0, iteración; 1930 de 5354, Loss: 0.6174495697021485\n",
            "Epoch: 0, iteración; 1940 de 5354, Loss: 0.5536284446716309\n",
            "Epoch: 0, iteración; 1950 de 5354, Loss: 0.5303585052490234\n",
            "Epoch: 0, iteración; 1960 de 5354, Loss: 0.5019007205963135\n",
            "Epoch: 0, iteración; 1970 de 5354, Loss: 0.5768118858337402\n",
            "Epoch: 0, iteración; 1980 de 5354, Loss: 0.5550589561462402\n",
            "Epoch: 0, iteración; 1990 de 5354, Loss: 0.5623700618743896\n",
            "Epoch: 0, iteración; 2000 de 5354, Loss: 0.5926313877105713\n",
            "Epoch: 0, iteración; 2010 de 5354, Loss: 0.5976652145385742\n",
            "Epoch: 0, iteración; 2020 de 5354, Loss: 0.5524172782897949\n",
            "Epoch: 0, iteración; 2030 de 5354, Loss: 0.6485888004302979\n",
            "Epoch: 0, iteración; 2040 de 5354, Loss: 0.5545204162597657\n",
            "Epoch: 0, iteración; 2050 de 5354, Loss: 0.5861481666564942\n",
            "Epoch: 0, iteración; 2060 de 5354, Loss: 0.6547823905944824\n",
            "Epoch: 0, iteración; 2070 de 5354, Loss: 0.5822604656219482\n",
            "Epoch: 0, iteración; 2080 de 5354, Loss: 0.597458028793335\n",
            "Epoch: 0, iteración; 2090 de 5354, Loss: 0.5324703216552734\n",
            "Epoch: 0, iteración; 2100 de 5354, Loss: 0.5458952903747558\n",
            "Epoch: 0, iteración; 2110 de 5354, Loss: 0.550575065612793\n",
            "Epoch: 0, iteración; 2120 de 5354, Loss: 0.5772483348846436\n",
            "Epoch: 0, iteración; 2130 de 5354, Loss: 0.5810178279876709\n",
            "Epoch: 0, iteración; 2140 de 5354, Loss: 0.5716471672058105\n",
            "Epoch: 0, iteración; 2150 de 5354, Loss: 0.5834585189819336\n",
            "Epoch: 0, iteración; 2160 de 5354, Loss: 0.635174560546875\n",
            "Epoch: 0, iteración; 2170 de 5354, Loss: 0.5908308029174805\n",
            "Epoch: 0, iteración; 2180 de 5354, Loss: 0.5985032081604004\n",
            "Epoch: 0, iteración; 2190 de 5354, Loss: 0.5628451824188232\n",
            "Epoch: 0, iteración; 2200 de 5354, Loss: 0.532672119140625\n",
            "Epoch: 0, iteración; 2210 de 5354, Loss: 0.5935828208923339\n",
            "Epoch: 0, iteración; 2220 de 5354, Loss: 0.5270788669586182\n",
            "Epoch: 0, iteración; 2230 de 5354, Loss: 0.5755144596099854\n",
            "Epoch: 0, iteración; 2240 de 5354, Loss: 0.6403862953186035\n",
            "Epoch: 0, iteración; 2250 de 5354, Loss: 0.5145530700683594\n",
            "Epoch: 0, iteración; 2260 de 5354, Loss: 0.5603788375854493\n",
            "Epoch: 0, iteración; 2270 de 5354, Loss: 0.5995330333709716\n",
            "Epoch: 0, iteración; 2280 de 5354, Loss: 0.5873831748962403\n",
            "Epoch: 0, iteración; 2290 de 5354, Loss: 0.6091885089874267\n",
            "Epoch: 0, iteración; 2300 de 5354, Loss: 0.5391454696655273\n",
            "Epoch: 0, iteración; 2310 de 5354, Loss: 0.6318070888519287\n",
            "Epoch: 0, iteración; 2320 de 5354, Loss: 0.5417786121368409\n",
            "Epoch: 0, iteración; 2330 de 5354, Loss: 0.5966846942901611\n",
            "Epoch: 0, iteración; 2340 de 5354, Loss: 0.5679108142852783\n",
            "Epoch: 0, iteración; 2350 de 5354, Loss: 0.5974371910095215\n",
            "Epoch: 0, iteración; 2360 de 5354, Loss: 0.5616039752960205\n",
            "Epoch: 0, iteración; 2370 de 5354, Loss: 0.4792762756347656\n",
            "Epoch: 0, iteración; 2380 de 5354, Loss: 0.44002480506896974\n",
            "Epoch: 0, iteración; 2390 de 5354, Loss: 0.5520984649658203\n",
            "Epoch: 0, iteración; 2400 de 5354, Loss: 0.47268028259277345\n",
            "Epoch: 0, iteración; 2410 de 5354, Loss: 0.5931617736816406\n",
            "Epoch: 0, iteración; 2420 de 5354, Loss: 0.6466882228851318\n",
            "Epoch: 0, iteración; 2430 de 5354, Loss: 0.47882585525512694\n",
            "Epoch: 0, iteración; 2440 de 5354, Loss: 0.5205065250396729\n",
            "Epoch: 0, iteración; 2450 de 5354, Loss: 0.5242668151855469\n",
            "Epoch: 0, iteración; 2460 de 5354, Loss: 0.582017183303833\n",
            "Epoch: 0, iteración; 2470 de 5354, Loss: 0.4570573329925537\n",
            "Epoch: 0, iteración; 2480 de 5354, Loss: 0.6158766746520996\n",
            "Epoch: 0, iteración; 2490 de 5354, Loss: 0.6234833717346191\n",
            "Epoch: 0, iteración; 2500 de 5354, Loss: 0.5826816558837891\n",
            "Epoch: 0, iteración; 2510 de 5354, Loss: 0.6020204544067382\n",
            "Epoch: 0, iteración; 2520 de 5354, Loss: 0.5729150772094727\n",
            "Epoch: 0, iteración; 2530 de 5354, Loss: 0.6069697380065918\n",
            "Epoch: 0, iteración; 2540 de 5354, Loss: 0.5994091987609863\n",
            "Epoch: 0, iteración; 2550 de 5354, Loss: 0.6355189323425293\n",
            "Epoch: 0, iteración; 2560 de 5354, Loss: 0.5011689186096191\n",
            "Epoch: 0, iteración; 2570 de 5354, Loss: 0.5435683250427246\n",
            "Epoch: 0, iteración; 2580 de 5354, Loss: 0.554308557510376\n",
            "Epoch: 0, iteración; 2590 de 5354, Loss: 0.533924913406372\n",
            "Epoch: 0, iteración; 2600 de 5354, Loss: 0.5606258869171142\n",
            "Epoch: 0, iteración; 2610 de 5354, Loss: 0.5967519283294678\n",
            "Epoch: 0, iteración; 2620 de 5354, Loss: 0.49744691848754885\n",
            "Epoch: 0, iteración; 2630 de 5354, Loss: 0.5382188320159912\n",
            "Epoch: 0, iteración; 2640 de 5354, Loss: 0.5218028068542481\n",
            "Epoch: 0, iteración; 2650 de 5354, Loss: 0.5629657745361328\n",
            "Epoch: 0, iteración; 2660 de 5354, Loss: 0.5631310939788818\n",
            "Epoch: 0, iteración; 2670 de 5354, Loss: 0.5345744132995606\n",
            "Epoch: 0, iteración; 2680 de 5354, Loss: 0.5933408260345459\n",
            "Epoch: 0, iteración; 2690 de 5354, Loss: 0.563548994064331\n",
            "Epoch: 0, iteración; 2700 de 5354, Loss: 0.5899764060974121\n",
            "Epoch: 0, iteración; 2710 de 5354, Loss: 0.6287253856658935\n",
            "Epoch: 0, iteración; 2720 de 5354, Loss: 0.5838698863983154\n",
            "Epoch: 0, iteración; 2730 de 5354, Loss: 0.5599058151245118\n",
            "Epoch: 0, iteración; 2740 de 5354, Loss: 0.5275018692016602\n",
            "Epoch: 0, iteración; 2750 de 5354, Loss: 0.5096682548522949\n",
            "Epoch: 0, iteración; 2760 de 5354, Loss: 0.5724071979522705\n",
            "Epoch: 0, iteración; 2770 de 5354, Loss: 0.5405905723571778\n",
            "Epoch: 0, iteración; 2780 de 5354, Loss: 0.5831935405731201\n",
            "Epoch: 0, iteración; 2790 de 5354, Loss: 0.5310372352600098\n",
            "Epoch: 0, iteración; 2800 de 5354, Loss: 0.6187910079956055\n",
            "Epoch: 0, iteración; 2810 de 5354, Loss: 0.5539493083953857\n",
            "Epoch: 0, iteración; 2820 de 5354, Loss: 0.5943548202514648\n",
            "Epoch: 0, iteración; 2830 de 5354, Loss: 0.5305091381072998\n",
            "Epoch: 0, iteración; 2840 de 5354, Loss: 0.5338699340820312\n",
            "Epoch: 0, iteración; 2850 de 5354, Loss: 0.5695877552032471\n",
            "Epoch: 0, iteración; 2860 de 5354, Loss: 0.5539957046508789\n",
            "Epoch: 0, iteración; 2870 de 5354, Loss: 0.566740608215332\n",
            "Epoch: 0, iteración; 2880 de 5354, Loss: 0.5149215221405029\n",
            "Epoch: 0, iteración; 2890 de 5354, Loss: 0.5707987785339356\n",
            "Epoch: 0, iteración; 2900 de 5354, Loss: 0.5260546684265137\n",
            "Epoch: 0, iteración; 2910 de 5354, Loss: 0.599656343460083\n",
            "Epoch: 0, iteración; 2920 de 5354, Loss: 0.6025142192840576\n",
            "Epoch: 0, iteración; 2930 de 5354, Loss: 0.6292571544647216\n",
            "Epoch: 0, iteración; 2940 de 5354, Loss: 0.5864753246307373\n",
            "Epoch: 0, iteración; 2950 de 5354, Loss: 0.5677652359008789\n",
            "Epoch: 0, iteración; 2960 de 5354, Loss: 0.5648504734039307\n",
            "Epoch: 0, iteración; 2970 de 5354, Loss: 0.5224475383758544\n",
            "Epoch: 0, iteración; 2980 de 5354, Loss: 0.5208408832550049\n",
            "Epoch: 0, iteración; 2990 de 5354, Loss: 0.6044551849365234\n",
            "Epoch: 0, iteración; 3000 de 5354, Loss: 0.5529842376708984\n",
            "Epoch: 0, iteración; 3010 de 5354, Loss: 0.6195433139801025\n",
            "Epoch: 0, iteración; 3020 de 5354, Loss: 0.5839897632598877\n",
            "Epoch: 0, iteración; 3030 de 5354, Loss: 0.5538405418395996\n",
            "Epoch: 0, iteración; 3040 de 5354, Loss: 0.5866055488586426\n",
            "Epoch: 0, iteración; 3050 de 5354, Loss: 0.6099935531616211\n",
            "Epoch: 0, iteración; 3060 de 5354, Loss: 0.5686532020568847\n",
            "Epoch: 0, iteración; 3070 de 5354, Loss: 0.6526107311248779\n",
            "Epoch: 0, iteración; 3080 de 5354, Loss: 0.5375600337982178\n",
            "Epoch: 0, iteración; 3090 de 5354, Loss: 0.5514999389648437\n",
            "Epoch: 0, iteración; 3100 de 5354, Loss: 0.5599429607391357\n",
            "Epoch: 0, iteración; 3110 de 5354, Loss: 0.5047598361968995\n",
            "Epoch: 0, iteración; 3120 de 5354, Loss: 0.6282700061798095\n",
            "Epoch: 0, iteración; 3130 de 5354, Loss: 0.5704453468322754\n",
            "Epoch: 0, iteración; 3140 de 5354, Loss: 0.5594888210296631\n",
            "Epoch: 0, iteración; 3150 de 5354, Loss: 0.5452523231506348\n",
            "Epoch: 0, iteración; 3160 de 5354, Loss: 0.6296359539031983\n",
            "Epoch: 0, iteración; 3170 de 5354, Loss: 0.5602159976959229\n",
            "Epoch: 0, iteración; 3180 de 5354, Loss: 0.5851338386535645\n",
            "Epoch: 0, iteración; 3190 de 5354, Loss: 0.5826164722442627\n",
            "Epoch: 0, iteración; 3200 de 5354, Loss: 0.5953579425811768\n",
            "Epoch: 0, iteración; 3210 de 5354, Loss: 0.5011850357055664\n",
            "Epoch: 0, iteración; 3220 de 5354, Loss: 0.586125659942627\n",
            "Epoch: 0, iteración; 3230 de 5354, Loss: 0.5841022491455078\n",
            "Epoch: 0, iteración; 3240 de 5354, Loss: 0.5765680789947509\n",
            "Epoch: 0, iteración; 3250 de 5354, Loss: 0.6178110599517822\n",
            "Epoch: 0, iteración; 3260 de 5354, Loss: 0.5587302207946777\n",
            "Epoch: 0, iteración; 3270 de 5354, Loss: 0.5843082427978515\n",
            "Epoch: 0, iteración; 3280 de 5354, Loss: 0.6363790035247803\n",
            "Epoch: 0, iteración; 3290 de 5354, Loss: 0.5317380428314209\n",
            "Epoch: 0, iteración; 3300 de 5354, Loss: 0.6011329650878906\n",
            "Epoch: 0, iteración; 3310 de 5354, Loss: 0.5264829158782959\n",
            "Epoch: 0, iteración; 3320 de 5354, Loss: 0.5800671577453613\n",
            "Epoch: 0, iteración; 3330 de 5354, Loss: 0.5740653514862061\n",
            "Epoch: 0, iteración; 3340 de 5354, Loss: 0.5471311569213867\n",
            "Epoch: 0, iteración; 3350 de 5354, Loss: 0.55545015335083\n",
            "Epoch: 0, iteración; 3360 de 5354, Loss: 0.514852237701416\n",
            "Epoch: 0, iteración; 3370 de 5354, Loss: 0.601712989807129\n",
            "Epoch: 0, iteración; 3380 de 5354, Loss: 0.5844972610473633\n",
            "Epoch: 0, iteración; 3390 de 5354, Loss: 0.5823339462280274\n",
            "Epoch: 0, iteración; 3400 de 5354, Loss: 0.5250865936279296\n",
            "Epoch: 0, iteración; 3410 de 5354, Loss: 0.6396623611450195\n",
            "Epoch: 0, iteración; 3420 de 5354, Loss: 0.5586248874664307\n",
            "Epoch: 0, iteración; 3430 de 5354, Loss: 0.5933820724487304\n",
            "Epoch: 0, iteración; 3440 de 5354, Loss: 0.5632429599761963\n",
            "Epoch: 0, iteración; 3450 de 5354, Loss: 0.5118472576141357\n",
            "Epoch: 0, iteración; 3460 de 5354, Loss: 0.5941366672515869\n",
            "Epoch: 0, iteración; 3470 de 5354, Loss: 0.5472448825836181\n",
            "Epoch: 0, iteración; 3480 de 5354, Loss: 0.530821704864502\n",
            "Epoch: 0, iteración; 3490 de 5354, Loss: 0.5684165477752685\n",
            "Epoch: 0, iteración; 3500 de 5354, Loss: 0.6363832950592041\n",
            "Epoch: 0, iteración; 3510 de 5354, Loss: 0.6438391208648682\n",
            "Epoch: 0, iteración; 3520 de 5354, Loss: 0.6208532810211181\n",
            "Epoch: 0, iteración; 3530 de 5354, Loss: 0.5077626228332519\n",
            "Epoch: 0, iteración; 3540 de 5354, Loss: 0.5573967456817627\n",
            "Epoch: 0, iteración; 3550 de 5354, Loss: 0.5298141479492188\n",
            "Epoch: 0, iteración; 3560 de 5354, Loss: 0.5434159278869629\n",
            "Epoch: 0, iteración; 3570 de 5354, Loss: 0.566927433013916\n",
            "Epoch: 0, iteración; 3580 de 5354, Loss: 0.5234744071960449\n",
            "Epoch: 0, iteración; 3590 de 5354, Loss: 0.5436157703399658\n",
            "Epoch: 0, iteración; 3600 de 5354, Loss: 0.45690269470214845\n",
            "Epoch: 0, iteración; 3610 de 5354, Loss: 0.5823148727416992\n",
            "Epoch: 0, iteración; 3620 de 5354, Loss: 0.59269700050354\n",
            "Epoch: 0, iteración; 3630 de 5354, Loss: 0.5908413887023926\n",
            "Epoch: 0, iteración; 3640 de 5354, Loss: 0.5435678482055664\n",
            "Epoch: 0, iteración; 3650 de 5354, Loss: 0.5698134422302246\n",
            "Epoch: 0, iteración; 3660 de 5354, Loss: 0.5877589702606201\n",
            "Epoch: 0, iteración; 3670 de 5354, Loss: 0.5183576583862305\n",
            "Epoch: 0, iteración; 3680 de 5354, Loss: 0.5468208312988281\n",
            "Epoch: 0, iteración; 3690 de 5354, Loss: 0.6288590431213379\n",
            "Epoch: 0, iteración; 3700 de 5354, Loss: 0.4980222225189209\n",
            "Epoch: 0, iteración; 3710 de 5354, Loss: 0.5491581916809082\n",
            "Epoch: 0, iteración; 3720 de 5354, Loss: 0.5681963920593261\n",
            "Epoch: 0, iteración; 3730 de 5354, Loss: 0.6061604976654053\n",
            "Epoch: 0, iteración; 3740 de 5354, Loss: 0.6230226039886475\n",
            "Epoch: 0, iteración; 3750 de 5354, Loss: 0.5590061664581298\n",
            "Epoch: 0, iteración; 3760 de 5354, Loss: 0.586573600769043\n",
            "Epoch: 0, iteración; 3770 de 5354, Loss: 0.551013994216919\n",
            "Epoch: 0, iteración; 3780 de 5354, Loss: 0.5524009227752685\n",
            "Epoch: 0, iteración; 3790 de 5354, Loss: 0.6558401584625244\n",
            "Epoch: 0, iteración; 3800 de 5354, Loss: 0.5624439716339111\n",
            "Epoch: 0, iteración; 3810 de 5354, Loss: 0.5211471080780029\n",
            "Epoch: 0, iteración; 3820 de 5354, Loss: 0.4865304946899414\n",
            "Epoch: 0, iteración; 3830 de 5354, Loss: 0.5444723606109619\n",
            "Epoch: 0, iteración; 3840 de 5354, Loss: 0.6154476642608643\n",
            "Epoch: 0, iteración; 3850 de 5354, Loss: 0.5257846355438233\n",
            "Epoch: 0, iteración; 3860 de 5354, Loss: 0.5967740535736084\n",
            "Epoch: 0, iteración; 3870 de 5354, Loss: 0.4912503719329834\n",
            "Epoch: 0, iteración; 3880 de 5354, Loss: 0.5100451469421386\n",
            "Epoch: 0, iteración; 3890 de 5354, Loss: 0.5086637973785401\n",
            "Epoch: 0, iteración; 3900 de 5354, Loss: 0.5755756378173829\n",
            "Epoch: 0, iteración; 3910 de 5354, Loss: 0.5389433860778808\n",
            "Epoch: 0, iteración; 3920 de 5354, Loss: 0.6186141967773438\n",
            "Epoch: 0, iteración; 3930 de 5354, Loss: 0.5450198650360107\n",
            "Epoch: 0, iteración; 3940 de 5354, Loss: 0.5184733390808105\n",
            "Epoch: 0, iteración; 3950 de 5354, Loss: 0.5667287349700928\n",
            "Epoch: 0, iteración; 3960 de 5354, Loss: 0.6228895664215088\n",
            "Epoch: 0, iteración; 3970 de 5354, Loss: 0.5912609577178956\n",
            "Epoch: 0, iteración; 3980 de 5354, Loss: 0.5434375286102295\n",
            "Epoch: 0, iteración; 3990 de 5354, Loss: 0.5313278675079346\n",
            "Epoch: 0, iteración; 4000 de 5354, Loss: 0.6067991256713867\n",
            "Epoch: 0, iteración; 4010 de 5354, Loss: 0.533323860168457\n",
            "Epoch: 0, iteración; 4020 de 5354, Loss: 0.5321368217468262\n",
            "Epoch: 0, iteración; 4030 de 5354, Loss: 0.5052600383758545\n",
            "Epoch: 0, iteración; 4040 de 5354, Loss: 0.5801506996154785\n",
            "Epoch: 0, iteración; 4050 de 5354, Loss: 0.5620753765106201\n",
            "Epoch: 0, iteración; 4060 de 5354, Loss: 0.5248091697692872\n",
            "Epoch: 0, iteración; 4070 de 5354, Loss: 0.6080781936645507\n",
            "Epoch: 0, iteración; 4080 de 5354, Loss: 0.6067080974578858\n",
            "Epoch: 0, iteración; 4090 de 5354, Loss: 0.4939138889312744\n",
            "Epoch: 0, iteración; 4100 de 5354, Loss: 0.5927031993865967\n",
            "Epoch: 0, iteración; 4110 de 5354, Loss: 0.5505562782287597\n",
            "Epoch: 0, iteración; 4120 de 5354, Loss: 0.4753566741943359\n",
            "Epoch: 0, iteración; 4130 de 5354, Loss: 0.5389376640319824\n",
            "Epoch: 0, iteración; 4140 de 5354, Loss: 0.6244893550872803\n",
            "Epoch: 0, iteración; 4150 de 5354, Loss: 0.5662744522094727\n",
            "Epoch: 0, iteración; 4160 de 5354, Loss: 0.5846018314361572\n",
            "Epoch: 0, iteración; 4170 de 5354, Loss: 0.6297011852264405\n",
            "Epoch: 0, iteración; 4180 de 5354, Loss: 0.5519503116607666\n",
            "Epoch: 0, iteración; 4190 de 5354, Loss: 0.5958611965179443\n",
            "Epoch: 0, iteración; 4200 de 5354, Loss: 0.597809886932373\n",
            "Epoch: 0, iteración; 4210 de 5354, Loss: 0.6383860588073731\n",
            "Epoch: 0, iteración; 4220 de 5354, Loss: 0.5649259567260743\n",
            "Epoch: 0, iteración; 4230 de 5354, Loss: 0.5296236515045166\n",
            "Epoch: 0, iteración; 4240 de 5354, Loss: 0.5533685207366943\n",
            "Epoch: 0, iteración; 4250 de 5354, Loss: 0.5159859657287598\n",
            "Epoch: 0, iteración; 4260 de 5354, Loss: 0.49141592979431153\n",
            "Epoch: 0, iteración; 4270 de 5354, Loss: 0.5135931968688965\n",
            "Epoch: 0, iteración; 4280 de 5354, Loss: 0.5681427955627442\n",
            "Epoch: 0, iteración; 4290 de 5354, Loss: 0.56681227684021\n",
            "Epoch: 0, iteración; 4300 de 5354, Loss: 0.610230827331543\n",
            "Epoch: 0, iteración; 4310 de 5354, Loss: 0.6338103771209717\n",
            "Epoch: 0, iteración; 4320 de 5354, Loss: 0.5927410125732422\n",
            "Epoch: 0, iteración; 4330 de 5354, Loss: 0.4856123924255371\n",
            "Epoch: 0, iteración; 4340 de 5354, Loss: 0.5766030788421631\n",
            "Epoch: 0, iteración; 4350 de 5354, Loss: 0.6036691188812255\n",
            "Epoch: 0, iteración; 4360 de 5354, Loss: 0.5420420169830322\n",
            "Epoch: 0, iteración; 4370 de 5354, Loss: 0.5125071048736572\n",
            "Epoch: 0, iteración; 4380 de 5354, Loss: 0.5779709815979004\n",
            "Epoch: 0, iteración; 4390 de 5354, Loss: 0.6036683082580566\n",
            "Epoch: 0, iteración; 4400 de 5354, Loss: 0.5242183685302735\n",
            "Epoch: 0, iteración; 4410 de 5354, Loss: 0.5736697673797607\n",
            "Epoch: 0, iteración; 4420 de 5354, Loss: 0.5400286197662354\n",
            "Epoch: 0, iteración; 4430 de 5354, Loss: 0.6093297958374023\n",
            "Epoch: 0, iteración; 4440 de 5354, Loss: 0.5999159336090087\n",
            "Epoch: 0, iteración; 4450 de 5354, Loss: 0.5736017227172852\n",
            "Epoch: 0, iteración; 4460 de 5354, Loss: 0.6142278671264648\n",
            "Epoch: 0, iteración; 4470 de 5354, Loss: 0.5374276638031006\n",
            "Epoch: 0, iteración; 4480 de 5354, Loss: 0.5732099056243897\n",
            "Epoch: 0, iteración; 4490 de 5354, Loss: 0.6377169609069824\n",
            "Epoch: 0, iteración; 4500 de 5354, Loss: 0.5475513935089111\n",
            "Epoch: 0, iteración; 4510 de 5354, Loss: 0.5200723171234131\n",
            "Epoch: 0, iteración; 4520 de 5354, Loss: 0.5203536033630372\n",
            "Epoch: 0, iteración; 4530 de 5354, Loss: 0.5134689807891846\n",
            "Epoch: 0, iteración; 4540 de 5354, Loss: 0.52745041847229\n",
            "Epoch: 0, iteración; 4550 de 5354, Loss: 0.5530439376831054\n",
            "Epoch: 0, iteración; 4560 de 5354, Loss: 0.6322402477264404\n",
            "Epoch: 0, iteración; 4570 de 5354, Loss: 0.5349512100219727\n",
            "Epoch: 0, iteración; 4580 de 5354, Loss: 0.5315155982971191\n",
            "Epoch: 0, iteración; 4590 de 5354, Loss: 0.6278954982757569\n",
            "Epoch: 0, iteración; 4600 de 5354, Loss: 0.5235934257507324\n",
            "Epoch: 0, iteración; 4610 de 5354, Loss: 0.5057929515838623\n",
            "Epoch: 0, iteración; 4620 de 5354, Loss: 0.5748607635498046\n",
            "Epoch: 0, iteración; 4630 de 5354, Loss: 0.6192163944244384\n",
            "Epoch: 0, iteración; 4640 de 5354, Loss: 0.5736189842224121\n",
            "Epoch: 0, iteración; 4650 de 5354, Loss: 0.5004994869232178\n",
            "Epoch: 0, iteración; 4660 de 5354, Loss: 0.5440681457519532\n",
            "Epoch: 0, iteración; 4670 de 5354, Loss: 0.5212979793548584\n",
            "Epoch: 0, iteración; 4680 de 5354, Loss: 0.5603382587432861\n",
            "Epoch: 0, iteración; 4690 de 5354, Loss: 0.6329179763793945\n",
            "Epoch: 0, iteración; 4700 de 5354, Loss: 0.5485804557800293\n",
            "Epoch: 0, iteración; 4710 de 5354, Loss: 0.5336226940155029\n",
            "Epoch: 0, iteración; 4720 de 5354, Loss: 0.48732662200927734\n",
            "Epoch: 0, iteración; 4730 de 5354, Loss: 0.5581521034240723\n",
            "Epoch: 0, iteración; 4740 de 5354, Loss: 0.5298530578613281\n",
            "Epoch: 0, iteración; 4750 de 5354, Loss: 0.5733358860015869\n",
            "Epoch: 0, iteración; 4760 de 5354, Loss: 0.5112029075622558\n",
            "Epoch: 0, iteración; 4770 de 5354, Loss: 0.5627066612243652\n",
            "Epoch: 0, iteración; 4780 de 5354, Loss: 0.6051722049713135\n",
            "Epoch: 0, iteración; 4790 de 5354, Loss: 0.5241777420043945\n",
            "Epoch: 0, iteración; 4800 de 5354, Loss: 0.5473638534545898\n",
            "Epoch: 0, iteración; 4810 de 5354, Loss: 0.6247369766235351\n",
            "Epoch: 0, iteración; 4820 de 5354, Loss: 0.607344675064087\n",
            "Epoch: 0, iteración; 4830 de 5354, Loss: 0.590820026397705\n",
            "Epoch: 0, iteración; 4840 de 5354, Loss: 0.5789130687713623\n",
            "Epoch: 0, iteración; 4850 de 5354, Loss: 0.5811042785644531\n",
            "Epoch: 0, iteración; 4860 de 5354, Loss: 0.6061176776885986\n",
            "Epoch: 0, iteración; 4870 de 5354, Loss: 0.585715389251709\n",
            "Epoch: 0, iteración; 4880 de 5354, Loss: 0.5534488677978515\n",
            "Epoch: 0, iteración; 4890 de 5354, Loss: 0.5464482307434082\n",
            "Epoch: 0, iteración; 4900 de 5354, Loss: 0.5328930854797364\n",
            "Epoch: 0, iteración; 4910 de 5354, Loss: 0.5482837677001953\n",
            "Epoch: 0, iteración; 4920 de 5354, Loss: 0.5229135036468506\n",
            "Epoch: 0, iteración; 4930 de 5354, Loss: 0.6402235984802246\n",
            "Epoch: 0, iteración; 4940 de 5354, Loss: 0.5229343891143798\n",
            "Epoch: 0, iteración; 4950 de 5354, Loss: 0.5267406463623047\n",
            "Epoch: 0, iteración; 4960 de 5354, Loss: 0.6217512130737305\n",
            "Epoch: 0, iteración; 4970 de 5354, Loss: 0.5173366069793701\n",
            "Epoch: 0, iteración; 4980 de 5354, Loss: 0.45212736129760744\n",
            "Epoch: 0, iteración; 4990 de 5354, Loss: 0.5412659645080566\n",
            "Epoch: 0, iteración; 5000 de 5354, Loss: 0.6271552085876465\n",
            "Epoch: 0, iteración; 5010 de 5354, Loss: 0.5810352802276612\n",
            "Epoch: 0, iteración; 5020 de 5354, Loss: 0.5678943157196045\n",
            "Epoch: 0, iteración; 5030 de 5354, Loss: 0.5665574073791504\n",
            "Epoch: 0, iteración; 5040 de 5354, Loss: 0.5448235988616943\n",
            "Epoch: 0, iteración; 5050 de 5354, Loss: 0.5629475116729736\n",
            "Epoch: 0, iteración; 5060 de 5354, Loss: 0.5269536972045898\n",
            "Epoch: 0, iteración; 5070 de 5354, Loss: 0.5425182819366455\n",
            "Epoch: 0, iteración; 5080 de 5354, Loss: 0.5094312191009521\n",
            "Epoch: 0, iteración; 5090 de 5354, Loss: 0.6050349235534668\n",
            "Epoch: 0, iteración; 5100 de 5354, Loss: 0.5703661441802979\n",
            "Epoch: 0, iteración; 5110 de 5354, Loss: 0.5922746181488037\n",
            "Epoch: 0, iteración; 5120 de 5354, Loss: 0.5850559711456299\n",
            "Epoch: 0, iteración; 5130 de 5354, Loss: 0.5367323398590088\n",
            "Epoch: 0, iteración; 5140 de 5354, Loss: 0.6052066326141358\n",
            "Epoch: 0, iteración; 5150 de 5354, Loss: 0.5525933742523194\n",
            "Epoch: 0, iteración; 5160 de 5354, Loss: 0.5726638793945312\n",
            "Epoch: 0, iteración; 5170 de 5354, Loss: 0.5734704494476318\n",
            "Epoch: 0, iteración; 5180 de 5354, Loss: 0.5622354984283447\n",
            "Epoch: 0, iteración; 5190 de 5354, Loss: 0.5858065605163574\n",
            "Epoch: 0, iteración; 5200 de 5354, Loss: 0.5906486988067627\n",
            "Epoch: 0, iteración; 5210 de 5354, Loss: 0.5947835922241211\n",
            "Epoch: 0, iteración; 5220 de 5354, Loss: 0.5785808086395263\n",
            "Epoch: 0, iteración; 5230 de 5354, Loss: 0.5357903957366943\n",
            "Epoch: 0, iteración; 5240 de 5354, Loss: 0.6068721771240234\n",
            "Epoch: 0, iteración; 5250 de 5354, Loss: 0.6453315258026123\n",
            "Epoch: 0, iteración; 5260 de 5354, Loss: 0.5660814762115478\n",
            "Epoch: 0, iteración; 5270 de 5354, Loss: 0.5589211940765381\n",
            "Epoch: 0, iteración; 5280 de 5354, Loss: 0.6017849445343018\n",
            "Epoch: 0, iteración; 5290 de 5354, Loss: 0.5710149765014648\n",
            "Epoch: 0, iteración; 5300 de 5354, Loss: 0.6081146240234375\n",
            "Epoch: 0, iteración; 5310 de 5354, Loss: 0.5709890842437744\n",
            "Epoch: 0, iteración; 5320 de 5354, Loss: 0.5677718162536621\n",
            "Epoch: 0, iteración; 5330 de 5354, Loss: 0.5215446949005127\n",
            "Epoch: 0, iteración; 5340 de 5354, Loss: 0.5874153137207031\n",
            "Epoch: 0, iteración; 5350 de 5354, Loss: 0.5553594589233398\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainBert(epoch)"
      ],
      "id": "SQF5Ds6_4nZZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38537bf-4293-47bf-f266-bbb981200f78",
        "id": "XzVRNR2X4nZZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30_separados.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "id": "XzVRNR2X4nZZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJUBEWAR4nZZ"
      },
      "source": [
        "##### Evaluación del modelo"
      ],
      "id": "VJUBEWAR4nZZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Xq5JdwC4nZZ"
      },
      "outputs": [],
      "source": [
        "def validationBert(epoch):\n",
        "  model.eval()\n",
        "  fin_targets=[]\n",
        "  fin_outputs=[]\n",
        "  num_iteraciones = len(testing_loader)\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testing_loader, 0):\n",
        "      ids = data['ids'].to(device)\n",
        "      mask = data['mask'].to(device)\n",
        "      token_type_ids = data['token_type_ids'].to(device)\n",
        "      targets = data['target'].to(device)\n",
        "\n",
        "      print(f\"Batch {i} de {num_iteraciones}\")\n",
        "\n",
        "      outputs = model(ids, mask, token_type_ids)\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "  return fin_outputs, fin_targets"
      ],
      "id": "9Xq5JdwC4nZZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "rtVit9Iq4nZZ"
      },
      "id": "rtVit9Iq4nZZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a612e1-6663-4391-fffc-28797c3412e0",
        "id": "Bc2DoI9w4nZZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado correctamente\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30_separados.pth\"):\n",
        "  model = BERTClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30_separados.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30_separados.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "id": "Bc2DoI9w4nZZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f660cabc-b76c-4490-c7d4-6da84a80cfa3",
        "id": "RM5xUeUs4nZZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 de 1562\n",
            "Batch 1 de 1562\n",
            "Batch 2 de 1562\n",
            "Batch 3 de 1562\n",
            "Batch 4 de 1562\n",
            "Batch 5 de 1562\n",
            "Batch 6 de 1562\n",
            "Batch 7 de 1562\n",
            "Batch 8 de 1562\n",
            "Batch 9 de 1562\n",
            "Batch 10 de 1562\n",
            "Batch 11 de 1562\n",
            "Batch 12 de 1562\n",
            "Batch 13 de 1562\n",
            "Batch 14 de 1562\n",
            "Batch 15 de 1562\n",
            "Batch 16 de 1562\n",
            "Batch 17 de 1562\n",
            "Batch 18 de 1562\n",
            "Batch 19 de 1562\n",
            "Batch 20 de 1562\n",
            "Batch 21 de 1562\n",
            "Batch 22 de 1562\n",
            "Batch 23 de 1562\n",
            "Batch 24 de 1562\n",
            "Batch 25 de 1562\n",
            "Batch 26 de 1562\n",
            "Batch 27 de 1562\n",
            "Batch 28 de 1562\n",
            "Batch 29 de 1562\n",
            "Batch 30 de 1562\n",
            "Batch 31 de 1562\n",
            "Batch 32 de 1562\n",
            "Batch 33 de 1562\n",
            "Batch 34 de 1562\n",
            "Batch 35 de 1562\n",
            "Batch 36 de 1562\n",
            "Batch 37 de 1562\n",
            "Batch 38 de 1562\n",
            "Batch 39 de 1562\n",
            "Batch 40 de 1562\n",
            "Batch 41 de 1562\n",
            "Batch 42 de 1562\n",
            "Batch 43 de 1562\n",
            "Batch 44 de 1562\n",
            "Batch 45 de 1562\n",
            "Batch 46 de 1562\n",
            "Batch 47 de 1562\n",
            "Batch 48 de 1562\n",
            "Batch 49 de 1562\n",
            "Batch 50 de 1562\n",
            "Batch 51 de 1562\n",
            "Batch 52 de 1562\n",
            "Batch 53 de 1562\n",
            "Batch 54 de 1562\n",
            "Batch 55 de 1562\n",
            "Batch 56 de 1562\n",
            "Batch 57 de 1562\n",
            "Batch 58 de 1562\n",
            "Batch 59 de 1562\n",
            "Batch 60 de 1562\n",
            "Batch 61 de 1562\n",
            "Batch 62 de 1562\n",
            "Batch 63 de 1562\n",
            "Batch 64 de 1562\n",
            "Batch 65 de 1562\n",
            "Batch 66 de 1562\n",
            "Batch 67 de 1562\n",
            "Batch 68 de 1562\n",
            "Batch 69 de 1562\n",
            "Batch 70 de 1562\n",
            "Batch 71 de 1562\n",
            "Batch 72 de 1562\n",
            "Batch 73 de 1562\n",
            "Batch 74 de 1562\n",
            "Batch 75 de 1562\n",
            "Batch 76 de 1562\n",
            "Batch 77 de 1562\n",
            "Batch 78 de 1562\n",
            "Batch 79 de 1562\n",
            "Batch 80 de 1562\n",
            "Batch 81 de 1562\n",
            "Batch 82 de 1562\n",
            "Batch 83 de 1562\n",
            "Batch 84 de 1562\n",
            "Batch 85 de 1562\n",
            "Batch 86 de 1562\n",
            "Batch 87 de 1562\n",
            "Batch 88 de 1562\n",
            "Batch 89 de 1562\n",
            "Batch 90 de 1562\n",
            "Batch 91 de 1562\n",
            "Batch 92 de 1562\n",
            "Batch 93 de 1562\n",
            "Batch 94 de 1562\n",
            "Batch 95 de 1562\n",
            "Batch 96 de 1562\n",
            "Batch 97 de 1562\n",
            "Batch 98 de 1562\n",
            "Batch 99 de 1562\n",
            "Batch 100 de 1562\n",
            "Batch 101 de 1562\n",
            "Batch 102 de 1562\n",
            "Batch 103 de 1562\n",
            "Batch 104 de 1562\n",
            "Batch 105 de 1562\n",
            "Batch 106 de 1562\n",
            "Batch 107 de 1562\n",
            "Batch 108 de 1562\n",
            "Batch 109 de 1562\n",
            "Batch 110 de 1562\n",
            "Batch 111 de 1562\n",
            "Batch 112 de 1562\n",
            "Batch 113 de 1562\n",
            "Batch 114 de 1562\n",
            "Batch 115 de 1562\n",
            "Batch 116 de 1562\n",
            "Batch 117 de 1562\n",
            "Batch 118 de 1562\n",
            "Batch 119 de 1562\n",
            "Batch 120 de 1562\n",
            "Batch 121 de 1562\n",
            "Batch 122 de 1562\n",
            "Batch 123 de 1562\n",
            "Batch 124 de 1562\n",
            "Batch 125 de 1562\n",
            "Batch 126 de 1562\n",
            "Batch 127 de 1562\n",
            "Batch 128 de 1562\n",
            "Batch 129 de 1562\n",
            "Batch 130 de 1562\n",
            "Batch 131 de 1562\n",
            "Batch 132 de 1562\n",
            "Batch 133 de 1562\n",
            "Batch 134 de 1562\n",
            "Batch 135 de 1562\n",
            "Batch 136 de 1562\n",
            "Batch 137 de 1562\n",
            "Batch 138 de 1562\n",
            "Batch 139 de 1562\n",
            "Batch 140 de 1562\n",
            "Batch 141 de 1562\n",
            "Batch 142 de 1562\n",
            "Batch 143 de 1562\n",
            "Batch 144 de 1562\n",
            "Batch 145 de 1562\n",
            "Batch 146 de 1562\n",
            "Batch 147 de 1562\n",
            "Batch 148 de 1562\n",
            "Batch 149 de 1562\n",
            "Batch 150 de 1562\n",
            "Batch 151 de 1562\n",
            "Batch 152 de 1562\n",
            "Batch 153 de 1562\n",
            "Batch 154 de 1562\n",
            "Batch 155 de 1562\n",
            "Batch 156 de 1562\n",
            "Batch 157 de 1562\n",
            "Batch 158 de 1562\n",
            "Batch 159 de 1562\n",
            "Batch 160 de 1562\n",
            "Batch 161 de 1562\n",
            "Batch 162 de 1562\n",
            "Batch 163 de 1562\n",
            "Batch 164 de 1562\n",
            "Batch 165 de 1562\n",
            "Batch 166 de 1562\n",
            "Batch 167 de 1562\n",
            "Batch 168 de 1562\n",
            "Batch 169 de 1562\n",
            "Batch 170 de 1562\n",
            "Batch 171 de 1562\n",
            "Batch 172 de 1562\n",
            "Batch 173 de 1562\n",
            "Batch 174 de 1562\n",
            "Batch 175 de 1562\n",
            "Batch 176 de 1562\n",
            "Batch 177 de 1562\n",
            "Batch 178 de 1562\n",
            "Batch 179 de 1562\n",
            "Batch 180 de 1562\n",
            "Batch 181 de 1562\n",
            "Batch 182 de 1562\n",
            "Batch 183 de 1562\n",
            "Batch 184 de 1562\n",
            "Batch 185 de 1562\n",
            "Batch 186 de 1562\n",
            "Batch 187 de 1562\n",
            "Batch 188 de 1562\n",
            "Batch 189 de 1562\n",
            "Batch 190 de 1562\n",
            "Batch 191 de 1562\n",
            "Batch 192 de 1562\n",
            "Batch 193 de 1562\n",
            "Batch 194 de 1562\n",
            "Batch 195 de 1562\n",
            "Batch 196 de 1562\n",
            "Batch 197 de 1562\n",
            "Batch 198 de 1562\n",
            "Batch 199 de 1562\n",
            "Batch 200 de 1562\n",
            "Batch 201 de 1562\n",
            "Batch 202 de 1562\n",
            "Batch 203 de 1562\n",
            "Batch 204 de 1562\n",
            "Batch 205 de 1562\n",
            "Batch 206 de 1562\n",
            "Batch 207 de 1562\n",
            "Batch 208 de 1562\n",
            "Batch 209 de 1562\n",
            "Batch 210 de 1562\n",
            "Batch 211 de 1562\n",
            "Batch 212 de 1562\n",
            "Batch 213 de 1562\n",
            "Batch 214 de 1562\n",
            "Batch 215 de 1562\n",
            "Batch 216 de 1562\n",
            "Batch 217 de 1562\n",
            "Batch 218 de 1562\n",
            "Batch 219 de 1562\n",
            "Batch 220 de 1562\n",
            "Batch 221 de 1562\n",
            "Batch 222 de 1562\n",
            "Batch 223 de 1562\n",
            "Batch 224 de 1562\n",
            "Batch 225 de 1562\n",
            "Batch 226 de 1562\n",
            "Batch 227 de 1562\n",
            "Batch 228 de 1562\n",
            "Batch 229 de 1562\n",
            "Batch 230 de 1562\n",
            "Batch 231 de 1562\n",
            "Batch 232 de 1562\n",
            "Batch 233 de 1562\n",
            "Batch 234 de 1562\n",
            "Batch 235 de 1562\n",
            "Batch 236 de 1562\n",
            "Batch 237 de 1562\n",
            "Batch 238 de 1562\n",
            "Batch 239 de 1562\n",
            "Batch 240 de 1562\n",
            "Batch 241 de 1562\n",
            "Batch 242 de 1562\n",
            "Batch 243 de 1562\n",
            "Batch 244 de 1562\n",
            "Batch 245 de 1562\n",
            "Batch 246 de 1562\n",
            "Batch 247 de 1562\n",
            "Batch 248 de 1562\n",
            "Batch 249 de 1562\n",
            "Batch 250 de 1562\n",
            "Batch 251 de 1562\n",
            "Batch 252 de 1562\n",
            "Batch 253 de 1562\n",
            "Batch 254 de 1562\n",
            "Batch 255 de 1562\n",
            "Batch 256 de 1562\n",
            "Batch 257 de 1562\n",
            "Batch 258 de 1562\n",
            "Batch 259 de 1562\n",
            "Batch 260 de 1562\n",
            "Batch 261 de 1562\n",
            "Batch 262 de 1562\n",
            "Batch 263 de 1562\n",
            "Batch 264 de 1562\n",
            "Batch 265 de 1562\n",
            "Batch 266 de 1562\n",
            "Batch 267 de 1562\n",
            "Batch 268 de 1562\n",
            "Batch 269 de 1562\n",
            "Batch 270 de 1562\n",
            "Batch 271 de 1562\n",
            "Batch 272 de 1562\n",
            "Batch 273 de 1562\n",
            "Batch 274 de 1562\n",
            "Batch 275 de 1562\n",
            "Batch 276 de 1562\n",
            "Batch 277 de 1562\n",
            "Batch 278 de 1562\n",
            "Batch 279 de 1562\n",
            "Batch 280 de 1562\n",
            "Batch 281 de 1562\n",
            "Batch 282 de 1562\n",
            "Batch 283 de 1562\n",
            "Batch 284 de 1562\n",
            "Batch 285 de 1562\n",
            "Batch 286 de 1562\n",
            "Batch 287 de 1562\n",
            "Batch 288 de 1562\n",
            "Batch 289 de 1562\n",
            "Batch 290 de 1562\n",
            "Batch 291 de 1562\n",
            "Batch 292 de 1562\n",
            "Batch 293 de 1562\n",
            "Batch 294 de 1562\n",
            "Batch 295 de 1562\n",
            "Batch 296 de 1562\n",
            "Batch 297 de 1562\n",
            "Batch 298 de 1562\n",
            "Batch 299 de 1562\n",
            "Batch 300 de 1562\n",
            "Batch 301 de 1562\n",
            "Batch 302 de 1562\n",
            "Batch 303 de 1562\n",
            "Batch 304 de 1562\n",
            "Batch 305 de 1562\n",
            "Batch 306 de 1562\n",
            "Batch 307 de 1562\n",
            "Batch 308 de 1562\n",
            "Batch 309 de 1562\n",
            "Batch 310 de 1562\n",
            "Batch 311 de 1562\n",
            "Batch 312 de 1562\n",
            "Batch 313 de 1562\n",
            "Batch 314 de 1562\n",
            "Batch 315 de 1562\n",
            "Batch 316 de 1562\n",
            "Batch 317 de 1562\n",
            "Batch 318 de 1562\n",
            "Batch 319 de 1562\n",
            "Batch 320 de 1562\n",
            "Batch 321 de 1562\n",
            "Batch 322 de 1562\n",
            "Batch 323 de 1562\n",
            "Batch 324 de 1562\n",
            "Batch 325 de 1562\n",
            "Batch 326 de 1562\n",
            "Batch 327 de 1562\n",
            "Batch 328 de 1562\n",
            "Batch 329 de 1562\n",
            "Batch 330 de 1562\n",
            "Batch 331 de 1562\n",
            "Batch 332 de 1562\n",
            "Batch 333 de 1562\n",
            "Batch 334 de 1562\n",
            "Batch 335 de 1562\n",
            "Batch 336 de 1562\n",
            "Batch 337 de 1562\n",
            "Batch 338 de 1562\n",
            "Batch 339 de 1562\n",
            "Batch 340 de 1562\n",
            "Batch 341 de 1562\n",
            "Batch 342 de 1562\n",
            "Batch 343 de 1562\n",
            "Batch 344 de 1562\n",
            "Batch 345 de 1562\n",
            "Batch 346 de 1562\n",
            "Batch 347 de 1562\n",
            "Batch 348 de 1562\n",
            "Batch 349 de 1562\n",
            "Batch 350 de 1562\n",
            "Batch 351 de 1562\n",
            "Batch 352 de 1562\n",
            "Batch 353 de 1562\n",
            "Batch 354 de 1562\n",
            "Batch 355 de 1562\n",
            "Batch 356 de 1562\n",
            "Batch 357 de 1562\n",
            "Batch 358 de 1562\n",
            "Batch 359 de 1562\n",
            "Batch 360 de 1562\n",
            "Batch 361 de 1562\n",
            "Batch 362 de 1562\n",
            "Batch 363 de 1562\n",
            "Batch 364 de 1562\n",
            "Batch 365 de 1562\n",
            "Batch 366 de 1562\n",
            "Batch 367 de 1562\n",
            "Batch 368 de 1562\n",
            "Batch 369 de 1562\n",
            "Batch 370 de 1562\n",
            "Batch 371 de 1562\n",
            "Batch 372 de 1562\n",
            "Batch 373 de 1562\n",
            "Batch 374 de 1562\n",
            "Batch 375 de 1562\n",
            "Batch 376 de 1562\n",
            "Batch 377 de 1562\n",
            "Batch 378 de 1562\n",
            "Batch 379 de 1562\n",
            "Batch 380 de 1562\n",
            "Batch 381 de 1562\n",
            "Batch 382 de 1562\n",
            "Batch 383 de 1562\n",
            "Batch 384 de 1562\n",
            "Batch 385 de 1562\n",
            "Batch 386 de 1562\n",
            "Batch 387 de 1562\n",
            "Batch 388 de 1562\n",
            "Batch 389 de 1562\n",
            "Batch 390 de 1562\n",
            "Batch 391 de 1562\n",
            "Batch 392 de 1562\n",
            "Batch 393 de 1562\n",
            "Batch 394 de 1562\n",
            "Batch 395 de 1562\n",
            "Batch 396 de 1562\n",
            "Batch 397 de 1562\n",
            "Batch 398 de 1562\n",
            "Batch 399 de 1562\n",
            "Batch 400 de 1562\n",
            "Batch 401 de 1562\n",
            "Batch 402 de 1562\n",
            "Batch 403 de 1562\n",
            "Batch 404 de 1562\n",
            "Batch 405 de 1562\n",
            "Batch 406 de 1562\n",
            "Batch 407 de 1562\n",
            "Batch 408 de 1562\n",
            "Batch 409 de 1562\n",
            "Batch 410 de 1562\n",
            "Batch 411 de 1562\n",
            "Batch 412 de 1562\n",
            "Batch 413 de 1562\n",
            "Batch 414 de 1562\n",
            "Batch 415 de 1562\n",
            "Batch 416 de 1562\n",
            "Batch 417 de 1562\n",
            "Batch 418 de 1562\n",
            "Batch 419 de 1562\n",
            "Batch 420 de 1562\n",
            "Batch 421 de 1562\n",
            "Batch 422 de 1562\n",
            "Batch 423 de 1562\n",
            "Batch 424 de 1562\n",
            "Batch 425 de 1562\n",
            "Batch 426 de 1562\n",
            "Batch 427 de 1562\n",
            "Batch 428 de 1562\n",
            "Batch 429 de 1562\n",
            "Batch 430 de 1562\n",
            "Batch 431 de 1562\n",
            "Batch 432 de 1562\n",
            "Batch 433 de 1562\n",
            "Batch 434 de 1562\n",
            "Batch 435 de 1562\n",
            "Batch 436 de 1562\n",
            "Batch 437 de 1562\n",
            "Batch 438 de 1562\n",
            "Batch 439 de 1562\n",
            "Batch 440 de 1562\n",
            "Batch 441 de 1562\n",
            "Batch 442 de 1562\n",
            "Batch 443 de 1562\n",
            "Batch 444 de 1562\n",
            "Batch 445 de 1562\n",
            "Batch 446 de 1562\n",
            "Batch 447 de 1562\n",
            "Batch 448 de 1562\n",
            "Batch 449 de 1562\n",
            "Batch 450 de 1562\n",
            "Batch 451 de 1562\n",
            "Batch 452 de 1562\n",
            "Batch 453 de 1562\n",
            "Batch 454 de 1562\n",
            "Batch 455 de 1562\n",
            "Batch 456 de 1562\n",
            "Batch 457 de 1562\n",
            "Batch 458 de 1562\n",
            "Batch 459 de 1562\n",
            "Batch 460 de 1562\n",
            "Batch 461 de 1562\n",
            "Batch 462 de 1562\n",
            "Batch 463 de 1562\n",
            "Batch 464 de 1562\n",
            "Batch 465 de 1562\n",
            "Batch 466 de 1562\n",
            "Batch 467 de 1562\n",
            "Batch 468 de 1562\n",
            "Batch 469 de 1562\n",
            "Batch 470 de 1562\n",
            "Batch 471 de 1562\n",
            "Batch 472 de 1562\n",
            "Batch 473 de 1562\n",
            "Batch 474 de 1562\n",
            "Batch 475 de 1562\n",
            "Batch 476 de 1562\n",
            "Batch 477 de 1562\n",
            "Batch 478 de 1562\n",
            "Batch 479 de 1562\n",
            "Batch 480 de 1562\n",
            "Batch 481 de 1562\n",
            "Batch 482 de 1562\n",
            "Batch 483 de 1562\n",
            "Batch 484 de 1562\n",
            "Batch 485 de 1562\n",
            "Batch 486 de 1562\n",
            "Batch 487 de 1562\n",
            "Batch 488 de 1562\n",
            "Batch 489 de 1562\n",
            "Batch 490 de 1562\n",
            "Batch 491 de 1562\n",
            "Batch 492 de 1562\n",
            "Batch 493 de 1562\n",
            "Batch 494 de 1562\n",
            "Batch 495 de 1562\n",
            "Batch 496 de 1562\n",
            "Batch 497 de 1562\n",
            "Batch 498 de 1562\n",
            "Batch 499 de 1562\n",
            "Batch 500 de 1562\n",
            "Batch 501 de 1562\n",
            "Batch 502 de 1562\n",
            "Batch 503 de 1562\n",
            "Batch 504 de 1562\n",
            "Batch 505 de 1562\n",
            "Batch 506 de 1562\n",
            "Batch 507 de 1562\n",
            "Batch 508 de 1562\n",
            "Batch 509 de 1562\n",
            "Batch 510 de 1562\n",
            "Batch 511 de 1562\n",
            "Batch 512 de 1562\n",
            "Batch 513 de 1562\n",
            "Batch 514 de 1562\n",
            "Batch 515 de 1562\n",
            "Batch 516 de 1562\n",
            "Batch 517 de 1562\n",
            "Batch 518 de 1562\n",
            "Batch 519 de 1562\n",
            "Batch 520 de 1562\n",
            "Batch 521 de 1562\n",
            "Batch 522 de 1562\n",
            "Batch 523 de 1562\n",
            "Batch 524 de 1562\n",
            "Batch 525 de 1562\n",
            "Batch 526 de 1562\n",
            "Batch 527 de 1562\n",
            "Batch 528 de 1562\n",
            "Batch 529 de 1562\n",
            "Batch 530 de 1562\n",
            "Batch 531 de 1562\n",
            "Batch 532 de 1562\n",
            "Batch 533 de 1562\n",
            "Batch 534 de 1562\n",
            "Batch 535 de 1562\n",
            "Batch 536 de 1562\n",
            "Batch 537 de 1562\n",
            "Batch 538 de 1562\n",
            "Batch 539 de 1562\n",
            "Batch 540 de 1562\n",
            "Batch 541 de 1562\n",
            "Batch 542 de 1562\n",
            "Batch 543 de 1562\n",
            "Batch 544 de 1562\n",
            "Batch 545 de 1562\n",
            "Batch 546 de 1562\n",
            "Batch 547 de 1562\n",
            "Batch 548 de 1562\n",
            "Batch 549 de 1562\n",
            "Batch 550 de 1562\n",
            "Batch 551 de 1562\n",
            "Batch 552 de 1562\n",
            "Batch 553 de 1562\n",
            "Batch 554 de 1562\n",
            "Batch 555 de 1562\n",
            "Batch 556 de 1562\n",
            "Batch 557 de 1562\n",
            "Batch 558 de 1562\n",
            "Batch 559 de 1562\n",
            "Batch 560 de 1562\n",
            "Batch 561 de 1562\n",
            "Batch 562 de 1562\n",
            "Batch 563 de 1562\n",
            "Batch 564 de 1562\n",
            "Batch 565 de 1562\n",
            "Batch 566 de 1562\n",
            "Batch 567 de 1562\n",
            "Batch 568 de 1562\n",
            "Batch 569 de 1562\n",
            "Batch 570 de 1562\n",
            "Batch 571 de 1562\n",
            "Batch 572 de 1562\n",
            "Batch 573 de 1562\n",
            "Batch 574 de 1562\n",
            "Batch 575 de 1562\n",
            "Batch 576 de 1562\n",
            "Batch 577 de 1562\n",
            "Batch 578 de 1562\n",
            "Batch 579 de 1562\n",
            "Batch 580 de 1562\n",
            "Batch 581 de 1562\n",
            "Batch 582 de 1562\n",
            "Batch 583 de 1562\n",
            "Batch 584 de 1562\n",
            "Batch 585 de 1562\n",
            "Batch 586 de 1562\n",
            "Batch 587 de 1562\n",
            "Batch 588 de 1562\n",
            "Batch 589 de 1562\n",
            "Batch 590 de 1562\n",
            "Batch 591 de 1562\n",
            "Batch 592 de 1562\n",
            "Batch 593 de 1562\n",
            "Batch 594 de 1562\n",
            "Batch 595 de 1562\n",
            "Batch 596 de 1562\n",
            "Batch 597 de 1562\n",
            "Batch 598 de 1562\n",
            "Batch 599 de 1562\n",
            "Batch 600 de 1562\n",
            "Batch 601 de 1562\n",
            "Batch 602 de 1562\n",
            "Batch 603 de 1562\n",
            "Batch 604 de 1562\n",
            "Batch 605 de 1562\n",
            "Batch 606 de 1562\n",
            "Batch 607 de 1562\n",
            "Batch 608 de 1562\n",
            "Batch 609 de 1562\n",
            "Batch 610 de 1562\n",
            "Batch 611 de 1562\n",
            "Batch 612 de 1562\n",
            "Batch 613 de 1562\n",
            "Batch 614 de 1562\n",
            "Batch 615 de 1562\n",
            "Batch 616 de 1562\n",
            "Batch 617 de 1562\n",
            "Batch 618 de 1562\n",
            "Batch 619 de 1562\n",
            "Batch 620 de 1562\n",
            "Batch 621 de 1562\n",
            "Batch 622 de 1562\n",
            "Batch 623 de 1562\n",
            "Batch 624 de 1562\n",
            "Batch 625 de 1562\n",
            "Batch 626 de 1562\n",
            "Batch 627 de 1562\n",
            "Batch 628 de 1562\n",
            "Batch 629 de 1562\n",
            "Batch 630 de 1562\n",
            "Batch 631 de 1562\n",
            "Batch 632 de 1562\n",
            "Batch 633 de 1562\n",
            "Batch 634 de 1562\n",
            "Batch 635 de 1562\n",
            "Batch 636 de 1562\n",
            "Batch 637 de 1562\n",
            "Batch 638 de 1562\n",
            "Batch 639 de 1562\n",
            "Batch 640 de 1562\n",
            "Batch 641 de 1562\n",
            "Batch 642 de 1562\n",
            "Batch 643 de 1562\n",
            "Batch 644 de 1562\n",
            "Batch 645 de 1562\n",
            "Batch 646 de 1562\n",
            "Batch 647 de 1562\n",
            "Batch 648 de 1562\n",
            "Batch 649 de 1562\n",
            "Batch 650 de 1562\n",
            "Batch 651 de 1562\n",
            "Batch 652 de 1562\n",
            "Batch 653 de 1562\n",
            "Batch 654 de 1562\n",
            "Batch 655 de 1562\n",
            "Batch 656 de 1562\n",
            "Batch 657 de 1562\n",
            "Batch 658 de 1562\n",
            "Batch 659 de 1562\n",
            "Batch 660 de 1562\n",
            "Batch 661 de 1562\n",
            "Batch 662 de 1562\n",
            "Batch 663 de 1562\n",
            "Batch 664 de 1562\n",
            "Batch 665 de 1562\n",
            "Batch 666 de 1562\n",
            "Batch 667 de 1562\n",
            "Batch 668 de 1562\n",
            "Batch 669 de 1562\n",
            "Batch 670 de 1562\n",
            "Batch 671 de 1562\n",
            "Batch 672 de 1562\n",
            "Batch 673 de 1562\n",
            "Batch 674 de 1562\n",
            "Batch 675 de 1562\n",
            "Batch 676 de 1562\n",
            "Batch 677 de 1562\n",
            "Batch 678 de 1562\n",
            "Batch 679 de 1562\n",
            "Batch 680 de 1562\n",
            "Batch 681 de 1562\n",
            "Batch 682 de 1562\n",
            "Batch 683 de 1562\n",
            "Batch 684 de 1562\n",
            "Batch 685 de 1562\n",
            "Batch 686 de 1562\n",
            "Batch 687 de 1562\n",
            "Batch 688 de 1562\n",
            "Batch 689 de 1562\n",
            "Batch 690 de 1562\n",
            "Batch 691 de 1562\n",
            "Batch 692 de 1562\n",
            "Batch 693 de 1562\n",
            "Batch 694 de 1562\n",
            "Batch 695 de 1562\n",
            "Batch 696 de 1562\n",
            "Batch 697 de 1562\n",
            "Batch 698 de 1562\n",
            "Batch 699 de 1562\n",
            "Batch 700 de 1562\n",
            "Batch 701 de 1562\n",
            "Batch 702 de 1562\n",
            "Batch 703 de 1562\n",
            "Batch 704 de 1562\n",
            "Batch 705 de 1562\n",
            "Batch 706 de 1562\n",
            "Batch 707 de 1562\n",
            "Batch 708 de 1562\n",
            "Batch 709 de 1562\n",
            "Batch 710 de 1562\n",
            "Batch 711 de 1562\n",
            "Batch 712 de 1562\n",
            "Batch 713 de 1562\n",
            "Batch 714 de 1562\n",
            "Batch 715 de 1562\n",
            "Batch 716 de 1562\n",
            "Batch 717 de 1562\n",
            "Batch 718 de 1562\n",
            "Batch 719 de 1562\n",
            "Batch 720 de 1562\n",
            "Batch 721 de 1562\n",
            "Batch 722 de 1562\n",
            "Batch 723 de 1562\n",
            "Batch 724 de 1562\n",
            "Batch 725 de 1562\n",
            "Batch 726 de 1562\n",
            "Batch 727 de 1562\n",
            "Batch 728 de 1562\n",
            "Batch 729 de 1562\n",
            "Batch 730 de 1562\n",
            "Batch 731 de 1562\n",
            "Batch 732 de 1562\n",
            "Batch 733 de 1562\n",
            "Batch 734 de 1562\n",
            "Batch 735 de 1562\n",
            "Batch 736 de 1562\n",
            "Batch 737 de 1562\n",
            "Batch 738 de 1562\n",
            "Batch 739 de 1562\n",
            "Batch 740 de 1562\n",
            "Batch 741 de 1562\n",
            "Batch 742 de 1562\n",
            "Batch 743 de 1562\n",
            "Batch 744 de 1562\n",
            "Batch 745 de 1562\n",
            "Batch 746 de 1562\n",
            "Batch 747 de 1562\n",
            "Batch 748 de 1562\n",
            "Batch 749 de 1562\n",
            "Batch 750 de 1562\n",
            "Batch 751 de 1562\n",
            "Batch 752 de 1562\n",
            "Batch 753 de 1562\n",
            "Batch 754 de 1562\n",
            "Batch 755 de 1562\n",
            "Batch 756 de 1562\n",
            "Batch 757 de 1562\n",
            "Batch 758 de 1562\n",
            "Batch 759 de 1562\n",
            "Batch 760 de 1562\n",
            "Batch 761 de 1562\n",
            "Batch 762 de 1562\n",
            "Batch 763 de 1562\n",
            "Batch 764 de 1562\n",
            "Batch 765 de 1562\n",
            "Batch 766 de 1562\n",
            "Batch 767 de 1562\n",
            "Batch 768 de 1562\n",
            "Batch 769 de 1562\n",
            "Batch 770 de 1562\n",
            "Batch 771 de 1562\n",
            "Batch 772 de 1562\n",
            "Batch 773 de 1562\n",
            "Batch 774 de 1562\n",
            "Batch 775 de 1562\n",
            "Batch 776 de 1562\n",
            "Batch 777 de 1562\n",
            "Batch 778 de 1562\n",
            "Batch 779 de 1562\n",
            "Batch 780 de 1562\n",
            "Batch 781 de 1562\n",
            "Batch 782 de 1562\n",
            "Batch 783 de 1562\n",
            "Batch 784 de 1562\n",
            "Batch 785 de 1562\n",
            "Batch 786 de 1562\n",
            "Batch 787 de 1562\n",
            "Batch 788 de 1562\n",
            "Batch 789 de 1562\n",
            "Batch 790 de 1562\n",
            "Batch 791 de 1562\n",
            "Batch 792 de 1562\n",
            "Batch 793 de 1562\n",
            "Batch 794 de 1562\n",
            "Batch 795 de 1562\n",
            "Batch 796 de 1562\n",
            "Batch 797 de 1562\n",
            "Batch 798 de 1562\n",
            "Batch 799 de 1562\n",
            "Batch 800 de 1562\n",
            "Batch 801 de 1562\n",
            "Batch 802 de 1562\n",
            "Batch 803 de 1562\n",
            "Batch 804 de 1562\n",
            "Batch 805 de 1562\n",
            "Batch 806 de 1562\n",
            "Batch 807 de 1562\n",
            "Batch 808 de 1562\n",
            "Batch 809 de 1562\n",
            "Batch 810 de 1562\n",
            "Batch 811 de 1562\n",
            "Batch 812 de 1562\n",
            "Batch 813 de 1562\n",
            "Batch 814 de 1562\n",
            "Batch 815 de 1562\n",
            "Batch 816 de 1562\n",
            "Batch 817 de 1562\n",
            "Batch 818 de 1562\n",
            "Batch 819 de 1562\n",
            "Batch 820 de 1562\n",
            "Batch 821 de 1562\n",
            "Batch 822 de 1562\n",
            "Batch 823 de 1562\n",
            "Batch 824 de 1562\n",
            "Batch 825 de 1562\n",
            "Batch 826 de 1562\n",
            "Batch 827 de 1562\n",
            "Batch 828 de 1562\n",
            "Batch 829 de 1562\n",
            "Batch 830 de 1562\n",
            "Batch 831 de 1562\n",
            "Batch 832 de 1562\n",
            "Batch 833 de 1562\n",
            "Batch 834 de 1562\n",
            "Batch 835 de 1562\n",
            "Batch 836 de 1562\n",
            "Batch 837 de 1562\n",
            "Batch 838 de 1562\n",
            "Batch 839 de 1562\n",
            "Batch 840 de 1562\n",
            "Batch 841 de 1562\n",
            "Batch 842 de 1562\n",
            "Batch 843 de 1562\n",
            "Batch 844 de 1562\n",
            "Batch 845 de 1562\n",
            "Batch 846 de 1562\n",
            "Batch 847 de 1562\n",
            "Batch 848 de 1562\n",
            "Batch 849 de 1562\n",
            "Batch 850 de 1562\n",
            "Batch 851 de 1562\n",
            "Batch 852 de 1562\n",
            "Batch 853 de 1562\n",
            "Batch 854 de 1562\n",
            "Batch 855 de 1562\n",
            "Batch 856 de 1562\n",
            "Batch 857 de 1562\n",
            "Batch 858 de 1562\n",
            "Batch 859 de 1562\n",
            "Batch 860 de 1562\n",
            "Batch 861 de 1562\n",
            "Batch 862 de 1562\n",
            "Batch 863 de 1562\n",
            "Batch 864 de 1562\n",
            "Batch 865 de 1562\n",
            "Batch 866 de 1562\n",
            "Batch 867 de 1562\n",
            "Batch 868 de 1562\n",
            "Batch 869 de 1562\n",
            "Batch 870 de 1562\n",
            "Batch 871 de 1562\n",
            "Batch 872 de 1562\n",
            "Batch 873 de 1562\n",
            "Batch 874 de 1562\n",
            "Batch 875 de 1562\n",
            "Batch 876 de 1562\n",
            "Batch 877 de 1562\n",
            "Batch 878 de 1562\n",
            "Batch 879 de 1562\n",
            "Batch 880 de 1562\n",
            "Batch 881 de 1562\n",
            "Batch 882 de 1562\n",
            "Batch 883 de 1562\n",
            "Batch 884 de 1562\n",
            "Batch 885 de 1562\n",
            "Batch 886 de 1562\n",
            "Batch 887 de 1562\n",
            "Batch 888 de 1562\n",
            "Batch 889 de 1562\n",
            "Batch 890 de 1562\n",
            "Batch 891 de 1562\n",
            "Batch 892 de 1562\n",
            "Batch 893 de 1562\n",
            "Batch 894 de 1562\n",
            "Batch 895 de 1562\n",
            "Batch 896 de 1562\n",
            "Batch 897 de 1562\n",
            "Batch 898 de 1562\n",
            "Batch 899 de 1562\n",
            "Batch 900 de 1562\n",
            "Batch 901 de 1562\n",
            "Batch 902 de 1562\n",
            "Batch 903 de 1562\n",
            "Batch 904 de 1562\n",
            "Batch 905 de 1562\n",
            "Batch 906 de 1562\n",
            "Batch 907 de 1562\n",
            "Batch 908 de 1562\n",
            "Batch 909 de 1562\n",
            "Batch 910 de 1562\n",
            "Batch 911 de 1562\n",
            "Batch 912 de 1562\n",
            "Batch 913 de 1562\n",
            "Batch 914 de 1562\n",
            "Batch 915 de 1562\n",
            "Batch 916 de 1562\n",
            "Batch 917 de 1562\n",
            "Batch 918 de 1562\n",
            "Batch 919 de 1562\n",
            "Batch 920 de 1562\n",
            "Batch 921 de 1562\n",
            "Batch 922 de 1562\n",
            "Batch 923 de 1562\n",
            "Batch 924 de 1562\n",
            "Batch 925 de 1562\n",
            "Batch 926 de 1562\n",
            "Batch 927 de 1562\n",
            "Batch 928 de 1562\n",
            "Batch 929 de 1562\n",
            "Batch 930 de 1562\n",
            "Batch 931 de 1562\n",
            "Batch 932 de 1562\n",
            "Batch 933 de 1562\n",
            "Batch 934 de 1562\n",
            "Batch 935 de 1562\n",
            "Batch 936 de 1562\n",
            "Batch 937 de 1562\n",
            "Batch 938 de 1562\n",
            "Batch 939 de 1562\n",
            "Batch 940 de 1562\n",
            "Batch 941 de 1562\n",
            "Batch 942 de 1562\n",
            "Batch 943 de 1562\n",
            "Batch 944 de 1562\n",
            "Batch 945 de 1562\n",
            "Batch 946 de 1562\n",
            "Batch 947 de 1562\n",
            "Batch 948 de 1562\n",
            "Batch 949 de 1562\n",
            "Batch 950 de 1562\n",
            "Batch 951 de 1562\n",
            "Batch 952 de 1562\n",
            "Batch 953 de 1562\n",
            "Batch 954 de 1562\n",
            "Batch 955 de 1562\n",
            "Batch 956 de 1562\n",
            "Batch 957 de 1562\n",
            "Batch 958 de 1562\n",
            "Batch 959 de 1562\n",
            "Batch 960 de 1562\n",
            "Batch 961 de 1562\n",
            "Batch 962 de 1562\n",
            "Batch 963 de 1562\n",
            "Batch 964 de 1562\n",
            "Batch 965 de 1562\n",
            "Batch 966 de 1562\n",
            "Batch 967 de 1562\n",
            "Batch 968 de 1562\n",
            "Batch 969 de 1562\n",
            "Batch 970 de 1562\n",
            "Batch 971 de 1562\n",
            "Batch 972 de 1562\n",
            "Batch 973 de 1562\n",
            "Batch 974 de 1562\n",
            "Batch 975 de 1562\n",
            "Batch 976 de 1562\n",
            "Batch 977 de 1562\n",
            "Batch 978 de 1562\n",
            "Batch 979 de 1562\n",
            "Batch 980 de 1562\n",
            "Batch 981 de 1562\n",
            "Batch 982 de 1562\n",
            "Batch 983 de 1562\n",
            "Batch 984 de 1562\n",
            "Batch 985 de 1562\n",
            "Batch 986 de 1562\n",
            "Batch 987 de 1562\n",
            "Batch 988 de 1562\n",
            "Batch 989 de 1562\n",
            "Batch 990 de 1562\n",
            "Batch 991 de 1562\n",
            "Batch 992 de 1562\n",
            "Batch 993 de 1562\n",
            "Batch 994 de 1562\n",
            "Batch 995 de 1562\n",
            "Batch 996 de 1562\n",
            "Batch 997 de 1562\n",
            "Batch 998 de 1562\n",
            "Batch 999 de 1562\n",
            "Batch 1000 de 1562\n",
            "Batch 1001 de 1562\n",
            "Batch 1002 de 1562\n",
            "Batch 1003 de 1562\n",
            "Batch 1004 de 1562\n",
            "Batch 1005 de 1562\n",
            "Batch 1006 de 1562\n",
            "Batch 1007 de 1562\n",
            "Batch 1008 de 1562\n",
            "Batch 1009 de 1562\n",
            "Batch 1010 de 1562\n",
            "Batch 1011 de 1562\n",
            "Batch 1012 de 1562\n",
            "Batch 1013 de 1562\n",
            "Batch 1014 de 1562\n",
            "Batch 1015 de 1562\n",
            "Batch 1016 de 1562\n",
            "Batch 1017 de 1562\n",
            "Batch 1018 de 1562\n",
            "Batch 1019 de 1562\n",
            "Batch 1020 de 1562\n",
            "Batch 1021 de 1562\n",
            "Batch 1022 de 1562\n",
            "Batch 1023 de 1562\n",
            "Batch 1024 de 1562\n",
            "Batch 1025 de 1562\n",
            "Batch 1026 de 1562\n",
            "Batch 1027 de 1562\n",
            "Batch 1028 de 1562\n",
            "Batch 1029 de 1562\n",
            "Batch 1030 de 1562\n",
            "Batch 1031 de 1562\n",
            "Batch 1032 de 1562\n",
            "Batch 1033 de 1562\n",
            "Batch 1034 de 1562\n",
            "Batch 1035 de 1562\n",
            "Batch 1036 de 1562\n",
            "Batch 1037 de 1562\n",
            "Batch 1038 de 1562\n",
            "Batch 1039 de 1562\n",
            "Batch 1040 de 1562\n",
            "Batch 1041 de 1562\n",
            "Batch 1042 de 1562\n",
            "Batch 1043 de 1562\n",
            "Batch 1044 de 1562\n",
            "Batch 1045 de 1562\n",
            "Batch 1046 de 1562\n",
            "Batch 1047 de 1562\n",
            "Batch 1048 de 1562\n",
            "Batch 1049 de 1562\n",
            "Batch 1050 de 1562\n",
            "Batch 1051 de 1562\n",
            "Batch 1052 de 1562\n",
            "Batch 1053 de 1562\n",
            "Batch 1054 de 1562\n",
            "Batch 1055 de 1562\n",
            "Batch 1056 de 1562\n",
            "Batch 1057 de 1562\n",
            "Batch 1058 de 1562\n",
            "Batch 1059 de 1562\n",
            "Batch 1060 de 1562\n",
            "Batch 1061 de 1562\n",
            "Batch 1062 de 1562\n",
            "Batch 1063 de 1562\n",
            "Batch 1064 de 1562\n",
            "Batch 1065 de 1562\n",
            "Batch 1066 de 1562\n",
            "Batch 1067 de 1562\n",
            "Batch 1068 de 1562\n",
            "Batch 1069 de 1562\n",
            "Batch 1070 de 1562\n",
            "Batch 1071 de 1562\n",
            "Batch 1072 de 1562\n",
            "Batch 1073 de 1562\n",
            "Batch 1074 de 1562\n",
            "Batch 1075 de 1562\n",
            "Batch 1076 de 1562\n",
            "Batch 1077 de 1562\n",
            "Batch 1078 de 1562\n",
            "Batch 1079 de 1562\n",
            "Batch 1080 de 1562\n",
            "Batch 1081 de 1562\n",
            "Batch 1082 de 1562\n",
            "Batch 1083 de 1562\n",
            "Batch 1084 de 1562\n",
            "Batch 1085 de 1562\n",
            "Batch 1086 de 1562\n",
            "Batch 1087 de 1562\n",
            "Batch 1088 de 1562\n",
            "Batch 1089 de 1562\n",
            "Batch 1090 de 1562\n",
            "Batch 1091 de 1562\n",
            "Batch 1092 de 1562\n",
            "Batch 1093 de 1562\n",
            "Batch 1094 de 1562\n",
            "Batch 1095 de 1562\n",
            "Batch 1096 de 1562\n",
            "Batch 1097 de 1562\n",
            "Batch 1098 de 1562\n",
            "Batch 1099 de 1562\n",
            "Batch 1100 de 1562\n",
            "Batch 1101 de 1562\n",
            "Batch 1102 de 1562\n",
            "Batch 1103 de 1562\n",
            "Batch 1104 de 1562\n",
            "Batch 1105 de 1562\n",
            "Batch 1106 de 1562\n",
            "Batch 1107 de 1562\n",
            "Batch 1108 de 1562\n",
            "Batch 1109 de 1562\n",
            "Batch 1110 de 1562\n",
            "Batch 1111 de 1562\n",
            "Batch 1112 de 1562\n",
            "Batch 1113 de 1562\n",
            "Batch 1114 de 1562\n",
            "Batch 1115 de 1562\n",
            "Batch 1116 de 1562\n",
            "Batch 1117 de 1562\n",
            "Batch 1118 de 1562\n",
            "Batch 1119 de 1562\n",
            "Batch 1120 de 1562\n",
            "Batch 1121 de 1562\n",
            "Batch 1122 de 1562\n",
            "Batch 1123 de 1562\n",
            "Batch 1124 de 1562\n",
            "Batch 1125 de 1562\n",
            "Batch 1126 de 1562\n",
            "Batch 1127 de 1562\n",
            "Batch 1128 de 1562\n",
            "Batch 1129 de 1562\n",
            "Batch 1130 de 1562\n",
            "Batch 1131 de 1562\n",
            "Batch 1132 de 1562\n",
            "Batch 1133 de 1562\n",
            "Batch 1134 de 1562\n",
            "Batch 1135 de 1562\n",
            "Batch 1136 de 1562\n",
            "Batch 1137 de 1562\n",
            "Batch 1138 de 1562\n",
            "Batch 1139 de 1562\n",
            "Batch 1140 de 1562\n",
            "Batch 1141 de 1562\n",
            "Batch 1142 de 1562\n",
            "Batch 1143 de 1562\n",
            "Batch 1144 de 1562\n",
            "Batch 1145 de 1562\n",
            "Batch 1146 de 1562\n",
            "Batch 1147 de 1562\n",
            "Batch 1148 de 1562\n",
            "Batch 1149 de 1562\n",
            "Batch 1150 de 1562\n",
            "Batch 1151 de 1562\n",
            "Batch 1152 de 1562\n",
            "Batch 1153 de 1562\n",
            "Batch 1154 de 1562\n",
            "Batch 1155 de 1562\n",
            "Batch 1156 de 1562\n",
            "Batch 1157 de 1562\n",
            "Batch 1158 de 1562\n",
            "Batch 1159 de 1562\n",
            "Batch 1160 de 1562\n",
            "Batch 1161 de 1562\n",
            "Batch 1162 de 1562\n",
            "Batch 1163 de 1562\n",
            "Batch 1164 de 1562\n",
            "Batch 1165 de 1562\n",
            "Batch 1166 de 1562\n",
            "Batch 1167 de 1562\n",
            "Batch 1168 de 1562\n",
            "Batch 1169 de 1562\n",
            "Batch 1170 de 1562\n",
            "Batch 1171 de 1562\n",
            "Batch 1172 de 1562\n",
            "Batch 1173 de 1562\n",
            "Batch 1174 de 1562\n",
            "Batch 1175 de 1562\n",
            "Batch 1176 de 1562\n",
            "Batch 1177 de 1562\n",
            "Batch 1178 de 1562\n",
            "Batch 1179 de 1562\n",
            "Batch 1180 de 1562\n",
            "Batch 1181 de 1562\n",
            "Batch 1182 de 1562\n",
            "Batch 1183 de 1562\n",
            "Batch 1184 de 1562\n",
            "Batch 1185 de 1562\n",
            "Batch 1186 de 1562\n",
            "Batch 1187 de 1562\n",
            "Batch 1188 de 1562\n",
            "Batch 1189 de 1562\n",
            "Batch 1190 de 1562\n",
            "Batch 1191 de 1562\n",
            "Batch 1192 de 1562\n",
            "Batch 1193 de 1562\n",
            "Batch 1194 de 1562\n",
            "Batch 1195 de 1562\n",
            "Batch 1196 de 1562\n",
            "Batch 1197 de 1562\n",
            "Batch 1198 de 1562\n",
            "Batch 1199 de 1562\n",
            "Batch 1200 de 1562\n",
            "Batch 1201 de 1562\n",
            "Batch 1202 de 1562\n",
            "Batch 1203 de 1562\n",
            "Batch 1204 de 1562\n",
            "Batch 1205 de 1562\n",
            "Batch 1206 de 1562\n",
            "Batch 1207 de 1562\n",
            "Batch 1208 de 1562\n",
            "Batch 1209 de 1562\n",
            "Batch 1210 de 1562\n",
            "Batch 1211 de 1562\n",
            "Batch 1212 de 1562\n",
            "Batch 1213 de 1562\n",
            "Batch 1214 de 1562\n",
            "Batch 1215 de 1562\n",
            "Batch 1216 de 1562\n",
            "Batch 1217 de 1562\n",
            "Batch 1218 de 1562\n",
            "Batch 1219 de 1562\n",
            "Batch 1220 de 1562\n",
            "Batch 1221 de 1562\n",
            "Batch 1222 de 1562\n",
            "Batch 1223 de 1562\n",
            "Batch 1224 de 1562\n",
            "Batch 1225 de 1562\n",
            "Batch 1226 de 1562\n",
            "Batch 1227 de 1562\n",
            "Batch 1228 de 1562\n",
            "Batch 1229 de 1562\n",
            "Batch 1230 de 1562\n",
            "Batch 1231 de 1562\n",
            "Batch 1232 de 1562\n",
            "Batch 1233 de 1562\n",
            "Batch 1234 de 1562\n",
            "Batch 1235 de 1562\n",
            "Batch 1236 de 1562\n",
            "Batch 1237 de 1562\n",
            "Batch 1238 de 1562\n",
            "Batch 1239 de 1562\n",
            "Batch 1240 de 1562\n",
            "Batch 1241 de 1562\n",
            "Batch 1242 de 1562\n",
            "Batch 1243 de 1562\n",
            "Batch 1244 de 1562\n",
            "Batch 1245 de 1562\n",
            "Batch 1246 de 1562\n",
            "Batch 1247 de 1562\n",
            "Batch 1248 de 1562\n",
            "Batch 1249 de 1562\n",
            "Batch 1250 de 1562\n",
            "Batch 1251 de 1562\n",
            "Batch 1252 de 1562\n",
            "Batch 1253 de 1562\n",
            "Batch 1254 de 1562\n",
            "Batch 1255 de 1562\n",
            "Batch 1256 de 1562\n",
            "Batch 1257 de 1562\n",
            "Batch 1258 de 1562\n",
            "Batch 1259 de 1562\n",
            "Batch 1260 de 1562\n",
            "Batch 1261 de 1562\n",
            "Batch 1262 de 1562\n",
            "Batch 1263 de 1562\n",
            "Batch 1264 de 1562\n",
            "Batch 1265 de 1562\n",
            "Batch 1266 de 1562\n",
            "Batch 1267 de 1562\n",
            "Batch 1268 de 1562\n",
            "Batch 1269 de 1562\n",
            "Batch 1270 de 1562\n",
            "Batch 1271 de 1562\n",
            "Batch 1272 de 1562\n",
            "Batch 1273 de 1562\n",
            "Batch 1274 de 1562\n",
            "Batch 1275 de 1562\n",
            "Batch 1276 de 1562\n",
            "Batch 1277 de 1562\n",
            "Batch 1278 de 1562\n",
            "Batch 1279 de 1562\n",
            "Batch 1280 de 1562\n",
            "Batch 1281 de 1562\n",
            "Batch 1282 de 1562\n",
            "Batch 1283 de 1562\n",
            "Batch 1284 de 1562\n",
            "Batch 1285 de 1562\n",
            "Batch 1286 de 1562\n",
            "Batch 1287 de 1562\n",
            "Batch 1288 de 1562\n",
            "Batch 1289 de 1562\n",
            "Batch 1290 de 1562\n",
            "Batch 1291 de 1562\n",
            "Batch 1292 de 1562\n",
            "Batch 1293 de 1562\n",
            "Batch 1294 de 1562\n",
            "Batch 1295 de 1562\n",
            "Batch 1296 de 1562\n",
            "Batch 1297 de 1562\n",
            "Batch 1298 de 1562\n",
            "Batch 1299 de 1562\n",
            "Batch 1300 de 1562\n",
            "Batch 1301 de 1562\n",
            "Batch 1302 de 1562\n",
            "Batch 1303 de 1562\n",
            "Batch 1304 de 1562\n",
            "Batch 1305 de 1562\n",
            "Batch 1306 de 1562\n",
            "Batch 1307 de 1562\n",
            "Batch 1308 de 1562\n",
            "Batch 1309 de 1562\n",
            "Batch 1310 de 1562\n",
            "Batch 1311 de 1562\n",
            "Batch 1312 de 1562\n",
            "Batch 1313 de 1562\n",
            "Batch 1314 de 1562\n",
            "Batch 1315 de 1562\n",
            "Batch 1316 de 1562\n",
            "Batch 1317 de 1562\n",
            "Batch 1318 de 1562\n",
            "Batch 1319 de 1562\n",
            "Batch 1320 de 1562\n",
            "Batch 1321 de 1562\n",
            "Batch 1322 de 1562\n",
            "Batch 1323 de 1562\n",
            "Batch 1324 de 1562\n",
            "Batch 1325 de 1562\n",
            "Batch 1326 de 1562\n",
            "Batch 1327 de 1562\n",
            "Batch 1328 de 1562\n",
            "Batch 1329 de 1562\n",
            "Batch 1330 de 1562\n",
            "Batch 1331 de 1562\n",
            "Batch 1332 de 1562\n",
            "Batch 1333 de 1562\n",
            "Batch 1334 de 1562\n",
            "Batch 1335 de 1562\n",
            "Batch 1336 de 1562\n",
            "Batch 1337 de 1562\n",
            "Batch 1338 de 1562\n",
            "Batch 1339 de 1562\n",
            "Batch 1340 de 1562\n",
            "Batch 1341 de 1562\n",
            "Batch 1342 de 1562\n",
            "Batch 1343 de 1562\n",
            "Batch 1344 de 1562\n",
            "Batch 1345 de 1562\n",
            "Batch 1346 de 1562\n",
            "Batch 1347 de 1562\n",
            "Batch 1348 de 1562\n",
            "Batch 1349 de 1562\n",
            "Batch 1350 de 1562\n",
            "Batch 1351 de 1562\n",
            "Batch 1352 de 1562\n",
            "Batch 1353 de 1562\n",
            "Batch 1354 de 1562\n",
            "Batch 1355 de 1562\n",
            "Batch 1356 de 1562\n",
            "Batch 1357 de 1562\n",
            "Batch 1358 de 1562\n",
            "Batch 1359 de 1562\n",
            "Batch 1360 de 1562\n",
            "Batch 1361 de 1562\n",
            "Batch 1362 de 1562\n",
            "Batch 1363 de 1562\n",
            "Batch 1364 de 1562\n",
            "Batch 1365 de 1562\n",
            "Batch 1366 de 1562\n",
            "Batch 1367 de 1562\n",
            "Batch 1368 de 1562\n",
            "Batch 1369 de 1562\n",
            "Batch 1370 de 1562\n",
            "Batch 1371 de 1562\n",
            "Batch 1372 de 1562\n",
            "Batch 1373 de 1562\n",
            "Batch 1374 de 1562\n",
            "Batch 1375 de 1562\n",
            "Batch 1376 de 1562\n",
            "Batch 1377 de 1562\n",
            "Batch 1378 de 1562\n",
            "Batch 1379 de 1562\n",
            "Batch 1380 de 1562\n",
            "Batch 1381 de 1562\n",
            "Batch 1382 de 1562\n",
            "Batch 1383 de 1562\n",
            "Batch 1384 de 1562\n",
            "Batch 1385 de 1562\n",
            "Batch 1386 de 1562\n",
            "Batch 1387 de 1562\n",
            "Batch 1388 de 1562\n",
            "Batch 1389 de 1562\n",
            "Batch 1390 de 1562\n",
            "Batch 1391 de 1562\n",
            "Batch 1392 de 1562\n",
            "Batch 1393 de 1562\n",
            "Batch 1394 de 1562\n",
            "Batch 1395 de 1562\n",
            "Batch 1396 de 1562\n",
            "Batch 1397 de 1562\n",
            "Batch 1398 de 1562\n",
            "Batch 1399 de 1562\n",
            "Batch 1400 de 1562\n",
            "Batch 1401 de 1562\n",
            "Batch 1402 de 1562\n",
            "Batch 1403 de 1562\n",
            "Batch 1404 de 1562\n",
            "Batch 1405 de 1562\n",
            "Batch 1406 de 1562\n",
            "Batch 1407 de 1562\n",
            "Batch 1408 de 1562\n",
            "Batch 1409 de 1562\n",
            "Batch 1410 de 1562\n",
            "Batch 1411 de 1562\n",
            "Batch 1412 de 1562\n",
            "Batch 1413 de 1562\n",
            "Batch 1414 de 1562\n",
            "Batch 1415 de 1562\n",
            "Batch 1416 de 1562\n",
            "Batch 1417 de 1562\n",
            "Batch 1418 de 1562\n",
            "Batch 1419 de 1562\n",
            "Batch 1420 de 1562\n",
            "Batch 1421 de 1562\n",
            "Batch 1422 de 1562\n",
            "Batch 1423 de 1562\n",
            "Batch 1424 de 1562\n",
            "Batch 1425 de 1562\n",
            "Batch 1426 de 1562\n",
            "Batch 1427 de 1562\n",
            "Batch 1428 de 1562\n",
            "Batch 1429 de 1562\n",
            "Batch 1430 de 1562\n",
            "Batch 1431 de 1562\n",
            "Batch 1432 de 1562\n",
            "Batch 1433 de 1562\n",
            "Batch 1434 de 1562\n",
            "Batch 1435 de 1562\n",
            "Batch 1436 de 1562\n",
            "Batch 1437 de 1562\n",
            "Batch 1438 de 1562\n",
            "Batch 1439 de 1562\n",
            "Batch 1440 de 1562\n",
            "Batch 1441 de 1562\n",
            "Batch 1442 de 1562\n",
            "Batch 1443 de 1562\n",
            "Batch 1444 de 1562\n",
            "Batch 1445 de 1562\n",
            "Batch 1446 de 1562\n",
            "Batch 1447 de 1562\n",
            "Batch 1448 de 1562\n",
            "Batch 1449 de 1562\n",
            "Batch 1450 de 1562\n",
            "Batch 1451 de 1562\n",
            "Batch 1452 de 1562\n",
            "Batch 1453 de 1562\n",
            "Batch 1454 de 1562\n",
            "Batch 1455 de 1562\n",
            "Batch 1456 de 1562\n",
            "Batch 1457 de 1562\n",
            "Batch 1458 de 1562\n",
            "Batch 1459 de 1562\n",
            "Batch 1460 de 1562\n",
            "Batch 1461 de 1562\n",
            "Batch 1462 de 1562\n",
            "Batch 1463 de 1562\n",
            "Batch 1464 de 1562\n",
            "Batch 1465 de 1562\n",
            "Batch 1466 de 1562\n",
            "Batch 1467 de 1562\n",
            "Batch 1468 de 1562\n",
            "Batch 1469 de 1562\n",
            "Batch 1470 de 1562\n",
            "Batch 1471 de 1562\n",
            "Batch 1472 de 1562\n",
            "Batch 1473 de 1562\n",
            "Batch 1474 de 1562\n",
            "Batch 1475 de 1562\n",
            "Batch 1476 de 1562\n",
            "Batch 1477 de 1562\n",
            "Batch 1478 de 1562\n",
            "Batch 1479 de 1562\n",
            "Batch 1480 de 1562\n",
            "Batch 1481 de 1562\n",
            "Batch 1482 de 1562\n",
            "Batch 1483 de 1562\n",
            "Batch 1484 de 1562\n",
            "Batch 1485 de 1562\n",
            "Batch 1486 de 1562\n",
            "Batch 1487 de 1562\n",
            "Batch 1488 de 1562\n",
            "Batch 1489 de 1562\n",
            "Batch 1490 de 1562\n",
            "Batch 1491 de 1562\n",
            "Batch 1492 de 1562\n",
            "Batch 1493 de 1562\n",
            "Batch 1494 de 1562\n",
            "Batch 1495 de 1562\n",
            "Batch 1496 de 1562\n",
            "Batch 1497 de 1562\n",
            "Batch 1498 de 1562\n",
            "Batch 1499 de 1562\n",
            "Batch 1500 de 1562\n",
            "Batch 1501 de 1562\n",
            "Batch 1502 de 1562\n",
            "Batch 1503 de 1562\n",
            "Batch 1504 de 1562\n",
            "Batch 1505 de 1562\n",
            "Batch 1506 de 1562\n",
            "Batch 1507 de 1562\n",
            "Batch 1508 de 1562\n",
            "Batch 1509 de 1562\n",
            "Batch 1510 de 1562\n",
            "Batch 1511 de 1562\n",
            "Batch 1512 de 1562\n",
            "Batch 1513 de 1562\n",
            "Batch 1514 de 1562\n",
            "Batch 1515 de 1562\n",
            "Batch 1516 de 1562\n",
            "Batch 1517 de 1562\n",
            "Batch 1518 de 1562\n",
            "Batch 1519 de 1562\n",
            "Batch 1520 de 1562\n",
            "Batch 1521 de 1562\n",
            "Batch 1522 de 1562\n",
            "Batch 1523 de 1562\n",
            "Batch 1524 de 1562\n",
            "Batch 1525 de 1562\n",
            "Batch 1526 de 1562\n",
            "Batch 1527 de 1562\n",
            "Batch 1528 de 1562\n",
            "Batch 1529 de 1562\n",
            "Batch 1530 de 1562\n",
            "Batch 1531 de 1562\n",
            "Batch 1532 de 1562\n",
            "Batch 1533 de 1562\n",
            "Batch 1534 de 1562\n",
            "Batch 1535 de 1562\n",
            "Batch 1536 de 1562\n",
            "Batch 1537 de 1562\n",
            "Batch 1538 de 1562\n",
            "Batch 1539 de 1562\n",
            "Batch 1540 de 1562\n",
            "Batch 1541 de 1562\n",
            "Batch 1542 de 1562\n",
            "Batch 1543 de 1562\n",
            "Batch 1544 de 1562\n",
            "Batch 1545 de 1562\n",
            "Batch 1546 de 1562\n",
            "Batch 1547 de 1562\n",
            "Batch 1548 de 1562\n",
            "Batch 1549 de 1562\n",
            "Batch 1550 de 1562\n",
            "Batch 1551 de 1562\n",
            "Batch 1552 de 1562\n",
            "Batch 1553 de 1562\n",
            "Batch 1554 de 1562\n",
            "Batch 1555 de 1562\n",
            "Batch 1556 de 1562\n",
            "Batch 1557 de 1562\n",
            "Batch 1558 de 1562\n",
            "Batch 1559 de 1562\n",
            "Batch 1560 de 1562\n",
            "Batch 1561 de 1562\n",
            "Accuracy Score = 0.7216674338089616\n",
            "F1 Score (Micro) = 0.7216674338089616\n",
            "F1 Score (Macro) = 0.4191677321864466\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationBert(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "\n",
        "  targets = np.array(targets).flatten().astype(int)\n",
        "\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "id": "RM5xUeUs4nZZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrBtRBXm4nZZ"
      },
      "source": [
        "##### Entrenamiento del modelo (50% de datos)"
      ],
      "id": "YrBtRBXm4nZZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-5\n",
        "- weight_decay=0.01\n",
        "- Dropout + Linear + Sigmoid"
      ],
      "metadata": {
        "id": "EOtn3wpDO-MD"
      },
      "id": "EOtn3wpDO-MD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34cdf490-7e6d-4108-bc35-481ba4d96282",
        "id": "OsqiTr364nZZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración; 0 de 8923, Loss: 0.06716524362564087\n",
            "Epoch: 0, iteración; 10 de 8923, Loss: 0.5760684490203858\n",
            "Epoch: 0, iteración; 20 de 8923, Loss: 0.5990167617797851\n",
            "Epoch: 0, iteración; 30 de 8923, Loss: 0.6765484809875488\n",
            "Epoch: 0, iteración; 40 de 8923, Loss: 0.5990793704986572\n",
            "Epoch: 0, iteración; 50 de 8923, Loss: 0.5697183609008789\n",
            "Epoch: 0, iteración; 60 de 8923, Loss: 0.5550312995910645\n",
            "Epoch: 0, iteración; 70 de 8923, Loss: 0.5230428218841553\n",
            "Epoch: 0, iteración; 80 de 8923, Loss: 0.5828387260437011\n",
            "Epoch: 0, iteración; 90 de 8923, Loss: 0.6101259708404541\n",
            "Epoch: 0, iteración; 100 de 8923, Loss: 0.5997524738311768\n",
            "Epoch: 0, iteración; 110 de 8923, Loss: 0.5246726989746093\n",
            "Epoch: 0, iteración; 120 de 8923, Loss: 0.6086777210235595\n",
            "Epoch: 0, iteración; 130 de 8923, Loss: 0.582326602935791\n",
            "Epoch: 0, iteración; 140 de 8923, Loss: 0.5876935482025146\n",
            "Epoch: 0, iteración; 150 de 8923, Loss: 0.5486178398132324\n",
            "Epoch: 0, iteración; 160 de 8923, Loss: 0.5636777877807617\n",
            "Epoch: 0, iteración; 170 de 8923, Loss: 0.5239377975463867\n",
            "Epoch: 0, iteración; 180 de 8923, Loss: 0.6587258815765381\n",
            "Epoch: 0, iteración; 190 de 8923, Loss: 0.5753613948822022\n",
            "Epoch: 0, iteración; 200 de 8923, Loss: 0.5995721817016602\n",
            "Epoch: 0, iteración; 210 de 8923, Loss: 0.6152090549468994\n",
            "Epoch: 0, iteración; 220 de 8923, Loss: 0.5178947448730469\n",
            "Epoch: 0, iteración; 230 de 8923, Loss: 0.5854888916015625\n",
            "Epoch: 0, iteración; 240 de 8923, Loss: 0.6026946544647217\n",
            "Epoch: 0, iteración; 250 de 8923, Loss: 0.6015538215637207\n",
            "Epoch: 0, iteración; 260 de 8923, Loss: 0.5470887184143066\n",
            "Epoch: 0, iteración; 270 de 8923, Loss: 0.5952194213867188\n",
            "Epoch: 0, iteración; 280 de 8923, Loss: 0.5977592468261719\n",
            "Epoch: 0, iteración; 290 de 8923, Loss: 0.561518383026123\n",
            "Epoch: 0, iteración; 300 de 8923, Loss: 0.6128191471099853\n",
            "Epoch: 0, iteración; 310 de 8923, Loss: 0.569556188583374\n",
            "Epoch: 0, iteración; 320 de 8923, Loss: 0.6103162288665771\n",
            "Epoch: 0, iteración; 330 de 8923, Loss: 0.6046970367431641\n",
            "Epoch: 0, iteración; 340 de 8923, Loss: 0.6330106735229493\n",
            "Epoch: 0, iteración; 350 de 8923, Loss: 0.6048196792602539\n",
            "Epoch: 0, iteración; 360 de 8923, Loss: 0.5710179328918457\n",
            "Epoch: 0, iteración; 370 de 8923, Loss: 0.5837148666381836\n",
            "Epoch: 0, iteración; 380 de 8923, Loss: 0.5104537010192871\n",
            "Epoch: 0, iteración; 390 de 8923, Loss: 0.5691532135009766\n",
            "Epoch: 0, iteración; 400 de 8923, Loss: 0.5440297603607178\n",
            "Epoch: 0, iteración; 410 de 8923, Loss: 0.6560054779052734\n",
            "Epoch: 0, iteración; 420 de 8923, Loss: 0.5626156330108643\n",
            "Epoch: 0, iteración; 430 de 8923, Loss: 0.5632258415222168\n",
            "Epoch: 0, iteración; 440 de 8923, Loss: 0.6025015354156494\n",
            "Epoch: 0, iteración; 450 de 8923, Loss: 0.5476837158203125\n",
            "Epoch: 0, iteración; 460 de 8923, Loss: 0.5322549343109131\n",
            "Epoch: 0, iteración; 470 de 8923, Loss: 0.5804959774017334\n",
            "Epoch: 0, iteración; 480 de 8923, Loss: 0.6455904483795166\n",
            "Epoch: 0, iteración; 490 de 8923, Loss: 0.5834756374359131\n",
            "Epoch: 0, iteración; 500 de 8923, Loss: 0.5041751861572266\n",
            "Epoch: 0, iteración; 510 de 8923, Loss: 0.5915382862091064\n",
            "Epoch: 0, iteración; 520 de 8923, Loss: 0.5408542633056641\n",
            "Epoch: 0, iteración; 530 de 8923, Loss: 0.5968640327453614\n",
            "Epoch: 0, iteración; 540 de 8923, Loss: 0.5551957130432129\n",
            "Epoch: 0, iteración; 550 de 8923, Loss: 0.5853829383850098\n",
            "Epoch: 0, iteración; 560 de 8923, Loss: 0.6114803314208984\n",
            "Epoch: 0, iteración; 570 de 8923, Loss: 0.6378513813018799\n",
            "Epoch: 0, iteración; 580 de 8923, Loss: 0.5675297737121582\n",
            "Epoch: 0, iteración; 590 de 8923, Loss: 0.5560359001159668\n",
            "Epoch: 0, iteración; 600 de 8923, Loss: 0.5872647762298584\n",
            "Epoch: 0, iteración; 610 de 8923, Loss: 0.5901455879211426\n",
            "Epoch: 0, iteración; 620 de 8923, Loss: 0.5373738765716553\n",
            "Epoch: 0, iteración; 630 de 8923, Loss: 0.5868695259094239\n",
            "Epoch: 0, iteración; 640 de 8923, Loss: 0.6103428363800049\n",
            "Epoch: 0, iteración; 650 de 8923, Loss: 0.570771312713623\n",
            "Epoch: 0, iteración; 660 de 8923, Loss: 0.5232301235198975\n",
            "Epoch: 0, iteración; 670 de 8923, Loss: 0.5058338642120361\n",
            "Epoch: 0, iteración; 680 de 8923, Loss: 0.5264565944671631\n",
            "Epoch: 0, iteración; 690 de 8923, Loss: 0.5520107746124268\n",
            "Epoch: 0, iteración; 700 de 8923, Loss: 0.5082008361816406\n",
            "Epoch: 0, iteración; 710 de 8923, Loss: 0.5905955791473388\n",
            "Epoch: 0, iteración; 720 de 8923, Loss: 0.6334882259368897\n",
            "Epoch: 0, iteración; 730 de 8923, Loss: 0.5945023536682129\n",
            "Epoch: 0, iteración; 740 de 8923, Loss: 0.5696427345275878\n",
            "Epoch: 0, iteración; 750 de 8923, Loss: 0.6004786014556884\n",
            "Epoch: 0, iteración; 760 de 8923, Loss: 0.6007430553436279\n",
            "Epoch: 0, iteración; 770 de 8923, Loss: 0.5578722953796387\n",
            "Epoch: 0, iteración; 780 de 8923, Loss: 0.5936739921569825\n",
            "Epoch: 0, iteración; 790 de 8923, Loss: 0.5169706821441651\n",
            "Epoch: 0, iteración; 800 de 8923, Loss: 0.5821220397949218\n",
            "Epoch: 0, iteración; 810 de 8923, Loss: 0.5528286457061767\n",
            "Epoch: 0, iteración; 820 de 8923, Loss: 0.5674234390258789\n",
            "Epoch: 0, iteración; 830 de 8923, Loss: 0.5427205085754394\n",
            "Epoch: 0, iteración; 840 de 8923, Loss: 0.5326987743377686\n",
            "Epoch: 0, iteración; 850 de 8923, Loss: 0.6037289142608643\n",
            "Epoch: 0, iteración; 860 de 8923, Loss: 0.5650505065917969\n",
            "Epoch: 0, iteración; 870 de 8923, Loss: 0.6200553417205811\n",
            "Epoch: 0, iteración; 880 de 8923, Loss: 0.5765709400177002\n",
            "Epoch: 0, iteración; 890 de 8923, Loss: 0.5188302040100098\n",
            "Epoch: 0, iteración; 900 de 8923, Loss: 0.5521984577178956\n",
            "Epoch: 0, iteración; 910 de 8923, Loss: 0.62173433303833\n",
            "Epoch: 0, iteración; 920 de 8923, Loss: 0.5664808273315429\n",
            "Epoch: 0, iteración; 930 de 8923, Loss: 0.5741486549377441\n",
            "Epoch: 0, iteración; 940 de 8923, Loss: 0.6002947807312011\n",
            "Epoch: 0, iteración; 950 de 8923, Loss: 0.5723763942718506\n",
            "Epoch: 0, iteración; 960 de 8923, Loss: 0.4772022247314453\n",
            "Epoch: 0, iteración; 970 de 8923, Loss: 0.5694404125213623\n",
            "Epoch: 0, iteración; 980 de 8923, Loss: 0.6346487998962402\n",
            "Epoch: 0, iteración; 990 de 8923, Loss: 0.5202033996582032\n",
            "Epoch: 0, iteración; 1000 de 8923, Loss: 0.5983538627624512\n",
            "Epoch: 0, iteración; 1010 de 8923, Loss: 0.5757079124450684\n",
            "Epoch: 0, iteración; 1020 de 8923, Loss: 0.6507115364074707\n",
            "Epoch: 0, iteración; 1030 de 8923, Loss: 0.5245268821716309\n",
            "Epoch: 0, iteración; 1040 de 8923, Loss: 0.6038595676422119\n",
            "Epoch: 0, iteración; 1050 de 8923, Loss: 0.6279914855957032\n",
            "Epoch: 0, iteración; 1060 de 8923, Loss: 0.5165842056274415\n",
            "Epoch: 0, iteración; 1070 de 8923, Loss: 0.6505853652954101\n",
            "Epoch: 0, iteración; 1080 de 8923, Loss: 0.5526845932006836\n",
            "Epoch: 0, iteración; 1090 de 8923, Loss: 0.5212795734405518\n",
            "Epoch: 0, iteración; 1100 de 8923, Loss: 0.6014562606811523\n",
            "Epoch: 0, iteración; 1110 de 8923, Loss: 0.6170313358306885\n",
            "Epoch: 0, iteración; 1120 de 8923, Loss: 0.6350216865539551\n",
            "Epoch: 0, iteración; 1130 de 8923, Loss: 0.5258512973785401\n",
            "Epoch: 0, iteración; 1140 de 8923, Loss: 0.6015462398529052\n",
            "Epoch: 0, iteración; 1150 de 8923, Loss: 0.5693797588348388\n",
            "Epoch: 0, iteración; 1160 de 8923, Loss: 0.5342272758483887\n",
            "Epoch: 0, iteración; 1170 de 8923, Loss: 0.5902013778686523\n",
            "Epoch: 0, iteración; 1180 de 8923, Loss: 0.5069401741027832\n",
            "Epoch: 0, iteración; 1190 de 8923, Loss: 0.554591703414917\n",
            "Epoch: 0, iteración; 1200 de 8923, Loss: 0.5265196800231934\n",
            "Epoch: 0, iteración; 1210 de 8923, Loss: 0.539882755279541\n",
            "Epoch: 0, iteración; 1220 de 8923, Loss: 0.6452029705047607\n",
            "Epoch: 0, iteración; 1230 de 8923, Loss: 0.5349108695983886\n",
            "Epoch: 0, iteración; 1240 de 8923, Loss: 0.512238597869873\n",
            "Epoch: 0, iteración; 1250 de 8923, Loss: 0.5679266452789307\n",
            "Epoch: 0, iteración; 1260 de 8923, Loss: 0.5670283794403076\n",
            "Epoch: 0, iteración; 1270 de 8923, Loss: 0.59819016456604\n",
            "Epoch: 0, iteración; 1280 de 8923, Loss: 0.6117087364196777\n",
            "Epoch: 0, iteración; 1290 de 8923, Loss: 0.552265214920044\n",
            "Epoch: 0, iteración; 1300 de 8923, Loss: 0.6144935607910156\n",
            "Epoch: 0, iteración; 1310 de 8923, Loss: 0.5634528160095215\n",
            "Epoch: 0, iteración; 1320 de 8923, Loss: 0.5655323028564453\n",
            "Epoch: 0, iteración; 1330 de 8923, Loss: 0.5531189918518067\n",
            "Epoch: 0, iteración; 1340 de 8923, Loss: 0.6239173412322998\n",
            "Epoch: 0, iteración; 1350 de 8923, Loss: 0.5735512733459472\n",
            "Epoch: 0, iteración; 1360 de 8923, Loss: 0.590851879119873\n",
            "Epoch: 0, iteración; 1370 de 8923, Loss: 0.5628498554229736\n",
            "Epoch: 0, iteración; 1380 de 8923, Loss: 0.5689296245574951\n",
            "Epoch: 0, iteración; 1390 de 8923, Loss: 0.6163867950439453\n",
            "Epoch: 0, iteración; 1400 de 8923, Loss: 0.611577033996582\n",
            "Epoch: 0, iteración; 1410 de 8923, Loss: 0.5536614894866944\n",
            "Epoch: 0, iteración; 1420 de 8923, Loss: 0.5995896339416504\n",
            "Epoch: 0, iteración; 1430 de 8923, Loss: 0.6002461910247803\n",
            "Epoch: 0, iteración; 1440 de 8923, Loss: 0.6039064884185791\n",
            "Epoch: 0, iteración; 1450 de 8923, Loss: 0.5668965816497803\n",
            "Epoch: 0, iteración; 1460 de 8923, Loss: 0.5557078838348388\n",
            "Epoch: 0, iteración; 1470 de 8923, Loss: 0.5497390270233155\n",
            "Epoch: 0, iteración; 1480 de 8923, Loss: 0.6038772583007812\n",
            "Epoch: 0, iteración; 1490 de 8923, Loss: 0.5479274272918702\n",
            "Epoch: 0, iteración; 1500 de 8923, Loss: 0.5569572448730469\n",
            "Epoch: 0, iteración; 1510 de 8923, Loss: 0.527833080291748\n",
            "Epoch: 0, iteración; 1520 de 8923, Loss: 0.5652257919311523\n",
            "Epoch: 0, iteración; 1530 de 8923, Loss: 0.6166941165924072\n",
            "Epoch: 0, iteración; 1540 de 8923, Loss: 0.5268494606018066\n",
            "Epoch: 0, iteración; 1550 de 8923, Loss: 0.5358051300048828\n",
            "Epoch: 0, iteración; 1560 de 8923, Loss: 0.5748186111450195\n",
            "Epoch: 0, iteración; 1570 de 8923, Loss: 0.5188951015472412\n",
            "Epoch: 0, iteración; 1580 de 8923, Loss: 0.5406364917755127\n",
            "Epoch: 0, iteración; 1590 de 8923, Loss: 0.5557964324951172\n",
            "Epoch: 0, iteración; 1600 de 8923, Loss: 0.5768839359283447\n",
            "Epoch: 0, iteración; 1610 de 8923, Loss: 0.5735194206237793\n",
            "Epoch: 0, iteración; 1620 de 8923, Loss: 0.6236315727233886\n",
            "Epoch: 0, iteración; 1630 de 8923, Loss: 0.5238278865814209\n",
            "Epoch: 0, iteración; 1640 de 8923, Loss: 0.5352514743804931\n",
            "Epoch: 0, iteración; 1650 de 8923, Loss: 0.5847177505493164\n",
            "Epoch: 0, iteración; 1660 de 8923, Loss: 0.5745204448699951\n",
            "Epoch: 0, iteración; 1670 de 8923, Loss: 0.5570169448852539\n",
            "Epoch: 0, iteración; 1680 de 8923, Loss: 0.5649729251861573\n",
            "Epoch: 0, iteración; 1690 de 8923, Loss: 0.5720073223114014\n",
            "Epoch: 0, iteración; 1700 de 8923, Loss: 0.6192558288574219\n",
            "Epoch: 0, iteración; 1710 de 8923, Loss: 0.6189826488494873\n",
            "Epoch: 0, iteración; 1720 de 8923, Loss: 0.5919219017028808\n",
            "Epoch: 0, iteración; 1730 de 8923, Loss: 0.6284249305725098\n",
            "Epoch: 0, iteración; 1740 de 8923, Loss: 0.6505273818969727\n",
            "Epoch: 0, iteración; 1750 de 8923, Loss: 0.6024025917053223\n",
            "Epoch: 0, iteración; 1760 de 8923, Loss: 0.5002790451049804\n",
            "Epoch: 0, iteración; 1770 de 8923, Loss: 0.5942734718322754\n",
            "Epoch: 0, iteración; 1780 de 8923, Loss: 0.5716882705688476\n",
            "Epoch: 0, iteración; 1790 de 8923, Loss: 0.6047561168670654\n",
            "Epoch: 0, iteración; 1800 de 8923, Loss: 0.5528875827789307\n",
            "Epoch: 0, iteración; 1810 de 8923, Loss: 0.5912455558776856\n",
            "Epoch: 0, iteración; 1820 de 8923, Loss: 0.5520447254180908\n",
            "Epoch: 0, iteración; 1830 de 8923, Loss: 0.6042314529418945\n",
            "Epoch: 0, iteración; 1840 de 8923, Loss: 0.5768434524536132\n",
            "Epoch: 0, iteración; 1850 de 8923, Loss: 0.516856050491333\n",
            "Epoch: 0, iteración; 1860 de 8923, Loss: 0.5511797904968262\n",
            "Epoch: 0, iteración; 1870 de 8923, Loss: 0.5094081401824951\n",
            "Epoch: 0, iteración; 1880 de 8923, Loss: 0.6118524551391602\n",
            "Epoch: 0, iteración; 1890 de 8923, Loss: 0.5893299579620361\n",
            "Epoch: 0, iteración; 1900 de 8923, Loss: 0.6379979133605957\n",
            "Epoch: 0, iteración; 1910 de 8923, Loss: 0.6755188941955567\n",
            "Epoch: 0, iteración; 1920 de 8923, Loss: 0.590670108795166\n",
            "Epoch: 0, iteración; 1930 de 8923, Loss: 0.5773123741149903\n",
            "Epoch: 0, iteración; 1940 de 8923, Loss: 0.5698604106903076\n",
            "Epoch: 0, iteración; 1950 de 8923, Loss: 0.5736926078796387\n",
            "Epoch: 0, iteración; 1960 de 8923, Loss: 0.6364965915679932\n",
            "Epoch: 0, iteración; 1970 de 8923, Loss: 0.5611829280853271\n",
            "Epoch: 0, iteración; 1980 de 8923, Loss: 0.5198546409606933\n",
            "Epoch: 0, iteración; 1990 de 8923, Loss: 0.5892620086669922\n",
            "Epoch: 0, iteración; 2000 de 8923, Loss: 0.5019140243530273\n",
            "Epoch: 0, iteración; 2010 de 8923, Loss: 0.5441348075866699\n",
            "Epoch: 0, iteración; 2020 de 8923, Loss: 0.5317593574523926\n",
            "Epoch: 0, iteración; 2030 de 8923, Loss: 0.5366994857788085\n",
            "Epoch: 0, iteración; 2040 de 8923, Loss: 0.6092195987701416\n",
            "Epoch: 0, iteración; 2050 de 8923, Loss: 0.5051066875457764\n",
            "Epoch: 0, iteración; 2060 de 8923, Loss: 0.5329290866851807\n",
            "Epoch: 0, iteración; 2070 de 8923, Loss: 0.5399898052215576\n",
            "Epoch: 0, iteración; 2080 de 8923, Loss: 0.5717020988464355\n",
            "Epoch: 0, iteración; 2090 de 8923, Loss: 0.5800695419311523\n",
            "Epoch: 0, iteración; 2100 de 8923, Loss: 0.5210333347320557\n",
            "Epoch: 0, iteración; 2110 de 8923, Loss: 0.585207462310791\n",
            "Epoch: 0, iteración; 2120 de 8923, Loss: 0.5453076362609863\n",
            "Epoch: 0, iteración; 2130 de 8923, Loss: 0.4880543231964111\n",
            "Epoch: 0, iteración; 2140 de 8923, Loss: 0.5222867965698242\n",
            "Epoch: 0, iteración; 2150 de 8923, Loss: 0.552874755859375\n",
            "Epoch: 0, iteración; 2160 de 8923, Loss: 0.581536340713501\n",
            "Epoch: 0, iteración; 2170 de 8923, Loss: 0.5252112865447998\n",
            "Epoch: 0, iteración; 2180 de 8923, Loss: 0.5830101013183594\n",
            "Epoch: 0, iteración; 2190 de 8923, Loss: 0.5445275783538819\n",
            "Epoch: 0, iteración; 2200 de 8923, Loss: 0.5970015525817871\n",
            "Epoch: 0, iteración; 2210 de 8923, Loss: 0.6162513256072998\n",
            "Epoch: 0, iteración; 2220 de 8923, Loss: 0.5916589260101318\n",
            "Epoch: 0, iteración; 2230 de 8923, Loss: 0.5124768257141114\n",
            "Epoch: 0, iteración; 2240 de 8923, Loss: 0.6336451530456543\n",
            "Epoch: 0, iteración; 2250 de 8923, Loss: 0.6032700061798095\n",
            "Epoch: 0, iteración; 2260 de 8923, Loss: 0.5547078132629395\n",
            "Epoch: 0, iteración; 2270 de 8923, Loss: 0.5415746688842773\n",
            "Epoch: 0, iteración; 2280 de 8923, Loss: 0.6073941707611084\n",
            "Epoch: 0, iteración; 2290 de 8923, Loss: 0.5899564743041992\n",
            "Epoch: 0, iteración; 2300 de 8923, Loss: 0.5325109481811523\n",
            "Epoch: 0, iteración; 2310 de 8923, Loss: 0.603828239440918\n",
            "Epoch: 0, iteración; 2320 de 8923, Loss: 0.6285514831542969\n",
            "Epoch: 0, iteración; 2330 de 8923, Loss: 0.573646354675293\n",
            "Epoch: 0, iteración; 2340 de 8923, Loss: 0.6206943988800049\n",
            "Epoch: 0, iteración; 2350 de 8923, Loss: 0.6448849201202392\n",
            "Epoch: 0, iteración; 2360 de 8923, Loss: 0.6045679092407227\n",
            "Epoch: 0, iteración; 2370 de 8923, Loss: 0.5952332019805908\n",
            "Epoch: 0, iteración; 2380 de 8923, Loss: 0.5576138496398926\n",
            "Epoch: 0, iteración; 2390 de 8923, Loss: 0.5955567359924316\n",
            "Epoch: 0, iteración; 2400 de 8923, Loss: 0.6195950031280517\n",
            "Epoch: 0, iteración; 2410 de 8923, Loss: 0.5157509326934815\n",
            "Epoch: 0, iteración; 2420 de 8923, Loss: 0.5847673416137695\n",
            "Epoch: 0, iteración; 2430 de 8923, Loss: 0.5719113349914551\n",
            "Epoch: 0, iteración; 2440 de 8923, Loss: 0.5504281997680665\n",
            "Epoch: 0, iteración; 2450 de 8923, Loss: 0.507102108001709\n",
            "Epoch: 0, iteración; 2460 de 8923, Loss: 0.6330214500427246\n",
            "Epoch: 0, iteración; 2470 de 8923, Loss: 0.617009449005127\n",
            "Epoch: 0, iteración; 2480 de 8923, Loss: 0.537941837310791\n",
            "Epoch: 0, iteración; 2490 de 8923, Loss: 0.5232061386108399\n",
            "Epoch: 0, iteración; 2500 de 8923, Loss: 0.581908130645752\n",
            "Epoch: 0, iteración; 2510 de 8923, Loss: 0.5351784706115723\n",
            "Epoch: 0, iteración; 2520 de 8923, Loss: 0.543346643447876\n",
            "Epoch: 0, iteración; 2530 de 8923, Loss: 0.5569748878479004\n",
            "Epoch: 0, iteración; 2540 de 8923, Loss: 0.6306937217712403\n",
            "Epoch: 0, iteración; 2550 de 8923, Loss: 0.5399517059326172\n",
            "Epoch: 0, iteración; 2560 de 8923, Loss: 0.5849040985107422\n",
            "Epoch: 0, iteración; 2570 de 8923, Loss: 0.5324442863464356\n",
            "Epoch: 0, iteración; 2580 de 8923, Loss: 0.5373594760894775\n",
            "Epoch: 0, iteración; 2590 de 8923, Loss: 0.5281531333923339\n",
            "Epoch: 0, iteración; 2600 de 8923, Loss: 0.6189981937408447\n",
            "Epoch: 0, iteración; 2610 de 8923, Loss: 0.5880661487579346\n",
            "Epoch: 0, iteración; 2620 de 8923, Loss: 0.6232197761535645\n",
            "Epoch: 0, iteración; 2630 de 8923, Loss: 0.5537301540374756\n",
            "Epoch: 0, iteración; 2640 de 8923, Loss: 0.5186557292938232\n",
            "Epoch: 0, iteración; 2650 de 8923, Loss: 0.5629086017608642\n",
            "Epoch: 0, iteración; 2660 de 8923, Loss: 0.5684663772583007\n",
            "Epoch: 0, iteración; 2670 de 8923, Loss: 0.6287803173065185\n",
            "Epoch: 0, iteración; 2680 de 8923, Loss: 0.5340779781341553\n",
            "Epoch: 0, iteración; 2690 de 8923, Loss: 0.5684398651123047\n",
            "Epoch: 0, iteración; 2700 de 8923, Loss: 0.5874181270599366\n",
            "Epoch: 0, iteración; 2710 de 8923, Loss: 0.5268208980560303\n",
            "Epoch: 0, iteración; 2720 de 8923, Loss: 0.6245237827301026\n",
            "Epoch: 0, iteración; 2730 de 8923, Loss: 0.6362750053405761\n",
            "Epoch: 0, iteración; 2740 de 8923, Loss: 0.5872756481170655\n",
            "Epoch: 0, iteración; 2750 de 8923, Loss: 0.5168524742126465\n",
            "Epoch: 0, iteración; 2760 de 8923, Loss: 0.5992780685424804\n",
            "Epoch: 0, iteración; 2770 de 8923, Loss: 0.5748239994049072\n",
            "Epoch: 0, iteración; 2780 de 8923, Loss: 0.5421915054321289\n",
            "Epoch: 0, iteración; 2790 de 8923, Loss: 0.5621233940124511\n",
            "Epoch: 0, iteración; 2800 de 8923, Loss: 0.5684186458587647\n",
            "Epoch: 0, iteración; 2810 de 8923, Loss: 0.5792294025421143\n",
            "Epoch: 0, iteración; 2820 de 8923, Loss: 0.5401254177093506\n",
            "Epoch: 0, iteración; 2830 de 8923, Loss: 0.523549747467041\n",
            "Epoch: 0, iteración; 2840 de 8923, Loss: 0.6064293861389161\n",
            "Epoch: 0, iteración; 2850 de 8923, Loss: 0.6034030437469482\n",
            "Epoch: 0, iteración; 2860 de 8923, Loss: 0.5753493309020996\n",
            "Epoch: 0, iteración; 2870 de 8923, Loss: 0.5659237384796143\n",
            "Epoch: 0, iteración; 2880 de 8923, Loss: 0.549985694885254\n",
            "Epoch: 0, iteración; 2890 de 8923, Loss: 0.6888956546783447\n",
            "Epoch: 0, iteración; 2900 de 8923, Loss: 0.5722220420837403\n",
            "Epoch: 0, iteración; 2910 de 8923, Loss: 0.5661362171173095\n",
            "Epoch: 0, iteración; 2920 de 8923, Loss: 0.5838060855865479\n",
            "Epoch: 0, iteración; 2930 de 8923, Loss: 0.5778857231140136\n",
            "Epoch: 0, iteración; 2940 de 8923, Loss: 0.5026693344116211\n",
            "Epoch: 0, iteración; 2950 de 8923, Loss: 0.5455712795257568\n",
            "Epoch: 0, iteración; 2960 de 8923, Loss: 0.5859341621398926\n",
            "Epoch: 0, iteración; 2970 de 8923, Loss: 0.570948314666748\n",
            "Epoch: 0, iteración; 2980 de 8923, Loss: 0.5335909843444824\n",
            "Epoch: 0, iteración; 2990 de 8923, Loss: 0.5929257869720459\n",
            "Epoch: 0, iteración; 3000 de 8923, Loss: 0.5591394424438476\n",
            "Epoch: 0, iteración; 3010 de 8923, Loss: 0.5684023857116699\n",
            "Epoch: 0, iteración; 3020 de 8923, Loss: 0.6267022609710693\n",
            "Epoch: 0, iteración; 3030 de 8923, Loss: 0.6031301498413086\n",
            "Epoch: 0, iteración; 3040 de 8923, Loss: 0.5194708824157714\n",
            "Epoch: 0, iteración; 3050 de 8923, Loss: 0.6022484779357911\n",
            "Epoch: 0, iteración; 3060 de 8923, Loss: 0.5343719482421875\n",
            "Epoch: 0, iteración; 3070 de 8923, Loss: 0.5272066593170166\n",
            "Epoch: 0, iteración; 3080 de 8923, Loss: 0.4922003269195557\n",
            "Epoch: 0, iteración; 3090 de 8923, Loss: 0.5703291416168212\n",
            "Epoch: 0, iteración; 3100 de 8923, Loss: 0.5095768928527832\n",
            "Epoch: 0, iteración; 3110 de 8923, Loss: 0.5327408790588379\n",
            "Epoch: 0, iteración; 3120 de 8923, Loss: 0.5658360481262207\n",
            "Epoch: 0, iteración; 3130 de 8923, Loss: 0.5703978538513184\n",
            "Epoch: 0, iteración; 3140 de 8923, Loss: 0.5685924530029297\n",
            "Epoch: 0, iteración; 3150 de 8923, Loss: 0.6041572570800782\n",
            "Epoch: 0, iteración; 3160 de 8923, Loss: 0.5234212875366211\n",
            "Epoch: 0, iteración; 3170 de 8923, Loss: 0.6329898834228516\n",
            "Epoch: 0, iteración; 3180 de 8923, Loss: 0.5749908447265625\n",
            "Epoch: 0, iteración; 3190 de 8923, Loss: 0.6154568195343018\n",
            "Epoch: 0, iteración; 3200 de 8923, Loss: 0.5323337078094482\n",
            "Epoch: 0, iteración; 3210 de 8923, Loss: 0.573754072189331\n",
            "Epoch: 0, iteración; 3220 de 8923, Loss: 0.5743771076202393\n",
            "Epoch: 0, iteración; 3230 de 8923, Loss: 0.5802784442901612\n",
            "Epoch: 0, iteración; 3240 de 8923, Loss: 0.48102798461914065\n",
            "Epoch: 0, iteración; 3250 de 8923, Loss: 0.5720257759094238\n",
            "Epoch: 0, iteración; 3260 de 8923, Loss: 0.5374876022338867\n",
            "Epoch: 0, iteración; 3270 de 8923, Loss: 0.5784106254577637\n",
            "Epoch: 0, iteración; 3280 de 8923, Loss: 0.5493064403533936\n",
            "Epoch: 0, iteración; 3290 de 8923, Loss: 0.5638072490692139\n",
            "Epoch: 0, iteración; 3300 de 8923, Loss: 0.5730399131774903\n",
            "Epoch: 0, iteración; 3310 de 8923, Loss: 0.4875919818878174\n",
            "Epoch: 0, iteración; 3320 de 8923, Loss: 0.5242443084716797\n",
            "Epoch: 0, iteración; 3330 de 8923, Loss: 0.6179970264434814\n",
            "Epoch: 0, iteración; 3340 de 8923, Loss: 0.5713036537170411\n",
            "Epoch: 0, iteración; 3350 de 8923, Loss: 0.5757821083068848\n",
            "Epoch: 0, iteración; 3360 de 8923, Loss: 0.5748334884643554\n",
            "Epoch: 0, iteración; 3370 de 8923, Loss: 0.5392154216766357\n",
            "Epoch: 0, iteración; 3380 de 8923, Loss: 0.5211393356323242\n",
            "Epoch: 0, iteración; 3390 de 8923, Loss: 0.5903179168701171\n",
            "Epoch: 0, iteración; 3400 de 8923, Loss: 0.53282151222229\n",
            "Epoch: 0, iteración; 3410 de 8923, Loss: 0.6258137702941895\n",
            "Epoch: 0, iteración; 3420 de 8923, Loss: 0.5823540210723877\n",
            "Epoch: 0, iteración; 3430 de 8923, Loss: 0.5369521617889405\n",
            "Epoch: 0, iteración; 3440 de 8923, Loss: 0.566542673110962\n",
            "Epoch: 0, iteración; 3450 de 8923, Loss: 0.632170295715332\n",
            "Epoch: 0, iteración; 3460 de 8923, Loss: 0.5337301731109619\n",
            "Epoch: 0, iteración; 3470 de 8923, Loss: 0.4998927593231201\n",
            "Epoch: 0, iteración; 3480 de 8923, Loss: 0.56271390914917\n",
            "Epoch: 0, iteración; 3490 de 8923, Loss: 0.6711966514587402\n",
            "Epoch: 0, iteración; 3500 de 8923, Loss: 0.5825772285461426\n",
            "Epoch: 0, iteración; 3510 de 8923, Loss: 0.5317193508148194\n",
            "Epoch: 0, iteración; 3520 de 8923, Loss: 0.5677976131439209\n",
            "Epoch: 0, iteración; 3530 de 8923, Loss: 0.5430572509765625\n",
            "Epoch: 0, iteración; 3540 de 8923, Loss: 0.5967274188995362\n",
            "Epoch: 0, iteración; 3550 de 8923, Loss: 0.6543601036071778\n",
            "Epoch: 0, iteración; 3560 de 8923, Loss: 0.48927927017211914\n",
            "Epoch: 0, iteración; 3570 de 8923, Loss: 0.5750983238220215\n",
            "Epoch: 0, iteración; 3580 de 8923, Loss: 0.55050687789917\n",
            "Epoch: 0, iteración; 3590 de 8923, Loss: 0.5213244438171387\n",
            "Epoch: 0, iteración; 3600 de 8923, Loss: 0.5427502632141114\n",
            "Epoch: 0, iteración; 3610 de 8923, Loss: 0.5546030044555664\n",
            "Epoch: 0, iteración; 3620 de 8923, Loss: 0.4918830871582031\n",
            "Epoch: 0, iteración; 3630 de 8923, Loss: 0.5023064613342285\n",
            "Epoch: 0, iteración; 3640 de 8923, Loss: 0.6142259120941163\n",
            "Epoch: 0, iteración; 3650 de 8923, Loss: 0.5081591606140137\n",
            "Epoch: 0, iteración; 3660 de 8923, Loss: 0.5586989879608154\n",
            "Epoch: 0, iteración; 3670 de 8923, Loss: 0.5570211410522461\n",
            "Epoch: 0, iteración; 3680 de 8923, Loss: 0.6003931999206543\n",
            "Epoch: 0, iteración; 3690 de 8923, Loss: 0.6172414779663086\n",
            "Epoch: 0, iteración; 3700 de 8923, Loss: 0.5851786613464356\n",
            "Epoch: 0, iteración; 3710 de 8923, Loss: 0.49716906547546386\n",
            "Epoch: 0, iteración; 3720 de 8923, Loss: 0.5601688385009765\n",
            "Epoch: 0, iteración; 3730 de 8923, Loss: 0.6125590801239014\n",
            "Epoch: 0, iteración; 3740 de 8923, Loss: 0.5373535633087159\n",
            "Epoch: 0, iteración; 3750 de 8923, Loss: 0.5586605072021484\n",
            "Epoch: 0, iteración; 3760 de 8923, Loss: 0.5964900970458984\n",
            "Epoch: 0, iteración; 3770 de 8923, Loss: 0.5864995002746582\n",
            "Epoch: 0, iteración; 3780 de 8923, Loss: 0.5490032196044922\n",
            "Epoch: 0, iteración; 3790 de 8923, Loss: 0.4921614646911621\n",
            "Epoch: 0, iteración; 3800 de 8923, Loss: 0.5581755638122559\n",
            "Epoch: 0, iteración; 3810 de 8923, Loss: 0.5351859569549561\n",
            "Epoch: 0, iteración; 3820 de 8923, Loss: 0.5627488613128662\n",
            "Epoch: 0, iteración; 3830 de 8923, Loss: 0.6158640384674072\n",
            "Epoch: 0, iteración; 3840 de 8923, Loss: 0.5180526733398437\n",
            "Epoch: 0, iteración; 3850 de 8923, Loss: 0.6190078258514404\n",
            "Epoch: 0, iteración; 3860 de 8923, Loss: 0.6023488998413086\n",
            "Epoch: 0, iteración; 3870 de 8923, Loss: 0.5566689491271972\n",
            "Epoch: 0, iteración; 3880 de 8923, Loss: 0.5085165977478028\n",
            "Epoch: 0, iteración; 3890 de 8923, Loss: 0.5395411491394043\n",
            "Epoch: 0, iteración; 3900 de 8923, Loss: 0.5467244625091553\n",
            "Epoch: 0, iteración; 3910 de 8923, Loss: 0.5368731021881104\n",
            "Epoch: 0, iteración; 3920 de 8923, Loss: 0.5919548988342285\n",
            "Epoch: 0, iteración; 3930 de 8923, Loss: 0.6288265705108642\n",
            "Epoch: 0, iteración; 3940 de 8923, Loss: 0.5626495361328125\n",
            "Epoch: 0, iteración; 3950 de 8923, Loss: 0.4889216423034668\n",
            "Epoch: 0, iteración; 3960 de 8923, Loss: 0.5636353969573975\n",
            "Epoch: 0, iteración; 3970 de 8923, Loss: 0.5667428493499755\n",
            "Epoch: 0, iteración; 3980 de 8923, Loss: 0.5090397357940674\n",
            "Epoch: 0, iteración; 3990 de 8923, Loss: 0.6187567710876465\n",
            "Epoch: 0, iteración; 4000 de 8923, Loss: 0.5510161876678467\n",
            "Epoch: 0, iteración; 4010 de 8923, Loss: 0.5616996765136719\n",
            "Epoch: 0, iteración; 4020 de 8923, Loss: 0.5432228565216064\n",
            "Epoch: 0, iteración; 4030 de 8923, Loss: 0.5686740398406982\n",
            "Epoch: 0, iteración; 4040 de 8923, Loss: 0.5875450611114502\n",
            "Epoch: 0, iteración; 4050 de 8923, Loss: 0.5215131282806397\n",
            "Epoch: 0, iteración; 4060 de 8923, Loss: 0.5769499778747559\n",
            "Epoch: 0, iteración; 4070 de 8923, Loss: 0.5475157737731934\n",
            "Epoch: 0, iteración; 4080 de 8923, Loss: 0.5163632392883301\n",
            "Epoch: 0, iteración; 4090 de 8923, Loss: 0.6212317943572998\n",
            "Epoch: 0, iteración; 4100 de 8923, Loss: 0.5096594810485839\n",
            "Epoch: 0, iteración; 4110 de 8923, Loss: 0.5996211051940918\n",
            "Epoch: 0, iteración; 4120 de 8923, Loss: 0.6081353187561035\n",
            "Epoch: 0, iteración; 4130 de 8923, Loss: 0.593119478225708\n",
            "Epoch: 0, iteración; 4140 de 8923, Loss: 0.564312744140625\n",
            "Epoch: 0, iteración; 4150 de 8923, Loss: 0.5843317985534668\n",
            "Epoch: 0, iteración; 4160 de 8923, Loss: 0.5774996280670166\n",
            "Epoch: 0, iteración; 4170 de 8923, Loss: 0.5631632804870605\n",
            "Epoch: 0, iteración; 4180 de 8923, Loss: 0.5708962917327881\n",
            "Epoch: 0, iteración; 4190 de 8923, Loss: 0.519569206237793\n",
            "Epoch: 0, iteración; 4200 de 8923, Loss: 0.5962339401245117\n",
            "Epoch: 0, iteración; 4210 de 8923, Loss: 0.5667314052581787\n",
            "Epoch: 0, iteración; 4220 de 8923, Loss: 0.5980043888092041\n",
            "Epoch: 0, iteración; 4230 de 8923, Loss: 0.6235692024230957\n",
            "Epoch: 0, iteración; 4240 de 8923, Loss: 0.549364709854126\n",
            "Epoch: 0, iteración; 4250 de 8923, Loss: 0.5614800930023194\n",
            "Epoch: 0, iteración; 4260 de 8923, Loss: 0.5538705348968506\n",
            "Epoch: 0, iteración; 4270 de 8923, Loss: 0.5941693782806396\n",
            "Epoch: 0, iteración; 4280 de 8923, Loss: 0.5499794960021973\n",
            "Epoch: 0, iteración; 4290 de 8923, Loss: 0.5708074569702148\n",
            "Epoch: 0, iteración; 4300 de 8923, Loss: 0.4640387535095215\n",
            "Epoch: 0, iteración; 4310 de 8923, Loss: 0.5364667415618897\n",
            "Epoch: 0, iteración; 4320 de 8923, Loss: 0.556654405593872\n",
            "Epoch: 0, iteración; 4330 de 8923, Loss: 0.5869097709655762\n",
            "Epoch: 0, iteración; 4340 de 8923, Loss: 0.5195433139801026\n",
            "Epoch: 0, iteración; 4350 de 8923, Loss: 0.5536773681640625\n",
            "Epoch: 0, iteración; 4360 de 8923, Loss: 0.4733442306518555\n",
            "Epoch: 0, iteración; 4370 de 8923, Loss: 0.5651520729064942\n",
            "Epoch: 0, iteración; 4380 de 8923, Loss: 0.5760014057159424\n",
            "Epoch: 0, iteración; 4390 de 8923, Loss: 0.5667500495910645\n",
            "Epoch: 0, iteración; 4400 de 8923, Loss: 0.4922469615936279\n",
            "Epoch: 0, iteración; 4410 de 8923, Loss: 0.6095818996429443\n",
            "Epoch: 0, iteración; 4420 de 8923, Loss: 0.6228954315185546\n",
            "Epoch: 0, iteración; 4430 de 8923, Loss: 0.5570967674255372\n",
            "Epoch: 0, iteración; 4440 de 8923, Loss: 0.5621068000793457\n",
            "Epoch: 0, iteración; 4450 de 8923, Loss: 0.5646249771118164\n",
            "Epoch: 0, iteración; 4460 de 8923, Loss: 0.6464882373809815\n",
            "Epoch: 0, iteración; 4470 de 8923, Loss: 0.5361902236938476\n",
            "Epoch: 0, iteración; 4480 de 8923, Loss: 0.5532697677612305\n",
            "Epoch: 0, iteración; 4490 de 8923, Loss: 0.5670793056488037\n",
            "Epoch: 0, iteración; 4500 de 8923, Loss: 0.5397261619567871\n",
            "Epoch: 0, iteración; 4510 de 8923, Loss: 0.5050441265106201\n",
            "Epoch: 0, iteración; 4520 de 8923, Loss: 0.616134786605835\n",
            "Epoch: 0, iteración; 4530 de 8923, Loss: 0.5968179702758789\n",
            "Epoch: 0, iteración; 4540 de 8923, Loss: 0.6083393096923828\n",
            "Epoch: 0, iteración; 4550 de 8923, Loss: 0.4849764347076416\n",
            "Epoch: 0, iteración; 4560 de 8923, Loss: 0.6313714504241943\n",
            "Epoch: 0, iteración; 4570 de 8923, Loss: 0.5876633644104003\n",
            "Epoch: 0, iteración; 4580 de 8923, Loss: 0.5940288543701172\n",
            "Epoch: 0, iteración; 4590 de 8923, Loss: 0.5619980812072753\n",
            "Epoch: 0, iteración; 4600 de 8923, Loss: 0.5722898006439209\n",
            "Epoch: 0, iteración; 4610 de 8923, Loss: 0.571494722366333\n",
            "Epoch: 0, iteración; 4620 de 8923, Loss: 0.5611666679382324\n",
            "Epoch: 0, iteración; 4630 de 8923, Loss: 0.5825296401977539\n",
            "Epoch: 0, iteración; 4640 de 8923, Loss: 0.6229063987731933\n",
            "Epoch: 0, iteración; 4650 de 8923, Loss: 0.5632947444915771\n",
            "Epoch: 0, iteración; 4660 de 8923, Loss: 0.6239221096038818\n",
            "Epoch: 0, iteración; 4670 de 8923, Loss: 0.5971734523773193\n",
            "Epoch: 0, iteración; 4680 de 8923, Loss: 0.6250800609588623\n",
            "Epoch: 0, iteración; 4690 de 8923, Loss: 0.6062443733215332\n",
            "Epoch: 0, iteración; 4700 de 8923, Loss: 0.558595848083496\n",
            "Epoch: 0, iteración; 4710 de 8923, Loss: 0.5870437622070312\n",
            "Epoch: 0, iteración; 4720 de 8923, Loss: 0.4981109619140625\n",
            "Epoch: 0, iteración; 4730 de 8923, Loss: 0.5659234523773193\n",
            "Epoch: 0, iteración; 4740 de 8923, Loss: 0.5417780876159668\n",
            "Epoch: 0, iteración; 4750 de 8923, Loss: 0.6455469131469727\n",
            "Epoch: 0, iteración; 4760 de 8923, Loss: 0.4845921516418457\n",
            "Epoch: 0, iteración; 4770 de 8923, Loss: 0.5303755760192871\n",
            "Epoch: 0, iteración; 4780 de 8923, Loss: 0.5105598449707032\n",
            "Epoch: 0, iteración; 4790 de 8923, Loss: 0.5870907783508301\n",
            "Epoch: 0, iteración; 4800 de 8923, Loss: 0.5350009441375733\n",
            "Epoch: 0, iteración; 4810 de 8923, Loss: 0.54825758934021\n",
            "Epoch: 0, iteración; 4820 de 8923, Loss: 0.6276401042938232\n",
            "Epoch: 0, iteración; 4830 de 8923, Loss: 0.588268518447876\n",
            "Epoch: 0, iteración; 4840 de 8923, Loss: 0.5814778327941894\n",
            "Epoch: 0, iteración; 4850 de 8923, Loss: 0.5703052997589111\n",
            "Epoch: 0, iteración; 4860 de 8923, Loss: 0.5260354518890381\n",
            "Epoch: 0, iteración; 4870 de 8923, Loss: 0.5824041366577148\n",
            "Epoch: 0, iteración; 4880 de 8923, Loss: 0.5096983909606934\n",
            "Epoch: 0, iteración; 4890 de 8923, Loss: 0.534649133682251\n",
            "Epoch: 0, iteración; 4900 de 8923, Loss: 0.5796411514282227\n",
            "Epoch: 0, iteración; 4910 de 8923, Loss: 0.6034302234649658\n",
            "Epoch: 0, iteración; 4920 de 8923, Loss: 0.5928269386291504\n",
            "Epoch: 0, iteración; 4930 de 8923, Loss: 0.535517692565918\n",
            "Epoch: 0, iteración; 4940 de 8923, Loss: 0.5786548137664795\n",
            "Epoch: 0, iteración; 4950 de 8923, Loss: 0.5613969802856446\n",
            "Epoch: 0, iteración; 4960 de 8923, Loss: 0.5724705219268799\n",
            "Epoch: 0, iteración; 4970 de 8923, Loss: 0.5460258007049561\n",
            "Epoch: 0, iteración; 4980 de 8923, Loss: 0.6764150619506836\n",
            "Epoch: 0, iteración; 4990 de 8923, Loss: 0.582028579711914\n",
            "Epoch: 0, iteración; 5000 de 8923, Loss: 0.5991718292236328\n",
            "Epoch: 0, iteración; 5010 de 8923, Loss: 0.5643433570861817\n",
            "Epoch: 0, iteración; 5020 de 8923, Loss: 0.6093570232391358\n",
            "Epoch: 0, iteración; 5030 de 8923, Loss: 0.6078051567077637\n",
            "Epoch: 0, iteración; 5040 de 8923, Loss: 0.5782077789306641\n",
            "Epoch: 0, iteración; 5050 de 8923, Loss: 0.6103699207305908\n",
            "Epoch: 0, iteración; 5060 de 8923, Loss: 0.5379424571990967\n",
            "Epoch: 0, iteración; 5070 de 8923, Loss: 0.5830044746398926\n",
            "Epoch: 0, iteración; 5080 de 8923, Loss: 0.5451972961425782\n",
            "Epoch: 0, iteración; 5090 de 8923, Loss: 0.6031326293945313\n",
            "Epoch: 0, iteración; 5100 de 8923, Loss: 0.5108100414276123\n",
            "Epoch: 0, iteración; 5110 de 8923, Loss: 0.6109815120697022\n",
            "Epoch: 0, iteración; 5120 de 8923, Loss: 0.559559440612793\n",
            "Epoch: 0, iteración; 5130 de 8923, Loss: 0.5892414093017578\n",
            "Epoch: 0, iteración; 5140 de 8923, Loss: 0.5238264083862305\n",
            "Epoch: 0, iteración; 5150 de 8923, Loss: 0.49774875640869143\n",
            "Epoch: 0, iteración; 5160 de 8923, Loss: 0.5315260887145996\n",
            "Epoch: 0, iteración; 5170 de 8923, Loss: 0.5285675048828125\n",
            "Epoch: 0, iteración; 5180 de 8923, Loss: 0.5862439632415771\n",
            "Epoch: 0, iteración; 5190 de 8923, Loss: 0.6827192306518555\n",
            "Epoch: 0, iteración; 5200 de 8923, Loss: 0.603797721862793\n",
            "Epoch: 0, iteración; 5210 de 8923, Loss: 0.5634312629699707\n",
            "Epoch: 0, iteración; 5220 de 8923, Loss: 0.6440526008605957\n",
            "Epoch: 0, iteración; 5230 de 8923, Loss: 0.6045819759368897\n",
            "Epoch: 0, iteración; 5240 de 8923, Loss: 0.5533973217010498\n",
            "Epoch: 0, iteración; 5250 de 8923, Loss: 0.5795094013214112\n",
            "Epoch: 0, iteración; 5260 de 8923, Loss: 0.5243640422821045\n",
            "Epoch: 0, iteración; 5270 de 8923, Loss: 0.5753342628479003\n",
            "Epoch: 0, iteración; 5280 de 8923, Loss: 0.5411611557006836\n",
            "Epoch: 0, iteración; 5290 de 8923, Loss: 0.5925027847290039\n",
            "Epoch: 0, iteración; 5300 de 8923, Loss: 0.4862854480743408\n",
            "Epoch: 0, iteración; 5310 de 8923, Loss: 0.5606214046478272\n",
            "Epoch: 0, iteración; 5320 de 8923, Loss: 0.6122113227844238\n",
            "Epoch: 0, iteración; 5330 de 8923, Loss: 0.5137114524841309\n",
            "Epoch: 0, iteración; 5340 de 8923, Loss: 0.5815573692321777\n",
            "Epoch: 0, iteración; 5350 de 8923, Loss: 0.5634522914886475\n",
            "Epoch: 0, iteración; 5360 de 8923, Loss: 0.486329984664917\n",
            "Epoch: 0, iteración; 5370 de 8923, Loss: 0.5730726718902588\n",
            "Epoch: 0, iteración; 5380 de 8923, Loss: 0.49492926597595216\n",
            "Epoch: 0, iteración; 5390 de 8923, Loss: 0.5714759826660156\n",
            "Epoch: 0, iteración; 5400 de 8923, Loss: 0.5383499145507813\n",
            "Epoch: 0, iteración; 5410 de 8923, Loss: 0.5940106391906739\n",
            "Epoch: 0, iteración; 5420 de 8923, Loss: 0.5464995384216309\n",
            "Epoch: 0, iteración; 5430 de 8923, Loss: 0.544414758682251\n",
            "Epoch: 0, iteración; 5440 de 8923, Loss: 0.48609938621521\n",
            "Epoch: 0, iteración; 5450 de 8923, Loss: 0.5502530097961426\n",
            "Epoch: 0, iteración; 5460 de 8923, Loss: 0.5077887535095215\n",
            "Epoch: 0, iteración; 5470 de 8923, Loss: 0.5388378620147705\n",
            "Epoch: 0, iteración; 5480 de 8923, Loss: 0.5701274871826172\n",
            "Epoch: 0, iteración; 5490 de 8923, Loss: 0.5919278144836426\n",
            "Epoch: 0, iteración; 5500 de 8923, Loss: 0.5058238983154297\n",
            "Epoch: 0, iteración; 5510 de 8923, Loss: 0.5707951068878174\n",
            "Epoch: 0, iteración; 5520 de 8923, Loss: 0.4877632617950439\n",
            "Epoch: 0, iteración; 5530 de 8923, Loss: 0.5379501342773437\n",
            "Epoch: 0, iteración; 5540 de 8923, Loss: 0.5697244167327881\n",
            "Epoch: 0, iteración; 5550 de 8923, Loss: 0.5775062561035156\n",
            "Epoch: 0, iteración; 5560 de 8923, Loss: 0.6083351612091065\n",
            "Epoch: 0, iteración; 5570 de 8923, Loss: 0.6186290264129639\n",
            "Epoch: 0, iteración; 5580 de 8923, Loss: 0.5217925548553467\n",
            "Epoch: 0, iteración; 5590 de 8923, Loss: 0.550816822052002\n",
            "Epoch: 0, iteración; 5600 de 8923, Loss: 0.5938234329223633\n",
            "Epoch: 0, iteración; 5610 de 8923, Loss: 0.5639595031738281\n",
            "Epoch: 0, iteración; 5620 de 8923, Loss: 0.5957335948944091\n",
            "Epoch: 0, iteración; 5630 de 8923, Loss: 0.5960671424865722\n",
            "Epoch: 0, iteración; 5640 de 8923, Loss: 0.5938931465148926\n",
            "Epoch: 0, iteración; 5650 de 8923, Loss: 0.519202995300293\n",
            "Epoch: 0, iteración; 5660 de 8923, Loss: 0.561793041229248\n",
            "Epoch: 0, iteración; 5670 de 8923, Loss: 0.5640949726104736\n",
            "Epoch: 0, iteración; 5680 de 8923, Loss: 0.5875483512878418\n",
            "Epoch: 0, iteración; 5690 de 8923, Loss: 0.5591497421264648\n",
            "Epoch: 0, iteración; 5700 de 8923, Loss: 0.564134168624878\n",
            "Epoch: 0, iteración; 5710 de 8923, Loss: 0.5435986518859863\n",
            "Epoch: 0, iteración; 5720 de 8923, Loss: 0.5156495094299316\n",
            "Epoch: 0, iteración; 5730 de 8923, Loss: 0.5809311389923095\n",
            "Epoch: 0, iteración; 5740 de 8923, Loss: 0.5985371112823487\n",
            "Epoch: 0, iteración; 5750 de 8923, Loss: 0.5525379657745362\n",
            "Epoch: 0, iteración; 5760 de 8923, Loss: 0.5858238220214844\n",
            "Epoch: 0, iteración; 5770 de 8923, Loss: 0.5459110736846924\n",
            "Epoch: 0, iteración; 5780 de 8923, Loss: 0.553169584274292\n",
            "Epoch: 0, iteración; 5790 de 8923, Loss: 0.5521083354949952\n",
            "Epoch: 0, iteración; 5800 de 8923, Loss: 0.5508910655975342\n",
            "Epoch: 0, iteración; 5810 de 8923, Loss: 0.5907716274261474\n",
            "Epoch: 0, iteración; 5820 de 8923, Loss: 0.6286401748657227\n",
            "Epoch: 0, iteración; 5830 de 8923, Loss: 0.5611112594604493\n",
            "Epoch: 0, iteración; 5840 de 8923, Loss: 0.6857764720916748\n",
            "Epoch: 0, iteración; 5850 de 8923, Loss: 0.5468335628509522\n",
            "Epoch: 0, iteración; 5860 de 8923, Loss: 0.4628158092498779\n",
            "Epoch: 0, iteración; 5870 de 8923, Loss: 0.5679151535034179\n",
            "Epoch: 0, iteración; 5880 de 8923, Loss: 0.5592738151550293\n",
            "Epoch: 0, iteración; 5890 de 8923, Loss: 0.5667457103729248\n",
            "Epoch: 0, iteración; 5900 de 8923, Loss: 0.5741785526275635\n",
            "Epoch: 0, iteración; 5910 de 8923, Loss: 0.6407824993133545\n",
            "Epoch: 0, iteración; 5920 de 8923, Loss: 0.595757007598877\n",
            "Epoch: 0, iteración; 5930 de 8923, Loss: 0.6191701412200927\n",
            "Epoch: 0, iteración; 5940 de 8923, Loss: 0.5393395900726319\n",
            "Epoch: 0, iteración; 5950 de 8923, Loss: 0.47895083427429197\n",
            "Epoch: 0, iteración; 5960 de 8923, Loss: 0.561281681060791\n",
            "Epoch: 0, iteración; 5970 de 8923, Loss: 0.5871464252471924\n",
            "Epoch: 0, iteración; 5980 de 8923, Loss: 0.5646237850189209\n",
            "Epoch: 0, iteración; 5990 de 8923, Loss: 0.5535142898559571\n",
            "Epoch: 0, iteración; 6000 de 8923, Loss: 0.6110694408416748\n",
            "Epoch: 0, iteración; 6010 de 8923, Loss: 0.5785212516784668\n",
            "Epoch: 0, iteración; 6020 de 8923, Loss: 0.5876697540283203\n",
            "Epoch: 0, iteración; 6030 de 8923, Loss: 0.5492219448089599\n",
            "Epoch: 0, iteración; 6040 de 8923, Loss: 0.5406729221343994\n",
            "Epoch: 0, iteración; 6050 de 8923, Loss: 0.620533800125122\n",
            "Epoch: 0, iteración; 6060 de 8923, Loss: 0.6200172901153564\n",
            "Epoch: 0, iteración; 6070 de 8923, Loss: 0.5559707641601562\n",
            "Epoch: 0, iteración; 6080 de 8923, Loss: 0.6328135013580323\n",
            "Epoch: 0, iteración; 6090 de 8923, Loss: 0.5498303413391114\n",
            "Epoch: 0, iteración; 6100 de 8923, Loss: 0.6199759006500244\n",
            "Epoch: 0, iteración; 6110 de 8923, Loss: 0.5628436088562012\n",
            "Epoch: 0, iteración; 6120 de 8923, Loss: 0.5192580699920655\n",
            "Epoch: 0, iteración; 6130 de 8923, Loss: 0.57671217918396\n",
            "Epoch: 0, iteración; 6140 de 8923, Loss: 0.5249724388122559\n",
            "Epoch: 0, iteración; 6150 de 8923, Loss: 0.5783382415771484\n",
            "Epoch: 0, iteración; 6160 de 8923, Loss: 0.5662873268127442\n",
            "Epoch: 0, iteración; 6170 de 8923, Loss: 0.5297293186187744\n",
            "Epoch: 0, iteración; 6180 de 8923, Loss: 0.5642680168151856\n",
            "Epoch: 0, iteración; 6190 de 8923, Loss: 0.6316120147705078\n",
            "Epoch: 0, iteración; 6200 de 8923, Loss: 0.5873448848724365\n",
            "Epoch: 0, iteración; 6210 de 8923, Loss: 0.6083510398864747\n",
            "Epoch: 0, iteración; 6220 de 8923, Loss: 0.6191575527191162\n",
            "Epoch: 0, iteración; 6230 de 8923, Loss: 0.6161280155181885\n",
            "Epoch: 0, iteración; 6240 de 8923, Loss: 0.6053582191467285\n",
            "Epoch: 0, iteración; 6250 de 8923, Loss: 0.6070173263549805\n",
            "Epoch: 0, iteración; 6260 de 8923, Loss: 0.5941526889801025\n",
            "Epoch: 0, iteración; 6270 de 8923, Loss: 0.6316121101379395\n",
            "Epoch: 0, iteración; 6280 de 8923, Loss: 0.5947210788726807\n",
            "Epoch: 0, iteración; 6290 de 8923, Loss: 0.5922466278076172\n",
            "Epoch: 0, iteración; 6300 de 8923, Loss: 0.5013360023498535\n",
            "Epoch: 0, iteración; 6310 de 8923, Loss: 0.5615068912506104\n",
            "Epoch: 0, iteración; 6320 de 8923, Loss: 0.5284002304077149\n",
            "Epoch: 0, iteración; 6330 de 8923, Loss: 0.4964920997619629\n",
            "Epoch: 0, iteración; 6340 de 8923, Loss: 0.540271806716919\n",
            "Epoch: 0, iteración; 6350 de 8923, Loss: 0.5551910877227784\n",
            "Epoch: 0, iteración; 6360 de 8923, Loss: 0.5585937023162841\n",
            "Epoch: 0, iteración; 6370 de 8923, Loss: 0.5692089080810547\n",
            "Epoch: 0, iteración; 6380 de 8923, Loss: 0.6023571968078614\n",
            "Epoch: 0, iteración; 6390 de 8923, Loss: 0.6018210887908936\n",
            "Epoch: 0, iteración; 6400 de 8923, Loss: 0.5103890419006347\n",
            "Epoch: 0, iteración; 6410 de 8923, Loss: 0.61569185256958\n",
            "Epoch: 0, iteración; 6420 de 8923, Loss: 0.6065236091613769\n",
            "Epoch: 0, iteración; 6430 de 8923, Loss: 0.5929909229278565\n",
            "Epoch: 0, iteración; 6440 de 8923, Loss: 0.5793148040771484\n",
            "Epoch: 0, iteración; 6450 de 8923, Loss: 0.5223466396331787\n",
            "Epoch: 0, iteración; 6460 de 8923, Loss: 0.6169206619262695\n",
            "Epoch: 0, iteración; 6470 de 8923, Loss: 0.6468006134033203\n",
            "Epoch: 0, iteración; 6480 de 8923, Loss: 0.5865074157714844\n",
            "Epoch: 0, iteración; 6490 de 8923, Loss: 0.548016881942749\n",
            "Epoch: 0, iteración; 6500 de 8923, Loss: 0.5499199390411377\n",
            "Epoch: 0, iteración; 6510 de 8923, Loss: 0.5808377742767334\n",
            "Epoch: 0, iteración; 6520 de 8923, Loss: 0.4911952018737793\n",
            "Epoch: 0, iteración; 6530 de 8923, Loss: 0.575744342803955\n",
            "Epoch: 0, iteración; 6540 de 8923, Loss: 0.5994418144226075\n",
            "Epoch: 0, iteración; 6550 de 8923, Loss: 0.5795624732971192\n",
            "Epoch: 0, iteración; 6560 de 8923, Loss: 0.6016069412231445\n",
            "Epoch: 0, iteración; 6570 de 8923, Loss: 0.5614318370819091\n",
            "Epoch: 0, iteración; 6580 de 8923, Loss: 0.5155625343322754\n",
            "Epoch: 0, iteración; 6590 de 8923, Loss: 0.5351307392120361\n",
            "Epoch: 0, iteración; 6600 de 8923, Loss: 0.4990551948547363\n",
            "Epoch: 0, iteración; 6610 de 8923, Loss: 0.6002392768859863\n",
            "Epoch: 0, iteración; 6620 de 8923, Loss: 0.6109339237213135\n",
            "Epoch: 0, iteración; 6630 de 8923, Loss: 0.6145362854003906\n",
            "Epoch: 0, iteración; 6640 de 8923, Loss: 0.48758859634399415\n",
            "Epoch: 0, iteración; 6650 de 8923, Loss: 0.5458675384521484\n",
            "Epoch: 0, iteración; 6660 de 8923, Loss: 0.5970166206359864\n",
            "Epoch: 0, iteración; 6670 de 8923, Loss: 0.5521990776062011\n",
            "Epoch: 0, iteración; 6680 de 8923, Loss: 0.5341472148895263\n",
            "Epoch: 0, iteración; 6690 de 8923, Loss: 0.6093294143676757\n",
            "Epoch: 0, iteración; 6700 de 8923, Loss: 0.5163367748260498\n",
            "Epoch: 0, iteración; 6710 de 8923, Loss: 0.5590590476989746\n",
            "Epoch: 0, iteración; 6720 de 8923, Loss: 0.6272175788879395\n",
            "Epoch: 0, iteración; 6730 de 8923, Loss: 0.5504054546356201\n",
            "Epoch: 0, iteración; 6740 de 8923, Loss: 0.538265323638916\n",
            "Epoch: 0, iteración; 6750 de 8923, Loss: 0.6124782085418701\n",
            "Epoch: 0, iteración; 6760 de 8923, Loss: 0.5320880889892579\n",
            "Epoch: 0, iteración; 6770 de 8923, Loss: 0.514026403427124\n",
            "Epoch: 0, iteración; 6780 de 8923, Loss: 0.5057810306549072\n",
            "Epoch: 0, iteración; 6790 de 8923, Loss: 0.5471344470977784\n",
            "Epoch: 0, iteración; 6800 de 8923, Loss: 0.5646373748779296\n",
            "Epoch: 0, iteración; 6810 de 8923, Loss: 0.6038177967071533\n",
            "Epoch: 0, iteración; 6820 de 8923, Loss: 0.5112275600433349\n",
            "Epoch: 0, iteración; 6830 de 8923, Loss: 0.6115445613861084\n",
            "Epoch: 0, iteración; 6840 de 8923, Loss: 0.6211256980895996\n",
            "Epoch: 0, iteración; 6850 de 8923, Loss: 0.5935294151306152\n",
            "Epoch: 0, iteración; 6860 de 8923, Loss: 0.6445898056030274\n",
            "Epoch: 0, iteración; 6870 de 8923, Loss: 0.5442442417144775\n",
            "Epoch: 0, iteración; 6880 de 8923, Loss: 0.5751227855682373\n",
            "Epoch: 0, iteración; 6890 de 8923, Loss: 0.6037068367004395\n",
            "Epoch: 0, iteración; 6900 de 8923, Loss: 0.5703836917877197\n",
            "Epoch: 0, iteración; 6910 de 8923, Loss: 0.5293521881103516\n",
            "Epoch: 0, iteración; 6920 de 8923, Loss: 0.5439492702484131\n",
            "Epoch: 0, iteración; 6930 de 8923, Loss: 0.5863325119018554\n",
            "Epoch: 0, iteración; 6940 de 8923, Loss: 0.5848121166229248\n",
            "Epoch: 0, iteración; 6950 de 8923, Loss: 0.5172037124633789\n",
            "Epoch: 0, iteración; 6960 de 8923, Loss: 0.5880059719085693\n",
            "Epoch: 0, iteración; 6970 de 8923, Loss: 0.5459803581237793\n",
            "Epoch: 0, iteración; 6980 de 8923, Loss: 0.5800906181335449\n",
            "Epoch: 0, iteración; 6990 de 8923, Loss: 0.5507465839385987\n",
            "Epoch: 0, iteración; 7000 de 8923, Loss: 0.6160508155822754\n",
            "Epoch: 0, iteración; 7010 de 8923, Loss: 0.6270851612091064\n",
            "Epoch: 0, iteración; 7020 de 8923, Loss: 0.5607118606567383\n",
            "Epoch: 0, iteración; 7030 de 8923, Loss: 0.5299712181091308\n",
            "Epoch: 0, iteración; 7040 de 8923, Loss: 0.504847240447998\n",
            "Epoch: 0, iteración; 7050 de 8923, Loss: 0.5161416530609131\n",
            "Epoch: 0, iteración; 7060 de 8923, Loss: 0.6614774227142334\n",
            "Epoch: 0, iteración; 7070 de 8923, Loss: 0.5679850578308105\n",
            "Epoch: 0, iteración; 7080 de 8923, Loss: 0.5527958393096923\n",
            "Epoch: 0, iteración; 7090 de 8923, Loss: 0.5491147994995117\n",
            "Epoch: 0, iteración; 7100 de 8923, Loss: 0.547647762298584\n",
            "Epoch: 0, iteración; 7110 de 8923, Loss: 0.5205524444580079\n",
            "Epoch: 0, iteración; 7120 de 8923, Loss: 0.46044101715087893\n",
            "Epoch: 0, iteración; 7130 de 8923, Loss: 0.5990496158599854\n",
            "Epoch: 0, iteración; 7140 de 8923, Loss: 0.551069688796997\n",
            "Epoch: 0, iteración; 7150 de 8923, Loss: 0.5683907508850098\n",
            "Epoch: 0, iteración; 7160 de 8923, Loss: 0.5340514659881592\n",
            "Epoch: 0, iteración; 7170 de 8923, Loss: 0.5710536956787109\n",
            "Epoch: 0, iteración; 7180 de 8923, Loss: 0.46576929092407227\n",
            "Epoch: 0, iteración; 7190 de 8923, Loss: 0.4947774887084961\n",
            "Epoch: 0, iteración; 7200 de 8923, Loss: 0.6063597202301025\n",
            "Epoch: 0, iteración; 7210 de 8923, Loss: 0.5439949989318847\n",
            "Epoch: 0, iteración; 7220 de 8923, Loss: 0.5669240474700927\n",
            "Epoch: 0, iteración; 7230 de 8923, Loss: 0.6003928661346436\n",
            "Epoch: 0, iteración; 7240 de 8923, Loss: 0.5985052108764648\n",
            "Epoch: 0, iteración; 7250 de 8923, Loss: 0.6182987213134765\n",
            "Epoch: 0, iteración; 7260 de 8923, Loss: 0.536181116104126\n",
            "Epoch: 0, iteración; 7270 de 8923, Loss: 0.5349923133850097\n",
            "Epoch: 0, iteración; 7280 de 8923, Loss: 0.5833814144134521\n",
            "Epoch: 0, iteración; 7290 de 8923, Loss: 0.5587064266204834\n",
            "Epoch: 0, iteración; 7300 de 8923, Loss: 0.4963398456573486\n",
            "Epoch: 0, iteración; 7310 de 8923, Loss: 0.637462043762207\n",
            "Epoch: 0, iteración; 7320 de 8923, Loss: 0.6116450309753418\n",
            "Epoch: 0, iteración; 7330 de 8923, Loss: 0.574092960357666\n",
            "Epoch: 0, iteración; 7340 de 8923, Loss: 0.5713718891143799\n",
            "Epoch: 0, iteración; 7350 de 8923, Loss: 0.5883501529693603\n",
            "Epoch: 0, iteración; 7360 de 8923, Loss: 0.5673337459564209\n",
            "Epoch: 0, iteración; 7370 de 8923, Loss: 0.6197312355041504\n",
            "Epoch: 0, iteración; 7380 de 8923, Loss: 0.5582235813140869\n",
            "Epoch: 0, iteración; 7390 de 8923, Loss: 0.553286361694336\n",
            "Epoch: 0, iteración; 7400 de 8923, Loss: 0.5481049060821533\n",
            "Epoch: 0, iteración; 7410 de 8923, Loss: 0.5797453403472901\n",
            "Epoch: 0, iteración; 7420 de 8923, Loss: 0.49429888725280763\n",
            "Epoch: 0, iteración; 7430 de 8923, Loss: 0.49108381271362306\n",
            "Epoch: 0, iteración; 7440 de 8923, Loss: 0.5526556968688965\n",
            "Epoch: 0, iteración; 7450 de 8923, Loss: 0.5842434883117675\n",
            "Epoch: 0, iteración; 7460 de 8923, Loss: 0.5968295574188233\n",
            "Epoch: 0, iteración; 7470 de 8923, Loss: 0.5586885452270508\n",
            "Epoch: 0, iteración; 7480 de 8923, Loss: 0.6191228866577149\n",
            "Epoch: 0, iteración; 7490 de 8923, Loss: 0.5830525875091552\n",
            "Epoch: 0, iteración; 7500 de 8923, Loss: 0.5307190895080567\n",
            "Epoch: 0, iteración; 7510 de 8923, Loss: 0.45561370849609373\n",
            "Epoch: 0, iteración; 7520 de 8923, Loss: 0.5691407680511474\n",
            "Epoch: 0, iteración; 7530 de 8923, Loss: 0.5238564014434814\n",
            "Epoch: 0, iteración; 7540 de 8923, Loss: 0.5773850917816162\n",
            "Epoch: 0, iteración; 7550 de 8923, Loss: 0.4887709140777588\n",
            "Epoch: 0, iteración; 7560 de 8923, Loss: 0.570405912399292\n",
            "Epoch: 0, iteración; 7570 de 8923, Loss: 0.6024932384490966\n",
            "Epoch: 0, iteración; 7580 de 8923, Loss: 0.5989424705505371\n",
            "Epoch: 0, iteración; 7590 de 8923, Loss: 0.5690275669097901\n",
            "Epoch: 0, iteración; 7600 de 8923, Loss: 0.6019359588623047\n",
            "Epoch: 0, iteración; 7610 de 8923, Loss: 0.5722012996673584\n",
            "Epoch: 0, iteración; 7620 de 8923, Loss: 0.5616499900817871\n",
            "Epoch: 0, iteración; 7630 de 8923, Loss: 0.5784965991973877\n",
            "Epoch: 0, iteración; 7640 de 8923, Loss: 0.6079878330230712\n",
            "Epoch: 0, iteración; 7650 de 8923, Loss: 0.6101189613342285\n",
            "Epoch: 0, iteración; 7660 de 8923, Loss: 0.61289381980896\n",
            "Epoch: 0, iteración; 7670 de 8923, Loss: 0.6102724075317383\n",
            "Epoch: 0, iteración; 7680 de 8923, Loss: 0.5490388393402099\n",
            "Epoch: 0, iteración; 7690 de 8923, Loss: 0.5218684673309326\n",
            "Epoch: 0, iteración; 7700 de 8923, Loss: 0.540852689743042\n",
            "Epoch: 0, iteración; 7710 de 8923, Loss: 0.45091233253479\n",
            "Epoch: 0, iteración; 7720 de 8923, Loss: 0.5231630802154541\n",
            "Epoch: 0, iteración; 7730 de 8923, Loss: 0.47202634811401367\n",
            "Epoch: 0, iteración; 7740 de 8923, Loss: 0.6415609836578369\n",
            "Epoch: 0, iteración; 7750 de 8923, Loss: 0.6306782722473144\n",
            "Epoch: 0, iteración; 7760 de 8923, Loss: 0.6066184043884277\n",
            "Epoch: 0, iteración; 7770 de 8923, Loss: 0.5304181575775146\n",
            "Epoch: 0, iteración; 7780 de 8923, Loss: 0.5218747615814209\n",
            "Epoch: 0, iteración; 7790 de 8923, Loss: 0.5604040622711182\n",
            "Epoch: 0, iteración; 7800 de 8923, Loss: 0.5843019008636474\n",
            "Epoch: 0, iteración; 7810 de 8923, Loss: 0.5692305564880371\n",
            "Epoch: 0, iteración; 7820 de 8923, Loss: 0.5790646076202393\n",
            "Epoch: 0, iteración; 7830 de 8923, Loss: 0.5550407886505127\n",
            "Epoch: 0, iteración; 7840 de 8923, Loss: 0.5823778629302978\n",
            "Epoch: 0, iteración; 7850 de 8923, Loss: 0.5315232753753663\n",
            "Epoch: 0, iteración; 7860 de 8923, Loss: 0.6091876029968262\n",
            "Epoch: 0, iteración; 7870 de 8923, Loss: 0.6206917762756348\n",
            "Epoch: 0, iteración; 7880 de 8923, Loss: 0.5740068435668946\n",
            "Epoch: 0, iteración; 7890 de 8923, Loss: 0.556638765335083\n",
            "Epoch: 0, iteración; 7900 de 8923, Loss: 0.6145291805267334\n",
            "Epoch: 0, iteración; 7910 de 8923, Loss: 0.6034610271453857\n",
            "Epoch: 0, iteración; 7920 de 8923, Loss: 0.5472793102264404\n",
            "Epoch: 0, iteración; 7930 de 8923, Loss: 0.591258955001831\n",
            "Epoch: 0, iteración; 7940 de 8923, Loss: 0.4877877712249756\n",
            "Epoch: 0, iteración; 7950 de 8923, Loss: 0.5744715690612793\n",
            "Epoch: 0, iteración; 7960 de 8923, Loss: 0.4778591156005859\n",
            "Epoch: 0, iteración; 7970 de 8923, Loss: 0.5228654384613037\n",
            "Epoch: 0, iteración; 7980 de 8923, Loss: 0.6248186111450196\n",
            "Epoch: 0, iteración; 7990 de 8923, Loss: 0.5512184143066406\n",
            "Epoch: 0, iteración; 8000 de 8923, Loss: 0.6238047122955322\n",
            "Epoch: 0, iteración; 8010 de 8923, Loss: 0.5259171485900879\n",
            "Epoch: 0, iteración; 8020 de 8923, Loss: 0.5918614864349365\n",
            "Epoch: 0, iteración; 8030 de 8923, Loss: 0.6090586185455322\n",
            "Epoch: 0, iteración; 8040 de 8923, Loss: 0.53616943359375\n",
            "Epoch: 0, iteración; 8050 de 8923, Loss: 0.6121403217315674\n",
            "Epoch: 0, iteración; 8060 de 8923, Loss: 0.5839920520782471\n",
            "Epoch: 0, iteración; 8070 de 8923, Loss: 0.4913275718688965\n",
            "Epoch: 0, iteración; 8080 de 8923, Loss: 0.5547996044158936\n",
            "Epoch: 0, iteración; 8090 de 8923, Loss: 0.5345021247863769\n",
            "Epoch: 0, iteración; 8100 de 8923, Loss: 0.571491003036499\n",
            "Epoch: 0, iteración; 8110 de 8923, Loss: 0.5430521488189697\n",
            "Epoch: 0, iteración; 8120 de 8923, Loss: 0.5135444164276123\n",
            "Epoch: 0, iteración; 8130 de 8923, Loss: 0.6016602516174316\n",
            "Epoch: 0, iteración; 8140 de 8923, Loss: 0.5507052421569825\n",
            "Epoch: 0, iteración; 8150 de 8923, Loss: 0.5645557403564453\n",
            "Epoch: 0, iteración; 8160 de 8923, Loss: 0.5657276153564453\n",
            "Epoch: 0, iteración; 8170 de 8923, Loss: 0.48093547821044924\n",
            "Epoch: 0, iteración; 8180 de 8923, Loss: 0.5758538246154785\n",
            "Epoch: 0, iteración; 8190 de 8923, Loss: 0.5815325736999511\n",
            "Epoch: 0, iteración; 8200 de 8923, Loss: 0.5611310482025147\n",
            "Epoch: 0, iteración; 8210 de 8923, Loss: 0.5830008506774902\n",
            "Epoch: 0, iteración; 8220 de 8923, Loss: 0.5647858619689942\n",
            "Epoch: 0, iteración; 8230 de 8923, Loss: 0.6067751884460449\n",
            "Epoch: 0, iteración; 8240 de 8923, Loss: 0.5422405242919922\n",
            "Epoch: 0, iteración; 8250 de 8923, Loss: 0.5362557888031005\n",
            "Epoch: 0, iteración; 8260 de 8923, Loss: 0.47867460250854493\n",
            "Epoch: 0, iteración; 8270 de 8923, Loss: 0.5458229064941407\n",
            "Epoch: 0, iteración; 8280 de 8923, Loss: 0.5366045475006104\n",
            "Epoch: 0, iteración; 8290 de 8923, Loss: 0.497055721282959\n",
            "Epoch: 0, iteración; 8300 de 8923, Loss: 0.5436264514923096\n",
            "Epoch: 0, iteración; 8310 de 8923, Loss: 0.6758581161499023\n",
            "Epoch: 0, iteración; 8320 de 8923, Loss: 0.526992654800415\n",
            "Epoch: 0, iteración; 8330 de 8923, Loss: 0.5688098907470703\n",
            "Epoch: 0, iteración; 8340 de 8923, Loss: 0.5910345554351807\n",
            "Epoch: 0, iteración; 8350 de 8923, Loss: 0.5633025646209717\n",
            "Epoch: 0, iteración; 8360 de 8923, Loss: 0.5950317859649659\n",
            "Epoch: 0, iteración; 8370 de 8923, Loss: 0.6279607772827148\n",
            "Epoch: 0, iteración; 8380 de 8923, Loss: 0.5744462013244629\n",
            "Epoch: 0, iteración; 8390 de 8923, Loss: 0.5462311744689942\n",
            "Epoch: 0, iteración; 8400 de 8923, Loss: 0.5683745861053466\n",
            "Epoch: 0, iteración; 8410 de 8923, Loss: 0.5349792003631592\n",
            "Epoch: 0, iteración; 8420 de 8923, Loss: 0.5937711715698242\n",
            "Epoch: 0, iteración; 8430 de 8923, Loss: 0.5836836338043213\n",
            "Epoch: 0, iteración; 8440 de 8923, Loss: 0.5772839546203613\n",
            "Epoch: 0, iteración; 8450 de 8923, Loss: 0.5805911540985107\n",
            "Epoch: 0, iteración; 8460 de 8923, Loss: 0.5617294788360596\n",
            "Epoch: 0, iteración; 8470 de 8923, Loss: 0.6410316467285156\n",
            "Epoch: 0, iteración; 8480 de 8923, Loss: 0.5128190994262696\n",
            "Epoch: 0, iteración; 8490 de 8923, Loss: 0.5886753082275391\n",
            "Epoch: 0, iteración; 8500 de 8923, Loss: 0.48073325157165525\n",
            "Epoch: 0, iteración; 8510 de 8923, Loss: 0.5065438270568847\n",
            "Epoch: 0, iteración; 8520 de 8923, Loss: 0.5182342529296875\n",
            "Epoch: 0, iteración; 8530 de 8923, Loss: 0.5837541580200195\n",
            "Epoch: 0, iteración; 8540 de 8923, Loss: 0.580448055267334\n",
            "Epoch: 0, iteración; 8550 de 8923, Loss: 0.5694637298583984\n",
            "Epoch: 0, iteración; 8560 de 8923, Loss: 0.5283647537231445\n",
            "Epoch: 0, iteración; 8570 de 8923, Loss: 0.581939697265625\n",
            "Epoch: 0, iteración; 8580 de 8923, Loss: 0.5884681701660156\n",
            "Epoch: 0, iteración; 8590 de 8923, Loss: 0.5547930717468261\n",
            "Epoch: 0, iteración; 8600 de 8923, Loss: 0.49074749946594237\n",
            "Epoch: 0, iteración; 8610 de 8923, Loss: 0.6320586204528809\n",
            "Epoch: 0, iteración; 8620 de 8923, Loss: 0.5553577899932861\n",
            "Epoch: 0, iteración; 8630 de 8923, Loss: 0.5315880298614502\n",
            "Epoch: 0, iteración; 8640 de 8923, Loss: 0.5637087821960449\n",
            "Epoch: 0, iteración; 8650 de 8923, Loss: 0.6036606311798096\n",
            "Epoch: 0, iteración; 8660 de 8923, Loss: 0.565422534942627\n",
            "Epoch: 0, iteración; 8670 de 8923, Loss: 0.5103124618530274\n",
            "Epoch: 0, iteración; 8680 de 8923, Loss: 0.5708540916442871\n",
            "Epoch: 0, iteración; 8690 de 8923, Loss: 0.6149543762207031\n",
            "Epoch: 0, iteración; 8700 de 8923, Loss: 0.6269013404846191\n",
            "Epoch: 0, iteración; 8710 de 8923, Loss: 0.5884252548217773\n",
            "Epoch: 0, iteración; 8720 de 8923, Loss: 0.5729049682617188\n",
            "Epoch: 0, iteración; 8730 de 8923, Loss: 0.5712344169616699\n",
            "Epoch: 0, iteración; 8740 de 8923, Loss: 0.5381765842437745\n",
            "Epoch: 0, iteración; 8750 de 8923, Loss: 0.5320194244384766\n",
            "Epoch: 0, iteración; 8760 de 8923, Loss: 0.605529499053955\n",
            "Epoch: 0, iteración; 8770 de 8923, Loss: 0.5625232219696045\n",
            "Epoch: 0, iteración; 8780 de 8923, Loss: 0.618934440612793\n",
            "Epoch: 0, iteración; 8790 de 8923, Loss: 0.5105964660644531\n",
            "Epoch: 0, iteración; 8800 de 8923, Loss: 0.5590833187103271\n",
            "Epoch: 0, iteración; 8810 de 8923, Loss: 0.5835085868835449\n",
            "Epoch: 0, iteración; 8820 de 8923, Loss: 0.5338105201721192\n",
            "Epoch: 0, iteración; 8830 de 8923, Loss: 0.5667474269866943\n",
            "Epoch: 0, iteración; 8840 de 8923, Loss: 0.6144824981689453\n",
            "Epoch: 0, iteración; 8850 de 8923, Loss: 0.6093850135803223\n",
            "Epoch: 0, iteración; 8860 de 8923, Loss: 0.5299747467041016\n",
            "Epoch: 0, iteración; 8870 de 8923, Loss: 0.5776790618896485\n",
            "Epoch: 0, iteración; 8880 de 8923, Loss: 0.5053471088409424\n",
            "Epoch: 0, iteración; 8890 de 8923, Loss: 0.5352293014526367\n",
            "Epoch: 0, iteración; 8900 de 8923, Loss: 0.5520036220550537\n",
            "Epoch: 0, iteración; 8910 de 8923, Loss: 0.562492847442627\n",
            "Epoch: 0, iteración; 8920 de 8923, Loss: 0.5115151405334473\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainBert(epoch)"
      ],
      "id": "OsqiTr364nZZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7a4ab4-8996-4847-e5d4-faa330f7fbb5",
        "id": "irtot1O74nZZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_50_separados.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "id": "irtot1O74nZZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OISXg3AL4nZZ"
      },
      "source": [
        "##### Evaluación del modelo"
      ],
      "id": "OISXg3AL4nZZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KecxrinW4nZZ"
      },
      "outputs": [],
      "source": [
        "def validationBert(epoch):\n",
        "  model.eval()\n",
        "  fin_targets=[]\n",
        "  fin_outputs=[]\n",
        "  num_iteraciones = len(testing_loader)\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testing_loader, 0):\n",
        "      ids = data['ids'].to(device)\n",
        "      mask = data['mask'].to(device)\n",
        "      token_type_ids = data['token_type_ids'].to(device)\n",
        "      targets = data['target'].to(device)\n",
        "\n",
        "      print(f\"Batch {i} de {num_iteraciones}\")\n",
        "\n",
        "      outputs = model(ids, mask, token_type_ids)\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "  return fin_outputs, fin_targets"
      ],
      "id": "KecxrinW4nZZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "D8kMrUNL4nZZ"
      },
      "id": "D8kMrUNL4nZZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8247f20-8595-49a6-96b8-20ac725d4621",
        "id": "veiQf7DD4nZa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La ruta existe\n",
            "Modelo cargado correctamente\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_50_separados.pth\"):\n",
        "  print(\"La ruta existe\")\n",
        "  model = BERTClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_50_separados.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_50_separados.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "id": "veiQf7DD4nZa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72280423-e96e-474d-8451-562155cc7c11",
        "id": "OPlHsK674nZa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 de 1116\n",
            "Batch 1 de 1116\n",
            "Batch 2 de 1116\n",
            "Batch 3 de 1116\n",
            "Batch 4 de 1116\n",
            "Batch 5 de 1116\n",
            "Batch 6 de 1116\n",
            "Batch 7 de 1116\n",
            "Batch 8 de 1116\n",
            "Batch 9 de 1116\n",
            "Batch 10 de 1116\n",
            "Batch 11 de 1116\n",
            "Batch 12 de 1116\n",
            "Batch 13 de 1116\n",
            "Batch 14 de 1116\n",
            "Batch 15 de 1116\n",
            "Batch 16 de 1116\n",
            "Batch 17 de 1116\n",
            "Batch 18 de 1116\n",
            "Batch 19 de 1116\n",
            "Batch 20 de 1116\n",
            "Batch 21 de 1116\n",
            "Batch 22 de 1116\n",
            "Batch 23 de 1116\n",
            "Batch 24 de 1116\n",
            "Batch 25 de 1116\n",
            "Batch 26 de 1116\n",
            "Batch 27 de 1116\n",
            "Batch 28 de 1116\n",
            "Batch 29 de 1116\n",
            "Batch 30 de 1116\n",
            "Batch 31 de 1116\n",
            "Batch 32 de 1116\n",
            "Batch 33 de 1116\n",
            "Batch 34 de 1116\n",
            "Batch 35 de 1116\n",
            "Batch 36 de 1116\n",
            "Batch 37 de 1116\n",
            "Batch 38 de 1116\n",
            "Batch 39 de 1116\n",
            "Batch 40 de 1116\n",
            "Batch 41 de 1116\n",
            "Batch 42 de 1116\n",
            "Batch 43 de 1116\n",
            "Batch 44 de 1116\n",
            "Batch 45 de 1116\n",
            "Batch 46 de 1116\n",
            "Batch 47 de 1116\n",
            "Batch 48 de 1116\n",
            "Batch 49 de 1116\n",
            "Batch 50 de 1116\n",
            "Batch 51 de 1116\n",
            "Batch 52 de 1116\n",
            "Batch 53 de 1116\n",
            "Batch 54 de 1116\n",
            "Batch 55 de 1116\n",
            "Batch 56 de 1116\n",
            "Batch 57 de 1116\n",
            "Batch 58 de 1116\n",
            "Batch 59 de 1116\n",
            "Batch 60 de 1116\n",
            "Batch 61 de 1116\n",
            "Batch 62 de 1116\n",
            "Batch 63 de 1116\n",
            "Batch 64 de 1116\n",
            "Batch 65 de 1116\n",
            "Batch 66 de 1116\n",
            "Batch 67 de 1116\n",
            "Batch 68 de 1116\n",
            "Batch 69 de 1116\n",
            "Batch 70 de 1116\n",
            "Batch 71 de 1116\n",
            "Batch 72 de 1116\n",
            "Batch 73 de 1116\n",
            "Batch 74 de 1116\n",
            "Batch 75 de 1116\n",
            "Batch 76 de 1116\n",
            "Batch 77 de 1116\n",
            "Batch 78 de 1116\n",
            "Batch 79 de 1116\n",
            "Batch 80 de 1116\n",
            "Batch 81 de 1116\n",
            "Batch 82 de 1116\n",
            "Batch 83 de 1116\n",
            "Batch 84 de 1116\n",
            "Batch 85 de 1116\n",
            "Batch 86 de 1116\n",
            "Batch 87 de 1116\n",
            "Batch 88 de 1116\n",
            "Batch 89 de 1116\n",
            "Batch 90 de 1116\n",
            "Batch 91 de 1116\n",
            "Batch 92 de 1116\n",
            "Batch 93 de 1116\n",
            "Batch 94 de 1116\n",
            "Batch 95 de 1116\n",
            "Batch 96 de 1116\n",
            "Batch 97 de 1116\n",
            "Batch 98 de 1116\n",
            "Batch 99 de 1116\n",
            "Batch 100 de 1116\n",
            "Batch 101 de 1116\n",
            "Batch 102 de 1116\n",
            "Batch 103 de 1116\n",
            "Batch 104 de 1116\n",
            "Batch 105 de 1116\n",
            "Batch 106 de 1116\n",
            "Batch 107 de 1116\n",
            "Batch 108 de 1116\n",
            "Batch 109 de 1116\n",
            "Batch 110 de 1116\n",
            "Batch 111 de 1116\n",
            "Batch 112 de 1116\n",
            "Batch 113 de 1116\n",
            "Batch 114 de 1116\n",
            "Batch 115 de 1116\n",
            "Batch 116 de 1116\n",
            "Batch 117 de 1116\n",
            "Batch 118 de 1116\n",
            "Batch 119 de 1116\n",
            "Batch 120 de 1116\n",
            "Batch 121 de 1116\n",
            "Batch 122 de 1116\n",
            "Batch 123 de 1116\n",
            "Batch 124 de 1116\n",
            "Batch 125 de 1116\n",
            "Batch 126 de 1116\n",
            "Batch 127 de 1116\n",
            "Batch 128 de 1116\n",
            "Batch 129 de 1116\n",
            "Batch 130 de 1116\n",
            "Batch 131 de 1116\n",
            "Batch 132 de 1116\n",
            "Batch 133 de 1116\n",
            "Batch 134 de 1116\n",
            "Batch 135 de 1116\n",
            "Batch 136 de 1116\n",
            "Batch 137 de 1116\n",
            "Batch 138 de 1116\n",
            "Batch 139 de 1116\n",
            "Batch 140 de 1116\n",
            "Batch 141 de 1116\n",
            "Batch 142 de 1116\n",
            "Batch 143 de 1116\n",
            "Batch 144 de 1116\n",
            "Batch 145 de 1116\n",
            "Batch 146 de 1116\n",
            "Batch 147 de 1116\n",
            "Batch 148 de 1116\n",
            "Batch 149 de 1116\n",
            "Batch 150 de 1116\n",
            "Batch 151 de 1116\n",
            "Batch 152 de 1116\n",
            "Batch 153 de 1116\n",
            "Batch 154 de 1116\n",
            "Batch 155 de 1116\n",
            "Batch 156 de 1116\n",
            "Batch 157 de 1116\n",
            "Batch 158 de 1116\n",
            "Batch 159 de 1116\n",
            "Batch 160 de 1116\n",
            "Batch 161 de 1116\n",
            "Batch 162 de 1116\n",
            "Batch 163 de 1116\n",
            "Batch 164 de 1116\n",
            "Batch 165 de 1116\n",
            "Batch 166 de 1116\n",
            "Batch 167 de 1116\n",
            "Batch 168 de 1116\n",
            "Batch 169 de 1116\n",
            "Batch 170 de 1116\n",
            "Batch 171 de 1116\n",
            "Batch 172 de 1116\n",
            "Batch 173 de 1116\n",
            "Batch 174 de 1116\n",
            "Batch 175 de 1116\n",
            "Batch 176 de 1116\n",
            "Batch 177 de 1116\n",
            "Batch 178 de 1116\n",
            "Batch 179 de 1116\n",
            "Batch 180 de 1116\n",
            "Batch 181 de 1116\n",
            "Batch 182 de 1116\n",
            "Batch 183 de 1116\n",
            "Batch 184 de 1116\n",
            "Batch 185 de 1116\n",
            "Batch 186 de 1116\n",
            "Batch 187 de 1116\n",
            "Batch 188 de 1116\n",
            "Batch 189 de 1116\n",
            "Batch 190 de 1116\n",
            "Batch 191 de 1116\n",
            "Batch 192 de 1116\n",
            "Batch 193 de 1116\n",
            "Batch 194 de 1116\n",
            "Batch 195 de 1116\n",
            "Batch 196 de 1116\n",
            "Batch 197 de 1116\n",
            "Batch 198 de 1116\n",
            "Batch 199 de 1116\n",
            "Batch 200 de 1116\n",
            "Batch 201 de 1116\n",
            "Batch 202 de 1116\n",
            "Batch 203 de 1116\n",
            "Batch 204 de 1116\n",
            "Batch 205 de 1116\n",
            "Batch 206 de 1116\n",
            "Batch 207 de 1116\n",
            "Batch 208 de 1116\n",
            "Batch 209 de 1116\n",
            "Batch 210 de 1116\n",
            "Batch 211 de 1116\n",
            "Batch 212 de 1116\n",
            "Batch 213 de 1116\n",
            "Batch 214 de 1116\n",
            "Batch 215 de 1116\n",
            "Batch 216 de 1116\n",
            "Batch 217 de 1116\n",
            "Batch 218 de 1116\n",
            "Batch 219 de 1116\n",
            "Batch 220 de 1116\n",
            "Batch 221 de 1116\n",
            "Batch 222 de 1116\n",
            "Batch 223 de 1116\n",
            "Batch 224 de 1116\n",
            "Batch 225 de 1116\n",
            "Batch 226 de 1116\n",
            "Batch 227 de 1116\n",
            "Batch 228 de 1116\n",
            "Batch 229 de 1116\n",
            "Batch 230 de 1116\n",
            "Batch 231 de 1116\n",
            "Batch 232 de 1116\n",
            "Batch 233 de 1116\n",
            "Batch 234 de 1116\n",
            "Batch 235 de 1116\n",
            "Batch 236 de 1116\n",
            "Batch 237 de 1116\n",
            "Batch 238 de 1116\n",
            "Batch 239 de 1116\n",
            "Batch 240 de 1116\n",
            "Batch 241 de 1116\n",
            "Batch 242 de 1116\n",
            "Batch 243 de 1116\n",
            "Batch 244 de 1116\n",
            "Batch 245 de 1116\n",
            "Batch 246 de 1116\n",
            "Batch 247 de 1116\n",
            "Batch 248 de 1116\n",
            "Batch 249 de 1116\n",
            "Batch 250 de 1116\n",
            "Batch 251 de 1116\n",
            "Batch 252 de 1116\n",
            "Batch 253 de 1116\n",
            "Batch 254 de 1116\n",
            "Batch 255 de 1116\n",
            "Batch 256 de 1116\n",
            "Batch 257 de 1116\n",
            "Batch 258 de 1116\n",
            "Batch 259 de 1116\n",
            "Batch 260 de 1116\n",
            "Batch 261 de 1116\n",
            "Batch 262 de 1116\n",
            "Batch 263 de 1116\n",
            "Batch 264 de 1116\n",
            "Batch 265 de 1116\n",
            "Batch 266 de 1116\n",
            "Batch 267 de 1116\n",
            "Batch 268 de 1116\n",
            "Batch 269 de 1116\n",
            "Batch 270 de 1116\n",
            "Batch 271 de 1116\n",
            "Batch 272 de 1116\n",
            "Batch 273 de 1116\n",
            "Batch 274 de 1116\n",
            "Batch 275 de 1116\n",
            "Batch 276 de 1116\n",
            "Batch 277 de 1116\n",
            "Batch 278 de 1116\n",
            "Batch 279 de 1116\n",
            "Batch 280 de 1116\n",
            "Batch 281 de 1116\n",
            "Batch 282 de 1116\n",
            "Batch 283 de 1116\n",
            "Batch 284 de 1116\n",
            "Batch 285 de 1116\n",
            "Batch 286 de 1116\n",
            "Batch 287 de 1116\n",
            "Batch 288 de 1116\n",
            "Batch 289 de 1116\n",
            "Batch 290 de 1116\n",
            "Batch 291 de 1116\n",
            "Batch 292 de 1116\n",
            "Batch 293 de 1116\n",
            "Batch 294 de 1116\n",
            "Batch 295 de 1116\n",
            "Batch 296 de 1116\n",
            "Batch 297 de 1116\n",
            "Batch 298 de 1116\n",
            "Batch 299 de 1116\n",
            "Batch 300 de 1116\n",
            "Batch 301 de 1116\n",
            "Batch 302 de 1116\n",
            "Batch 303 de 1116\n",
            "Batch 304 de 1116\n",
            "Batch 305 de 1116\n",
            "Batch 306 de 1116\n",
            "Batch 307 de 1116\n",
            "Batch 308 de 1116\n",
            "Batch 309 de 1116\n",
            "Batch 310 de 1116\n",
            "Batch 311 de 1116\n",
            "Batch 312 de 1116\n",
            "Batch 313 de 1116\n",
            "Batch 314 de 1116\n",
            "Batch 315 de 1116\n",
            "Batch 316 de 1116\n",
            "Batch 317 de 1116\n",
            "Batch 318 de 1116\n",
            "Batch 319 de 1116\n",
            "Batch 320 de 1116\n",
            "Batch 321 de 1116\n",
            "Batch 322 de 1116\n",
            "Batch 323 de 1116\n",
            "Batch 324 de 1116\n",
            "Batch 325 de 1116\n",
            "Batch 326 de 1116\n",
            "Batch 327 de 1116\n",
            "Batch 328 de 1116\n",
            "Batch 329 de 1116\n",
            "Batch 330 de 1116\n",
            "Batch 331 de 1116\n",
            "Batch 332 de 1116\n",
            "Batch 333 de 1116\n",
            "Batch 334 de 1116\n",
            "Batch 335 de 1116\n",
            "Batch 336 de 1116\n",
            "Batch 337 de 1116\n",
            "Batch 338 de 1116\n",
            "Batch 339 de 1116\n",
            "Batch 340 de 1116\n",
            "Batch 341 de 1116\n",
            "Batch 342 de 1116\n",
            "Batch 343 de 1116\n",
            "Batch 344 de 1116\n",
            "Batch 345 de 1116\n",
            "Batch 346 de 1116\n",
            "Batch 347 de 1116\n",
            "Batch 348 de 1116\n",
            "Batch 349 de 1116\n",
            "Batch 350 de 1116\n",
            "Batch 351 de 1116\n",
            "Batch 352 de 1116\n",
            "Batch 353 de 1116\n",
            "Batch 354 de 1116\n",
            "Batch 355 de 1116\n",
            "Batch 356 de 1116\n",
            "Batch 357 de 1116\n",
            "Batch 358 de 1116\n",
            "Batch 359 de 1116\n",
            "Batch 360 de 1116\n",
            "Batch 361 de 1116\n",
            "Batch 362 de 1116\n",
            "Batch 363 de 1116\n",
            "Batch 364 de 1116\n",
            "Batch 365 de 1116\n",
            "Batch 366 de 1116\n",
            "Batch 367 de 1116\n",
            "Batch 368 de 1116\n",
            "Batch 369 de 1116\n",
            "Batch 370 de 1116\n",
            "Batch 371 de 1116\n",
            "Batch 372 de 1116\n",
            "Batch 373 de 1116\n",
            "Batch 374 de 1116\n",
            "Batch 375 de 1116\n",
            "Batch 376 de 1116\n",
            "Batch 377 de 1116\n",
            "Batch 378 de 1116\n",
            "Batch 379 de 1116\n",
            "Batch 380 de 1116\n",
            "Batch 381 de 1116\n",
            "Batch 382 de 1116\n",
            "Batch 383 de 1116\n",
            "Batch 384 de 1116\n",
            "Batch 385 de 1116\n",
            "Batch 386 de 1116\n",
            "Batch 387 de 1116\n",
            "Batch 388 de 1116\n",
            "Batch 389 de 1116\n",
            "Batch 390 de 1116\n",
            "Batch 391 de 1116\n",
            "Batch 392 de 1116\n",
            "Batch 393 de 1116\n",
            "Batch 394 de 1116\n",
            "Batch 395 de 1116\n",
            "Batch 396 de 1116\n",
            "Batch 397 de 1116\n",
            "Batch 398 de 1116\n",
            "Batch 399 de 1116\n",
            "Batch 400 de 1116\n",
            "Batch 401 de 1116\n",
            "Batch 402 de 1116\n",
            "Batch 403 de 1116\n",
            "Batch 404 de 1116\n",
            "Batch 405 de 1116\n",
            "Batch 406 de 1116\n",
            "Batch 407 de 1116\n",
            "Batch 408 de 1116\n",
            "Batch 409 de 1116\n",
            "Batch 410 de 1116\n",
            "Batch 411 de 1116\n",
            "Batch 412 de 1116\n",
            "Batch 413 de 1116\n",
            "Batch 414 de 1116\n",
            "Batch 415 de 1116\n",
            "Batch 416 de 1116\n",
            "Batch 417 de 1116\n",
            "Batch 418 de 1116\n",
            "Batch 419 de 1116\n",
            "Batch 420 de 1116\n",
            "Batch 421 de 1116\n",
            "Batch 422 de 1116\n",
            "Batch 423 de 1116\n",
            "Batch 424 de 1116\n",
            "Batch 425 de 1116\n",
            "Batch 426 de 1116\n",
            "Batch 427 de 1116\n",
            "Batch 428 de 1116\n",
            "Batch 429 de 1116\n",
            "Batch 430 de 1116\n",
            "Batch 431 de 1116\n",
            "Batch 432 de 1116\n",
            "Batch 433 de 1116\n",
            "Batch 434 de 1116\n",
            "Batch 435 de 1116\n",
            "Batch 436 de 1116\n",
            "Batch 437 de 1116\n",
            "Batch 438 de 1116\n",
            "Batch 439 de 1116\n",
            "Batch 440 de 1116\n",
            "Batch 441 de 1116\n",
            "Batch 442 de 1116\n",
            "Batch 443 de 1116\n",
            "Batch 444 de 1116\n",
            "Batch 445 de 1116\n",
            "Batch 446 de 1116\n",
            "Batch 447 de 1116\n",
            "Batch 448 de 1116\n",
            "Batch 449 de 1116\n",
            "Batch 450 de 1116\n",
            "Batch 451 de 1116\n",
            "Batch 452 de 1116\n",
            "Batch 453 de 1116\n",
            "Batch 454 de 1116\n",
            "Batch 455 de 1116\n",
            "Batch 456 de 1116\n",
            "Batch 457 de 1116\n",
            "Batch 458 de 1116\n",
            "Batch 459 de 1116\n",
            "Batch 460 de 1116\n",
            "Batch 461 de 1116\n",
            "Batch 462 de 1116\n",
            "Batch 463 de 1116\n",
            "Batch 464 de 1116\n",
            "Batch 465 de 1116\n",
            "Batch 466 de 1116\n",
            "Batch 467 de 1116\n",
            "Batch 468 de 1116\n",
            "Batch 469 de 1116\n",
            "Batch 470 de 1116\n",
            "Batch 471 de 1116\n",
            "Batch 472 de 1116\n",
            "Batch 473 de 1116\n",
            "Batch 474 de 1116\n",
            "Batch 475 de 1116\n",
            "Batch 476 de 1116\n",
            "Batch 477 de 1116\n",
            "Batch 478 de 1116\n",
            "Batch 479 de 1116\n",
            "Batch 480 de 1116\n",
            "Batch 481 de 1116\n",
            "Batch 482 de 1116\n",
            "Batch 483 de 1116\n",
            "Batch 484 de 1116\n",
            "Batch 485 de 1116\n",
            "Batch 486 de 1116\n",
            "Batch 487 de 1116\n",
            "Batch 488 de 1116\n",
            "Batch 489 de 1116\n",
            "Batch 490 de 1116\n",
            "Batch 491 de 1116\n",
            "Batch 492 de 1116\n",
            "Batch 493 de 1116\n",
            "Batch 494 de 1116\n",
            "Batch 495 de 1116\n",
            "Batch 496 de 1116\n",
            "Batch 497 de 1116\n",
            "Batch 498 de 1116\n",
            "Batch 499 de 1116\n",
            "Batch 500 de 1116\n",
            "Batch 501 de 1116\n",
            "Batch 502 de 1116\n",
            "Batch 503 de 1116\n",
            "Batch 504 de 1116\n",
            "Batch 505 de 1116\n",
            "Batch 506 de 1116\n",
            "Batch 507 de 1116\n",
            "Batch 508 de 1116\n",
            "Batch 509 de 1116\n",
            "Batch 510 de 1116\n",
            "Batch 511 de 1116\n",
            "Batch 512 de 1116\n",
            "Batch 513 de 1116\n",
            "Batch 514 de 1116\n",
            "Batch 515 de 1116\n",
            "Batch 516 de 1116\n",
            "Batch 517 de 1116\n",
            "Batch 518 de 1116\n",
            "Batch 519 de 1116\n",
            "Batch 520 de 1116\n",
            "Batch 521 de 1116\n",
            "Batch 522 de 1116\n",
            "Batch 523 de 1116\n",
            "Batch 524 de 1116\n",
            "Batch 525 de 1116\n",
            "Batch 526 de 1116\n",
            "Batch 527 de 1116\n",
            "Batch 528 de 1116\n",
            "Batch 529 de 1116\n",
            "Batch 530 de 1116\n",
            "Batch 531 de 1116\n",
            "Batch 532 de 1116\n",
            "Batch 533 de 1116\n",
            "Batch 534 de 1116\n",
            "Batch 535 de 1116\n",
            "Batch 536 de 1116\n",
            "Batch 537 de 1116\n",
            "Batch 538 de 1116\n",
            "Batch 539 de 1116\n",
            "Batch 540 de 1116\n",
            "Batch 541 de 1116\n",
            "Batch 542 de 1116\n",
            "Batch 543 de 1116\n",
            "Batch 544 de 1116\n",
            "Batch 545 de 1116\n",
            "Batch 546 de 1116\n",
            "Batch 547 de 1116\n",
            "Batch 548 de 1116\n",
            "Batch 549 de 1116\n",
            "Batch 550 de 1116\n",
            "Batch 551 de 1116\n",
            "Batch 552 de 1116\n",
            "Batch 553 de 1116\n",
            "Batch 554 de 1116\n",
            "Batch 555 de 1116\n",
            "Batch 556 de 1116\n",
            "Batch 557 de 1116\n",
            "Batch 558 de 1116\n",
            "Batch 559 de 1116\n",
            "Batch 560 de 1116\n",
            "Batch 561 de 1116\n",
            "Batch 562 de 1116\n",
            "Batch 563 de 1116\n",
            "Batch 564 de 1116\n",
            "Batch 565 de 1116\n",
            "Batch 566 de 1116\n",
            "Batch 567 de 1116\n",
            "Batch 568 de 1116\n",
            "Batch 569 de 1116\n",
            "Batch 570 de 1116\n",
            "Batch 571 de 1116\n",
            "Batch 572 de 1116\n",
            "Batch 573 de 1116\n",
            "Batch 574 de 1116\n",
            "Batch 575 de 1116\n",
            "Batch 576 de 1116\n",
            "Batch 577 de 1116\n",
            "Batch 578 de 1116\n",
            "Batch 579 de 1116\n",
            "Batch 580 de 1116\n",
            "Batch 581 de 1116\n",
            "Batch 582 de 1116\n",
            "Batch 583 de 1116\n",
            "Batch 584 de 1116\n",
            "Batch 585 de 1116\n",
            "Batch 586 de 1116\n",
            "Batch 587 de 1116\n",
            "Batch 588 de 1116\n",
            "Batch 589 de 1116\n",
            "Batch 590 de 1116\n",
            "Batch 591 de 1116\n",
            "Batch 592 de 1116\n",
            "Batch 593 de 1116\n",
            "Batch 594 de 1116\n",
            "Batch 595 de 1116\n",
            "Batch 596 de 1116\n",
            "Batch 597 de 1116\n",
            "Batch 598 de 1116\n",
            "Batch 599 de 1116\n",
            "Batch 600 de 1116\n",
            "Batch 601 de 1116\n",
            "Batch 602 de 1116\n",
            "Batch 603 de 1116\n",
            "Batch 604 de 1116\n",
            "Batch 605 de 1116\n",
            "Batch 606 de 1116\n",
            "Batch 607 de 1116\n",
            "Batch 608 de 1116\n",
            "Batch 609 de 1116\n",
            "Batch 610 de 1116\n",
            "Batch 611 de 1116\n",
            "Batch 612 de 1116\n",
            "Batch 613 de 1116\n",
            "Batch 614 de 1116\n",
            "Batch 615 de 1116\n",
            "Batch 616 de 1116\n",
            "Batch 617 de 1116\n",
            "Batch 618 de 1116\n",
            "Batch 619 de 1116\n",
            "Batch 620 de 1116\n",
            "Batch 621 de 1116\n",
            "Batch 622 de 1116\n",
            "Batch 623 de 1116\n",
            "Batch 624 de 1116\n",
            "Batch 625 de 1116\n",
            "Batch 626 de 1116\n",
            "Batch 627 de 1116\n",
            "Batch 628 de 1116\n",
            "Batch 629 de 1116\n",
            "Batch 630 de 1116\n",
            "Batch 631 de 1116\n",
            "Batch 632 de 1116\n",
            "Batch 633 de 1116\n",
            "Batch 634 de 1116\n",
            "Batch 635 de 1116\n",
            "Batch 636 de 1116\n",
            "Batch 637 de 1116\n",
            "Batch 638 de 1116\n",
            "Batch 639 de 1116\n",
            "Batch 640 de 1116\n",
            "Batch 641 de 1116\n",
            "Batch 642 de 1116\n",
            "Batch 643 de 1116\n",
            "Batch 644 de 1116\n",
            "Batch 645 de 1116\n",
            "Batch 646 de 1116\n",
            "Batch 647 de 1116\n",
            "Batch 648 de 1116\n",
            "Batch 649 de 1116\n",
            "Batch 650 de 1116\n",
            "Batch 651 de 1116\n",
            "Batch 652 de 1116\n",
            "Batch 653 de 1116\n",
            "Batch 654 de 1116\n",
            "Batch 655 de 1116\n",
            "Batch 656 de 1116\n",
            "Batch 657 de 1116\n",
            "Batch 658 de 1116\n",
            "Batch 659 de 1116\n",
            "Batch 660 de 1116\n",
            "Batch 661 de 1116\n",
            "Batch 662 de 1116\n",
            "Batch 663 de 1116\n",
            "Batch 664 de 1116\n",
            "Batch 665 de 1116\n",
            "Batch 666 de 1116\n",
            "Batch 667 de 1116\n",
            "Batch 668 de 1116\n",
            "Batch 669 de 1116\n",
            "Batch 670 de 1116\n",
            "Batch 671 de 1116\n",
            "Batch 672 de 1116\n",
            "Batch 673 de 1116\n",
            "Batch 674 de 1116\n",
            "Batch 675 de 1116\n",
            "Batch 676 de 1116\n",
            "Batch 677 de 1116\n",
            "Batch 678 de 1116\n",
            "Batch 679 de 1116\n",
            "Batch 680 de 1116\n",
            "Batch 681 de 1116\n",
            "Batch 682 de 1116\n",
            "Batch 683 de 1116\n",
            "Batch 684 de 1116\n",
            "Batch 685 de 1116\n",
            "Batch 686 de 1116\n",
            "Batch 687 de 1116\n",
            "Batch 688 de 1116\n",
            "Batch 689 de 1116\n",
            "Batch 690 de 1116\n",
            "Batch 691 de 1116\n",
            "Batch 692 de 1116\n",
            "Batch 693 de 1116\n",
            "Batch 694 de 1116\n",
            "Batch 695 de 1116\n",
            "Batch 696 de 1116\n",
            "Batch 697 de 1116\n",
            "Batch 698 de 1116\n",
            "Batch 699 de 1116\n",
            "Batch 700 de 1116\n",
            "Batch 701 de 1116\n",
            "Batch 702 de 1116\n",
            "Batch 703 de 1116\n",
            "Batch 704 de 1116\n",
            "Batch 705 de 1116\n",
            "Batch 706 de 1116\n",
            "Batch 707 de 1116\n",
            "Batch 708 de 1116\n",
            "Batch 709 de 1116\n",
            "Batch 710 de 1116\n",
            "Batch 711 de 1116\n",
            "Batch 712 de 1116\n",
            "Batch 713 de 1116\n",
            "Batch 714 de 1116\n",
            "Batch 715 de 1116\n",
            "Batch 716 de 1116\n",
            "Batch 717 de 1116\n",
            "Batch 718 de 1116\n",
            "Batch 719 de 1116\n",
            "Batch 720 de 1116\n",
            "Batch 721 de 1116\n",
            "Batch 722 de 1116\n",
            "Batch 723 de 1116\n",
            "Batch 724 de 1116\n",
            "Batch 725 de 1116\n",
            "Batch 726 de 1116\n",
            "Batch 727 de 1116\n",
            "Batch 728 de 1116\n",
            "Batch 729 de 1116\n",
            "Batch 730 de 1116\n",
            "Batch 731 de 1116\n",
            "Batch 732 de 1116\n",
            "Batch 733 de 1116\n",
            "Batch 734 de 1116\n",
            "Batch 735 de 1116\n",
            "Batch 736 de 1116\n",
            "Batch 737 de 1116\n",
            "Batch 738 de 1116\n",
            "Batch 739 de 1116\n",
            "Batch 740 de 1116\n",
            "Batch 741 de 1116\n",
            "Batch 742 de 1116\n",
            "Batch 743 de 1116\n",
            "Batch 744 de 1116\n",
            "Batch 745 de 1116\n",
            "Batch 746 de 1116\n",
            "Batch 747 de 1116\n",
            "Batch 748 de 1116\n",
            "Batch 749 de 1116\n",
            "Batch 750 de 1116\n",
            "Batch 751 de 1116\n",
            "Batch 752 de 1116\n",
            "Batch 753 de 1116\n",
            "Batch 754 de 1116\n",
            "Batch 755 de 1116\n",
            "Batch 756 de 1116\n",
            "Batch 757 de 1116\n",
            "Batch 758 de 1116\n",
            "Batch 759 de 1116\n",
            "Batch 760 de 1116\n",
            "Batch 761 de 1116\n",
            "Batch 762 de 1116\n",
            "Batch 763 de 1116\n",
            "Batch 764 de 1116\n",
            "Batch 765 de 1116\n",
            "Batch 766 de 1116\n",
            "Batch 767 de 1116\n",
            "Batch 768 de 1116\n",
            "Batch 769 de 1116\n",
            "Batch 770 de 1116\n",
            "Batch 771 de 1116\n",
            "Batch 772 de 1116\n",
            "Batch 773 de 1116\n",
            "Batch 774 de 1116\n",
            "Batch 775 de 1116\n",
            "Batch 776 de 1116\n",
            "Batch 777 de 1116\n",
            "Batch 778 de 1116\n",
            "Batch 779 de 1116\n",
            "Batch 780 de 1116\n",
            "Batch 781 de 1116\n",
            "Batch 782 de 1116\n",
            "Batch 783 de 1116\n",
            "Batch 784 de 1116\n",
            "Batch 785 de 1116\n",
            "Batch 786 de 1116\n",
            "Batch 787 de 1116\n",
            "Batch 788 de 1116\n",
            "Batch 789 de 1116\n",
            "Batch 790 de 1116\n",
            "Batch 791 de 1116\n",
            "Batch 792 de 1116\n",
            "Batch 793 de 1116\n",
            "Batch 794 de 1116\n",
            "Batch 795 de 1116\n",
            "Batch 796 de 1116\n",
            "Batch 797 de 1116\n",
            "Batch 798 de 1116\n",
            "Batch 799 de 1116\n",
            "Batch 800 de 1116\n",
            "Batch 801 de 1116\n",
            "Batch 802 de 1116\n",
            "Batch 803 de 1116\n",
            "Batch 804 de 1116\n",
            "Batch 805 de 1116\n",
            "Batch 806 de 1116\n",
            "Batch 807 de 1116\n",
            "Batch 808 de 1116\n",
            "Batch 809 de 1116\n",
            "Batch 810 de 1116\n",
            "Batch 811 de 1116\n",
            "Batch 812 de 1116\n",
            "Batch 813 de 1116\n",
            "Batch 814 de 1116\n",
            "Batch 815 de 1116\n",
            "Batch 816 de 1116\n",
            "Batch 817 de 1116\n",
            "Batch 818 de 1116\n",
            "Batch 819 de 1116\n",
            "Batch 820 de 1116\n",
            "Batch 821 de 1116\n",
            "Batch 822 de 1116\n",
            "Batch 823 de 1116\n",
            "Batch 824 de 1116\n",
            "Batch 825 de 1116\n",
            "Batch 826 de 1116\n",
            "Batch 827 de 1116\n",
            "Batch 828 de 1116\n",
            "Batch 829 de 1116\n",
            "Batch 830 de 1116\n",
            "Batch 831 de 1116\n",
            "Batch 832 de 1116\n",
            "Batch 833 de 1116\n",
            "Batch 834 de 1116\n",
            "Batch 835 de 1116\n",
            "Batch 836 de 1116\n",
            "Batch 837 de 1116\n",
            "Batch 838 de 1116\n",
            "Batch 839 de 1116\n",
            "Batch 840 de 1116\n",
            "Batch 841 de 1116\n",
            "Batch 842 de 1116\n",
            "Batch 843 de 1116\n",
            "Batch 844 de 1116\n",
            "Batch 845 de 1116\n",
            "Batch 846 de 1116\n",
            "Batch 847 de 1116\n",
            "Batch 848 de 1116\n",
            "Batch 849 de 1116\n",
            "Batch 850 de 1116\n",
            "Batch 851 de 1116\n",
            "Batch 852 de 1116\n",
            "Batch 853 de 1116\n",
            "Batch 854 de 1116\n",
            "Batch 855 de 1116\n",
            "Batch 856 de 1116\n",
            "Batch 857 de 1116\n",
            "Batch 858 de 1116\n",
            "Batch 859 de 1116\n",
            "Batch 860 de 1116\n",
            "Batch 861 de 1116\n",
            "Batch 862 de 1116\n",
            "Batch 863 de 1116\n",
            "Batch 864 de 1116\n",
            "Batch 865 de 1116\n",
            "Batch 866 de 1116\n",
            "Batch 867 de 1116\n",
            "Batch 868 de 1116\n",
            "Batch 869 de 1116\n",
            "Batch 870 de 1116\n",
            "Batch 871 de 1116\n",
            "Batch 872 de 1116\n",
            "Batch 873 de 1116\n",
            "Batch 874 de 1116\n",
            "Batch 875 de 1116\n",
            "Batch 876 de 1116\n",
            "Batch 877 de 1116\n",
            "Batch 878 de 1116\n",
            "Batch 879 de 1116\n",
            "Batch 880 de 1116\n",
            "Batch 881 de 1116\n",
            "Batch 882 de 1116\n",
            "Batch 883 de 1116\n",
            "Batch 884 de 1116\n",
            "Batch 885 de 1116\n",
            "Batch 886 de 1116\n",
            "Batch 887 de 1116\n",
            "Batch 888 de 1116\n",
            "Batch 889 de 1116\n",
            "Batch 890 de 1116\n",
            "Batch 891 de 1116\n",
            "Batch 892 de 1116\n",
            "Batch 893 de 1116\n",
            "Batch 894 de 1116\n",
            "Batch 895 de 1116\n",
            "Batch 896 de 1116\n",
            "Batch 897 de 1116\n",
            "Batch 898 de 1116\n",
            "Batch 899 de 1116\n",
            "Batch 900 de 1116\n",
            "Batch 901 de 1116\n",
            "Batch 902 de 1116\n",
            "Batch 903 de 1116\n",
            "Batch 904 de 1116\n",
            "Batch 905 de 1116\n",
            "Batch 906 de 1116\n",
            "Batch 907 de 1116\n",
            "Batch 908 de 1116\n",
            "Batch 909 de 1116\n",
            "Batch 910 de 1116\n",
            "Batch 911 de 1116\n",
            "Batch 912 de 1116\n",
            "Batch 913 de 1116\n",
            "Batch 914 de 1116\n",
            "Batch 915 de 1116\n",
            "Batch 916 de 1116\n",
            "Batch 917 de 1116\n",
            "Batch 918 de 1116\n",
            "Batch 919 de 1116\n",
            "Batch 920 de 1116\n",
            "Batch 921 de 1116\n",
            "Batch 922 de 1116\n",
            "Batch 923 de 1116\n",
            "Batch 924 de 1116\n",
            "Batch 925 de 1116\n",
            "Batch 926 de 1116\n",
            "Batch 927 de 1116\n",
            "Batch 928 de 1116\n",
            "Batch 929 de 1116\n",
            "Batch 930 de 1116\n",
            "Batch 931 de 1116\n",
            "Batch 932 de 1116\n",
            "Batch 933 de 1116\n",
            "Batch 934 de 1116\n",
            "Batch 935 de 1116\n",
            "Batch 936 de 1116\n",
            "Batch 937 de 1116\n",
            "Batch 938 de 1116\n",
            "Batch 939 de 1116\n",
            "Batch 940 de 1116\n",
            "Batch 941 de 1116\n",
            "Batch 942 de 1116\n",
            "Batch 943 de 1116\n",
            "Batch 944 de 1116\n",
            "Batch 945 de 1116\n",
            "Batch 946 de 1116\n",
            "Batch 947 de 1116\n",
            "Batch 948 de 1116\n",
            "Batch 949 de 1116\n",
            "Batch 950 de 1116\n",
            "Batch 951 de 1116\n",
            "Batch 952 de 1116\n",
            "Batch 953 de 1116\n",
            "Batch 954 de 1116\n",
            "Batch 955 de 1116\n",
            "Batch 956 de 1116\n",
            "Batch 957 de 1116\n",
            "Batch 958 de 1116\n",
            "Batch 959 de 1116\n",
            "Batch 960 de 1116\n",
            "Batch 961 de 1116\n",
            "Batch 962 de 1116\n",
            "Batch 963 de 1116\n",
            "Batch 964 de 1116\n",
            "Batch 965 de 1116\n",
            "Batch 966 de 1116\n",
            "Batch 967 de 1116\n",
            "Batch 968 de 1116\n",
            "Batch 969 de 1116\n",
            "Batch 970 de 1116\n",
            "Batch 971 de 1116\n",
            "Batch 972 de 1116\n",
            "Batch 973 de 1116\n",
            "Batch 974 de 1116\n",
            "Batch 975 de 1116\n",
            "Batch 976 de 1116\n",
            "Batch 977 de 1116\n",
            "Batch 978 de 1116\n",
            "Batch 979 de 1116\n",
            "Batch 980 de 1116\n",
            "Batch 981 de 1116\n",
            "Batch 982 de 1116\n",
            "Batch 983 de 1116\n",
            "Batch 984 de 1116\n",
            "Batch 985 de 1116\n",
            "Batch 986 de 1116\n",
            "Batch 987 de 1116\n",
            "Batch 988 de 1116\n",
            "Batch 989 de 1116\n",
            "Batch 990 de 1116\n",
            "Batch 991 de 1116\n",
            "Batch 992 de 1116\n",
            "Batch 993 de 1116\n",
            "Batch 994 de 1116\n",
            "Batch 995 de 1116\n",
            "Batch 996 de 1116\n",
            "Batch 997 de 1116\n",
            "Batch 998 de 1116\n",
            "Batch 999 de 1116\n",
            "Batch 1000 de 1116\n",
            "Batch 1001 de 1116\n",
            "Batch 1002 de 1116\n",
            "Batch 1003 de 1116\n",
            "Batch 1004 de 1116\n",
            "Batch 1005 de 1116\n",
            "Batch 1006 de 1116\n",
            "Batch 1007 de 1116\n",
            "Batch 1008 de 1116\n",
            "Batch 1009 de 1116\n",
            "Batch 1010 de 1116\n",
            "Batch 1011 de 1116\n",
            "Batch 1012 de 1116\n",
            "Batch 1013 de 1116\n",
            "Batch 1014 de 1116\n",
            "Batch 1015 de 1116\n",
            "Batch 1016 de 1116\n",
            "Batch 1017 de 1116\n",
            "Batch 1018 de 1116\n",
            "Batch 1019 de 1116\n",
            "Batch 1020 de 1116\n",
            "Batch 1021 de 1116\n",
            "Batch 1022 de 1116\n",
            "Batch 1023 de 1116\n",
            "Batch 1024 de 1116\n",
            "Batch 1025 de 1116\n",
            "Batch 1026 de 1116\n",
            "Batch 1027 de 1116\n",
            "Batch 1028 de 1116\n",
            "Batch 1029 de 1116\n",
            "Batch 1030 de 1116\n",
            "Batch 1031 de 1116\n",
            "Batch 1032 de 1116\n",
            "Batch 1033 de 1116\n",
            "Batch 1034 de 1116\n",
            "Batch 1035 de 1116\n",
            "Batch 1036 de 1116\n",
            "Batch 1037 de 1116\n",
            "Batch 1038 de 1116\n",
            "Batch 1039 de 1116\n",
            "Batch 1040 de 1116\n",
            "Batch 1041 de 1116\n",
            "Batch 1042 de 1116\n",
            "Batch 1043 de 1116\n",
            "Batch 1044 de 1116\n",
            "Batch 1045 de 1116\n",
            "Batch 1046 de 1116\n",
            "Batch 1047 de 1116\n",
            "Batch 1048 de 1116\n",
            "Batch 1049 de 1116\n",
            "Batch 1050 de 1116\n",
            "Batch 1051 de 1116\n",
            "Batch 1052 de 1116\n",
            "Batch 1053 de 1116\n",
            "Batch 1054 de 1116\n",
            "Batch 1055 de 1116\n",
            "Batch 1056 de 1116\n",
            "Batch 1057 de 1116\n",
            "Batch 1058 de 1116\n",
            "Batch 1059 de 1116\n",
            "Batch 1060 de 1116\n",
            "Batch 1061 de 1116\n",
            "Batch 1062 de 1116\n",
            "Batch 1063 de 1116\n",
            "Batch 1064 de 1116\n",
            "Batch 1065 de 1116\n",
            "Batch 1066 de 1116\n",
            "Batch 1067 de 1116\n",
            "Batch 1068 de 1116\n",
            "Batch 1069 de 1116\n",
            "Batch 1070 de 1116\n",
            "Batch 1071 de 1116\n",
            "Batch 1072 de 1116\n",
            "Batch 1073 de 1116\n",
            "Batch 1074 de 1116\n",
            "Batch 1075 de 1116\n",
            "Batch 1076 de 1116\n",
            "Batch 1077 de 1116\n",
            "Batch 1078 de 1116\n",
            "Batch 1079 de 1116\n",
            "Batch 1080 de 1116\n",
            "Batch 1081 de 1116\n",
            "Batch 1082 de 1116\n",
            "Batch 1083 de 1116\n",
            "Batch 1084 de 1116\n",
            "Batch 1085 de 1116\n",
            "Batch 1086 de 1116\n",
            "Batch 1087 de 1116\n",
            "Batch 1088 de 1116\n",
            "Batch 1089 de 1116\n",
            "Batch 1090 de 1116\n",
            "Batch 1091 de 1116\n",
            "Batch 1092 de 1116\n",
            "Batch 1093 de 1116\n",
            "Batch 1094 de 1116\n",
            "Batch 1095 de 1116\n",
            "Batch 1096 de 1116\n",
            "Batch 1097 de 1116\n",
            "Batch 1098 de 1116\n",
            "Batch 1099 de 1116\n",
            "Batch 1100 de 1116\n",
            "Batch 1101 de 1116\n",
            "Batch 1102 de 1116\n",
            "Batch 1103 de 1116\n",
            "Batch 1104 de 1116\n",
            "Batch 1105 de 1116\n",
            "Batch 1106 de 1116\n",
            "Batch 1107 de 1116\n",
            "Batch 1108 de 1116\n",
            "Batch 1109 de 1116\n",
            "Batch 1110 de 1116\n",
            "Batch 1111 de 1116\n",
            "Batch 1112 de 1116\n",
            "Batch 1113 de 1116\n",
            "Batch 1114 de 1116\n",
            "Batch 1115 de 1116\n",
            "Accuracy Score = 0.7224588143001233\n",
            "F1 Score (Micro) = 0.7224588143001233\n",
            "F1 Score (Macro) = 0.4194345944890855\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationBert(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "\n",
        "  targets = np.array(targets).flatten().astype(int)\n",
        "\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "id": "OPlHsK674nZa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0nrqlVD4nZa"
      },
      "source": [
        "##### Entrenamiento del modelo (80% de datos)"
      ],
      "id": "c0nrqlVD4nZa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-3\n",
        "- weight_decay=0.01\n",
        "- Dropout + Linear + Sigmoid"
      ],
      "metadata": {
        "id": "7ExiyfROPFaG"
      },
      "id": "7ExiyfROPFaG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b69d75-1ade-4a81-bf2b-e89a4225799c",
        "id": "2lTZI-6z4nZa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración; 0 de 14277, Loss: 0.0793895661830902\n",
            "Epoch: 0, iteración; 10 de 14277, Loss: 0.5832354068756104\n",
            "Epoch: 0, iteración; 20 de 14277, Loss: 0.5882619380950928\n",
            "Epoch: 0, iteración; 30 de 14277, Loss: 0.5497564315795899\n",
            "Epoch: 0, iteración; 40 de 14277, Loss: 0.5226046085357666\n",
            "Epoch: 0, iteración; 50 de 14277, Loss: 0.6374249458312988\n",
            "Epoch: 0, iteración; 60 de 14277, Loss: 0.6370265483856201\n",
            "Epoch: 0, iteración; 70 de 14277, Loss: 0.5931281089782715\n",
            "Epoch: 0, iteración; 80 de 14277, Loss: 0.5791791915893555\n",
            "Epoch: 0, iteración; 90 de 14277, Loss: 0.5664691925048828\n",
            "Epoch: 0, iteración; 100 de 14277, Loss: 0.6570603847503662\n",
            "Epoch: 0, iteración; 110 de 14277, Loss: 0.6109620571136475\n",
            "Epoch: 0, iteración; 120 de 14277, Loss: 0.6524017333984375\n",
            "Epoch: 0, iteración; 130 de 14277, Loss: 0.6393204689025879\n",
            "Epoch: 0, iteración; 140 de 14277, Loss: 0.5577010154724121\n",
            "Epoch: 0, iteración; 150 de 14277, Loss: 0.5565076351165772\n",
            "Epoch: 0, iteración; 160 de 14277, Loss: 0.56684250831604\n",
            "Epoch: 0, iteración; 170 de 14277, Loss: 0.6449070453643799\n",
            "Epoch: 0, iteración; 180 de 14277, Loss: 0.611880874633789\n",
            "Epoch: 0, iteración; 190 de 14277, Loss: 0.6772336006164551\n",
            "Epoch: 0, iteración; 200 de 14277, Loss: 0.6308260917663574\n",
            "Epoch: 0, iteración; 210 de 14277, Loss: 0.6028852939605713\n",
            "Epoch: 0, iteración; 220 de 14277, Loss: 0.5821812629699707\n",
            "Epoch: 0, iteración; 230 de 14277, Loss: 0.5588471412658691\n",
            "Epoch: 0, iteración; 240 de 14277, Loss: 0.6441409111022949\n",
            "Epoch: 0, iteración; 250 de 14277, Loss: 0.567362117767334\n",
            "Epoch: 0, iteración; 260 de 14277, Loss: 0.5451848030090332\n",
            "Epoch: 0, iteración; 270 de 14277, Loss: 0.6118564128875732\n",
            "Epoch: 0, iteración; 280 de 14277, Loss: 0.6567292213439941\n",
            "Epoch: 0, iteración; 290 de 14277, Loss: 0.6120350360870361\n",
            "Epoch: 0, iteración; 300 de 14277, Loss: 0.5795756816864014\n",
            "Epoch: 0, iteración; 310 de 14277, Loss: 0.6538276672363281\n",
            "Epoch: 0, iteración; 320 de 14277, Loss: 0.5392712116241455\n",
            "Epoch: 0, iteración; 330 de 14277, Loss: 0.5782853603363037\n",
            "Epoch: 0, iteración; 340 de 14277, Loss: 0.5997971534729004\n",
            "Epoch: 0, iteración; 350 de 14277, Loss: 0.5661265850067139\n",
            "Epoch: 0, iteración; 360 de 14277, Loss: 0.5310618877410889\n",
            "Epoch: 0, iteración; 370 de 14277, Loss: 0.5881758213043213\n",
            "Epoch: 0, iteración; 380 de 14277, Loss: 0.6244092464447022\n",
            "Epoch: 0, iteración; 390 de 14277, Loss: 0.6234465599060058\n",
            "Epoch: 0, iteración; 400 de 14277, Loss: 0.6110249042510987\n",
            "Epoch: 0, iteración; 410 de 14277, Loss: 0.5780415058135986\n",
            "Epoch: 0, iteración; 420 de 14277, Loss: 0.6004843711853027\n",
            "Epoch: 0, iteración; 430 de 14277, Loss: 0.5993823051452637\n",
            "Epoch: 0, iteración; 440 de 14277, Loss: 0.5666641235351563\n",
            "Epoch: 0, iteración; 450 de 14277, Loss: 0.46274795532226565\n",
            "Epoch: 0, iteración; 460 de 14277, Loss: 0.6360012054443359\n",
            "Epoch: 0, iteración; 470 de 14277, Loss: 0.6470358848571778\n",
            "Epoch: 0, iteración; 480 de 14277, Loss: 0.4833213329315186\n",
            "Epoch: 0, iteración; 490 de 14277, Loss: 0.6235856533050537\n",
            "Epoch: 0, iteración; 500 de 14277, Loss: 0.5646659851074218\n",
            "Epoch: 0, iteración; 510 de 14277, Loss: 0.5882779598236084\n",
            "Epoch: 0, iteración; 520 de 14277, Loss: 0.5533746719360352\n",
            "Epoch: 0, iteración; 530 de 14277, Loss: 0.5882516384124756\n",
            "Epoch: 0, iteración; 540 de 14277, Loss: 0.6588572502136231\n",
            "Epoch: 0, iteración; 550 de 14277, Loss: 0.6223655700683594\n",
            "Epoch: 0, iteración; 560 de 14277, Loss: 0.5551441192626954\n",
            "Epoch: 0, iteración; 570 de 14277, Loss: 0.5667277812957764\n",
            "Epoch: 0, iteración; 580 de 14277, Loss: 0.5657752990722656\n",
            "Epoch: 0, iteración; 590 de 14277, Loss: 0.6226461410522461\n",
            "Epoch: 0, iteración; 600 de 14277, Loss: 0.6113093376159668\n",
            "Epoch: 0, iteración; 610 de 14277, Loss: 0.5782209396362304\n",
            "Epoch: 0, iteración; 620 de 14277, Loss: 0.6111354827880859\n",
            "Epoch: 0, iteración; 630 de 14277, Loss: 0.6114082336425781\n",
            "Epoch: 0, iteración; 640 de 14277, Loss: 0.6654594898223877\n",
            "Epoch: 0, iteración; 650 de 14277, Loss: 0.5691660881042481\n",
            "Epoch: 0, iteración; 660 de 14277, Loss: 0.6111766815185546\n",
            "Epoch: 0, iteración; 670 de 14277, Loss: 0.6428750991821289\n",
            "Epoch: 0, iteración; 680 de 14277, Loss: 0.5696134567260742\n",
            "Epoch: 0, iteración; 690 de 14277, Loss: 0.5691497325897217\n",
            "Epoch: 0, iteración; 700 de 14277, Loss: 0.6324419021606446\n",
            "Epoch: 0, iteración; 710 de 14277, Loss: 0.6114254951477051\n",
            "Epoch: 0, iteración; 720 de 14277, Loss: 0.6220074653625488\n",
            "Epoch: 0, iteración; 730 de 14277, Loss: 0.5905219078063965\n",
            "Epoch: 0, iteración; 740 de 14277, Loss: 0.6219155788421631\n",
            "Epoch: 0, iteración; 750 de 14277, Loss: 0.5682723045349121\n",
            "Epoch: 0, iteración; 760 de 14277, Loss: 0.5448861122131348\n",
            "Epoch: 0, iteración; 770 de 14277, Loss: 0.6120283126831054\n",
            "Epoch: 0, iteración; 780 de 14277, Loss: 0.6453545570373536\n",
            "Epoch: 0, iteración; 790 de 14277, Loss: 0.610771369934082\n",
            "Epoch: 0, iteración; 800 de 14277, Loss: 0.5792102813720703\n",
            "Epoch: 0, iteración; 810 de 14277, Loss: 0.4916065216064453\n",
            "Epoch: 0, iteración; 820 de 14277, Loss: 0.5998233318328857\n",
            "Epoch: 0, iteración; 830 de 14277, Loss: 0.5060581207275391\n",
            "Epoch: 0, iteración; 840 de 14277, Loss: 0.5164884090423584\n",
            "Epoch: 0, iteración; 850 de 14277, Loss: 0.7328373908996582\n",
            "Epoch: 0, iteración; 860 de 14277, Loss: 0.6711527824401855\n",
            "Epoch: 0, iteración; 870 de 14277, Loss: 0.5771749496459961\n",
            "Epoch: 0, iteración; 880 de 14277, Loss: 0.5658125400543212\n",
            "Epoch: 0, iteración; 890 de 14277, Loss: 0.6459871292114258\n",
            "Epoch: 0, iteración; 900 de 14277, Loss: 0.5565519332885742\n",
            "Epoch: 0, iteración; 910 de 14277, Loss: 0.6446560859680176\n",
            "Epoch: 0, iteración; 920 de 14277, Loss: 0.48922152519226075\n",
            "Epoch: 0, iteración; 930 de 14277, Loss: 0.5302627563476563\n",
            "Epoch: 0, iteración; 940 de 14277, Loss: 0.5998948574066162\n",
            "Epoch: 0, iteración; 950 de 14277, Loss: 0.59996657371521\n",
            "Epoch: 0, iteración; 960 de 14277, Loss: 0.5532903671264648\n",
            "Epoch: 0, iteración; 970 de 14277, Loss: 0.6708033084869385\n",
            "Epoch: 0, iteración; 980 de 14277, Loss: 0.6577305793762207\n",
            "Epoch: 0, iteración; 990 de 14277, Loss: 0.6671790599822998\n",
            "Epoch: 0, iteración; 1000 de 14277, Loss: 0.6113649368286133\n",
            "Epoch: 0, iteración; 1010 de 14277, Loss: 0.6118840217590332\n",
            "Epoch: 0, iteración; 1020 de 14277, Loss: 0.5811797618865967\n",
            "Epoch: 0, iteración; 1030 de 14277, Loss: 0.6522641181945801\n",
            "Epoch: 0, iteración; 1040 de 14277, Loss: 0.5829696178436279\n",
            "Epoch: 0, iteración; 1050 de 14277, Loss: 0.5702788829803467\n",
            "Epoch: 0, iteración; 1060 de 14277, Loss: 0.5899335861206054\n",
            "Epoch: 0, iteración; 1070 de 14277, Loss: 0.5673359394073486\n",
            "Epoch: 0, iteración; 1080 de 14277, Loss: 0.565959358215332\n",
            "Epoch: 0, iteración; 1090 de 14277, Loss: 0.5183816909790039\n",
            "Epoch: 0, iteración; 1100 de 14277, Loss: 0.5647048950195312\n",
            "Epoch: 0, iteración; 1110 de 14277, Loss: 0.5885035514831543\n",
            "Epoch: 0, iteración; 1120 de 14277, Loss: 0.5885800361633301\n",
            "Epoch: 0, iteración; 1130 de 14277, Loss: 0.5884325981140137\n",
            "Epoch: 0, iteración; 1140 de 14277, Loss: 0.5761013507843018\n",
            "Epoch: 0, iteración; 1150 de 14277, Loss: 0.5885985374450684\n",
            "Epoch: 0, iteración; 1160 de 14277, Loss: 0.5766101360321045\n",
            "Epoch: 0, iteración; 1170 de 14277, Loss: 0.5177563667297364\n",
            "Epoch: 0, iteración; 1180 de 14277, Loss: 0.5526068687438965\n",
            "Epoch: 0, iteración; 1190 de 14277, Loss: 0.5765419960021972\n",
            "Epoch: 0, iteración; 1200 de 14277, Loss: 0.5763842582702636\n",
            "Epoch: 0, iteración; 1210 de 14277, Loss: 0.6002884387969971\n",
            "Epoch: 0, iteración; 1220 de 14277, Loss: 0.588641881942749\n",
            "Epoch: 0, iteración; 1230 de 14277, Loss: 0.6002500057220459\n",
            "Epoch: 0, iteración; 1240 de 14277, Loss: 0.6119675159454345\n",
            "Epoch: 0, iteración; 1250 de 14277, Loss: 0.5538536548614502\n",
            "Epoch: 0, iteración; 1260 de 14277, Loss: 0.5770785331726074\n",
            "Epoch: 0, iteración; 1270 de 14277, Loss: 0.6353493690490722\n",
            "Epoch: 0, iteración; 1280 de 14277, Loss: 0.5543377876281739\n",
            "Epoch: 0, iteración; 1290 de 14277, Loss: 0.5998965263366699\n",
            "Epoch: 0, iteración; 1300 de 14277, Loss: 0.5887406349182129\n",
            "Epoch: 0, iteración; 1310 de 14277, Loss: 0.6345973014831543\n",
            "Epoch: 0, iteración; 1320 de 14277, Loss: 0.5435081958770752\n",
            "Epoch: 0, iteración; 1330 de 14277, Loss: 0.6000706195831299\n",
            "Epoch: 0, iteración; 1340 de 14277, Loss: 0.5999585628509522\n",
            "Epoch: 0, iteración; 1350 de 14277, Loss: 0.497771167755127\n",
            "Epoch: 0, iteración; 1360 de 14277, Loss: 0.5763433456420899\n",
            "Epoch: 0, iteración; 1370 de 14277, Loss: 0.6001267433166504\n",
            "Epoch: 0, iteración; 1380 de 14277, Loss: 0.6474165439605712\n",
            "Epoch: 0, iteración; 1390 de 14277, Loss: 0.5887368679046631\n",
            "Epoch: 0, iteración; 1400 de 14277, Loss: 0.5662934303283691\n",
            "Epoch: 0, iteración; 1410 de 14277, Loss: 0.6229230880737304\n",
            "Epoch: 0, iteración; 1420 de 14277, Loss: 0.645744514465332\n",
            "Epoch: 0, iteración; 1430 de 14277, Loss: 0.6018877983093261\n",
            "Epoch: 0, iteración; 1440 de 14277, Loss: 0.4903686046600342\n",
            "Epoch: 0, iteración; 1450 de 14277, Loss: 0.5995075225830078\n",
            "Epoch: 0, iteración; 1460 de 14277, Loss: 0.5652037143707276\n",
            "Epoch: 0, iteración; 1470 de 14277, Loss: 0.6235319137573242\n",
            "Epoch: 0, iteración; 1480 de 14277, Loss: 0.682061767578125\n",
            "Epoch: 0, iteración; 1490 de 14277, Loss: 0.633384370803833\n",
            "Epoch: 0, iteración; 1500 de 14277, Loss: 0.6543320178985595\n",
            "Epoch: 0, iteración; 1510 de 14277, Loss: 0.6516990184783935\n",
            "Epoch: 0, iteración; 1520 de 14277, Loss: 0.5649158954620361\n",
            "Epoch: 0, iteración; 1530 de 14277, Loss: 0.5908427238464355\n",
            "Epoch: 0, iteración; 1540 de 14277, Loss: 0.5907505989074707\n",
            "Epoch: 0, iteración; 1550 de 14277, Loss: 0.6316564559936524\n",
            "Epoch: 0, iteración; 1560 de 14277, Loss: 0.611183500289917\n",
            "Epoch: 0, iteración; 1570 de 14277, Loss: 0.6316559791564942\n",
            "Epoch: 0, iteración; 1580 de 14277, Loss: 0.6134052753448487\n",
            "Epoch: 0, iteración; 1590 de 14277, Loss: 0.581027889251709\n",
            "Epoch: 0, iteración; 1600 de 14277, Loss: 0.6120285987854004\n",
            "Epoch: 0, iteración; 1610 de 14277, Loss: 0.6216904640197753\n",
            "Epoch: 0, iteración; 1620 de 14277, Loss: 0.5995560169219971\n",
            "Epoch: 0, iteración; 1630 de 14277, Loss: 0.6009980201721191\n",
            "Epoch: 0, iteración; 1640 de 14277, Loss: 0.5574763774871826\n",
            "Epoch: 0, iteración; 1650 de 14277, Loss: 0.5566033840179443\n",
            "Epoch: 0, iteración; 1660 de 14277, Loss: 0.6227678775787353\n",
            "Epoch: 0, iteración; 1670 de 14277, Loss: 0.5207393646240235\n",
            "Epoch: 0, iteración; 1680 de 14277, Loss: 0.5891973972320557\n",
            "Epoch: 0, iteración; 1690 de 14277, Loss: 0.6700246334075928\n",
            "Epoch: 0, iteración; 1700 de 14277, Loss: 0.5319784164428711\n",
            "Epoch: 0, iteración; 1710 de 14277, Loss: 0.645958423614502\n",
            "Epoch: 0, iteración; 1720 de 14277, Loss: 0.5998971462249756\n",
            "Epoch: 0, iteración; 1730 de 14277, Loss: 0.7210051059722901\n",
            "Epoch: 0, iteración; 1740 de 14277, Loss: 0.5388110160827637\n",
            "Epoch: 0, iteración; 1750 de 14277, Loss: 0.5998208522796631\n",
            "Epoch: 0, iteración; 1760 de 14277, Loss: 0.6110489368438721\n",
            "Epoch: 0, iteración; 1770 de 14277, Loss: 0.6316067218780518\n",
            "Epoch: 0, iteración; 1780 de 14277, Loss: 0.5797154903411865\n",
            "Epoch: 0, iteración; 1790 de 14277, Loss: 0.6220250129699707\n",
            "Epoch: 0, iteración; 1800 de 14277, Loss: 0.5899797916412354\n",
            "Epoch: 0, iteración; 1810 de 14277, Loss: 0.633332633972168\n",
            "Epoch: 0, iteración; 1820 de 14277, Loss: 0.5899497985839843\n",
            "Epoch: 0, iteración; 1830 de 14277, Loss: 0.5900907516479492\n",
            "Epoch: 0, iteración; 1840 de 14277, Loss: 0.620946216583252\n",
            "Epoch: 0, iteración; 1850 de 14277, Loss: 0.5585916996002197\n",
            "Epoch: 0, iteración; 1860 de 14277, Loss: 0.567189073562622\n",
            "Epoch: 0, iteración; 1870 de 14277, Loss: 0.5778450489044189\n",
            "Epoch: 0, iteración; 1880 de 14277, Loss: 0.611792516708374\n",
            "Epoch: 0, iteración; 1890 de 14277, Loss: 0.6461009979248047\n",
            "Epoch: 0, iteración; 1900 de 14277, Loss: 0.5667732715606689\n",
            "Epoch: 0, iteración; 1910 de 14277, Loss: 0.544624137878418\n",
            "Epoch: 0, iteración; 1920 de 14277, Loss: 0.6115310668945313\n",
            "Epoch: 0, iteración; 1930 de 14277, Loss: 0.6339941024780273\n",
            "Epoch: 0, iteración; 1940 de 14277, Loss: 0.6892336368560791\n",
            "Epoch: 0, iteración; 1950 de 14277, Loss: 0.6726696491241455\n",
            "Epoch: 0, iteración; 1960 de 14277, Loss: 0.6588682174682617\n",
            "Epoch: 0, iteración; 1970 de 14277, Loss: 0.4861496925354004\n",
            "Epoch: 0, iteración; 1980 de 14277, Loss: 0.6428496360778808\n",
            "Epoch: 0, iteración; 1990 de 14277, Loss: 0.7103452205657959\n",
            "Epoch: 0, iteración; 2000 de 14277, Loss: 0.5611715316772461\n",
            "Epoch: 0, iteración; 2010 de 14277, Loss: 0.6520177364349365\n",
            "Epoch: 0, iteración; 2020 de 14277, Loss: 0.572740125656128\n",
            "Epoch: 0, iteración; 2030 de 14277, Loss: 0.5704697132110595\n",
            "Epoch: 0, iteración; 2040 de 14277, Loss: 0.6335284233093261\n",
            "Epoch: 0, iteración; 2050 de 14277, Loss: 0.5785586357116699\n",
            "Epoch: 0, iteración; 2060 de 14277, Loss: 0.5999993801116943\n",
            "Epoch: 0, iteración; 2070 de 14277, Loss: 0.5905994892120361\n",
            "Epoch: 0, iteración; 2080 de 14277, Loss: 0.6117813110351562\n",
            "Epoch: 0, iteración; 2090 de 14277, Loss: 0.5889359951019287\n",
            "Epoch: 0, iteración; 2100 de 14277, Loss: 0.5454429149627685\n",
            "Epoch: 0, iteración; 2110 de 14277, Loss: 0.6009256839752197\n",
            "Epoch: 0, iteración; 2120 de 14277, Loss: 0.5214889049530029\n",
            "Epoch: 0, iteración; 2130 de 14277, Loss: 0.5184304714202881\n",
            "Epoch: 0, iteración; 2140 de 14277, Loss: 0.5051138401031494\n",
            "Epoch: 0, iteración; 2150 de 14277, Loss: 0.6123554229736328\n",
            "Epoch: 0, iteración; 2160 de 14277, Loss: 0.5764220237731934\n",
            "Epoch: 0, iteración; 2170 de 14277, Loss: 0.5400040626525879\n",
            "Epoch: 0, iteración; 2180 de 14277, Loss: 0.5278852939605713\n",
            "Epoch: 0, iteración; 2190 de 14277, Loss: 0.5398308277130127\n",
            "Epoch: 0, iteración; 2200 de 14277, Loss: 0.5400100231170655\n",
            "Epoch: 0, iteración; 2210 de 14277, Loss: 0.5278014183044434\n",
            "Epoch: 0, iteración; 2220 de 14277, Loss: 0.6486450672149658\n",
            "Epoch: 0, iteración; 2230 de 14277, Loss: 0.551761531829834\n",
            "Epoch: 0, iteración; 2240 de 14277, Loss: 0.5769189834594727\n",
            "Epoch: 0, iteración; 2250 de 14277, Loss: 0.6237948894500732\n",
            "Epoch: 0, iteración; 2260 de 14277, Loss: 0.5642758369445801\n",
            "Epoch: 0, iteración; 2270 de 14277, Loss: 0.635999345779419\n",
            "Epoch: 0, iteración; 2280 de 14277, Loss: 0.5417403221130371\n",
            "Epoch: 0, iteración; 2290 de 14277, Loss: 0.5291337490081787\n",
            "Epoch: 0, iteración; 2300 de 14277, Loss: 0.5519839286804199\n",
            "Epoch: 0, iteración; 2310 de 14277, Loss: 0.5641858100891113\n",
            "Epoch: 0, iteración; 2320 de 14277, Loss: 0.6119234085083007\n",
            "Epoch: 0, iteración; 2330 de 14277, Loss: 0.6593623161315918\n",
            "Epoch: 0, iteración; 2340 de 14277, Loss: 0.5067145347595214\n",
            "Epoch: 0, iteración; 2350 de 14277, Loss: 0.6348801612854004\n",
            "Epoch: 0, iteración; 2360 de 14277, Loss: 0.5421727180480957\n",
            "Epoch: 0, iteración; 2370 de 14277, Loss: 0.5294171333312988\n",
            "Epoch: 0, iteración; 2380 de 14277, Loss: 0.5528673648834228\n",
            "Epoch: 0, iteración; 2390 de 14277, Loss: 0.6002319812774658\n",
            "Epoch: 0, iteración; 2400 de 14277, Loss: 0.6359078884124756\n",
            "Epoch: 0, iteración; 2410 de 14277, Loss: 0.5293402671813965\n",
            "Epoch: 0, iteración; 2420 de 14277, Loss: 0.6122698783874512\n",
            "Epoch: 0, iteración; 2430 de 14277, Loss: 0.5885252952575684\n",
            "Epoch: 0, iteración; 2440 de 14277, Loss: 0.5760322570800781\n",
            "Epoch: 0, iteración; 2450 de 14277, Loss: 0.6009603500366211\n",
            "Epoch: 0, iteración; 2460 de 14277, Loss: 0.6352412700653076\n",
            "Epoch: 0, iteración; 2470 de 14277, Loss: 0.6573267936706543\n",
            "Epoch: 0, iteración; 2480 de 14277, Loss: 0.6557713508605957\n",
            "Epoch: 0, iteración; 2490 de 14277, Loss: 0.5802694320678711\n",
            "Epoch: 0, iteración; 2500 de 14277, Loss: 0.6522030830383301\n",
            "Epoch: 0, iteración; 2510 de 14277, Loss: 0.5903426170349121\n",
            "Epoch: 0, iteración; 2520 de 14277, Loss: 0.6709204196929932\n",
            "Epoch: 0, iteración; 2530 de 14277, Loss: 0.630770492553711\n",
            "Epoch: 0, iteración; 2540 de 14277, Loss: 0.5473886966705322\n",
            "Epoch: 0, iteración; 2550 de 14277, Loss: 0.5616701126098633\n",
            "Epoch: 0, iteración; 2560 de 14277, Loss: 0.7396203994750976\n",
            "Epoch: 0, iteración; 2570 de 14277, Loss: 0.5799742698669433\n",
            "Epoch: 0, iteración; 2580 de 14277, Loss: 0.591176176071167\n",
            "Epoch: 0, iteración; 2590 de 14277, Loss: 0.5289857864379883\n",
            "Epoch: 0, iteración; 2600 de 14277, Loss: 0.6220903873443604\n",
            "Epoch: 0, iteración; 2610 de 14277, Loss: 0.5668432235717773\n",
            "Epoch: 0, iteración; 2620 de 14277, Loss: 0.5779191970825195\n",
            "Epoch: 0, iteración; 2630 de 14277, Loss: 0.5879082202911377\n",
            "Epoch: 0, iteración; 2640 de 14277, Loss: 0.4846555233001709\n",
            "Epoch: 0, iteración; 2650 de 14277, Loss: 0.5764062881469727\n",
            "Epoch: 0, iteración; 2660 de 14277, Loss: 0.6711204528808594\n",
            "Epoch: 0, iteración; 2670 de 14277, Loss: 0.5882108211517334\n",
            "Epoch: 0, iteración; 2680 de 14277, Loss: 0.5301831245422364\n",
            "Epoch: 0, iteración; 2690 de 14277, Loss: 0.5646798133850097\n",
            "Epoch: 0, iteración; 2700 de 14277, Loss: 0.5881617069244385\n",
            "Epoch: 0, iteración; 2710 de 14277, Loss: 0.6004838943481445\n",
            "Epoch: 0, iteración; 2720 de 14277, Loss: 0.6112963199615479\n",
            "Epoch: 0, iteración; 2730 de 14277, Loss: 0.5529265880584717\n",
            "Epoch: 0, iteración; 2740 de 14277, Loss: 0.6576248168945312\n",
            "Epoch: 0, iteración; 2750 de 14277, Loss: 0.5432222843170166\n",
            "Epoch: 0, iteración; 2760 de 14277, Loss: 0.5993837833404541\n",
            "Epoch: 0, iteración; 2770 de 14277, Loss: 0.49713430404663084\n",
            "Epoch: 0, iteración; 2780 de 14277, Loss: 0.5413815975189209\n",
            "Epoch: 0, iteración; 2790 de 14277, Loss: 0.5766086578369141\n",
            "Epoch: 0, iteración; 2800 de 14277, Loss: 0.5765237808227539\n",
            "Epoch: 0, iteración; 2810 de 14277, Loss: 0.5284382820129394\n",
            "Epoch: 0, iteración; 2820 de 14277, Loss: 0.5405014991760254\n",
            "Epoch: 0, iteración; 2830 de 14277, Loss: 0.5761068344116211\n",
            "Epoch: 0, iteración; 2840 de 14277, Loss: 0.6484085559844971\n",
            "Epoch: 0, iteración; 2850 de 14277, Loss: 0.6121891021728516\n",
            "Epoch: 0, iteración; 2860 de 14277, Loss: 0.5887502670288086\n",
            "Epoch: 0, iteración; 2870 de 14277, Loss: 0.6581360340118408\n",
            "Epoch: 0, iteración; 2880 de 14277, Loss: 0.6111085891723633\n",
            "Epoch: 0, iteración; 2890 de 14277, Loss: 0.6349799156188964\n",
            "Epoch: 0, iteración; 2900 de 14277, Loss: 0.5456389427185059\n",
            "Epoch: 0, iteración; 2910 de 14277, Loss: 0.6789949417114258\n",
            "Epoch: 0, iteración; 2920 de 14277, Loss: 0.6444771766662598\n",
            "Epoch: 0, iteración; 2930 de 14277, Loss: 0.6105021953582763\n",
            "Epoch: 0, iteración; 2940 de 14277, Loss: 0.6621931552886963\n",
            "Epoch: 0, iteración; 2950 de 14277, Loss: 0.5616551399230957\n",
            "Epoch: 0, iteración; 2960 de 14277, Loss: 0.559580135345459\n",
            "Epoch: 0, iteración; 2970 de 14277, Loss: 0.6103318214416504\n",
            "Epoch: 0, iteración; 2980 de 14277, Loss: 0.5453649044036866\n",
            "Epoch: 0, iteración; 2990 de 14277, Loss: 0.6000803470611572\n",
            "Epoch: 0, iteración; 3000 de 14277, Loss: 0.4729790210723877\n",
            "Epoch: 0, iteración; 3010 de 14277, Loss: 0.5767034530639649\n",
            "Epoch: 0, iteración; 3020 de 14277, Loss: 0.46791839599609375\n",
            "Epoch: 0, iteración; 3030 de 14277, Loss: 0.6613272190093994\n",
            "Epoch: 0, iteración; 3040 de 14277, Loss: 0.5880710124969483\n",
            "Epoch: 0, iteración; 3050 de 14277, Loss: 0.6124085426330567\n",
            "Epoch: 0, iteración; 3060 de 14277, Loss: 0.4929840087890625\n",
            "Epoch: 0, iteración; 3070 de 14277, Loss: 0.5877219200134277\n",
            "Epoch: 0, iteración; 3080 de 14277, Loss: 0.5400131702423095\n",
            "Epoch: 0, iteración; 3090 de 14277, Loss: 0.5758634090423584\n",
            "Epoch: 0, iteración; 3100 de 14277, Loss: 0.5520555973052979\n",
            "Epoch: 0, iteración; 3110 de 14277, Loss: 0.5281058311462402\n",
            "Epoch: 0, iteración; 3120 de 14277, Loss: 0.6358510971069335\n",
            "Epoch: 0, iteración; 3130 de 14277, Loss: 0.6001011371612549\n",
            "Epoch: 0, iteración; 3140 de 14277, Loss: 0.5172290802001953\n",
            "Epoch: 0, iteración; 3150 de 14277, Loss: 0.5520339965820312\n",
            "Epoch: 0, iteración; 3160 de 14277, Loss: 0.5285238265991211\n",
            "Epoch: 0, iteración; 3170 de 14277, Loss: 0.6002511024475098\n",
            "Epoch: 0, iteración; 3180 de 14277, Loss: 0.5286134719848633\n",
            "Epoch: 0, iteración; 3190 de 14277, Loss: 0.6363210201263427\n",
            "Epoch: 0, iteración; 3200 de 14277, Loss: 0.6845122337341308\n",
            "Epoch: 0, iteración; 3210 de 14277, Loss: 0.6224270820617676\n",
            "Epoch: 0, iteración; 3220 de 14277, Loss: 0.6350195407867432\n",
            "Epoch: 0, iteración; 3230 de 14277, Loss: 0.5334675788879395\n",
            "Epoch: 0, iteración; 3240 de 14277, Loss: 0.6225392341613769\n",
            "Epoch: 0, iteración; 3250 de 14277, Loss: 0.6453914642333984\n",
            "Epoch: 0, iteración; 3260 de 14277, Loss: 0.6307624340057373\n",
            "Epoch: 0, iteración; 3270 de 14277, Loss: 0.5993232250213623\n",
            "Epoch: 0, iteración; 3280 de 14277, Loss: 0.6626498222351074\n",
            "Epoch: 0, iteración; 3290 de 14277, Loss: 0.6418481349945069\n",
            "Epoch: 0, iteración; 3300 de 14277, Loss: 0.5605284214019776\n",
            "Epoch: 0, iteración; 3310 de 14277, Loss: 0.561954402923584\n",
            "Epoch: 0, iteración; 3320 de 14277, Loss: 0.5580938816070556\n",
            "Epoch: 0, iteración; 3330 de 14277, Loss: 0.5560719013214112\n",
            "Epoch: 0, iteración; 3340 de 14277, Loss: 0.5887600898742675\n",
            "Epoch: 0, iteración; 3350 de 14277, Loss: 0.6360305786132813\n",
            "Epoch: 0, iteración; 3360 de 14277, Loss: 0.6233642578125\n",
            "Epoch: 0, iteración; 3370 de 14277, Loss: 0.5651657581329346\n",
            "Epoch: 0, iteración; 3380 de 14277, Loss: 0.6121774673461914\n",
            "Epoch: 0, iteración; 3390 de 14277, Loss: 0.5662751197814941\n",
            "Epoch: 0, iteración; 3400 de 14277, Loss: 0.6116102695465088\n",
            "Epoch: 0, iteración; 3410 de 14277, Loss: 0.6107356071472168\n",
            "Epoch: 0, iteración; 3420 de 14277, Loss: 0.5318713188171387\n",
            "Epoch: 0, iteración; 3430 de 14277, Loss: 0.6454676151275635\n",
            "Epoch: 0, iteración; 3440 de 14277, Loss: 0.5437777519226075\n",
            "Epoch: 0, iteración; 3450 de 14277, Loss: 0.5314570903778076\n",
            "Epoch: 0, iteración; 3460 de 14277, Loss: 0.6010013103485108\n",
            "Epoch: 0, iteración; 3470 de 14277, Loss: 0.5178948402404785\n",
            "Epoch: 0, iteración; 3480 de 14277, Loss: 0.5640889167785644\n",
            "Epoch: 0, iteración; 3490 de 14277, Loss: 0.6246542930603027\n",
            "Epoch: 0, iteración; 3500 de 14277, Loss: 0.6712208271026612\n",
            "Epoch: 0, iteración; 3510 de 14277, Loss: 0.6933554649353028\n",
            "Epoch: 0, iteración; 3520 de 14277, Loss: 0.5671425819396972\n",
            "Epoch: 0, iteración; 3530 de 14277, Loss: 0.5777458190917969\n",
            "Epoch: 0, iteración; 3540 de 14277, Loss: 0.6327341556549072\n",
            "Epoch: 0, iteración; 3550 de 14277, Loss: 0.6541203498840332\n",
            "Epoch: 0, iteración; 3560 de 14277, Loss: 0.5044230461120606\n",
            "Epoch: 0, iteración; 3570 de 14277, Loss: 0.532130765914917\n",
            "Epoch: 0, iteración; 3580 de 14277, Loss: 0.5761366367340088\n",
            "Epoch: 0, iteración; 3590 de 14277, Loss: 0.6586455345153809\n",
            "Epoch: 0, iteración; 3600 de 14277, Loss: 0.6111926555633544\n",
            "Epoch: 0, iteración; 3610 de 14277, Loss: 0.6005595684051513\n",
            "Epoch: 0, iteración; 3620 de 14277, Loss: 0.5328649044036865\n",
            "Epoch: 0, iteración; 3630 de 14277, Loss: 0.6458307266235351\n",
            "Epoch: 0, iteración; 3640 de 14277, Loss: 0.667186975479126\n",
            "Epoch: 0, iteración; 3650 de 14277, Loss: 0.5120311260223389\n",
            "Epoch: 0, iteración; 3660 de 14277, Loss: 0.6340281963348389\n",
            "Epoch: 0, iteración; 3670 de 14277, Loss: 0.7316845417022705\n",
            "Epoch: 0, iteración; 3680 de 14277, Loss: 0.5909255027770997\n",
            "Epoch: 0, iteración; 3690 de 14277, Loss: 0.5613964557647705\n",
            "Epoch: 0, iteración; 3700 de 14277, Loss: 0.5794126510620117\n",
            "Epoch: 0, iteración; 3710 de 14277, Loss: 0.6542377471923828\n",
            "Epoch: 0, iteración; 3720 de 14277, Loss: 0.5796068191528321\n",
            "Epoch: 0, iteración; 3730 de 14277, Loss: 0.5785705089569092\n",
            "Epoch: 0, iteración; 3740 de 14277, Loss: 0.589524507522583\n",
            "Epoch: 0, iteración; 3750 de 14277, Loss: 0.6123224258422851\n",
            "Epoch: 0, iteración; 3760 de 14277, Loss: 0.6114391326904297\n",
            "Epoch: 0, iteración; 3770 de 14277, Loss: 0.6760928153991699\n",
            "Epoch: 0, iteración; 3780 de 14277, Loss: 0.5992453098297119\n",
            "Epoch: 0, iteración; 3790 de 14277, Loss: 0.5912483692169189\n",
            "Epoch: 0, iteración; 3800 de 14277, Loss: 0.6008881568908692\n",
            "Epoch: 0, iteración; 3810 de 14277, Loss: 0.6622942924499512\n",
            "Epoch: 0, iteración; 3820 de 14277, Loss: 0.631703519821167\n",
            "Epoch: 0, iteración; 3830 de 14277, Loss: 0.5927689552307129\n",
            "Epoch: 0, iteración; 3840 de 14277, Loss: 0.5926295280456543\n",
            "Epoch: 0, iteración; 3850 de 14277, Loss: 0.6416975021362304\n",
            "Epoch: 0, iteración; 3860 de 14277, Loss: 0.5389743328094483\n",
            "Epoch: 0, iteración; 3870 de 14277, Loss: 0.600613021850586\n",
            "Epoch: 0, iteración; 3880 de 14277, Loss: 0.5673310279846191\n",
            "Epoch: 0, iteración; 3890 de 14277, Loss: 0.5441442966461182\n",
            "Epoch: 0, iteración; 3900 de 14277, Loss: 0.5770642757415771\n",
            "Epoch: 0, iteración; 3910 de 14277, Loss: 0.4575864315032959\n",
            "Epoch: 0, iteración; 3920 de 14277, Loss: 0.503441047668457\n",
            "Epoch: 0, iteración; 3930 de 14277, Loss: 0.6128297805786133\n",
            "Epoch: 0, iteración; 3940 de 14277, Loss: 0.6494847297668457\n",
            "Epoch: 0, iteración; 3950 de 14277, Loss: 0.5398914813995361\n",
            "Epoch: 0, iteración; 3960 de 14277, Loss: 0.6124907016754151\n",
            "Epoch: 0, iteración; 3970 de 14277, Loss: 0.5528283596038819\n",
            "Epoch: 0, iteración; 3980 de 14277, Loss: 0.6243709564208985\n",
            "Epoch: 0, iteración; 3990 de 14277, Loss: 0.4693160057067871\n",
            "Epoch: 0, iteración; 4000 de 14277, Loss: 0.5641395092010498\n",
            "Epoch: 0, iteración; 4010 de 14277, Loss: 0.6365042209625245\n",
            "Epoch: 0, iteración; 4020 de 14277, Loss: 0.6360749721527099\n",
            "Epoch: 0, iteración; 4030 de 14277, Loss: 0.6471212387084961\n",
            "Epoch: 0, iteración; 4040 de 14277, Loss: 0.5997599601745606\n",
            "Epoch: 0, iteración; 4050 de 14277, Loss: 0.5777403831481933\n",
            "Epoch: 0, iteración; 4060 de 14277, Loss: 0.5552234172821044\n",
            "Epoch: 0, iteración; 4070 de 14277, Loss: 0.6459450721740723\n",
            "Epoch: 0, iteración; 4080 de 14277, Loss: 0.6336676120758057\n",
            "Epoch: 0, iteración; 4090 de 14277, Loss: 0.6222557544708252\n",
            "Epoch: 0, iteración; 4100 de 14277, Loss: 0.5790617942810059\n",
            "Epoch: 0, iteración; 4110 de 14277, Loss: 0.6112342357635498\n",
            "Epoch: 0, iteración; 4120 de 14277, Loss: 0.589123010635376\n",
            "Epoch: 0, iteración; 4130 de 14277, Loss: 0.5900846958160401\n",
            "Epoch: 0, iteración; 4140 de 14277, Loss: 0.6557252883911133\n",
            "Epoch: 0, iteración; 4150 de 14277, Loss: 0.6102684020996094\n",
            "Epoch: 0, iteración; 4160 de 14277, Loss: 0.653929615020752\n",
            "Epoch: 0, iteración; 4170 de 14277, Loss: 0.5512869834899903\n",
            "Epoch: 0, iteración; 4180 de 14277, Loss: 0.5908414840698242\n",
            "Epoch: 0, iteración; 4190 de 14277, Loss: 0.5895316123962402\n",
            "Epoch: 0, iteración; 4200 de 14277, Loss: 0.5900688648223877\n",
            "Epoch: 0, iteración; 4210 de 14277, Loss: 0.6001245021820069\n",
            "Epoch: 0, iteración; 4220 de 14277, Loss: 0.532902717590332\n",
            "Epoch: 0, iteración; 4230 de 14277, Loss: 0.6457659721374511\n",
            "Epoch: 0, iteración; 4240 de 14277, Loss: 0.6229852676391602\n",
            "Epoch: 0, iteración; 4250 de 14277, Loss: 0.588612413406372\n",
            "Epoch: 0, iteración; 4260 de 14277, Loss: 0.5222091197967529\n",
            "Epoch: 0, iteración; 4270 de 14277, Loss: 0.5989310264587402\n",
            "Epoch: 0, iteración; 4280 de 14277, Loss: 0.5654143333435059\n",
            "Epoch: 0, iteración; 4290 de 14277, Loss: 0.5654963493347168\n",
            "Epoch: 0, iteración; 4300 de 14277, Loss: 0.5882376670837403\n",
            "Epoch: 0, iteración; 4310 de 14277, Loss: 0.5419475555419921\n",
            "Epoch: 0, iteración; 4320 de 14277, Loss: 0.6587677955627441\n",
            "Epoch: 0, iteración; 4330 de 14277, Loss: 0.6233042716979981\n",
            "Epoch: 0, iteración; 4340 de 14277, Loss: 0.4734302520751953\n",
            "Epoch: 0, iteración; 4350 de 14277, Loss: 0.6117351531982422\n",
            "Epoch: 0, iteración; 4360 de 14277, Loss: 0.6112611770629883\n",
            "Epoch: 0, iteración; 4370 de 14277, Loss: 0.5302820205688477\n",
            "Epoch: 0, iteración; 4380 de 14277, Loss: 0.4946750640869141\n",
            "Epoch: 0, iteración; 4390 de 14277, Loss: 0.6002384185791015\n",
            "Epoch: 0, iteración; 4400 de 14277, Loss: 0.5044101715087891\n",
            "Epoch: 0, iteración; 4410 de 14277, Loss: 0.5762840270996094\n",
            "Epoch: 0, iteración; 4420 de 14277, Loss: 0.5888696193695069\n",
            "Epoch: 0, iteración; 4430 de 14277, Loss: 0.5520733833312989\n",
            "Epoch: 0, iteración; 4440 de 14277, Loss: 0.5634026527404785\n",
            "Epoch: 0, iteración; 4450 de 14277, Loss: 0.6120111465454101\n",
            "Epoch: 0, iteración; 4460 de 14277, Loss: 0.5766049385070801\n",
            "Epoch: 0, iteración; 4470 de 14277, Loss: 0.6475998878479003\n",
            "Epoch: 0, iteración; 4480 de 14277, Loss: 0.5876950263977051\n",
            "Epoch: 0, iteración; 4490 de 14277, Loss: 0.5654398918151855\n",
            "Epoch: 0, iteración; 4500 de 14277, Loss: 0.5539196968078614\n",
            "Epoch: 0, iteración; 4510 de 14277, Loss: 0.5880719661712647\n",
            "Epoch: 0, iteración; 4520 de 14277, Loss: 0.6242673873901368\n",
            "Epoch: 0, iteración; 4530 de 14277, Loss: 0.5996132373809815\n",
            "Epoch: 0, iteración; 4540 de 14277, Loss: 0.5767200469970704\n",
            "Epoch: 0, iteración; 4550 de 14277, Loss: 0.6116887092590332\n",
            "Epoch: 0, iteración; 4560 de 14277, Loss: 0.5438199996948242\n",
            "Epoch: 0, iteración; 4570 de 14277, Loss: 0.6912130355834961\n",
            "Epoch: 0, iteración; 4580 de 14277, Loss: 0.6117458343505859\n",
            "Epoch: 0, iteración; 4590 de 14277, Loss: 0.5788136482238769\n",
            "Epoch: 0, iteración; 4600 de 14277, Loss: 0.556698226928711\n",
            "Epoch: 0, iteración; 4610 de 14277, Loss: 0.6008597373962402\n",
            "Epoch: 0, iteración; 4620 de 14277, Loss: 0.5768668174743652\n",
            "Epoch: 0, iteración; 4630 de 14277, Loss: 0.6794139862060546\n",
            "Epoch: 0, iteración; 4640 de 14277, Loss: 0.6332304954528809\n",
            "Epoch: 0, iteración; 4650 de 14277, Loss: 0.6332170963287354\n",
            "Epoch: 0, iteración; 4660 de 14277, Loss: 0.6024519443511963\n",
            "Epoch: 0, iteración; 4670 de 14277, Loss: 0.5604694366455079\n",
            "Epoch: 0, iteración; 4680 de 14277, Loss: 0.5671093463897705\n",
            "Epoch: 0, iteración; 4690 de 14277, Loss: 0.5451769828796387\n",
            "Epoch: 0, iteración; 4700 de 14277, Loss: 0.5997708320617676\n",
            "Epoch: 0, iteración; 4710 de 14277, Loss: 0.5769338607788086\n",
            "Epoch: 0, iteración; 4720 de 14277, Loss: 0.5877334594726562\n",
            "Epoch: 0, iteración; 4730 de 14277, Loss: 0.5415692329406738\n",
            "Epoch: 0, iteración; 4740 de 14277, Loss: 0.5407570838928223\n",
            "Epoch: 0, iteración; 4750 de 14277, Loss: 0.6239425659179687\n",
            "Epoch: 0, iteración; 4760 de 14277, Loss: 0.624358081817627\n",
            "Epoch: 0, iteración; 4770 de 14277, Loss: 0.6812643527984619\n",
            "Epoch: 0, iteración; 4780 de 14277, Loss: 0.6110366344451904\n",
            "Epoch: 0, iteración; 4790 de 14277, Loss: 0.6008554935455322\n",
            "Epoch: 0, iteración; 4800 de 14277, Loss: 0.5557186603546143\n",
            "Epoch: 0, iteración; 4810 de 14277, Loss: 0.5891664028167725\n",
            "Epoch: 0, iteración; 4820 de 14277, Loss: 0.47516732215881347\n",
            "Epoch: 0, iteración; 4830 de 14277, Loss: 0.553198766708374\n",
            "Epoch: 0, iteración; 4840 de 14277, Loss: 0.5037653923034668\n",
            "Epoch: 0, iteración; 4850 de 14277, Loss: 0.5145550727844238\n",
            "Epoch: 0, iteración; 4860 de 14277, Loss: 0.6615872859954834\n",
            "Epoch: 0, iteración; 4870 de 14277, Loss: 0.5638677597045898\n",
            "Epoch: 0, iteración; 4880 de 14277, Loss: 0.6608541488647461\n",
            "Epoch: 0, iteración; 4890 de 14277, Loss: 0.5884604454040527\n",
            "Epoch: 0, iteración; 4900 de 14277, Loss: 0.5651802539825439\n",
            "Epoch: 0, iteración; 4910 de 14277, Loss: 0.6589164733886719\n",
            "Epoch: 0, iteración; 4920 de 14277, Loss: 0.5892877101898193\n",
            "Epoch: 0, iteración; 4930 de 14277, Loss: 0.6003308296203613\n",
            "Epoch: 0, iteración; 4940 de 14277, Loss: 0.6120189666748047\n",
            "Epoch: 0, iteración; 4950 de 14277, Loss: 0.6458051681518555\n",
            "Epoch: 0, iteración; 4960 de 14277, Loss: 0.588533353805542\n",
            "Epoch: 0, iteración; 4970 de 14277, Loss: 0.5780706405639648\n",
            "Epoch: 0, iteración; 4980 de 14277, Loss: 0.5346272468566895\n",
            "Epoch: 0, iteración; 4990 de 14277, Loss: 0.5896083831787109\n",
            "Epoch: 0, iteración; 5000 de 14277, Loss: 0.5998695373535157\n",
            "Epoch: 0, iteración; 5010 de 14277, Loss: 0.5656089305877685\n",
            "Epoch: 0, iteración; 5020 de 14277, Loss: 0.6237257480621338\n",
            "Epoch: 0, iteración; 5030 de 14277, Loss: 0.6113947868347168\n",
            "Epoch: 0, iteración; 5040 de 14277, Loss: 0.66703200340271\n",
            "Epoch: 0, iteración; 5050 de 14277, Loss: 0.5556011199951172\n",
            "Epoch: 0, iteración; 5060 de 14277, Loss: 0.5457388401031494\n",
            "Epoch: 0, iteración; 5070 de 14277, Loss: 0.6212449550628663\n",
            "Epoch: 0, iteración; 5080 de 14277, Loss: 0.6234926223754883\n",
            "Epoch: 0, iteración; 5090 de 14277, Loss: 0.6001122474670411\n",
            "Epoch: 0, iteración; 5100 de 14277, Loss: 0.5901080131530761\n",
            "Epoch: 0, iteración; 5110 de 14277, Loss: 0.5331343173980713\n",
            "Epoch: 0, iteración; 5120 de 14277, Loss: 0.5532330513000489\n",
            "Epoch: 0, iteración; 5130 de 14277, Loss: 0.6108211994171142\n",
            "Epoch: 0, iteración; 5140 de 14277, Loss: 0.6109705448150635\n",
            "Epoch: 0, iteración; 5150 de 14277, Loss: 0.5769871711730957\n",
            "Epoch: 0, iteración; 5160 de 14277, Loss: 0.5658293247222901\n",
            "Epoch: 0, iteración; 5170 de 14277, Loss: 0.6458652973175049\n",
            "Epoch: 0, iteración; 5180 de 14277, Loss: 0.6117228507995606\n",
            "Epoch: 0, iteración; 5190 de 14277, Loss: 0.5669386386871338\n",
            "Epoch: 0, iteración; 5200 de 14277, Loss: 0.5561563491821289\n",
            "Epoch: 0, iteración; 5210 de 14277, Loss: 0.577226972579956\n",
            "Epoch: 0, iteración; 5220 de 14277, Loss: 0.5999429225921631\n",
            "Epoch: 0, iteración; 5230 de 14277, Loss: 0.48395357131958006\n",
            "Epoch: 0, iteración; 5240 de 14277, Loss: 0.6123532772064209\n",
            "Epoch: 0, iteración; 5250 de 14277, Loss: 0.624256706237793\n",
            "Epoch: 0, iteración; 5260 de 14277, Loss: 0.6002265930175781\n",
            "Epoch: 0, iteración; 5270 de 14277, Loss: 0.5181790828704834\n",
            "Epoch: 0, iteración; 5280 de 14277, Loss: 0.5649005889892578\n",
            "Epoch: 0, iteración; 5290 de 14277, Loss: 0.5282752990722657\n",
            "Epoch: 0, iteración; 5300 de 14277, Loss: 0.5999827861785889\n",
            "Epoch: 0, iteración; 5310 de 14277, Loss: 0.5880703449249267\n",
            "Epoch: 0, iteración; 5320 de 14277, Loss: 0.6600246429443359\n",
            "Epoch: 0, iteración; 5330 de 14277, Loss: 0.6586217403411865\n",
            "Epoch: 0, iteración; 5340 de 14277, Loss: 0.7340651988983155\n",
            "Epoch: 0, iteración; 5350 de 14277, Loss: 0.5799944400787354\n",
            "Epoch: 0, iteración; 5360 de 14277, Loss: 0.5808060169219971\n",
            "Epoch: 0, iteración; 5370 de 14277, Loss: 0.6232530117034912\n",
            "Epoch: 0, iteración; 5380 de 14277, Loss: 0.601564359664917\n",
            "Epoch: 0, iteración; 5390 de 14277, Loss: 0.5680264949798584\n",
            "Epoch: 0, iteración; 5400 de 14277, Loss: 0.6325475692749023\n",
            "Epoch: 0, iteración; 5410 de 14277, Loss: 0.6421774387359619\n",
            "Epoch: 0, iteración; 5420 de 14277, Loss: 0.5918138027191162\n",
            "Epoch: 0, iteración; 5430 de 14277, Loss: 0.6106116771697998\n",
            "Epoch: 0, iteración; 5440 de 14277, Loss: 0.6319766044616699\n",
            "Epoch: 0, iteración; 5450 de 14277, Loss: 0.5708468437194825\n",
            "Epoch: 0, iteración; 5460 de 14277, Loss: 0.48093400001525877\n",
            "Epoch: 0, iteración; 5470 de 14277, Loss: 0.7384487628936768\n",
            "Epoch: 0, iteración; 5480 de 14277, Loss: 0.610844898223877\n",
            "Epoch: 0, iteración; 5490 de 14277, Loss: 0.545136547088623\n",
            "Epoch: 0, iteración; 5500 de 14277, Loss: 0.6458561897277832\n",
            "Epoch: 0, iteración; 5510 de 14277, Loss: 0.49744815826416017\n",
            "Epoch: 0, iteración; 5520 de 14277, Loss: 0.6243328094482422\n",
            "Epoch: 0, iteración; 5530 de 14277, Loss: 0.6113576889038086\n",
            "Epoch: 0, iteración; 5540 de 14277, Loss: 0.5194357395172119\n",
            "Epoch: 0, iteración; 5550 de 14277, Loss: 0.6125159740447998\n",
            "Epoch: 0, iteración; 5560 de 14277, Loss: 0.6696425914764405\n",
            "Epoch: 0, iteración; 5570 de 14277, Loss: 0.656373405456543\n",
            "Epoch: 0, iteración; 5580 de 14277, Loss: 0.6235736846923828\n",
            "Epoch: 0, iteración; 5590 de 14277, Loss: 0.6211266040802002\n",
            "Epoch: 0, iteración; 5600 de 14277, Loss: 0.5617900848388672\n",
            "Epoch: 0, iteración; 5610 de 14277, Loss: 0.5794223785400391\n",
            "Epoch: 0, iteración; 5620 de 14277, Loss: 0.5888250350952149\n",
            "Epoch: 0, iteración; 5630 de 14277, Loss: 0.5660651683807373\n",
            "Epoch: 0, iteración; 5640 de 14277, Loss: 0.5649914741516113\n",
            "Epoch: 0, iteración; 5650 de 14277, Loss: 0.5772121906280517\n",
            "Epoch: 0, iteración; 5660 de 14277, Loss: 0.6939404964447021\n",
            "Epoch: 0, iteración; 5670 de 14277, Loss: 0.5650465965270997\n",
            "Epoch: 0, iteración; 5680 de 14277, Loss: 0.633599328994751\n",
            "Epoch: 0, iteración; 5690 de 14277, Loss: 0.588485860824585\n",
            "Epoch: 0, iteración; 5700 de 14277, Loss: 0.499768590927124\n",
            "Epoch: 0, iteración; 5710 de 14277, Loss: 0.5991203308105468\n",
            "Epoch: 0, iteración; 5720 de 14277, Loss: 0.5888285160064697\n",
            "Epoch: 0, iteración; 5730 de 14277, Loss: 0.7284589290618897\n",
            "Epoch: 0, iteración; 5740 de 14277, Loss: 0.6229046821594239\n",
            "Epoch: 0, iteración; 5750 de 14277, Loss: 0.5349287986755371\n",
            "Epoch: 0, iteración; 5760 de 14277, Loss: 0.4978629589080811\n",
            "Epoch: 0, iteración; 5770 de 14277, Loss: 0.5151415824890136\n",
            "Epoch: 0, iteración; 5780 de 14277, Loss: 0.6250592231750488\n",
            "Epoch: 0, iteración; 5790 de 14277, Loss: 0.6375828266143799\n",
            "Epoch: 0, iteración; 5800 de 14277, Loss: 0.4798106670379639\n",
            "Epoch: 0, iteración; 5810 de 14277, Loss: 0.6129204750061035\n",
            "Epoch: 0, iteración; 5820 de 14277, Loss: 0.6365440368652344\n",
            "Epoch: 0, iteración; 5830 de 14277, Loss: 0.6354360103607177\n",
            "Epoch: 0, iteración; 5840 de 14277, Loss: 0.5663737297058106\n",
            "Epoch: 0, iteración; 5850 de 14277, Loss: 0.6116370677947998\n",
            "Epoch: 0, iteración; 5860 de 14277, Loss: 0.5656547546386719\n",
            "Epoch: 0, iteración; 5870 de 14277, Loss: 0.6230327129364014\n",
            "Epoch: 0, iteración; 5880 de 14277, Loss: 0.5319664955139161\n",
            "Epoch: 0, iteración; 5890 de 14277, Loss: 0.5304659366607666\n",
            "Epoch: 0, iteración; 5900 de 14277, Loss: 0.6361751079559326\n",
            "Epoch: 0, iteración; 5910 de 14277, Loss: 0.6349905967712403\n",
            "Epoch: 0, iteración; 5920 de 14277, Loss: 0.5889214992523193\n",
            "Epoch: 0, iteración; 5930 de 14277, Loss: 0.5782182693481446\n",
            "Epoch: 0, iteración; 5940 de 14277, Loss: 0.6111133575439454\n",
            "Epoch: 0, iteración; 5950 de 14277, Loss: 0.6222905158996582\n",
            "Epoch: 0, iteración; 5960 de 14277, Loss: 0.622794246673584\n",
            "Epoch: 0, iteración; 5970 de 14277, Loss: 0.5008116245269776\n",
            "Epoch: 0, iteración; 5980 de 14277, Loss: 0.5878129005432129\n",
            "Epoch: 0, iteración; 5990 de 14277, Loss: 0.6112652778625488\n",
            "Epoch: 0, iteración; 6000 de 14277, Loss: 0.634428071975708\n",
            "Epoch: 0, iteración; 6010 de 14277, Loss: 0.47432718276977537\n",
            "Epoch: 0, iteración; 6020 de 14277, Loss: 0.5524929523468017\n",
            "Epoch: 0, iteración; 6030 de 14277, Loss: 0.5650121212005615\n",
            "Epoch: 0, iteración; 6040 de 14277, Loss: 0.5762329578399659\n",
            "Epoch: 0, iteración; 6050 de 14277, Loss: 0.6001545429229737\n",
            "Epoch: 0, iteración; 6060 de 14277, Loss: 0.576094675064087\n",
            "Epoch: 0, iteración; 6070 de 14277, Loss: 0.6360301017761231\n",
            "Epoch: 0, iteración; 6080 de 14277, Loss: 0.5995738983154297\n",
            "Epoch: 0, iteración; 6090 de 14277, Loss: 0.6463193416595459\n",
            "Epoch: 0, iteración; 6100 de 14277, Loss: 0.5663920879364014\n",
            "Epoch: 0, iteración; 6110 de 14277, Loss: 0.5333226203918457\n",
            "Epoch: 0, iteración; 6120 de 14277, Loss: 0.5775825500488281\n",
            "Epoch: 0, iteración; 6130 de 14277, Loss: 0.564665699005127\n",
            "Epoch: 0, iteración; 6140 de 14277, Loss: 0.5760439872741699\n",
            "Epoch: 0, iteración; 6150 de 14277, Loss: 0.6477873802185059\n",
            "Epoch: 0, iteración; 6160 de 14277, Loss: 0.6466922283172607\n",
            "Epoch: 0, iteración; 6170 de 14277, Loss: 0.5545266151428223\n",
            "Epoch: 0, iteración; 6180 de 14277, Loss: 0.5084582805633545\n",
            "Epoch: 0, iteración; 6190 de 14277, Loss: 0.6124684810638428\n",
            "Epoch: 0, iteración; 6200 de 14277, Loss: 0.6347238063812256\n",
            "Epoch: 0, iteración; 6210 de 14277, Loss: 0.5539835929870606\n",
            "Epoch: 0, iteración; 6220 de 14277, Loss: 0.5656597137451171\n",
            "Epoch: 0, iteración; 6230 de 14277, Loss: 0.5528007030487061\n",
            "Epoch: 0, iteración; 6240 de 14277, Loss: 0.647239875793457\n",
            "Epoch: 0, iteración; 6250 de 14277, Loss: 0.6237071990966797\n",
            "Epoch: 0, iteración; 6260 de 14277, Loss: 0.6221819877624511\n",
            "Epoch: 0, iteración; 6270 de 14277, Loss: 0.544776201248169\n",
            "Epoch: 0, iteración; 6280 de 14277, Loss: 0.5311032295227051\n",
            "Epoch: 0, iteración; 6290 de 14277, Loss: 0.5540097713470459\n",
            "Epoch: 0, iteración; 6300 de 14277, Loss: 0.6239963054656983\n",
            "Epoch: 0, iteración; 6310 de 14277, Loss: 0.5884769439697266\n",
            "Epoch: 0, iteración; 6320 de 14277, Loss: 0.6316409587860108\n",
            "Epoch: 0, iteración; 6330 de 14277, Loss: 0.5627607345581055\n",
            "Epoch: 0, iteración; 6340 de 14277, Loss: 0.6321921825408936\n",
            "Epoch: 0, iteración; 6350 de 14277, Loss: 0.6158495903015136\n",
            "Epoch: 0, iteración; 6360 de 14277, Loss: 0.6113169670104981\n",
            "Epoch: 0, iteración; 6370 de 14277, Loss: 0.629143762588501\n",
            "Epoch: 0, iteración; 6380 de 14277, Loss: 0.600579309463501\n",
            "Epoch: 0, iteración; 6390 de 14277, Loss: 0.5725865840911866\n",
            "Epoch: 0, iteración; 6400 de 14277, Loss: 0.5775871276855469\n",
            "Epoch: 0, iteración; 6410 de 14277, Loss: 0.6692910194396973\n",
            "Epoch: 0, iteración; 6420 de 14277, Loss: 0.5919164657592774\n",
            "Epoch: 0, iteración; 6430 de 14277, Loss: 0.5658700942993165\n",
            "Epoch: 0, iteración; 6440 de 14277, Loss: 0.6459850788116455\n",
            "Epoch: 0, iteración; 6450 de 14277, Loss: 0.5313890457153321\n",
            "Epoch: 0, iteración; 6460 de 14277, Loss: 0.5540647506713867\n",
            "Epoch: 0, iteración; 6470 de 14277, Loss: 0.6579140186309814\n",
            "Epoch: 0, iteración; 6480 de 14277, Loss: 0.5883508682250976\n",
            "Epoch: 0, iteración; 6490 de 14277, Loss: 0.5885111808776855\n",
            "Epoch: 0, iteración; 6500 de 14277, Loss: 0.5773117065429687\n",
            "Epoch: 0, iteración; 6510 de 14277, Loss: 0.5422155380249023\n",
            "Epoch: 0, iteración; 6520 de 14277, Loss: 0.5996132850646972\n",
            "Epoch: 0, iteración; 6530 de 14277, Loss: 0.5419683933258057\n",
            "Epoch: 0, iteración; 6540 de 14277, Loss: 0.6351134300231933\n",
            "Epoch: 0, iteración; 6550 de 14277, Loss: 0.6689764022827148\n",
            "Epoch: 0, iteración; 6560 de 14277, Loss: 0.6110205173492431\n",
            "Epoch: 0, iteración; 6570 de 14277, Loss: 0.5793581008911133\n",
            "Epoch: 0, iteración; 6580 de 14277, Loss: 0.5562310695648194\n",
            "Epoch: 0, iteración; 6590 de 14277, Loss: 0.5431363105773925\n",
            "Epoch: 0, iteración; 6600 de 14277, Loss: 0.5302335739135742\n",
            "Epoch: 0, iteración; 6610 de 14277, Loss: 0.588606595993042\n",
            "Epoch: 0, iteración; 6620 de 14277, Loss: 0.5281587600708008\n",
            "Epoch: 0, iteración; 6630 de 14277, Loss: 0.6478279113769532\n",
            "Epoch: 0, iteración; 6640 de 14277, Loss: 0.5523608207702637\n",
            "Epoch: 0, iteración; 6650 de 14277, Loss: 0.6127678394317627\n",
            "Epoch: 0, iteración; 6660 de 14277, Loss: 0.6000566005706787\n",
            "Epoch: 0, iteración; 6670 de 14277, Loss: 0.5537751674652099\n",
            "Epoch: 0, iteración; 6680 de 14277, Loss: 0.49378528594970705\n",
            "Epoch: 0, iteración; 6690 de 14277, Loss: 0.5764121055603028\n",
            "Epoch: 0, iteración; 6700 de 14277, Loss: 0.5646358966827393\n",
            "Epoch: 0, iteración; 6710 de 14277, Loss: 0.5642143726348877\n",
            "Epoch: 0, iteración; 6720 de 14277, Loss: 0.46730985641479494\n",
            "Epoch: 0, iteración; 6730 de 14277, Loss: 0.5516624450683594\n",
            "Epoch: 0, iteración; 6740 de 14277, Loss: 0.6492848873138428\n",
            "Epoch: 0, iteración; 6750 de 14277, Loss: 0.563662338256836\n",
            "Epoch: 0, iteración; 6760 de 14277, Loss: 0.6129309654235839\n",
            "Epoch: 0, iteración; 6770 de 14277, Loss: 0.6000885963439941\n",
            "Epoch: 0, iteración; 6780 de 14277, Loss: 0.5759370803833008\n",
            "Epoch: 0, iteración; 6790 de 14277, Loss: 0.6125002384185791\n",
            "Epoch: 0, iteración; 6800 de 14277, Loss: 0.6000404357910156\n",
            "Epoch: 0, iteración; 6810 de 14277, Loss: 0.5653156757354736\n",
            "Epoch: 0, iteración; 6820 de 14277, Loss: 0.5889346122741699\n",
            "Epoch: 0, iteración; 6830 de 14277, Loss: 0.5535050868988037\n",
            "Epoch: 0, iteración; 6840 de 14277, Loss: 0.612235689163208\n",
            "Epoch: 0, iteración; 6850 de 14277, Loss: 0.6808467864990234\n",
            "Epoch: 0, iteración; 6860 de 14277, Loss: 0.5662886142730713\n",
            "Epoch: 0, iteración; 6870 de 14277, Loss: 0.6114052295684814\n",
            "Epoch: 0, iteración; 6880 de 14277, Loss: 0.6329058170318603\n",
            "Epoch: 0, iteración; 6890 de 14277, Loss: 0.5892486095428466\n",
            "Epoch: 0, iteración; 6900 de 14277, Loss: 0.5345499992370606\n",
            "Epoch: 0, iteración; 6910 de 14277, Loss: 0.5774772644042969\n",
            "Epoch: 0, iteración; 6920 de 14277, Loss: 0.5187496662139892\n",
            "Epoch: 0, iteración; 6930 de 14277, Loss: 0.4804572105407715\n",
            "Epoch: 0, iteración; 6940 de 14277, Loss: 0.5998998165130616\n",
            "Epoch: 0, iteración; 6950 de 14277, Loss: 0.6856770515441895\n",
            "Epoch: 0, iteración; 6960 de 14277, Loss: 0.6241815567016602\n",
            "Epoch: 0, iteración; 6970 de 14277, Loss: 0.5531399726867676\n",
            "Epoch: 0, iteración; 6980 de 14277, Loss: 0.5295678615570069\n",
            "Epoch: 0, iteración; 6990 de 14277, Loss: 0.5053208351135254\n",
            "Epoch: 0, iteración; 7000 de 14277, Loss: 0.6368424892425537\n",
            "Epoch: 0, iteración; 7010 de 14277, Loss: 0.5884509563446045\n",
            "Epoch: 0, iteración; 7020 de 14277, Loss: 0.5037362098693847\n",
            "Epoch: 0, iteración; 7030 de 14277, Loss: 0.5757045745849609\n",
            "Epoch: 0, iteración; 7040 de 14277, Loss: 0.5521540641784668\n",
            "Epoch: 0, iteración; 7050 de 14277, Loss: 0.6484658241271972\n",
            "Epoch: 0, iteración; 7060 de 14277, Loss: 0.6242082595825196\n",
            "Epoch: 0, iteración; 7070 de 14277, Loss: 0.6236764907836914\n",
            "Epoch: 0, iteración; 7080 de 14277, Loss: 0.5883160591125488\n",
            "Epoch: 0, iteración; 7090 de 14277, Loss: 0.6126204490661621\n",
            "Epoch: 0, iteración; 7100 de 14277, Loss: 0.5213809013366699\n",
            "Epoch: 0, iteración; 7110 de 14277, Loss: 0.5536334037780761\n",
            "Epoch: 0, iteración; 7120 de 14277, Loss: 0.6242299556732178\n",
            "Epoch: 0, iteración; 7130 de 14277, Loss: 0.636117696762085\n",
            "Epoch: 0, iteración; 7140 de 14277, Loss: 0.6814460754394531\n",
            "Epoch: 0, iteración; 7150 de 14277, Loss: 0.5223320007324219\n",
            "Epoch: 0, iteración; 7160 de 14277, Loss: 0.6908143520355224\n",
            "Epoch: 0, iteración; 7170 de 14277, Loss: 0.6541245460510254\n",
            "Epoch: 0, iteración; 7180 de 14277, Loss: 0.5718506336212158\n",
            "Epoch: 0, iteración; 7190 de 14277, Loss: 0.683414077758789\n",
            "Epoch: 0, iteración; 7200 de 14277, Loss: 0.5415844917297363\n",
            "Epoch: 0, iteración; 7210 de 14277, Loss: 0.4869281768798828\n",
            "Epoch: 0, iteración; 7220 de 14277, Loss: 0.5402929782867432\n",
            "Epoch: 0, iteración; 7230 de 14277, Loss: 0.5510976791381836\n",
            "Epoch: 0, iteración; 7240 de 14277, Loss: 0.5760798454284668\n",
            "Epoch: 0, iteración; 7250 de 14277, Loss: 0.5758588790893555\n",
            "Epoch: 0, iteración; 7260 de 14277, Loss: 0.6862105369567871\n",
            "Epoch: 0, iteración; 7270 de 14277, Loss: 0.5768224716186523\n",
            "Epoch: 0, iteración; 7280 de 14277, Loss: 0.5756133556365967\n",
            "Epoch: 0, iteración; 7290 de 14277, Loss: 0.6471022605895996\n",
            "Epoch: 0, iteración; 7300 de 14277, Loss: 0.6008589744567872\n",
            "Epoch: 0, iteración; 7310 de 14277, Loss: 0.5109529495239258\n",
            "Epoch: 0, iteración; 7320 de 14277, Loss: 0.5998739719390869\n",
            "Epoch: 0, iteración; 7330 de 14277, Loss: 0.6940564155578614\n",
            "Epoch: 0, iteración; 7340 de 14277, Loss: 0.6457581043243408\n",
            "Epoch: 0, iteración; 7350 de 14277, Loss: 0.5581112861633301\n",
            "Epoch: 0, iteración; 7360 de 14277, Loss: 0.588095760345459\n",
            "Epoch: 0, iteración; 7370 de 14277, Loss: 0.6888257503509522\n",
            "Epoch: 0, iteración; 7380 de 14277, Loss: 0.6200648307800293\n",
            "Epoch: 0, iteración; 7390 de 14277, Loss: 0.6291421413421631\n",
            "Epoch: 0, iteración; 7400 de 14277, Loss: 0.6754844665527344\n",
            "Epoch: 0, iteración; 7410 de 14277, Loss: 0.5916380882263184\n",
            "Epoch: 0, iteración; 7420 de 14277, Loss: 0.631660795211792\n",
            "Epoch: 0, iteración; 7430 de 14277, Loss: 0.5934796333312988\n",
            "Epoch: 0, iteración; 7440 de 14277, Loss: 0.6712849617004395\n",
            "Epoch: 0, iteración; 7450 de 14277, Loss: 0.6434296131134033\n",
            "Epoch: 0, iteración; 7460 de 14277, Loss: 0.6297991275787354\n",
            "Epoch: 0, iteración; 7470 de 14277, Loss: 0.6226191520690918\n",
            "Epoch: 0, iteración; 7480 de 14277, Loss: 0.5945255279541015\n",
            "Epoch: 0, iteración; 7490 de 14277, Loss: 0.5601038932800293\n",
            "Epoch: 0, iteración; 7500 de 14277, Loss: 0.6704830169677735\n",
            "Epoch: 0, iteración; 7510 de 14277, Loss: 0.5430052757263184\n",
            "Epoch: 0, iteración; 7520 de 14277, Loss: 0.5883004665374756\n",
            "Epoch: 0, iteración; 7530 de 14277, Loss: 0.5301372051239014\n",
            "Epoch: 0, iteración; 7540 de 14277, Loss: 0.612419319152832\n",
            "Epoch: 0, iteración; 7550 de 14277, Loss: 0.565457820892334\n",
            "Epoch: 0, iteración; 7560 de 14277, Loss: 0.6115128517150878\n",
            "Epoch: 0, iteración; 7570 de 14277, Loss: 0.5291563987731933\n",
            "Epoch: 0, iteración; 7580 de 14277, Loss: 0.6480545997619629\n",
            "Epoch: 0, iteración; 7590 de 14277, Loss: 0.623743200302124\n",
            "Epoch: 0, iteración; 7600 de 14277, Loss: 0.5542530059814453\n",
            "Epoch: 0, iteración; 7610 de 14277, Loss: 0.6918814659118653\n",
            "Epoch: 0, iteración; 7620 de 14277, Loss: 0.7364267826080322\n",
            "Epoch: 0, iteración; 7630 de 14277, Loss: 0.5381112098693848\n",
            "Epoch: 0, iteración; 7640 de 14277, Loss: 0.5807380676269531\n",
            "Epoch: 0, iteración; 7650 de 14277, Loss: 0.6118205547332763\n",
            "Epoch: 0, iteración; 7660 de 14277, Loss: 0.6343984603881836\n",
            "Epoch: 0, iteración; 7670 de 14277, Loss: 0.6107511043548584\n",
            "Epoch: 0, iteración; 7680 de 14277, Loss: 0.6323657512664795\n",
            "Epoch: 0, iteración; 7690 de 14277, Loss: 0.570643424987793\n",
            "Epoch: 0, iteración; 7700 de 14277, Loss: 0.5469391822814942\n",
            "Epoch: 0, iteración; 7710 de 14277, Loss: 0.5898006439208985\n",
            "Epoch: 0, iteración; 7720 de 14277, Loss: 0.5876338958740235\n",
            "Epoch: 0, iteración; 7730 de 14277, Loss: 0.49496893882751464\n",
            "Epoch: 0, iteración; 7740 de 14277, Loss: 0.5643741607666015\n",
            "Epoch: 0, iteración; 7750 de 14277, Loss: 0.5752670764923096\n",
            "Epoch: 0, iteración; 7760 de 14277, Loss: 0.6595967769622803\n",
            "Epoch: 0, iteración; 7770 de 14277, Loss: 0.566003942489624\n",
            "Epoch: 0, iteración; 7780 de 14277, Loss: 0.5419662952423095\n",
            "Epoch: 0, iteración; 7790 de 14277, Loss: 0.5049891948699952\n",
            "Epoch: 0, iteración; 7800 de 14277, Loss: 0.660038948059082\n",
            "Epoch: 0, iteración; 7810 de 14277, Loss: 0.5641608238220215\n",
            "Epoch: 0, iteración; 7820 de 14277, Loss: 0.6357030391693115\n",
            "Epoch: 0, iteración; 7830 de 14277, Loss: 0.5420430660247803\n",
            "Epoch: 0, iteración; 7840 de 14277, Loss: 0.704912519454956\n",
            "Epoch: 0, iteración; 7850 de 14277, Loss: 0.5202849388122559\n",
            "Epoch: 0, iteración; 7860 de 14277, Loss: 0.5652786254882812\n",
            "Epoch: 0, iteración; 7870 de 14277, Loss: 0.6342424392700196\n",
            "Epoch: 0, iteración; 7880 de 14277, Loss: 0.6342312812805175\n",
            "Epoch: 0, iteración; 7890 de 14277, Loss: 0.6123167991638183\n",
            "Epoch: 0, iteración; 7900 de 14277, Loss: 0.5898383617401123\n",
            "Epoch: 0, iteración; 7910 de 14277, Loss: 0.6007328987121582\n",
            "Epoch: 0, iteración; 7920 de 14277, Loss: 0.6006863117218018\n",
            "Epoch: 0, iteración; 7930 de 14277, Loss: 0.578047227859497\n",
            "Epoch: 0, iteración; 7940 de 14277, Loss: 0.5668070793151856\n",
            "Epoch: 0, iteración; 7950 de 14277, Loss: 0.6341038703918457\n",
            "Epoch: 0, iteración; 7960 de 14277, Loss: 0.521630859375\n",
            "Epoch: 0, iteración; 7970 de 14277, Loss: 0.6342348098754883\n",
            "Epoch: 0, iteración; 7980 de 14277, Loss: 0.5187155246734619\n",
            "Epoch: 0, iteración; 7990 de 14277, Loss: 0.5416927814483643\n",
            "Epoch: 0, iteración; 8000 de 14277, Loss: 0.540669059753418\n",
            "Epoch: 0, iteración; 8010 de 14277, Loss: 0.6124705791473388\n",
            "Epoch: 0, iteración; 8020 de 14277, Loss: 0.5999761104583741\n",
            "Epoch: 0, iteración; 8030 de 14277, Loss: 0.5282681465148926\n",
            "Epoch: 0, iteración; 8040 de 14277, Loss: 0.5643882751464844\n",
            "Epoch: 0, iteración; 8050 de 14277, Loss: 0.6120142459869384\n",
            "Epoch: 0, iteración; 8060 de 14277, Loss: 0.6364717483520508\n",
            "Epoch: 0, iteración; 8070 de 14277, Loss: 0.6356390476226806\n",
            "Epoch: 0, iteración; 8080 de 14277, Loss: 0.6565103530883789\n",
            "Epoch: 0, iteración; 8090 de 14277, Loss: 0.6110684871673584\n",
            "Epoch: 0, iteración; 8100 de 14277, Loss: 0.6117197036743164\n",
            "Epoch: 0, iteración; 8110 de 14277, Loss: 0.5698635578155518\n",
            "Epoch: 0, iteración; 8120 de 14277, Loss: 0.5899378299713135\n",
            "Epoch: 0, iteración; 8130 de 14277, Loss: 0.5554941654205322\n",
            "Epoch: 0, iteración; 8140 de 14277, Loss: 0.588558292388916\n",
            "Epoch: 0, iteración; 8150 de 14277, Loss: 0.6676904678344726\n",
            "Epoch: 0, iteración; 8160 de 14277, Loss: 0.6002349853515625\n",
            "Epoch: 0, iteración; 8170 de 14277, Loss: 0.5681662082672119\n",
            "Epoch: 0, iteración; 8180 de 14277, Loss: 0.6336322784423828\n",
            "Epoch: 0, iteración; 8190 de 14277, Loss: 0.4905416488647461\n",
            "Epoch: 0, iteración; 8200 de 14277, Loss: 0.5065567493438721\n",
            "Epoch: 0, iteración; 8210 de 14277, Loss: 0.6610319137573242\n",
            "Epoch: 0, iteración; 8220 de 14277, Loss: 0.6002071380615235\n",
            "Epoch: 0, iteración; 8230 de 14277, Loss: 0.6484183311462403\n",
            "Epoch: 0, iteración; 8240 de 14277, Loss: 0.5874547004699707\n",
            "Epoch: 0, iteración; 8250 de 14277, Loss: 0.5063503742218017\n",
            "Epoch: 0, iteración; 8260 de 14277, Loss: 0.6244947910308838\n",
            "Epoch: 0, iteración; 8270 de 14277, Loss: 0.5292162895202637\n",
            "Epoch: 0, iteración; 8280 de 14277, Loss: 0.6594420433044433\n",
            "Epoch: 0, iteración; 8290 de 14277, Loss: 0.6701981067657471\n",
            "Epoch: 0, iteración; 8300 de 14277, Loss: 0.510311508178711\n",
            "Epoch: 0, iteración; 8310 de 14277, Loss: 0.6459874153137207\n",
            "Epoch: 0, iteración; 8320 de 14277, Loss: 0.6117652416229248\n",
            "Epoch: 0, iteración; 8330 de 14277, Loss: 0.5882907390594483\n",
            "Epoch: 0, iteración; 8340 de 14277, Loss: 0.5891356945037842\n",
            "Epoch: 0, iteración; 8350 de 14277, Loss: 0.7103198051452637\n",
            "Epoch: 0, iteración; 8360 de 14277, Loss: 0.6321037292480469\n",
            "Epoch: 0, iteración; 8370 de 14277, Loss: 0.5923799037933349\n",
            "Epoch: 0, iteración; 8380 de 14277, Loss: 0.581722640991211\n",
            "Epoch: 0, iteración; 8390 de 14277, Loss: 0.5482007026672363\n",
            "Epoch: 0, iteración; 8400 de 14277, Loss: 0.532301664352417\n",
            "Epoch: 0, iteración; 8410 de 14277, Loss: 0.5886489391326905\n",
            "Epoch: 0, iteración; 8420 de 14277, Loss: 0.5758527755737305\n",
            "Epoch: 0, iteración; 8430 de 14277, Loss: 0.611649751663208\n",
            "Epoch: 0, iteración; 8440 de 14277, Loss: 0.5764722347259521\n",
            "Epoch: 0, iteración; 8450 de 14277, Loss: 0.611643934249878\n",
            "Epoch: 0, iteración; 8460 de 14277, Loss: 0.5881967544555664\n",
            "Epoch: 0, iteración; 8470 de 14277, Loss: 0.5433529376983642\n",
            "Epoch: 0, iteración; 8480 de 14277, Loss: 0.565463638305664\n",
            "Epoch: 0, iteración; 8490 de 14277, Loss: 0.6004555225372314\n",
            "Epoch: 0, iteración; 8500 de 14277, Loss: 0.5411429882049561\n",
            "Epoch: 0, iteración; 8510 de 14277, Loss: 0.5883429050445557\n",
            "Epoch: 0, iteración; 8520 de 14277, Loss: 0.5169863700866699\n",
            "Epoch: 0, iteración; 8530 de 14277, Loss: 0.6243936061859131\n",
            "Epoch: 0, iteración; 8540 de 14277, Loss: 0.5404711723327636\n",
            "Epoch: 0, iteración; 8550 de 14277, Loss: 0.6356257438659668\n",
            "Epoch: 0, iteración; 8560 de 14277, Loss: 0.6355173110961914\n",
            "Epoch: 0, iteración; 8570 de 14277, Loss: 0.5180613994598389\n",
            "Epoch: 0, iteración; 8580 de 14277, Loss: 0.48233399391174314\n",
            "Epoch: 0, iteración; 8590 de 14277, Loss: 0.5155569553375244\n",
            "Epoch: 0, iteración; 8600 de 14277, Loss: 0.6006155490875245\n",
            "Epoch: 0, iteración; 8610 de 14277, Loss: 0.5635532379150391\n",
            "Epoch: 0, iteración; 8620 de 14277, Loss: 0.6369677066802979\n",
            "Epoch: 0, iteración; 8630 de 14277, Loss: 0.5522381782531738\n",
            "Epoch: 0, iteración; 8640 de 14277, Loss: 0.6242478370666504\n",
            "Epoch: 0, iteración; 8650 de 14277, Loss: 0.588447093963623\n",
            "Epoch: 0, iteración; 8660 de 14277, Loss: 0.5769848823547363\n",
            "Epoch: 0, iteración; 8670 de 14277, Loss: 0.5769991397857666\n",
            "Epoch: 0, iteración; 8680 de 14277, Loss: 0.6240516185760498\n",
            "Epoch: 0, iteración; 8690 de 14277, Loss: 0.691617774963379\n",
            "Epoch: 0, iteración; 8700 de 14277, Loss: 0.5896820068359375\n",
            "Epoch: 0, iteración; 8710 de 14277, Loss: 0.6095323085784912\n",
            "Epoch: 0, iteración; 8720 de 14277, Loss: 0.525994062423706\n",
            "Epoch: 0, iteración; 8730 de 14277, Loss: 0.5874558448791504\n",
            "Epoch: 0, iteración; 8740 de 14277, Loss: 0.5876959800720215\n",
            "Epoch: 0, iteración; 8750 de 14277, Loss: 0.6457108497619629\n",
            "Epoch: 0, iteración; 8760 de 14277, Loss: 0.6326345443725586\n",
            "Epoch: 0, iteración; 8770 de 14277, Loss: 0.4907837390899658\n",
            "Epoch: 0, iteración; 8780 de 14277, Loss: 0.4970214366912842\n",
            "Epoch: 0, iteración; 8790 de 14277, Loss: 0.5156430244445801\n",
            "Epoch: 0, iteración; 8800 de 14277, Loss: 0.6736551761627197\n",
            "Epoch: 0, iteración; 8810 de 14277, Loss: 0.5277238845825195\n",
            "Epoch: 0, iteración; 8820 de 14277, Loss: 0.600451135635376\n",
            "Epoch: 0, iteración; 8830 de 14277, Loss: 0.6245296478271485\n",
            "Epoch: 0, iteración; 8840 de 14277, Loss: 0.6716949462890625\n",
            "Epoch: 0, iteración; 8850 de 14277, Loss: 0.6231054782867431\n",
            "Epoch: 0, iteración; 8860 de 14277, Loss: 0.5999823570251465\n",
            "Epoch: 0, iteración; 8870 de 14277, Loss: 0.5560678005218506\n",
            "Epoch: 0, iteración; 8880 de 14277, Loss: 0.5661156177520752\n",
            "Epoch: 0, iteración; 8890 de 14277, Loss: 0.5755655288696289\n",
            "Epoch: 0, iteración; 8900 de 14277, Loss: 0.6692334651947022\n",
            "Epoch: 0, iteración; 8910 de 14277, Loss: 0.6124348640441895\n",
            "Epoch: 0, iteración; 8920 de 14277, Loss: 0.5998067855834961\n",
            "Epoch: 0, iteración; 8930 de 14277, Loss: 0.5783860206604003\n",
            "Epoch: 0, iteración; 8940 de 14277, Loss: 0.6015657424926758\n",
            "Epoch: 0, iteración; 8950 de 14277, Loss: 0.5550064086914063\n",
            "Epoch: 0, iteración; 8960 de 14277, Loss: 0.6334933280944824\n",
            "Epoch: 0, iteración; 8970 de 14277, Loss: 0.5670606613159179\n",
            "Epoch: 0, iteración; 8980 de 14277, Loss: 0.5894254684448242\n",
            "Epoch: 0, iteración; 8990 de 14277, Loss: 0.6349587440490723\n",
            "Epoch: 0, iteración; 9000 de 14277, Loss: 0.6232414722442627\n",
            "Epoch: 0, iteración; 9010 de 14277, Loss: 0.5445051670074463\n",
            "Epoch: 0, iteración; 9020 de 14277, Loss: 0.6243876457214356\n",
            "Epoch: 0, iteración; 9030 de 14277, Loss: 0.6569632053375244\n",
            "Epoch: 0, iteración; 9040 de 14277, Loss: 0.6100325584411621\n",
            "Epoch: 0, iteración; 9050 de 14277, Loss: 0.568403673171997\n",
            "Epoch: 0, iteración; 9060 de 14277, Loss: 0.6003421783447266\n",
            "Epoch: 0, iteración; 9070 de 14277, Loss: 0.5677994728088379\n",
            "Epoch: 0, iteración; 9080 de 14277, Loss: 0.6552579402923584\n",
            "Epoch: 0, iteración; 9090 de 14277, Loss: 0.5006059646606446\n",
            "Epoch: 0, iteración; 9100 de 14277, Loss: 0.576421070098877\n",
            "Epoch: 0, iteración; 9110 de 14277, Loss: 0.6007076263427734\n",
            "Epoch: 0, iteración; 9120 de 14277, Loss: 0.5998848438262939\n",
            "Epoch: 0, iteración; 9130 de 14277, Loss: 0.5769818305969239\n",
            "Epoch: 0, iteración; 9140 de 14277, Loss: 0.5661384105682373\n",
            "Epoch: 0, iteración; 9150 de 14277, Loss: 0.5880910873413085\n",
            "Epoch: 0, iteración; 9160 de 14277, Loss: 0.576362419128418\n",
            "Epoch: 0, iteración; 9170 de 14277, Loss: 0.577014684677124\n",
            "Epoch: 0, iteración; 9180 de 14277, Loss: 0.5528147697448731\n",
            "Epoch: 0, iteración; 9190 de 14277, Loss: 0.5414219379425049\n",
            "Epoch: 0, iteración; 9200 de 14277, Loss: 0.5761688232421875\n",
            "Epoch: 0, iteración; 9210 de 14277, Loss: 0.6240537166595459\n",
            "Epoch: 0, iteración; 9220 de 14277, Loss: 0.5402501106262207\n",
            "Epoch: 0, iteración; 9230 de 14277, Loss: 0.5767178535461426\n",
            "Epoch: 0, iteración; 9240 de 14277, Loss: 0.5284121036529541\n",
            "Epoch: 0, iteración; 9250 de 14277, Loss: 0.624091100692749\n",
            "Epoch: 0, iteración; 9260 de 14277, Loss: 0.5287018775939941\n",
            "Epoch: 0, iteración; 9270 de 14277, Loss: 0.5763431549072265\n",
            "Epoch: 0, iteración; 9280 de 14277, Loss: 0.5164061546325683\n",
            "Epoch: 0, iteración; 9290 de 14277, Loss: 0.576268196105957\n",
            "Epoch: 0, iteración; 9300 de 14277, Loss: 0.552151870727539\n",
            "Epoch: 0, iteración; 9310 de 14277, Loss: 0.515980863571167\n",
            "Epoch: 0, iteración; 9320 de 14277, Loss: 0.5151900291442871\n",
            "Epoch: 0, iteración; 9330 de 14277, Loss: 0.5390288352966308\n",
            "Epoch: 0, iteración; 9340 de 14277, Loss: 0.6854539394378663\n",
            "Epoch: 0, iteración; 9350 de 14277, Loss: 0.6005373954772949\n",
            "Epoch: 0, iteración; 9360 de 14277, Loss: 0.5880973815917969\n",
            "Epoch: 0, iteración; 9370 de 14277, Loss: 0.5879746913909912\n",
            "Epoch: 0, iteración; 9380 de 14277, Loss: 0.6231649398803711\n",
            "Epoch: 0, iteración; 9390 de 14277, Loss: 0.6688068389892579\n",
            "Epoch: 0, iteración; 9400 de 14277, Loss: 0.5782748222351074\n",
            "Epoch: 0, iteración; 9410 de 14277, Loss: 0.6434684753417969\n",
            "Epoch: 0, iteración; 9420 de 14277, Loss: 0.5588619232177734\n",
            "Epoch: 0, iteración; 9430 de 14277, Loss: 0.622035026550293\n",
            "Epoch: 0, iteración; 9440 de 14277, Loss: 0.544989538192749\n",
            "Epoch: 0, iteración; 9450 de 14277, Loss: 0.5098259449005127\n",
            "Epoch: 0, iteración; 9460 de 14277, Loss: 0.6231928825378418\n",
            "Epoch: 0, iteración; 9470 de 14277, Loss: 0.5764331340789794\n",
            "Epoch: 0, iteración; 9480 de 14277, Loss: 0.589307165145874\n",
            "Epoch: 0, iteración; 9490 de 14277, Loss: 0.5646921634674072\n",
            "Epoch: 0, iteración; 9500 de 14277, Loss: 0.6356679439544678\n",
            "Epoch: 0, iteración; 9510 de 14277, Loss: 0.5182017803192138\n",
            "Epoch: 0, iteración; 9520 de 14277, Loss: 0.6229334831237793\n",
            "Epoch: 0, iteración; 9530 de 14277, Loss: 0.576039171218872\n",
            "Epoch: 0, iteración; 9540 de 14277, Loss: 0.541676664352417\n",
            "Epoch: 0, iteración; 9550 de 14277, Loss: 0.5410799026489258\n",
            "Epoch: 0, iteración; 9560 de 14277, Loss: 0.6005650997161865\n",
            "Epoch: 0, iteración; 9570 de 14277, Loss: 0.6002621173858642\n",
            "Epoch: 0, iteración; 9580 de 14277, Loss: 0.5765241622924805\n",
            "Epoch: 0, iteración; 9590 de 14277, Loss: 0.5168325424194335\n",
            "Epoch: 0, iteración; 9600 de 14277, Loss: 0.539777135848999\n",
            "Epoch: 0, iteración; 9610 de 14277, Loss: 0.5034963130950928\n",
            "Epoch: 0, iteración; 9620 de 14277, Loss: 0.6127637386322021\n",
            "Epoch: 0, iteración; 9630 de 14277, Loss: 0.5878956317901611\n",
            "Epoch: 0, iteración; 9640 de 14277, Loss: 0.6371147632598877\n",
            "Epoch: 0, iteración; 9650 de 14277, Loss: 0.6002058029174805\n",
            "Epoch: 0, iteración; 9660 de 14277, Loss: 0.5994690895080567\n",
            "Epoch: 0, iteración; 9670 de 14277, Loss: 0.6113441467285157\n",
            "Epoch: 0, iteración; 9680 de 14277, Loss: 0.6804756641387939\n",
            "Epoch: 0, iteración; 9690 de 14277, Loss: 0.49093236923217776\n",
            "Epoch: 0, iteración; 9700 de 14277, Loss: 0.5650879383087158\n",
            "Epoch: 0, iteración; 9710 de 14277, Loss: 0.5533254623413086\n",
            "Epoch: 0, iteración; 9720 de 14277, Loss: 0.6120189666748047\n",
            "Epoch: 0, iteración; 9730 de 14277, Loss: 0.6243800640106201\n",
            "Epoch: 0, iteración; 9740 de 14277, Loss: 0.6353219032287598\n",
            "Epoch: 0, iteración; 9750 de 14277, Loss: 0.5774298191070557\n",
            "Epoch: 0, iteración; 9760 de 14277, Loss: 0.611385726928711\n",
            "Epoch: 0, iteración; 9770 de 14277, Loss: 0.610997486114502\n",
            "Epoch: 0, iteración; 9780 de 14277, Loss: 0.6657607078552246\n",
            "Epoch: 0, iteración; 9790 de 14277, Loss: 0.5895270824432373\n",
            "Epoch: 0, iteración; 9800 de 14277, Loss: 0.6663655281066895\n",
            "Epoch: 0, iteración; 9810 de 14277, Loss: 0.583941125869751\n",
            "Epoch: 0, iteración; 9820 de 14277, Loss: 0.5379151344299317\n",
            "Epoch: 0, iteración; 9830 de 14277, Loss: 0.5295043468475342\n",
            "Epoch: 0, iteración; 9840 de 14277, Loss: 0.6007227897644043\n",
            "Epoch: 0, iteración; 9850 de 14277, Loss: 0.6375048637390137\n",
            "Epoch: 0, iteración; 9860 de 14277, Loss: 0.5636699676513672\n",
            "Epoch: 0, iteración; 9870 de 14277, Loss: 0.6127312183380127\n",
            "Epoch: 0, iteración; 9880 de 14277, Loss: 0.5527987480163574\n",
            "Epoch: 0, iteración; 9890 de 14277, Loss: 0.5767652034759522\n",
            "Epoch: 0, iteración; 9900 de 14277, Loss: 0.5528270721435546\n",
            "Epoch: 0, iteración; 9910 de 14277, Loss: 0.6241473197937012\n",
            "Epoch: 0, iteración; 9920 de 14277, Loss: 0.6123604297637939\n",
            "Epoch: 0, iteración; 9930 de 14277, Loss: 0.5769613742828369\n",
            "Epoch: 0, iteración; 9940 de 14277, Loss: 0.5998342037200928\n",
            "Epoch: 0, iteración; 9950 de 14277, Loss: 0.5202681541442871\n",
            "Epoch: 0, iteración; 9960 de 14277, Loss: 0.6586741447448731\n",
            "Epoch: 0, iteración; 9970 de 14277, Loss: 0.6684596061706543\n",
            "Epoch: 0, iteración; 9980 de 14277, Loss: 0.5449939250946045\n",
            "Epoch: 0, iteración; 9990 de 14277, Loss: 0.6225183486938477\n",
            "Epoch: 0, iteración; 10000 de 14277, Loss: 0.5890365600585937\n",
            "Epoch: 0, iteración; 10010 de 14277, Loss: 0.6324847221374512\n",
            "Epoch: 0, iteración; 10020 de 14277, Loss: 0.5909956932067871\n",
            "Epoch: 0, iteración; 10030 de 14277, Loss: 0.5990202903747559\n",
            "Epoch: 0, iteración; 10040 de 14277, Loss: 0.6211377620697022\n",
            "Epoch: 0, iteración; 10050 de 14277, Loss: 0.5237400531768799\n",
            "Epoch: 0, iteración; 10060 de 14277, Loss: 0.6333131313323974\n",
            "Epoch: 0, iteración; 10070 de 14277, Loss: 0.6120911121368409\n",
            "Epoch: 0, iteración; 10080 de 14277, Loss: 0.5450165748596192\n",
            "Epoch: 0, iteración; 10090 de 14277, Loss: 0.5550923347473145\n",
            "Epoch: 0, iteración; 10100 de 14277, Loss: 0.5302511692047119\n",
            "Epoch: 0, iteración; 10110 de 14277, Loss: 0.5280118942260742\n",
            "Epoch: 0, iteración; 10120 de 14277, Loss: 0.5274765968322754\n",
            "Epoch: 0, iteración; 10130 de 14277, Loss: 0.6127038955688476\n",
            "Epoch: 0, iteración; 10140 de 14277, Loss: 0.6001965999603271\n",
            "Epoch: 0, iteración; 10150 de 14277, Loss: 0.5886329650878906\n",
            "Epoch: 0, iteración; 10160 de 14277, Loss: 0.5759248256683349\n",
            "Epoch: 0, iteración; 10170 de 14277, Loss: 0.5885655879974365\n",
            "Epoch: 0, iteración; 10180 de 14277, Loss: 0.5885733604431153\n",
            "Epoch: 0, iteración; 10190 de 14277, Loss: 0.5878472805023194\n",
            "Epoch: 0, iteración; 10200 de 14277, Loss: 0.5996873378753662\n",
            "Epoch: 0, iteración; 10210 de 14277, Loss: 0.5999927997589112\n",
            "Epoch: 0, iteración; 10220 de 14277, Loss: 0.5658023834228516\n",
            "Epoch: 0, iteración; 10230 de 14277, Loss: 0.6684757709503174\n",
            "Epoch: 0, iteración; 10240 de 14277, Loss: 0.6110067367553711\n",
            "Epoch: 0, iteración; 10250 de 14277, Loss: 0.6219161987304688\n",
            "Epoch: 0, iteración; 10260 de 14277, Loss: 0.5680915832519531\n",
            "Epoch: 0, iteración; 10270 de 14277, Loss: 0.6631272315979004\n",
            "Epoch: 0, iteración; 10280 de 14277, Loss: 0.6000720024108886\n",
            "Epoch: 0, iteración; 10290 de 14277, Loss: 0.6120104312896728\n",
            "Epoch: 0, iteración; 10300 de 14277, Loss: 0.5491750717163086\n",
            "Epoch: 0, iteración; 10310 de 14277, Loss: 0.589178466796875\n",
            "Epoch: 0, iteración; 10320 de 14277, Loss: 0.6008071899414062\n",
            "Epoch: 0, iteración; 10330 de 14277, Loss: 0.5549800872802735\n",
            "Epoch: 0, iteración; 10340 de 14277, Loss: 0.6004885196685791\n",
            "Epoch: 0, iteración; 10350 de 14277, Loss: 0.669537353515625\n",
            "Epoch: 0, iteración; 10360 de 14277, Loss: 0.6332605361938477\n",
            "Epoch: 0, iteración; 10370 de 14277, Loss: 0.5886707305908203\n",
            "Epoch: 0, iteración; 10380 de 14277, Loss: 0.6228762626647949\n",
            "Epoch: 0, iteración; 10390 de 14277, Loss: 0.6207276344299316\n",
            "Epoch: 0, iteración; 10400 de 14277, Loss: 0.549745512008667\n",
            "Epoch: 0, iteración; 10410 de 14277, Loss: 0.5897393226623535\n",
            "Epoch: 0, iteración; 10420 de 14277, Loss: 0.5892541408538818\n",
            "Epoch: 0, iteración; 10430 de 14277, Loss: 0.679643201828003\n",
            "Epoch: 0, iteración; 10440 de 14277, Loss: 0.557276725769043\n",
            "Epoch: 0, iteración; 10450 de 14277, Loss: 0.4986879825592041\n",
            "Epoch: 0, iteración; 10460 de 14277, Loss: 0.5885590553283692\n",
            "Epoch: 0, iteración; 10470 de 14277, Loss: 0.5522266864776612\n",
            "Epoch: 0, iteración; 10480 de 14277, Loss: 0.636894702911377\n",
            "Epoch: 0, iteración; 10490 de 14277, Loss: 0.5638293743133544\n",
            "Epoch: 0, iteración; 10500 de 14277, Loss: 0.5882680892944336\n",
            "Epoch: 0, iteración; 10510 de 14277, Loss: 0.5647551536560058\n",
            "Epoch: 0, iteración; 10520 de 14277, Loss: 0.5287276268005371\n",
            "Epoch: 0, iteración; 10530 de 14277, Loss: 0.5638493061065674\n",
            "Epoch: 0, iteración; 10540 de 14277, Loss: 0.6001473903656006\n",
            "Epoch: 0, iteración; 10550 de 14277, Loss: 0.5993339538574218\n",
            "Epoch: 0, iteración; 10560 de 14277, Loss: 0.576669979095459\n",
            "Epoch: 0, iteración; 10570 de 14277, Loss: 0.6586298942565918\n",
            "Epoch: 0, iteración; 10580 de 14277, Loss: 0.6570217132568359\n",
            "Epoch: 0, iteración; 10590 de 14277, Loss: 0.5800001144409179\n",
            "Epoch: 0, iteración; 10600 de 14277, Loss: 0.6540756225585938\n",
            "Epoch: 0, iteración; 10610 de 14277, Loss: 0.6528764724731445\n",
            "Epoch: 0, iteración; 10620 de 14277, Loss: 0.6315094947814941\n",
            "Epoch: 0, iteración; 10630 de 14277, Loss: 0.5455492019653321\n",
            "Epoch: 0, iteración; 10640 de 14277, Loss: 0.6340008735656738\n",
            "Epoch: 0, iteración; 10650 de 14277, Loss: 0.5458148956298828\n",
            "Epoch: 0, iteración; 10660 de 14277, Loss: 0.6337966442108154\n",
            "Epoch: 0, iteración; 10670 de 14277, Loss: 0.5674508094787598\n",
            "Epoch: 0, iteración; 10680 de 14277, Loss: 0.6008461475372314\n",
            "Epoch: 0, iteración; 10690 de 14277, Loss: 0.49649224281311033\n",
            "Epoch: 0, iteración; 10700 de 14277, Loss: 0.6237299919128418\n",
            "Epoch: 0, iteración; 10710 de 14277, Loss: 0.6118367195129395\n",
            "Epoch: 0, iteración; 10720 de 14277, Loss: 0.6003971099853516\n",
            "Epoch: 0, iteración; 10730 de 14277, Loss: 0.6113508224487305\n",
            "Epoch: 0, iteración; 10740 de 14277, Loss: 0.6119576930999756\n",
            "Epoch: 0, iteración; 10750 de 14277, Loss: 0.6108961582183838\n",
            "Epoch: 0, iteración; 10760 de 14277, Loss: 0.6107656002044678\n",
            "Epoch: 0, iteración; 10770 de 14277, Loss: 0.5998941421508789\n",
            "Epoch: 0, iteración; 10780 de 14277, Loss: 0.5900533676147461\n",
            "Epoch: 0, iteración; 10790 de 14277, Loss: 0.5353584289550781\n",
            "Epoch: 0, iteración; 10800 de 14277, Loss: 0.5887079238891602\n",
            "Epoch: 0, iteración; 10810 de 14277, Loss: 0.6581714630126954\n",
            "Epoch: 0, iteración; 10820 de 14277, Loss: 0.6124602317810058\n",
            "Epoch: 0, iteración; 10830 de 14277, Loss: 0.6219836711883545\n",
            "Epoch: 0, iteración; 10840 de 14277, Loss: 0.5679322719573975\n",
            "Epoch: 0, iteración; 10850 de 14277, Loss: 0.5894888877868653\n",
            "Epoch: 0, iteración; 10860 de 14277, Loss: 0.5436160087585449\n",
            "Epoch: 0, iteración; 10870 de 14277, Loss: 0.6234744548797607\n",
            "Epoch: 0, iteración; 10880 de 14277, Loss: 0.6230986595153809\n",
            "Epoch: 0, iteración; 10890 de 14277, Loss: 0.49590530395507815\n",
            "Epoch: 0, iteración; 10900 de 14277, Loss: 0.5294761657714844\n",
            "Epoch: 0, iteración; 10910 de 14277, Loss: 0.6125691890716553\n",
            "Epoch: 0, iteración; 10920 de 14277, Loss: 0.5763679027557373\n",
            "Epoch: 0, iteración; 10930 de 14277, Loss: 0.6601183891296387\n",
            "Epoch: 0, iteración; 10940 de 14277, Loss: 0.5654045104980469\n",
            "Epoch: 0, iteración; 10950 de 14277, Loss: 0.6229478359222412\n",
            "Epoch: 0, iteración; 10960 de 14277, Loss: 0.5890309333801269\n",
            "Epoch: 0, iteración; 10970 de 14277, Loss: 0.6115616798400879\n",
            "Epoch: 0, iteración; 10980 de 14277, Loss: 0.6002575874328613\n",
            "Epoch: 0, iteración; 10990 de 14277, Loss: 0.611487627029419\n",
            "Epoch: 0, iteración; 11000 de 14277, Loss: 0.5894904136657715\n",
            "Epoch: 0, iteración; 11010 de 14277, Loss: 0.5332573890686035\n",
            "Epoch: 0, iteración; 11020 de 14277, Loss: 0.6338833332061767\n",
            "Epoch: 0, iteración; 11030 de 14277, Loss: 0.5308550357818603\n",
            "Epoch: 0, iteración; 11040 de 14277, Loss: 0.5999107360839844\n",
            "Epoch: 0, iteración; 11050 de 14277, Loss: 0.5659218311309815\n",
            "Epoch: 0, iteración; 11060 de 14277, Loss: 0.5301432609558105\n",
            "Epoch: 0, iteración; 11070 de 14277, Loss: 0.5997838497161865\n",
            "Epoch: 0, iteración; 11080 de 14277, Loss: 0.5886995315551757\n",
            "Epoch: 0, iteración; 11090 de 14277, Loss: 0.541239070892334\n",
            "Epoch: 0, iteración; 11100 de 14277, Loss: 0.6004400730133057\n",
            "Epoch: 0, iteración; 11110 de 14277, Loss: 0.5764894485473633\n",
            "Epoch: 0, iteración; 11120 de 14277, Loss: 0.6121205806732177\n",
            "Epoch: 0, iteración; 11130 de 14277, Loss: 0.5178279876708984\n",
            "Epoch: 0, iteración; 11140 de 14277, Loss: 0.552009391784668\n",
            "Epoch: 0, iteración; 11150 de 14277, Loss: 0.6364902496337891\n",
            "Epoch: 0, iteración; 11160 de 14277, Loss: 0.5169687747955323\n",
            "Epoch: 0, iteración; 11170 de 14277, Loss: 0.564455223083496\n",
            "Epoch: 0, iteración; 11180 de 14277, Loss: 0.6721317291259765\n",
            "Epoch: 0, iteración; 11190 de 14277, Loss: 0.4813100337982178\n",
            "Epoch: 0, iteración; 11200 de 14277, Loss: 0.5401826858520508\n",
            "Epoch: 0, iteración; 11210 de 14277, Loss: 0.5515357494354248\n",
            "Epoch: 0, iteración; 11220 de 14277, Loss: 0.527950382232666\n",
            "Epoch: 0, iteración; 11230 de 14277, Loss: 0.6491408824920655\n",
            "Epoch: 0, iteración; 11240 de 14277, Loss: 0.5759983539581299\n",
            "Epoch: 0, iteración; 11250 de 14277, Loss: 0.5764397621154785\n",
            "Epoch: 0, iteración; 11260 de 14277, Loss: 0.672329330444336\n",
            "Epoch: 0, iteración; 11270 de 14277, Loss: 0.5658615589141845\n",
            "Epoch: 0, iteración; 11280 de 14277, Loss: 0.5421095848083496\n",
            "Epoch: 0, iteración; 11290 de 14277, Loss: 0.6004796981811523\n",
            "Epoch: 0, iteración; 11300 de 14277, Loss: 0.5402889728546143\n",
            "Epoch: 0, iteración; 11310 de 14277, Loss: 0.6122776985168457\n",
            "Epoch: 0, iteración; 11320 de 14277, Loss: 0.5644981384277343\n",
            "Epoch: 0, iteración; 11330 de 14277, Loss: 0.564704704284668\n",
            "Epoch: 0, iteración; 11340 de 14277, Loss: 0.5999659538269043\n",
            "Epoch: 0, iteración; 11350 de 14277, Loss: 0.6244208812713623\n",
            "Epoch: 0, iteración; 11360 de 14277, Loss: 0.5418317317962646\n",
            "Epoch: 0, iteración; 11370 de 14277, Loss: 0.5175954818725585\n",
            "Epoch: 0, iteración; 11380 de 14277, Loss: 0.6239584445953369\n",
            "Epoch: 0, iteración; 11390 de 14277, Loss: 0.49307842254638673\n",
            "Epoch: 0, iteración; 11400 de 14277, Loss: 0.6727001190185546\n",
            "Epoch: 0, iteración; 11410 de 14277, Loss: 0.5765787124633789\n",
            "Epoch: 0, iteración; 11420 de 14277, Loss: 0.6234373092651367\n",
            "Epoch: 0, iteración; 11430 de 14277, Loss: 0.6001975059509277\n",
            "Epoch: 0, iteración; 11440 de 14277, Loss: 0.5542304039001464\n",
            "Epoch: 0, iteración; 11450 de 14277, Loss: 0.5066144466400146\n",
            "Epoch: 0, iteración; 11460 de 14277, Loss: 0.5879189014434815\n",
            "Epoch: 0, iteración; 11470 de 14277, Loss: 0.6003772735595703\n",
            "Epoch: 0, iteración; 11480 de 14277, Loss: 0.6005195617675781\n",
            "Epoch: 0, iteración; 11490 de 14277, Loss: 0.5412482738494873\n",
            "Epoch: 0, iteración; 11500 de 14277, Loss: 0.6368774890899658\n",
            "Epoch: 0, iteración; 11510 de 14277, Loss: 0.5881203651428223\n",
            "Epoch: 0, iteración; 11520 de 14277, Loss: 0.5886477947235107\n",
            "Epoch: 0, iteración; 11530 de 14277, Loss: 0.5769306659698487\n",
            "Epoch: 0, iteración; 11540 de 14277, Loss: 0.7272892951965332\n",
            "Epoch: 0, iteración; 11550 de 14277, Loss: 0.5798370838165283\n",
            "Epoch: 0, iteración; 11560 de 14277, Loss: 0.5013778686523438\n",
            "Epoch: 0, iteración; 11570 de 14277, Loss: 0.5767520427703857\n",
            "Epoch: 0, iteración; 11580 de 14277, Loss: 0.5412660121917725\n",
            "Epoch: 0, iteración; 11590 de 14277, Loss: 0.5874785423278809\n",
            "Epoch: 0, iteración; 11600 de 14277, Loss: 0.5162014484405517\n",
            "Epoch: 0, iteración; 11610 de 14277, Loss: 0.612432861328125\n",
            "Epoch: 0, iteración; 11620 de 14277, Loss: 0.6002893447875977\n",
            "Epoch: 0, iteración; 11630 de 14277, Loss: 0.6000335216522217\n",
            "Epoch: 0, iteración; 11640 de 14277, Loss: 0.5891006469726563\n",
            "Epoch: 0, iteración; 11650 de 14277, Loss: 0.5537439823150635\n",
            "Epoch: 0, iteración; 11660 de 14277, Loss: 0.5770792961120605\n",
            "Epoch: 0, iteración; 11670 de 14277, Loss: 0.5644041061401367\n",
            "Epoch: 0, iteración; 11680 de 14277, Loss: 0.671119213104248\n",
            "Epoch: 0, iteración; 11690 de 14277, Loss: 0.6219647407531739\n",
            "Epoch: 0, iteración; 11700 de 14277, Loss: 0.5662990570068359\n",
            "Epoch: 0, iteración; 11710 de 14277, Loss: 0.5665373802185059\n",
            "Epoch: 0, iteración; 11720 de 14277, Loss: 0.5890841484069824\n",
            "Epoch: 0, iteración; 11730 de 14277, Loss: 0.6112744808197021\n",
            "Epoch: 0, iteración; 11740 de 14277, Loss: 0.4844535827636719\n",
            "Epoch: 0, iteración; 11750 de 14277, Loss: 0.6355169296264649\n",
            "Epoch: 0, iteración; 11760 de 14277, Loss: 0.5879851341247558\n",
            "Epoch: 0, iteración; 11770 de 14277, Loss: 0.5770566940307618\n",
            "Epoch: 0, iteración; 11780 de 14277, Loss: 0.6003657817840576\n",
            "Epoch: 0, iteración; 11790 de 14277, Loss: 0.5999272346496582\n",
            "Epoch: 0, iteración; 11800 de 14277, Loss: 0.5071441650390625\n",
            "Epoch: 0, iteración; 11810 de 14277, Loss: 0.5166766166687011\n",
            "Epoch: 0, iteración; 11820 de 14277, Loss: 0.5400580406188965\n",
            "Epoch: 0, iteración; 11830 de 14277, Loss: 0.5272715568542481\n",
            "Epoch: 0, iteración; 11840 de 14277, Loss: 0.6248290538787842\n",
            "Epoch: 0, iteración; 11850 de 14277, Loss: 0.5639468193054199\n",
            "Epoch: 0, iteración; 11860 de 14277, Loss: 0.6128892421722412\n",
            "Epoch: 0, iteración; 11870 de 14277, Loss: 0.552458381652832\n",
            "Epoch: 0, iteración; 11880 de 14277, Loss: 0.6838418483734131\n",
            "Epoch: 0, iteración; 11890 de 14277, Loss: 0.6605638980865478\n",
            "Epoch: 0, iteración; 11900 de 14277, Loss: 0.6339525699615478\n",
            "Epoch: 0, iteración; 11910 de 14277, Loss: 0.5763181209564209\n",
            "Epoch: 0, iteración; 11920 de 14277, Loss: 0.633485984802246\n",
            "Epoch: 0, iteración; 11930 de 14277, Loss: 0.665408706665039\n",
            "Epoch: 0, iteración; 11940 de 14277, Loss: 0.6113176822662354\n",
            "Epoch: 0, iteración; 11950 de 14277, Loss: 0.5818299293518067\n",
            "Epoch: 0, iteración; 11960 de 14277, Loss: 0.558861255645752\n",
            "Epoch: 0, iteración; 11970 de 14277, Loss: 0.5102159976959229\n",
            "Epoch: 0, iteración; 11980 de 14277, Loss: 0.5643841743469238\n",
            "Epoch: 0, iteración; 11990 de 14277, Loss: 0.6003207683563232\n",
            "Epoch: 0, iteración; 12000 de 14277, Loss: 0.6487485885620117\n",
            "Epoch: 0, iteración; 12010 de 14277, Loss: 0.6115640163421631\n",
            "Epoch: 0, iteración; 12020 de 14277, Loss: 0.5996705055236816\n",
            "Epoch: 0, iteración; 12030 de 14277, Loss: 0.5999737739562988\n",
            "Epoch: 0, iteración; 12040 de 14277, Loss: 0.5549783706665039\n",
            "Epoch: 0, iteración; 12050 de 14277, Loss: 0.5883743286132812\n",
            "Epoch: 0, iteración; 12060 de 14277, Loss: 0.6113128185272216\n",
            "Epoch: 0, iteración; 12070 de 14277, Loss: 0.5547357559204101\n",
            "Epoch: 0, iteración; 12080 de 14277, Loss: 0.5776322841644287\n",
            "Epoch: 0, iteración; 12090 de 14277, Loss: 0.5195425033569336\n",
            "Epoch: 0, iteración; 12100 de 14277, Loss: 0.5888844490051269\n",
            "Epoch: 0, iteración; 12110 de 14277, Loss: 0.6475369930267334\n",
            "Epoch: 0, iteración; 12120 de 14277, Loss: 0.7392763137817383\n",
            "Epoch: 0, iteración; 12130 de 14277, Loss: 0.5882059574127197\n",
            "Epoch: 0, iteración; 12140 de 14277, Loss: 0.5465759754180908\n",
            "Epoch: 0, iteración; 12150 de 14277, Loss: 0.6537487506866455\n",
            "Epoch: 0, iteración; 12160 de 14277, Loss: 0.5791823863983154\n",
            "Epoch: 0, iteración; 12170 de 14277, Loss: 0.5895103931427002\n",
            "Epoch: 0, iteración; 12180 de 14277, Loss: 0.6225318431854248\n",
            "Epoch: 0, iteración; 12190 de 14277, Loss: 0.5996628761291504\n",
            "Epoch: 0, iteración; 12200 de 14277, Loss: 0.6436823844909668\n",
            "Epoch: 0, iteración; 12210 de 14277, Loss: 0.5390180587768555\n",
            "Epoch: 0, iteración; 12220 de 14277, Loss: 0.6105233192443847\n",
            "Epoch: 0, iteración; 12230 de 14277, Loss: 0.7001330852508545\n",
            "Epoch: 0, iteración; 12240 de 14277, Loss: 0.6411216259002686\n",
            "Epoch: 0, iteración; 12250 de 14277, Loss: 0.5746497631072998\n",
            "Epoch: 0, iteración; 12260 de 14277, Loss: 0.5596794128417969\n",
            "Epoch: 0, iteración; 12270 de 14277, Loss: 0.6458969116210938\n",
            "Epoch: 0, iteración; 12280 de 14277, Loss: 0.599769926071167\n",
            "Epoch: 0, iteración; 12290 de 14277, Loss: 0.589170265197754\n",
            "Epoch: 0, iteración; 12300 de 14277, Loss: 0.5793605327606202\n",
            "Epoch: 0, iteración; 12310 de 14277, Loss: 0.6463594436645508\n",
            "Epoch: 0, iteración; 12320 de 14277, Loss: 0.5222873687744141\n",
            "Epoch: 0, iteración; 12330 de 14277, Loss: 0.5885921478271484\n",
            "Epoch: 0, iteración; 12340 de 14277, Loss: 0.5998975276947022\n",
            "Epoch: 0, iteración; 12350 de 14277, Loss: 0.5661122322082519\n",
            "Epoch: 0, iteración; 12360 de 14277, Loss: 0.6610681056976319\n",
            "Epoch: 0, iteración; 12370 de 14277, Loss: 0.6236854553222656\n",
            "Epoch: 0, iteración; 12380 de 14277, Loss: 0.6002550601959229\n",
            "Epoch: 0, iteración; 12390 de 14277, Loss: 0.5773562908172607\n",
            "Epoch: 0, iteración; 12400 de 14277, Loss: 0.6241694450378418\n",
            "Epoch: 0, iteración; 12410 de 14277, Loss: 0.6007725238800049\n",
            "Epoch: 0, iteración; 12420 de 14277, Loss: 0.5656879901885986\n",
            "Epoch: 0, iteración; 12430 de 14277, Loss: 0.6003407955169677\n",
            "Epoch: 0, iteración; 12440 de 14277, Loss: 0.5650788307189941\n",
            "Epoch: 0, iteración; 12450 de 14277, Loss: 0.5917566776275635\n",
            "Epoch: 0, iteración; 12460 de 14277, Loss: 0.6245337963104248\n",
            "Epoch: 0, iteración; 12470 de 14277, Loss: 0.6015274524688721\n",
            "Epoch: 0, iteración; 12480 de 14277, Loss: 0.6032498836517334\n",
            "Epoch: 0, iteración; 12490 de 14277, Loss: 0.5893218994140625\n",
            "Epoch: 0, iteración; 12500 de 14277, Loss: 0.6121067523956298\n",
            "Epoch: 0, iteración; 12510 de 14277, Loss: 0.6569659233093261\n",
            "Epoch: 0, iteración; 12520 de 14277, Loss: 0.5364771842956543\n",
            "Epoch: 0, iteración; 12530 de 14277, Loss: 0.5774394035339355\n",
            "Epoch: 0, iteración; 12540 de 14277, Loss: 0.6012285709381103\n",
            "Epoch: 0, iteración; 12550 de 14277, Loss: 0.6009215831756591\n",
            "Epoch: 0, iteración; 12560 de 14277, Loss: 0.6584753513336181\n",
            "Epoch: 0, iteración; 12570 de 14277, Loss: 0.634131383895874\n",
            "Epoch: 0, iteración; 12580 de 14277, Loss: 0.6110162734985352\n",
            "Epoch: 0, iteración; 12590 de 14277, Loss: 0.6004159927368165\n",
            "Epoch: 0, iteración; 12600 de 14277, Loss: 0.612475061416626\n",
            "Epoch: 0, iteración; 12610 de 14277, Loss: 0.6127511978149414\n",
            "Epoch: 0, iteración; 12620 de 14277, Loss: 0.6311543464660645\n",
            "Epoch: 0, iteración; 12630 de 14277, Loss: 0.6318686485290528\n",
            "Epoch: 0, iteración; 12640 de 14277, Loss: 0.5419679164886475\n",
            "Epoch: 0, iteración; 12650 de 14277, Loss: 0.5898720741271972\n",
            "Epoch: 0, iteración; 12660 de 14277, Loss: 0.5890141487121582\n",
            "Epoch: 0, iteración; 12670 de 14277, Loss: 0.5541696548461914\n",
            "Epoch: 0, iteración; 12680 de 14277, Loss: 0.6344021797180176\n",
            "Epoch: 0, iteración; 12690 de 14277, Loss: 0.6555092334747314\n",
            "Epoch: 0, iteración; 12700 de 14277, Loss: 0.6111879825592041\n",
            "Epoch: 0, iteración; 12710 de 14277, Loss: 0.5905031204223633\n",
            "Epoch: 0, iteración; 12720 de 14277, Loss: 0.6212769508361816\n",
            "Epoch: 0, iteración; 12730 de 14277, Loss: 0.6928285121917724\n",
            "Epoch: 0, iteración; 12740 de 14277, Loss: 0.5936234474182129\n",
            "Epoch: 0, iteración; 12750 de 14277, Loss: 0.603403377532959\n",
            "Epoch: 0, iteración; 12760 de 14277, Loss: 0.5814402580261231\n",
            "Epoch: 0, iteración; 12770 de 14277, Loss: 0.5503407955169678\n",
            "Epoch: 0, iteración; 12780 de 14277, Loss: 0.5901119232177734\n",
            "Epoch: 0, iteración; 12790 de 14277, Loss: 0.5769073486328125\n",
            "Epoch: 0, iteración; 12800 de 14277, Loss: 0.5878301620483398\n",
            "Epoch: 0, iteración; 12810 de 14277, Loss: 0.5302113056182861\n",
            "Epoch: 0, iteración; 12820 de 14277, Loss: 0.6232584476470947\n",
            "Epoch: 0, iteración; 12830 de 14277, Loss: 0.6238102436065673\n",
            "Epoch: 0, iteración; 12840 de 14277, Loss: 0.6679933071136475\n",
            "Epoch: 0, iteración; 12850 de 14277, Loss: 0.5785205364227295\n",
            "Epoch: 0, iteración; 12860 de 14277, Loss: 0.6215288162231445\n",
            "Epoch: 0, iteración; 12870 de 14277, Loss: 0.6097649097442627\n",
            "Epoch: 0, iteración; 12880 de 14277, Loss: 0.5911409378051757\n",
            "Epoch: 0, iteración; 12890 de 14277, Loss: 0.5470213413238525\n",
            "Epoch: 0, iteración; 12900 de 14277, Loss: 0.622879934310913\n",
            "Epoch: 0, iteración; 12910 de 14277, Loss: 0.5336946487426758\n",
            "Epoch: 0, iteración; 12920 de 14277, Loss: 0.6216566562652588\n",
            "Epoch: 0, iteración; 12930 de 14277, Loss: 0.6229457855224609\n",
            "Epoch: 0, iteración; 12940 de 14277, Loss: 0.6552743911743164\n",
            "Epoch: 0, iteración; 12950 de 14277, Loss: 0.6754431247711181\n",
            "Epoch: 0, iteración; 12960 de 14277, Loss: 0.6418588161468506\n",
            "Epoch: 0, iteración; 12970 de 14277, Loss: 0.6028364181518555\n",
            "Epoch: 0, iteración; 12980 de 14277, Loss: 0.5067190170288086\n",
            "Epoch: 0, iteración; 12990 de 14277, Loss: 0.5474834442138672\n",
            "Epoch: 0, iteración; 13000 de 14277, Loss: 0.5772266387939453\n",
            "Epoch: 0, iteración; 13010 de 14277, Loss: 0.5532019138336182\n",
            "Epoch: 0, iteración; 13020 de 14277, Loss: 0.6002397060394287\n",
            "Epoch: 0, iteración; 13030 de 14277, Loss: 0.6117026805877686\n",
            "Epoch: 0, iteración; 13040 de 14277, Loss: 0.599702262878418\n",
            "Epoch: 0, iteración; 13050 de 14277, Loss: 0.6336174011230469\n",
            "Epoch: 0, iteración; 13060 de 14277, Loss: 0.6010410785675049\n",
            "Epoch: 0, iteración; 13070 de 14277, Loss: 0.5764847755432129\n",
            "Epoch: 0, iteración; 13080 de 14277, Loss: 0.6331786155700684\n",
            "Epoch: 0, iteración; 13090 de 14277, Loss: 0.5786775112152099\n",
            "Epoch: 0, iteración; 13100 de 14277, Loss: 0.6008300304412841\n",
            "Epoch: 0, iteración; 13110 de 14277, Loss: 0.6768032550811768\n",
            "Epoch: 0, iteración; 13120 de 14277, Loss: 0.5785503387451172\n",
            "Epoch: 0, iteración; 13130 de 14277, Loss: 0.5685325622558594\n",
            "Epoch: 0, iteración; 13140 de 14277, Loss: 0.5361530780792236\n",
            "Epoch: 0, iteración; 13150 de 14277, Loss: 0.6002741813659668\n",
            "Epoch: 0, iteración; 13160 de 14277, Loss: 0.6566780090332032\n",
            "Epoch: 0, iteración; 13170 de 14277, Loss: 0.5883032798767089\n",
            "Epoch: 0, iteración; 13180 de 14277, Loss: 0.6547967910766601\n",
            "Epoch: 0, iteración; 13190 de 14277, Loss: 0.6006827354431152\n",
            "Epoch: 0, iteración; 13200 de 14277, Loss: 0.5370586395263672\n",
            "Epoch: 0, iteración; 13210 de 14277, Loss: 0.5894075393676758\n",
            "Epoch: 0, iteración; 13220 de 14277, Loss: 0.567849588394165\n",
            "Epoch: 0, iteración; 13230 de 14277, Loss: 0.6121330261230469\n",
            "Epoch: 0, iteración; 13240 de 14277, Loss: 0.555823564529419\n",
            "Epoch: 0, iteración; 13250 de 14277, Loss: 0.5542014598846435\n",
            "Epoch: 0, iteración; 13260 de 14277, Loss: 0.5764708042144775\n",
            "Epoch: 0, iteración; 13270 de 14277, Loss: 0.5767673015594482\n",
            "Epoch: 0, iteración; 13280 de 14277, Loss: 0.4820775032043457\n",
            "Epoch: 0, iteración; 13290 de 14277, Loss: 0.6239136219024658\n",
            "Epoch: 0, iteración; 13300 de 14277, Loss: 0.5403591156005859\n",
            "Epoch: 0, iteración; 13310 de 14277, Loss: 0.6604115009307862\n",
            "Epoch: 0, iteración; 13320 de 14277, Loss: 0.6125707149505615\n",
            "Epoch: 0, iteración; 13330 de 14277, Loss: 0.6699477195739746\n",
            "Epoch: 0, iteración; 13340 de 14277, Loss: 0.5778877258300781\n",
            "Epoch: 0, iteración; 13350 de 14277, Loss: 0.6219732761383057\n",
            "Epoch: 0, iteración; 13360 de 14277, Loss: 0.611518383026123\n",
            "Epoch: 0, iteración; 13370 de 14277, Loss: 0.6335036277770996\n",
            "Epoch: 0, iteración; 13380 de 14277, Loss: 0.6414585113525391\n",
            "Epoch: 0, iteración; 13390 de 14277, Loss: 0.6304581165313721\n",
            "Epoch: 0, iteración; 13400 de 14277, Loss: 0.5620424747467041\n",
            "Epoch: 0, iteración; 13410 de 14277, Loss: 0.6636266708374023\n",
            "Epoch: 0, iteración; 13420 de 14277, Loss: 0.6103529453277587\n",
            "Epoch: 0, iteración; 13430 de 14277, Loss: 0.6011134624481201\n",
            "Epoch: 0, iteración; 13440 de 14277, Loss: 0.5921065330505371\n",
            "Epoch: 0, iteración; 13450 de 14277, Loss: 0.6105076789855957\n",
            "Epoch: 0, iteración; 13460 de 14277, Loss: 0.6112870693206787\n",
            "Epoch: 0, iteración; 13470 de 14277, Loss: 0.6634628295898437\n",
            "Epoch: 0, iteración; 13480 de 14277, Loss: 0.5821639060974121\n",
            "Epoch: 0, iteración; 13490 de 14277, Loss: 0.6260317802429199\n",
            "Epoch: 0, iteración; 13500 de 14277, Loss: 0.6124420642852784\n",
            "Epoch: 0, iteración; 13510 de 14277, Loss: 0.5603540897369385\n",
            "Epoch: 0, iteración; 13520 de 14277, Loss: 0.6106834411621094\n",
            "Epoch: 0, iteración; 13530 de 14277, Loss: 0.6432096481323242\n",
            "Epoch: 0, iteración; 13540 de 14277, Loss: 0.5373076915740966\n",
            "Epoch: 0, iteración; 13550 de 14277, Loss: 0.6011778831481933\n",
            "Epoch: 0, iteración; 13560 de 14277, Loss: 0.6326716423034668\n",
            "Epoch: 0, iteración; 13570 de 14277, Loss: 0.5916612625122071\n",
            "Epoch: 0, iteración; 13580 de 14277, Loss: 0.5768986701965332\n",
            "Epoch: 0, iteración; 13590 de 14277, Loss: 0.6175688743591309\n",
            "Epoch: 0, iteración; 13600 de 14277, Loss: 0.5545647144317627\n",
            "Epoch: 0, iteración; 13610 de 14277, Loss: 0.6223615646362305\n",
            "Epoch: 0, iteración; 13620 de 14277, Loss: 0.5825163364410401\n",
            "Epoch: 0, iteración; 13630 de 14277, Loss: 0.5221800804138184\n",
            "Epoch: 0, iteración; 13640 de 14277, Loss: 0.6585047245025635\n",
            "Epoch: 0, iteración; 13650 de 14277, Loss: 0.5888994693756103\n",
            "Epoch: 0, iteración; 13660 de 14277, Loss: 0.6123955249786377\n",
            "Epoch: 0, iteración; 13670 de 14277, Loss: 0.6024842262268066\n",
            "Epoch: 0, iteración; 13680 de 14277, Loss: 0.5894537448883057\n",
            "Epoch: 0, iteración; 13690 de 14277, Loss: 0.5807931900024415\n",
            "Epoch: 0, iteración; 13700 de 14277, Loss: 0.6652494430541992\n",
            "Epoch: 0, iteración; 13710 de 14277, Loss: 0.6104731559753418\n",
            "Epoch: 0, iteración; 13720 de 14277, Loss: 0.6021659851074219\n",
            "Epoch: 0, iteración; 13730 de 14277, Loss: 0.5399999618530273\n",
            "Epoch: 0, iteración; 13740 de 14277, Loss: 0.5998126029968261\n",
            "Epoch: 0, iteración; 13750 de 14277, Loss: 0.6332046985626221\n",
            "Epoch: 0, iteración; 13760 de 14277, Loss: 0.5466525077819824\n",
            "Epoch: 0, iteración; 13770 de 14277, Loss: 0.5326882362365722\n",
            "Epoch: 0, iteración; 13780 de 14277, Loss: 0.5768280029296875\n",
            "Epoch: 0, iteración; 13790 de 14277, Loss: 0.5642891883850097\n",
            "Epoch: 0, iteración; 13800 de 14277, Loss: 0.647434139251709\n",
            "Epoch: 0, iteración; 13810 de 14277, Loss: 0.530229902267456\n",
            "Epoch: 0, iteración; 13820 de 14277, Loss: 0.6119935035705566\n",
            "Epoch: 0, iteración; 13830 de 14277, Loss: 0.5539797782897949\n",
            "Epoch: 0, iteración; 13840 de 14277, Loss: 0.611884069442749\n",
            "Epoch: 0, iteración; 13850 de 14277, Loss: 0.6002695083618164\n",
            "Epoch: 0, iteración; 13860 de 14277, Loss: 0.5353927135467529\n",
            "Epoch: 0, iteración; 13870 de 14277, Loss: 0.554101037979126\n",
            "Epoch: 0, iteración; 13880 de 14277, Loss: 0.4703530311584473\n",
            "Epoch: 0, iteración; 13890 de 14277, Loss: 0.5281403064727783\n",
            "Epoch: 0, iteración; 13900 de 14277, Loss: 0.5521701335906982\n",
            "Epoch: 0, iteración; 13910 de 14277, Loss: 0.6001968383789062\n",
            "Epoch: 0, iteración; 13920 de 14277, Loss: 0.5518977642059326\n",
            "Epoch: 0, iteración; 13930 de 14277, Loss: 0.6720633983612061\n",
            "Epoch: 0, iteración; 13940 de 14277, Loss: 0.5535112380981445\n",
            "Epoch: 0, iteración; 13950 de 14277, Loss: 0.6117886543273926\n",
            "Epoch: 0, iteración; 13960 de 14277, Loss: 0.5080164432525635\n",
            "Epoch: 0, iteración; 13970 de 14277, Loss: 0.5648267269134521\n",
            "Epoch: 0, iteración; 13980 de 14277, Loss: 0.5290911674499512\n",
            "Epoch: 0, iteración; 13990 de 14277, Loss: 0.5397074699401856\n",
            "Epoch: 0, iteración; 14000 de 14277, Loss: 0.5519024848937988\n",
            "Epoch: 0, iteración; 14010 de 14277, Loss: 0.5643431186676026\n",
            "Epoch: 0, iteración; 14020 de 14277, Loss: 0.6492427825927735\n",
            "Epoch: 0, iteración; 14030 de 14277, Loss: 0.5296456813812256\n",
            "Epoch: 0, iteración; 14040 de 14277, Loss: 0.6237377643585205\n",
            "Epoch: 0, iteración; 14050 de 14277, Loss: 0.6125515937805176\n",
            "Epoch: 0, iteración; 14060 de 14277, Loss: 0.6668826103210449\n",
            "Epoch: 0, iteración; 14070 de 14277, Loss: 0.4924503803253174\n",
            "Epoch: 0, iteración; 14080 de 14277, Loss: 0.5430169105529785\n",
            "Epoch: 0, iteración; 14090 de 14277, Loss: 0.6234672546386719\n",
            "Epoch: 0, iteración; 14100 de 14277, Loss: 0.5301077365875244\n",
            "Epoch: 0, iteración; 14110 de 14277, Loss: 0.6121837615966796\n",
            "Epoch: 0, iteración; 14120 de 14277, Loss: 0.6004986763000488\n",
            "Epoch: 0, iteración; 14130 de 14277, Loss: 0.6232123851776123\n",
            "Epoch: 0, iteración; 14140 de 14277, Loss: 0.5550986289978027\n",
            "Epoch: 0, iteración; 14150 de 14277, Loss: 0.6113885879516602\n",
            "Epoch: 0, iteración; 14160 de 14277, Loss: 0.5879735469818115\n",
            "Epoch: 0, iteración; 14170 de 14277, Loss: 0.62166428565979\n",
            "Epoch: 0, iteración; 14180 de 14277, Loss: 0.5790571212768555\n",
            "Epoch: 0, iteración; 14190 de 14277, Loss: 0.6218216896057129\n",
            "Epoch: 0, iteración; 14200 de 14277, Loss: 0.5679545402526855\n",
            "Epoch: 0, iteración; 14210 de 14277, Loss: 0.6425384521484375\n",
            "Epoch: 0, iteración; 14220 de 14277, Loss: 0.612119483947754\n",
            "Epoch: 0, iteración; 14230 de 14277, Loss: 0.7020026683807373\n",
            "Epoch: 0, iteración; 14240 de 14277, Loss: 0.6592679977416992\n",
            "Epoch: 0, iteración; 14250 de 14277, Loss: 0.5876613616943359\n",
            "Epoch: 0, iteración; 14260 de 14277, Loss: 0.6235532760620117\n",
            "Epoch: 0, iteración; 14270 de 14277, Loss: 0.5931155204772949\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainBert(epoch)"
      ],
      "id": "2lTZI-6z4nZa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3736839-36b8-4442-c669-e391f3c30cbf",
        "id": "aDAUOoel4nZa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_80_separados.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "id": "aDAUOoel4nZa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_4rEjvp4nZa"
      },
      "source": [
        "##### Evaluación del modelo"
      ],
      "id": "k_4rEjvp4nZa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "008_vQ7C4nZa"
      },
      "outputs": [],
      "source": [
        "def validationBert(epoch):\n",
        "  model.eval()\n",
        "  fin_targets=[]\n",
        "  fin_outputs=[]\n",
        "  num_iteraciones = len(testing_loader)\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testing_loader, 0):\n",
        "      ids = data['ids'].to(device)\n",
        "      mask = data['mask'].to(device)\n",
        "      token_type_ids = data['token_type_ids'].to(device)\n",
        "      targets = data['target'].to(device)\n",
        "\n",
        "      print(f\"Batch {i} de {num_iteraciones}\")\n",
        "\n",
        "      outputs = model(ids, mask, token_type_ids)\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "  return fin_outputs, fin_targets"
      ],
      "id": "008_vQ7C4nZa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "EeaLoVf-4nZa"
      },
      "id": "EeaLoVf-4nZa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d6465e9-0f22-4bf5-ea86-ae5a72c7d759",
        "id": "bJF8c39V4nZa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado correctamente\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_80_separados.pth\"):\n",
        "  model = BERTClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_80_separados.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_80_separados.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "id": "bJF8c39V4nZa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab97039b-007a-43e7-c9b3-576a2fee341d",
        "id": "ClP1uSsP4nZa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 de 447\n",
            "Batch 1 de 447\n",
            "Batch 2 de 447\n",
            "Batch 3 de 447\n",
            "Batch 4 de 447\n",
            "Batch 5 de 447\n",
            "Batch 6 de 447\n",
            "Batch 7 de 447\n",
            "Batch 8 de 447\n",
            "Batch 9 de 447\n",
            "Batch 10 de 447\n",
            "Batch 11 de 447\n",
            "Batch 12 de 447\n",
            "Batch 13 de 447\n",
            "Batch 14 de 447\n",
            "Batch 15 de 447\n",
            "Batch 16 de 447\n",
            "Batch 17 de 447\n",
            "Batch 18 de 447\n",
            "Batch 19 de 447\n",
            "Batch 20 de 447\n",
            "Batch 21 de 447\n",
            "Batch 22 de 447\n",
            "Batch 23 de 447\n",
            "Batch 24 de 447\n",
            "Batch 25 de 447\n",
            "Batch 26 de 447\n",
            "Batch 27 de 447\n",
            "Batch 28 de 447\n",
            "Batch 29 de 447\n",
            "Batch 30 de 447\n",
            "Batch 31 de 447\n",
            "Batch 32 de 447\n",
            "Batch 33 de 447\n",
            "Batch 34 de 447\n",
            "Batch 35 de 447\n",
            "Batch 36 de 447\n",
            "Batch 37 de 447\n",
            "Batch 38 de 447\n",
            "Batch 39 de 447\n",
            "Batch 40 de 447\n",
            "Batch 41 de 447\n",
            "Batch 42 de 447\n",
            "Batch 43 de 447\n",
            "Batch 44 de 447\n",
            "Batch 45 de 447\n",
            "Batch 46 de 447\n",
            "Batch 47 de 447\n",
            "Batch 48 de 447\n",
            "Batch 49 de 447\n",
            "Batch 50 de 447\n",
            "Batch 51 de 447\n",
            "Batch 52 de 447\n",
            "Batch 53 de 447\n",
            "Batch 54 de 447\n",
            "Batch 55 de 447\n",
            "Batch 56 de 447\n",
            "Batch 57 de 447\n",
            "Batch 58 de 447\n",
            "Batch 59 de 447\n",
            "Batch 60 de 447\n",
            "Batch 61 de 447\n",
            "Batch 62 de 447\n",
            "Batch 63 de 447\n",
            "Batch 64 de 447\n",
            "Batch 65 de 447\n",
            "Batch 66 de 447\n",
            "Batch 67 de 447\n",
            "Batch 68 de 447\n",
            "Batch 69 de 447\n",
            "Batch 70 de 447\n",
            "Batch 71 de 447\n",
            "Batch 72 de 447\n",
            "Batch 73 de 447\n",
            "Batch 74 de 447\n",
            "Batch 75 de 447\n",
            "Batch 76 de 447\n",
            "Batch 77 de 447\n",
            "Batch 78 de 447\n",
            "Batch 79 de 447\n",
            "Batch 80 de 447\n",
            "Batch 81 de 447\n",
            "Batch 82 de 447\n",
            "Batch 83 de 447\n",
            "Batch 84 de 447\n",
            "Batch 85 de 447\n",
            "Batch 86 de 447\n",
            "Batch 87 de 447\n",
            "Batch 88 de 447\n",
            "Batch 89 de 447\n",
            "Batch 90 de 447\n",
            "Batch 91 de 447\n",
            "Batch 92 de 447\n",
            "Batch 93 de 447\n",
            "Batch 94 de 447\n",
            "Batch 95 de 447\n",
            "Batch 96 de 447\n",
            "Batch 97 de 447\n",
            "Batch 98 de 447\n",
            "Batch 99 de 447\n",
            "Batch 100 de 447\n",
            "Batch 101 de 447\n",
            "Batch 102 de 447\n",
            "Batch 103 de 447\n",
            "Batch 104 de 447\n",
            "Batch 105 de 447\n",
            "Batch 106 de 447\n",
            "Batch 107 de 447\n",
            "Batch 108 de 447\n",
            "Batch 109 de 447\n",
            "Batch 110 de 447\n",
            "Batch 111 de 447\n",
            "Batch 112 de 447\n",
            "Batch 113 de 447\n",
            "Batch 114 de 447\n",
            "Batch 115 de 447\n",
            "Batch 116 de 447\n",
            "Batch 117 de 447\n",
            "Batch 118 de 447\n",
            "Batch 119 de 447\n",
            "Batch 120 de 447\n",
            "Batch 121 de 447\n",
            "Batch 122 de 447\n",
            "Batch 123 de 447\n",
            "Batch 124 de 447\n",
            "Batch 125 de 447\n",
            "Batch 126 de 447\n",
            "Batch 127 de 447\n",
            "Batch 128 de 447\n",
            "Batch 129 de 447\n",
            "Batch 130 de 447\n",
            "Batch 131 de 447\n",
            "Batch 132 de 447\n",
            "Batch 133 de 447\n",
            "Batch 134 de 447\n",
            "Batch 135 de 447\n",
            "Batch 136 de 447\n",
            "Batch 137 de 447\n",
            "Batch 138 de 447\n",
            "Batch 139 de 447\n",
            "Batch 140 de 447\n",
            "Batch 141 de 447\n",
            "Batch 142 de 447\n",
            "Batch 143 de 447\n",
            "Batch 144 de 447\n",
            "Batch 145 de 447\n",
            "Batch 146 de 447\n",
            "Batch 147 de 447\n",
            "Batch 148 de 447\n",
            "Batch 149 de 447\n",
            "Batch 150 de 447\n",
            "Batch 151 de 447\n",
            "Batch 152 de 447\n",
            "Batch 153 de 447\n",
            "Batch 154 de 447\n",
            "Batch 155 de 447\n",
            "Batch 156 de 447\n",
            "Batch 157 de 447\n",
            "Batch 158 de 447\n",
            "Batch 159 de 447\n",
            "Batch 160 de 447\n",
            "Batch 161 de 447\n",
            "Batch 162 de 447\n",
            "Batch 163 de 447\n",
            "Batch 164 de 447\n",
            "Batch 165 de 447\n",
            "Batch 166 de 447\n",
            "Batch 167 de 447\n",
            "Batch 168 de 447\n",
            "Batch 169 de 447\n",
            "Batch 170 de 447\n",
            "Batch 171 de 447\n",
            "Batch 172 de 447\n",
            "Batch 173 de 447\n",
            "Batch 174 de 447\n",
            "Batch 175 de 447\n",
            "Batch 176 de 447\n",
            "Batch 177 de 447\n",
            "Batch 178 de 447\n",
            "Batch 179 de 447\n",
            "Batch 180 de 447\n",
            "Batch 181 de 447\n",
            "Batch 182 de 447\n",
            "Batch 183 de 447\n",
            "Batch 184 de 447\n",
            "Batch 185 de 447\n",
            "Batch 186 de 447\n",
            "Batch 187 de 447\n",
            "Batch 188 de 447\n",
            "Batch 189 de 447\n",
            "Batch 190 de 447\n",
            "Batch 191 de 447\n",
            "Batch 192 de 447\n",
            "Batch 193 de 447\n",
            "Batch 194 de 447\n",
            "Batch 195 de 447\n",
            "Batch 196 de 447\n",
            "Batch 197 de 447\n",
            "Batch 198 de 447\n",
            "Batch 199 de 447\n",
            "Batch 200 de 447\n",
            "Batch 201 de 447\n",
            "Batch 202 de 447\n",
            "Batch 203 de 447\n",
            "Batch 204 de 447\n",
            "Batch 205 de 447\n",
            "Batch 206 de 447\n",
            "Batch 207 de 447\n",
            "Batch 208 de 447\n",
            "Batch 209 de 447\n",
            "Batch 210 de 447\n",
            "Batch 211 de 447\n",
            "Batch 212 de 447\n",
            "Batch 213 de 447\n",
            "Batch 214 de 447\n",
            "Batch 215 de 447\n",
            "Batch 216 de 447\n",
            "Batch 217 de 447\n",
            "Batch 218 de 447\n",
            "Batch 219 de 447\n",
            "Batch 220 de 447\n",
            "Batch 221 de 447\n",
            "Batch 222 de 447\n",
            "Batch 223 de 447\n",
            "Batch 224 de 447\n",
            "Batch 225 de 447\n",
            "Batch 226 de 447\n",
            "Batch 227 de 447\n",
            "Batch 228 de 447\n",
            "Batch 229 de 447\n",
            "Batch 230 de 447\n",
            "Batch 231 de 447\n",
            "Batch 232 de 447\n",
            "Batch 233 de 447\n",
            "Batch 234 de 447\n",
            "Batch 235 de 447\n",
            "Batch 236 de 447\n",
            "Batch 237 de 447\n",
            "Batch 238 de 447\n",
            "Batch 239 de 447\n",
            "Batch 240 de 447\n",
            "Batch 241 de 447\n",
            "Batch 242 de 447\n",
            "Batch 243 de 447\n",
            "Batch 244 de 447\n",
            "Batch 245 de 447\n",
            "Batch 246 de 447\n",
            "Batch 247 de 447\n",
            "Batch 248 de 447\n",
            "Batch 249 de 447\n",
            "Batch 250 de 447\n",
            "Batch 251 de 447\n",
            "Batch 252 de 447\n",
            "Batch 253 de 447\n",
            "Batch 254 de 447\n",
            "Batch 255 de 447\n",
            "Batch 256 de 447\n",
            "Batch 257 de 447\n",
            "Batch 258 de 447\n",
            "Batch 259 de 447\n",
            "Batch 260 de 447\n",
            "Batch 261 de 447\n",
            "Batch 262 de 447\n",
            "Batch 263 de 447\n",
            "Batch 264 de 447\n",
            "Batch 265 de 447\n",
            "Batch 266 de 447\n",
            "Batch 267 de 447\n",
            "Batch 268 de 447\n",
            "Batch 269 de 447\n",
            "Batch 270 de 447\n",
            "Batch 271 de 447\n",
            "Batch 272 de 447\n",
            "Batch 273 de 447\n",
            "Batch 274 de 447\n",
            "Batch 275 de 447\n",
            "Batch 276 de 447\n",
            "Batch 277 de 447\n",
            "Batch 278 de 447\n",
            "Batch 279 de 447\n",
            "Batch 280 de 447\n",
            "Batch 281 de 447\n",
            "Batch 282 de 447\n",
            "Batch 283 de 447\n",
            "Batch 284 de 447\n",
            "Batch 285 de 447\n",
            "Batch 286 de 447\n",
            "Batch 287 de 447\n",
            "Batch 288 de 447\n",
            "Batch 289 de 447\n",
            "Batch 290 de 447\n",
            "Batch 291 de 447\n",
            "Batch 292 de 447\n",
            "Batch 293 de 447\n",
            "Batch 294 de 447\n",
            "Batch 295 de 447\n",
            "Batch 296 de 447\n",
            "Batch 297 de 447\n",
            "Batch 298 de 447\n",
            "Batch 299 de 447\n",
            "Batch 300 de 447\n",
            "Batch 301 de 447\n",
            "Batch 302 de 447\n",
            "Batch 303 de 447\n",
            "Batch 304 de 447\n",
            "Batch 305 de 447\n",
            "Batch 306 de 447\n",
            "Batch 307 de 447\n",
            "Batch 308 de 447\n",
            "Batch 309 de 447\n",
            "Batch 310 de 447\n",
            "Batch 311 de 447\n",
            "Batch 312 de 447\n",
            "Batch 313 de 447\n",
            "Batch 314 de 447\n",
            "Batch 315 de 447\n",
            "Batch 316 de 447\n",
            "Batch 317 de 447\n",
            "Batch 318 de 447\n",
            "Batch 319 de 447\n",
            "Batch 320 de 447\n",
            "Batch 321 de 447\n",
            "Batch 322 de 447\n",
            "Batch 323 de 447\n",
            "Batch 324 de 447\n",
            "Batch 325 de 447\n",
            "Batch 326 de 447\n",
            "Batch 327 de 447\n",
            "Batch 328 de 447\n",
            "Batch 329 de 447\n",
            "Batch 330 de 447\n",
            "Batch 331 de 447\n",
            "Batch 332 de 447\n",
            "Batch 333 de 447\n",
            "Batch 334 de 447\n",
            "Batch 335 de 447\n",
            "Batch 336 de 447\n",
            "Batch 337 de 447\n",
            "Batch 338 de 447\n",
            "Batch 339 de 447\n",
            "Batch 340 de 447\n",
            "Batch 341 de 447\n",
            "Batch 342 de 447\n",
            "Batch 343 de 447\n",
            "Batch 344 de 447\n",
            "Batch 345 de 447\n",
            "Batch 346 de 447\n",
            "Batch 347 de 447\n",
            "Batch 348 de 447\n",
            "Batch 349 de 447\n",
            "Batch 350 de 447\n",
            "Batch 351 de 447\n",
            "Batch 352 de 447\n",
            "Batch 353 de 447\n",
            "Batch 354 de 447\n",
            "Batch 355 de 447\n",
            "Batch 356 de 447\n",
            "Batch 357 de 447\n",
            "Batch 358 de 447\n",
            "Batch 359 de 447\n",
            "Batch 360 de 447\n",
            "Batch 361 de 447\n",
            "Batch 362 de 447\n",
            "Batch 363 de 447\n",
            "Batch 364 de 447\n",
            "Batch 365 de 447\n",
            "Batch 366 de 447\n",
            "Batch 367 de 447\n",
            "Batch 368 de 447\n",
            "Batch 369 de 447\n",
            "Batch 370 de 447\n",
            "Batch 371 de 447\n",
            "Batch 372 de 447\n",
            "Batch 373 de 447\n",
            "Batch 374 de 447\n",
            "Batch 375 de 447\n",
            "Batch 376 de 447\n",
            "Batch 377 de 447\n",
            "Batch 378 de 447\n",
            "Batch 379 de 447\n",
            "Batch 380 de 447\n",
            "Batch 381 de 447\n",
            "Batch 382 de 447\n",
            "Batch 383 de 447\n",
            "Batch 384 de 447\n",
            "Batch 385 de 447\n",
            "Batch 386 de 447\n",
            "Batch 387 de 447\n",
            "Batch 388 de 447\n",
            "Batch 389 de 447\n",
            "Batch 390 de 447\n",
            "Batch 391 de 447\n",
            "Batch 392 de 447\n",
            "Batch 393 de 447\n",
            "Batch 394 de 447\n",
            "Batch 395 de 447\n",
            "Batch 396 de 447\n",
            "Batch 397 de 447\n",
            "Batch 398 de 447\n",
            "Batch 399 de 447\n",
            "Batch 400 de 447\n",
            "Batch 401 de 447\n",
            "Batch 402 de 447\n",
            "Batch 403 de 447\n",
            "Batch 404 de 447\n",
            "Batch 405 de 447\n",
            "Batch 406 de 447\n",
            "Batch 407 de 447\n",
            "Batch 408 de 447\n",
            "Batch 409 de 447\n",
            "Batch 410 de 447\n",
            "Batch 411 de 447\n",
            "Batch 412 de 447\n",
            "Batch 413 de 447\n",
            "Batch 414 de 447\n",
            "Batch 415 de 447\n",
            "Batch 416 de 447\n",
            "Batch 417 de 447\n",
            "Batch 418 de 447\n",
            "Batch 419 de 447\n",
            "Batch 420 de 447\n",
            "Batch 421 de 447\n",
            "Batch 422 de 447\n",
            "Batch 423 de 447\n",
            "Batch 424 de 447\n",
            "Batch 425 de 447\n",
            "Batch 426 de 447\n",
            "Batch 427 de 447\n",
            "Batch 428 de 447\n",
            "Batch 429 de 447\n",
            "Batch 430 de 447\n",
            "Batch 431 de 447\n",
            "Batch 432 de 447\n",
            "Batch 433 de 447\n",
            "Batch 434 de 447\n",
            "Batch 435 de 447\n",
            "Batch 436 de 447\n",
            "Batch 437 de 447\n",
            "Batch 438 de 447\n",
            "Batch 439 de 447\n",
            "Batch 440 de 447\n",
            "Batch 441 de 447\n",
            "Batch 442 de 447\n",
            "Batch 443 de 447\n",
            "Batch 444 de 447\n",
            "Batch 445 de 447\n",
            "Batch 446 de 447\n",
            "Accuracy Score = 0.7243468515794634\n",
            "F1 Score (Micro) = 0.7243468515794634\n",
            "F1 Score (Macro) = 0.4200702723561549\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationBert(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "\n",
        "  targets = np.array(targets).flatten().astype(int)\n",
        "\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "id": "ClP1uSsP4nZa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK8D5HD-XNGu"
      },
      "source": [
        "###2.5.6 Modelo 2: RoBERTa"
      ],
      "id": "SK8D5HD-XNGu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDREd3hYXNGz"
      },
      "source": [
        "##### Generación Dataset y Dataloader"
      ],
      "id": "TDREd3hYXNGz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6a83888-5326-4797-ce2a-b7e54367cda6",
        "id": "j9sDA2mqXNGz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset:(142768, 2)\n",
            "TRAIN Dataset: (71384, 2)\n",
            "TEST Dataset: (71384, 2)\n"
          ]
        }
      ],
      "source": [
        "training_loader, testing_loader = generate_loaders(datos, tokenizerRB,\n",
        "                                                   restaurantsDataset,\n",
        "                                                   DataCollatorRestaurant\n",
        "                                                   )"
      ],
      "id": "j9sDA2mqXNGz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU1lENq3XNG0"
      },
      "source": [
        "##### Definición del modelo"
      ],
      "id": "IU1lENq3XNG0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d19b65b3-da87-42b3-977f-6eb9d1b5699f",
        "id": "a9oY09RUXNG0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaClass(\n",
              "  (l1): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l4): Dropout(p=0.2, inplace=False)\n",
              "  (l5): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (l6): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "class RobertaClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RobertaClass, self).__init__()\n",
        "        self.dropout = 0.2\n",
        "        self.hidden_embd = 768\n",
        "        self.output_layer = 1\n",
        "\n",
        "        # Layers\n",
        "        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        #self.l2 = torch.nn.Linear(self.hidden_embd, 256)\n",
        "        #self.l3 = torch.nn.Linear(256, 64)\n",
        "        self.l4 = torch.nn.Dropout(self.dropout)\n",
        "        # self.l5 = torch.nn.Linear(64, self.output_layer)\n",
        "        self.l5 = torch.nn.Linear(self.hidden_embd, self.output_layer)\n",
        "        self.l6 = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, output_1 = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
        "        #output_2 = self.l2(output_1)\n",
        "        #output_3 = self.l3(output_2)\n",
        "        output_4 = self.l4(output_1)\n",
        "        output = self.l5(output_4)\n",
        "        output = self.l6(output)\n",
        "        return output\n",
        "\n",
        "model = RobertaClass()\n",
        "model.to(device)"
      ],
      "id": "a9oY09RUXNG0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a7f336d-7840-4066-e89f-f8b7f2aa4502",
        "id": "3ls6n0_6XNG0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 0.01\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE,\n",
        "                             weight_decay=0.01)\n",
        "optimizer"
      ],
      "id": "3ls6n0_6XNG0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Función de entrenamiento"
      ],
      "metadata": {
        "id": "QcMJtZ-_XNG0"
      },
      "id": "QcMJtZ-_XNG0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ayUpOLDXNG0"
      },
      "outputs": [],
      "source": [
        "def trainRoberta(epoch):\n",
        "  model.train()\n",
        "  loss_fn = torch.nn.BCELoss() #funcion perdida categorical cross entropy\n",
        "  num_iteraciones = len(training_loader)\n",
        "  sum_loss = 0\n",
        "\n",
        "  for iteracion,data in enumerate(training_loader, 0):\n",
        "    ids = data['ids'].to(device)\n",
        "    mask = data['mask'].to(device)\n",
        "    targets = data['target'].to(device)\n",
        "    token_type_ids = data[\"token_type_ids\"].to(device)\n",
        "\n",
        "    output = model(ids, mask, token_type_ids)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    perdida = loss_fn(output.squeeze(), targets)\n",
        "    with torch.no_grad():\n",
        "      sum_loss+=perdida\n",
        "      if iteracion % PASOS_POR_INTERVALO == 0:\n",
        "        print(f'Epoch: {epoch}, iteración; {iteracion:6} de {num_iteraciones}, Loss: {sum_loss.cpu().numpy()/PASOS_POR_INTERVALO}')\n",
        "        sum_loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    perdida.backward()\n",
        "    optimizer.step()"
      ],
      "id": "9ayUpOLDXNG0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L3BT6Y5XNG0"
      },
      "source": [
        "##### Entrenamiento del modelo (30% de datos)"
      ],
      "id": "5L3BT6Y5XNG0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-3\n",
        "- weight_decay=0.01\n",
        "- Dropout + Linear + Sigmoid"
      ],
      "metadata": {
        "id": "E7YA65BkX8m6"
      },
      "id": "E7YA65BkX8m6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "906151db-9077-443c-fa2d-5551ecaa6831",
        "id": "5EamFBKVXNG0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración;      0 de 5354, Loss: 0.07095611095428467\n",
            "Epoch: 0, iteración;     10 de 5354, Loss: 0.6335700035095215\n",
            "Epoch: 0, iteración;     20 de 5354, Loss: 0.5745832443237304\n",
            "Epoch: 0, iteración;     30 de 5354, Loss: 0.6549041748046875\n",
            "Epoch: 0, iteración;     40 de 5354, Loss: 0.7494820117950439\n",
            "Epoch: 0, iteración;     50 de 5354, Loss: 0.6497314453125\n",
            "Epoch: 0, iteración;     60 de 5354, Loss: 0.5600525856018066\n",
            "Epoch: 0, iteración;     70 de 5354, Loss: 0.5947575569152832\n",
            "Epoch: 0, iteración;     80 de 5354, Loss: 0.627333688735962\n",
            "Epoch: 0, iteración;     90 de 5354, Loss: 0.5397816658020019\n",
            "Epoch: 0, iteración;    100 de 5354, Loss: 0.574896240234375\n",
            "Epoch: 0, iteración;    110 de 5354, Loss: 0.568597412109375\n",
            "Epoch: 0, iteración;    120 de 5354, Loss: 0.5479228496551514\n",
            "Epoch: 0, iteración;    130 de 5354, Loss: 0.6033951759338378\n",
            "Epoch: 0, iteración;    140 de 5354, Loss: 0.6093110561370849\n",
            "Epoch: 0, iteración;    150 de 5354, Loss: 0.5871122360229493\n",
            "Epoch: 0, iteración;    160 de 5354, Loss: 0.5405819416046143\n",
            "Epoch: 0, iteración;    170 de 5354, Loss: 0.5629069328308105\n",
            "Epoch: 0, iteración;    180 de 5354, Loss: 0.5794865608215332\n",
            "Epoch: 0, iteración;    190 de 5354, Loss: 0.5389620780944824\n",
            "Epoch: 0, iteración;    200 de 5354, Loss: 0.5844008445739746\n",
            "Epoch: 0, iteración;    210 de 5354, Loss: 0.5937108516693115\n",
            "Epoch: 0, iteración;    220 de 5354, Loss: 0.6368338584899902\n",
            "Epoch: 0, iteración;    230 de 5354, Loss: 0.5764197826385498\n",
            "Epoch: 0, iteración;    240 de 5354, Loss: 0.5826995849609375\n",
            "Epoch: 0, iteración;    250 de 5354, Loss: 0.6533382415771485\n",
            "Epoch: 0, iteración;    260 de 5354, Loss: 0.6307730674743652\n",
            "Epoch: 0, iteración;    270 de 5354, Loss: 0.556636905670166\n",
            "Epoch: 0, iteración;    280 de 5354, Loss: 0.5052146911621094\n",
            "Epoch: 0, iteración;    290 de 5354, Loss: 0.5813092708587646\n",
            "Epoch: 0, iteración;    300 de 5354, Loss: 0.512773084640503\n",
            "Epoch: 0, iteración;    310 de 5354, Loss: 0.6514806270599365\n",
            "Epoch: 0, iteración;    320 de 5354, Loss: 0.5845591068267822\n",
            "Epoch: 0, iteración;    330 de 5354, Loss: 0.511448335647583\n",
            "Epoch: 0, iteración;    340 de 5354, Loss: 0.559641170501709\n",
            "Epoch: 0, iteración;    350 de 5354, Loss: 0.7248124122619629\n",
            "Epoch: 0, iteración;    360 de 5354, Loss: 0.618746280670166\n",
            "Epoch: 0, iteración;    370 de 5354, Loss: 0.5956037521362305\n",
            "Epoch: 0, iteración;    380 de 5354, Loss: 0.5982995986938476\n",
            "Epoch: 0, iteración;    390 de 5354, Loss: 0.6246171474456788\n",
            "Epoch: 0, iteración;    400 de 5354, Loss: 0.6564788818359375\n",
            "Epoch: 0, iteración;    410 de 5354, Loss: 0.6287809848785401\n",
            "Epoch: 0, iteración;    420 de 5354, Loss: 0.6392704486846924\n",
            "Epoch: 0, iteración;    430 de 5354, Loss: 0.5993495941162109\n",
            "Epoch: 0, iteración;    440 de 5354, Loss: 0.6470396995544434\n",
            "Epoch: 0, iteración;    450 de 5354, Loss: 0.6103384971618653\n",
            "Epoch: 0, iteración;    460 de 5354, Loss: 0.6003291130065918\n",
            "Epoch: 0, iteración;    470 de 5354, Loss: 0.573191785812378\n",
            "Epoch: 0, iteración;    480 de 5354, Loss: 0.540217399597168\n",
            "Epoch: 0, iteración;    490 de 5354, Loss: 0.5656997203826905\n",
            "Epoch: 0, iteración;    500 de 5354, Loss: 0.5600983619689941\n",
            "Epoch: 0, iteración;    510 de 5354, Loss: 0.5723709106445313\n",
            "Epoch: 0, iteración;    520 de 5354, Loss: 0.6151356220245361\n",
            "Epoch: 0, iteración;    530 de 5354, Loss: 0.568238353729248\n",
            "Epoch: 0, iteración;    540 de 5354, Loss: 0.5484557628631592\n",
            "Epoch: 0, iteración;    550 de 5354, Loss: 0.5216837882995605\n",
            "Epoch: 0, iteración;    560 de 5354, Loss: 0.595188045501709\n",
            "Epoch: 0, iteración;    570 de 5354, Loss: 0.6388534545898438\n",
            "Epoch: 0, iteración;    580 de 5354, Loss: 0.547993278503418\n",
            "Epoch: 0, iteración;    590 de 5354, Loss: 0.5920341491699219\n",
            "Epoch: 0, iteración;    600 de 5354, Loss: 0.5623633861541748\n",
            "Epoch: 0, iteración;    610 de 5354, Loss: 0.573538064956665\n",
            "Epoch: 0, iteración;    620 de 5354, Loss: 0.589592170715332\n",
            "Epoch: 0, iteración;    630 de 5354, Loss: 0.6290562629699707\n",
            "Epoch: 0, iteración;    640 de 5354, Loss: 0.5494730949401856\n",
            "Epoch: 0, iteración;    650 de 5354, Loss: 0.5859691619873046\n",
            "Epoch: 0, iteración;    660 de 5354, Loss: 0.5510196208953857\n",
            "Epoch: 0, iteración;    670 de 5354, Loss: 0.6373188018798828\n",
            "Epoch: 0, iteración;    680 de 5354, Loss: 0.586869478225708\n",
            "Epoch: 0, iteración;    690 de 5354, Loss: 0.6460853576660156\n",
            "Epoch: 0, iteración;    700 de 5354, Loss: 0.6223067760467529\n",
            "Epoch: 0, iteración;    710 de 5354, Loss: 0.5634538650512695\n",
            "Epoch: 0, iteración;    720 de 5354, Loss: 0.677515172958374\n",
            "Epoch: 0, iteración;    730 de 5354, Loss: 0.5434298038482666\n",
            "Epoch: 0, iteración;    740 de 5354, Loss: 0.6292678833007812\n",
            "Epoch: 0, iteración;    750 de 5354, Loss: 0.5737803459167481\n",
            "Epoch: 0, iteración;    760 de 5354, Loss: 0.5606246948242187\n",
            "Epoch: 0, iteración;    770 de 5354, Loss: 0.6195175170898437\n",
            "Epoch: 0, iteración;    780 de 5354, Loss: 0.5506484031677246\n",
            "Epoch: 0, iteración;    790 de 5354, Loss: 0.600300407409668\n",
            "Epoch: 0, iteración;    800 de 5354, Loss: 0.4804863929748535\n",
            "Epoch: 0, iteración;    810 de 5354, Loss: 0.6501087188720703\n",
            "Epoch: 0, iteración;    820 de 5354, Loss: 0.5752926349639893\n",
            "Epoch: 0, iteración;    830 de 5354, Loss: 0.6727843284606934\n",
            "Epoch: 0, iteración;    840 de 5354, Loss: 0.5815307140350342\n",
            "Epoch: 0, iteración;    850 de 5354, Loss: 0.5875268936157226\n",
            "Epoch: 0, iteración;    860 de 5354, Loss: 0.6201767444610595\n",
            "Epoch: 0, iteración;    870 de 5354, Loss: 0.5451461791992187\n",
            "Epoch: 0, iteración;    880 de 5354, Loss: 0.6260536670684814\n",
            "Epoch: 0, iteración;    890 de 5354, Loss: 0.6121884346008301\n",
            "Epoch: 0, iteración;    900 de 5354, Loss: 0.6381942749023437\n",
            "Epoch: 0, iteración;    910 de 5354, Loss: 0.6141922473907471\n",
            "Epoch: 0, iteración;    920 de 5354, Loss: 0.5758286952972412\n",
            "Epoch: 0, iteración;    930 de 5354, Loss: 0.5348225116729737\n",
            "Epoch: 0, iteración;    940 de 5354, Loss: 0.5534382820129394\n",
            "Epoch: 0, iteración;    950 de 5354, Loss: 0.6334585189819336\n",
            "Epoch: 0, iteración;    960 de 5354, Loss: 0.6528220176696777\n",
            "Epoch: 0, iteración;    970 de 5354, Loss: 0.5837838172912597\n",
            "Epoch: 0, iteración;    980 de 5354, Loss: 0.650098466873169\n",
            "Epoch: 0, iteración;    990 de 5354, Loss: 0.6404853343963623\n",
            "Epoch: 0, iteración;   1000 de 5354, Loss: 0.6156875133514405\n",
            "Epoch: 0, iteración;   1010 de 5354, Loss: 0.5434397220611572\n",
            "Epoch: 0, iteración;   1020 de 5354, Loss: 0.48937373161315917\n",
            "Epoch: 0, iteración;   1030 de 5354, Loss: 0.7050445556640625\n",
            "Epoch: 0, iteración;   1040 de 5354, Loss: 0.620812177658081\n",
            "Epoch: 0, iteración;   1050 de 5354, Loss: 0.6476186752319336\n",
            "Epoch: 0, iteración;   1060 de 5354, Loss: 0.5772330284118652\n",
            "Epoch: 0, iteración;   1070 de 5354, Loss: 0.5660756587982178\n",
            "Epoch: 0, iteración;   1080 de 5354, Loss: 0.5324203491210937\n",
            "Epoch: 0, iteración;   1090 de 5354, Loss: 0.5973270416259766\n",
            "Epoch: 0, iteración;   1100 de 5354, Loss: 0.601891565322876\n",
            "Epoch: 0, iteración;   1110 de 5354, Loss: 0.5604257583618164\n",
            "Epoch: 0, iteración;   1120 de 5354, Loss: 0.5716598033905029\n",
            "Epoch: 0, iteración;   1130 de 5354, Loss: 0.6418687343597412\n",
            "Epoch: 0, iteración;   1140 de 5354, Loss: 0.5801959037780762\n",
            "Epoch: 0, iteración;   1150 de 5354, Loss: 0.5740597724914551\n",
            "Epoch: 0, iteración;   1160 de 5354, Loss: 0.6212727546691894\n",
            "Epoch: 0, iteración;   1170 de 5354, Loss: 0.6487017154693604\n",
            "Epoch: 0, iteración;   1180 de 5354, Loss: 0.5979770183563232\n",
            "Epoch: 0, iteración;   1190 de 5354, Loss: 0.5825095176696777\n",
            "Epoch: 0, iteración;   1200 de 5354, Loss: 0.5804950714111328\n",
            "Epoch: 0, iteración;   1210 de 5354, Loss: 0.538004732131958\n",
            "Epoch: 0, iteración;   1220 de 5354, Loss: 0.547615385055542\n",
            "Epoch: 0, iteración;   1230 de 5354, Loss: 0.6134223461151123\n",
            "Epoch: 0, iteración;   1240 de 5354, Loss: 0.5525652408599854\n",
            "Epoch: 0, iteración;   1250 de 5354, Loss: 0.6496218681335449\n",
            "Epoch: 0, iteración;   1260 de 5354, Loss: 0.5945364952087402\n",
            "Epoch: 0, iteración;   1270 de 5354, Loss: 0.5994383335113526\n",
            "Epoch: 0, iteración;   1280 de 5354, Loss: 0.587613868713379\n",
            "Epoch: 0, iteración;   1290 de 5354, Loss: 0.5875344753265381\n",
            "Epoch: 0, iteración;   1300 de 5354, Loss: 0.6390841007232666\n",
            "Epoch: 0, iteración;   1310 de 5354, Loss: 0.5832790851593017\n",
            "Epoch: 0, iteración;   1320 de 5354, Loss: 0.5911919116973877\n",
            "Epoch: 0, iteración;   1330 de 5354, Loss: 0.6101421356201172\n",
            "Epoch: 0, iteración;   1340 de 5354, Loss: 0.6043079376220704\n",
            "Epoch: 0, iteración;   1350 de 5354, Loss: 0.5939787864685059\n",
            "Epoch: 0, iteración;   1360 de 5354, Loss: 0.5407154083251953\n",
            "Epoch: 0, iteración;   1370 de 5354, Loss: 0.5099803447723389\n",
            "Epoch: 0, iteración;   1380 de 5354, Loss: 0.7378374576568604\n",
            "Epoch: 0, iteración;   1390 de 5354, Loss: 0.6601858615875245\n",
            "Epoch: 0, iteración;   1400 de 5354, Loss: 0.5811863899230957\n",
            "Epoch: 0, iteración;   1410 de 5354, Loss: 0.6166488647460937\n",
            "Epoch: 0, iteración;   1420 de 5354, Loss: 0.6460082530975342\n",
            "Epoch: 0, iteración;   1430 de 5354, Loss: 0.5219186782836914\n",
            "Epoch: 0, iteración;   1440 de 5354, Loss: 0.6228094100952148\n",
            "Epoch: 0, iteración;   1450 de 5354, Loss: 0.6062275886535644\n",
            "Epoch: 0, iteración;   1460 de 5354, Loss: 0.49610652923583987\n",
            "Epoch: 0, iteración;   1470 de 5354, Loss: 0.6016026496887207\n",
            "Epoch: 0, iteración;   1480 de 5354, Loss: 0.6005002021789551\n",
            "Epoch: 0, iteración;   1490 de 5354, Loss: 0.6266119003295898\n",
            "Epoch: 0, iteración;   1500 de 5354, Loss: 0.618990135192871\n",
            "Epoch: 0, iteración;   1510 de 5354, Loss: 0.53335599899292\n",
            "Epoch: 0, iteración;   1520 de 5354, Loss: 0.4461087226867676\n",
            "Epoch: 0, iteración;   1530 de 5354, Loss: 0.652740478515625\n",
            "Epoch: 0, iteración;   1540 de 5354, Loss: 0.5462825298309326\n",
            "Epoch: 0, iteración;   1550 de 5354, Loss: 0.515000295639038\n",
            "Epoch: 0, iteración;   1560 de 5354, Loss: 0.6518832206726074\n",
            "Epoch: 0, iteración;   1570 de 5354, Loss: 0.6067574977874756\n",
            "Epoch: 0, iteración;   1580 de 5354, Loss: 0.6267270088195801\n",
            "Epoch: 0, iteración;   1590 de 5354, Loss: 0.5766504287719727\n",
            "Epoch: 0, iteración;   1600 de 5354, Loss: 0.5546499252319336\n",
            "Epoch: 0, iteración;   1610 de 5354, Loss: 0.5682632446289062\n",
            "Epoch: 0, iteración;   1620 de 5354, Loss: 0.5477426052093506\n",
            "Epoch: 0, iteración;   1630 de 5354, Loss: 0.4838114261627197\n",
            "Epoch: 0, iteración;   1640 de 5354, Loss: 0.607974910736084\n",
            "Epoch: 0, iteración;   1650 de 5354, Loss: 0.5790566444396973\n",
            "Epoch: 0, iteración;   1660 de 5354, Loss: 0.5252470016479492\n",
            "Epoch: 0, iteración;   1670 de 5354, Loss: 0.6011430740356445\n",
            "Epoch: 0, iteración;   1680 de 5354, Loss: 0.5612411975860596\n",
            "Epoch: 0, iteración;   1690 de 5354, Loss: 0.5876776218414307\n",
            "Epoch: 0, iteración;   1700 de 5354, Loss: 0.5555420875549316\n",
            "Epoch: 0, iteración;   1710 de 5354, Loss: 0.6389602184295654\n",
            "Epoch: 0, iteración;   1720 de 5354, Loss: 0.5685308456420899\n",
            "Epoch: 0, iteración;   1730 de 5354, Loss: 0.5178479194641114\n",
            "Epoch: 0, iteración;   1740 de 5354, Loss: 0.5928951263427734\n",
            "Epoch: 0, iteración;   1750 de 5354, Loss: 0.5639106750488281\n",
            "Epoch: 0, iteración;   1760 de 5354, Loss: 0.6087060928344726\n",
            "Epoch: 0, iteración;   1770 de 5354, Loss: 0.5757534027099609\n",
            "Epoch: 0, iteración;   1780 de 5354, Loss: 0.6629782676696777\n",
            "Epoch: 0, iteración;   1790 de 5354, Loss: 0.6302125930786133\n",
            "Epoch: 0, iteración;   1800 de 5354, Loss: 0.5777180671691895\n",
            "Epoch: 0, iteración;   1810 de 5354, Loss: 0.6413374900817871\n",
            "Epoch: 0, iteración;   1820 de 5354, Loss: 0.5555455684661865\n",
            "Epoch: 0, iteración;   1830 de 5354, Loss: 0.5607616424560546\n",
            "Epoch: 0, iteración;   1840 de 5354, Loss: 0.6704970836639405\n",
            "Epoch: 0, iteración;   1850 de 5354, Loss: 0.5591851711273194\n",
            "Epoch: 0, iteración;   1860 de 5354, Loss: 0.5917064189910889\n",
            "Epoch: 0, iteración;   1870 de 5354, Loss: 0.6091505527496338\n",
            "Epoch: 0, iteración;   1880 de 5354, Loss: 0.603142261505127\n",
            "Epoch: 0, iteración;   1890 de 5354, Loss: 0.5839116096496582\n",
            "Epoch: 0, iteración;   1900 de 5354, Loss: 0.5762479782104493\n",
            "Epoch: 0, iteración;   1910 de 5354, Loss: 0.5463752269744873\n",
            "Epoch: 0, iteración;   1920 de 5354, Loss: 0.6578017234802246\n",
            "Epoch: 0, iteración;   1930 de 5354, Loss: 0.5717323780059814\n",
            "Epoch: 0, iteración;   1940 de 5354, Loss: 0.5177821636199951\n",
            "Epoch: 0, iteración;   1950 de 5354, Loss: 0.6428514003753663\n",
            "Epoch: 0, iteración;   1960 de 5354, Loss: 0.6573541641235352\n",
            "Epoch: 0, iteración;   1970 de 5354, Loss: 0.5711688041687012\n",
            "Epoch: 0, iteración;   1980 de 5354, Loss: 0.5562541961669922\n",
            "Epoch: 0, iteración;   1990 de 5354, Loss: 0.489380931854248\n",
            "Epoch: 0, iteración;   2000 de 5354, Loss: 0.6279016017913819\n",
            "Epoch: 0, iteración;   2010 de 5354, Loss: 0.5493910789489747\n",
            "Epoch: 0, iteración;   2020 de 5354, Loss: 0.6707608222961425\n",
            "Epoch: 0, iteración;   2030 de 5354, Loss: 0.6401561737060547\n",
            "Epoch: 0, iteración;   2040 de 5354, Loss: 0.6445343971252442\n",
            "Epoch: 0, iteración;   2050 de 5354, Loss: 0.6212562084197998\n",
            "Epoch: 0, iteración;   2060 de 5354, Loss: 0.6235089778900147\n",
            "Epoch: 0, iteración;   2070 de 5354, Loss: 0.6339715003967286\n",
            "Epoch: 0, iteración;   2080 de 5354, Loss: 0.5700879096984863\n",
            "Epoch: 0, iteración;   2090 de 5354, Loss: 0.572309923171997\n",
            "Epoch: 0, iteración;   2100 de 5354, Loss: 0.4737867832183838\n",
            "Epoch: 0, iteración;   2110 de 5354, Loss: 0.5486568927764892\n",
            "Epoch: 0, iteración;   2120 de 5354, Loss: 0.6429177284240722\n",
            "Epoch: 0, iteración;   2130 de 5354, Loss: 0.5573832511901855\n",
            "Epoch: 0, iteración;   2140 de 5354, Loss: 0.5775765895843505\n",
            "Epoch: 0, iteración;   2150 de 5354, Loss: 0.5641396999359131\n",
            "Epoch: 0, iteración;   2160 de 5354, Loss: 0.5633790016174316\n",
            "Epoch: 0, iteración;   2170 de 5354, Loss: 0.6161398887634277\n",
            "Epoch: 0, iteración;   2180 de 5354, Loss: 0.5185567378997803\n",
            "Epoch: 0, iteración;   2190 de 5354, Loss: 0.586794662475586\n",
            "Epoch: 0, iteración;   2200 de 5354, Loss: 0.5101564407348633\n",
            "Epoch: 0, iteración;   2210 de 5354, Loss: 0.60685133934021\n",
            "Epoch: 0, iteración;   2220 de 5354, Loss: 0.6172738552093506\n",
            "Epoch: 0, iteración;   2230 de 5354, Loss: 0.6353503704071045\n",
            "Epoch: 0, iteración;   2240 de 5354, Loss: 0.5748895645141602\n",
            "Epoch: 0, iteración;   2250 de 5354, Loss: 0.5391330242156982\n",
            "Epoch: 0, iteración;   2260 de 5354, Loss: 0.6131162166595459\n",
            "Epoch: 0, iteración;   2270 de 5354, Loss: 0.51080322265625\n",
            "Epoch: 0, iteración;   2280 de 5354, Loss: 0.5354235172271729\n",
            "Epoch: 0, iteración;   2290 de 5354, Loss: 0.4709972381591797\n",
            "Epoch: 0, iteración;   2300 de 5354, Loss: 0.47384061813354494\n",
            "Epoch: 0, iteración;   2310 de 5354, Loss: 0.6075573921203613\n",
            "Epoch: 0, iteración;   2320 de 5354, Loss: 0.5681292533874511\n",
            "Epoch: 0, iteración;   2330 de 5354, Loss: 0.6276298999786377\n",
            "Epoch: 0, iteración;   2340 de 5354, Loss: 0.6149417877197265\n",
            "Epoch: 0, iteración;   2350 de 5354, Loss: 0.5831324100494385\n",
            "Epoch: 0, iteración;   2360 de 5354, Loss: 0.6248121738433838\n",
            "Epoch: 0, iteración;   2370 de 5354, Loss: 0.566977596282959\n",
            "Epoch: 0, iteración;   2380 de 5354, Loss: 0.5712375640869141\n",
            "Epoch: 0, iteración;   2390 de 5354, Loss: 0.5802511215209961\n",
            "Epoch: 0, iteración;   2400 de 5354, Loss: 0.5158172130584717\n",
            "Epoch: 0, iteración;   2410 de 5354, Loss: 0.6837235927581787\n",
            "Epoch: 0, iteración;   2420 de 5354, Loss: 0.5723321437835693\n",
            "Epoch: 0, iteración;   2430 de 5354, Loss: 0.6207515239715576\n",
            "Epoch: 0, iteración;   2440 de 5354, Loss: 0.6120943069458008\n",
            "Epoch: 0, iteración;   2450 de 5354, Loss: 0.5654129028320313\n",
            "Epoch: 0, iteración;   2460 de 5354, Loss: 0.6103048324584961\n",
            "Epoch: 0, iteración;   2470 de 5354, Loss: 0.6742300987243652\n",
            "Epoch: 0, iteración;   2480 de 5354, Loss: 0.6111604690551757\n",
            "Epoch: 0, iteración;   2490 de 5354, Loss: 0.6636502265930175\n",
            "Epoch: 0, iteración;   2500 de 5354, Loss: 0.5913375854492188\n",
            "Epoch: 0, iteración;   2510 de 5354, Loss: 0.555637788772583\n",
            "Epoch: 0, iteración;   2520 de 5354, Loss: 0.6019711017608642\n",
            "Epoch: 0, iteración;   2530 de 5354, Loss: 0.5841657638549804\n",
            "Epoch: 0, iteración;   2540 de 5354, Loss: 0.6143746376037598\n",
            "Epoch: 0, iteración;   2550 de 5354, Loss: 0.6109929561614991\n",
            "Epoch: 0, iteración;   2560 de 5354, Loss: 0.567501163482666\n",
            "Epoch: 0, iteración;   2570 de 5354, Loss: 0.591734504699707\n",
            "Epoch: 0, iteración;   2580 de 5354, Loss: 0.5966516971588135\n",
            "Epoch: 0, iteración;   2590 de 5354, Loss: 0.552999210357666\n",
            "Epoch: 0, iteración;   2600 de 5354, Loss: 0.6388103485107421\n",
            "Epoch: 0, iteración;   2610 de 5354, Loss: 0.6099635601043701\n",
            "Epoch: 0, iteración;   2620 de 5354, Loss: 0.6122282981872559\n",
            "Epoch: 0, iteración;   2630 de 5354, Loss: 0.5852056026458741\n",
            "Epoch: 0, iteración;   2640 de 5354, Loss: 0.6148159027099609\n",
            "Epoch: 0, iteración;   2650 de 5354, Loss: 0.5668930053710938\n",
            "Epoch: 0, iteración;   2660 de 5354, Loss: 0.4987330913543701\n",
            "Epoch: 0, iteración;   2670 de 5354, Loss: 0.5729007720947266\n",
            "Epoch: 0, iteración;   2680 de 5354, Loss: 0.5352690696716309\n",
            "Epoch: 0, iteración;   2690 de 5354, Loss: 0.553717041015625\n",
            "Epoch: 0, iteración;   2700 de 5354, Loss: 0.5883572101593018\n",
            "Epoch: 0, iteración;   2710 de 5354, Loss: 0.5775083541870117\n",
            "Epoch: 0, iteración;   2720 de 5354, Loss: 0.5635404109954834\n",
            "Epoch: 0, iteración;   2730 de 5354, Loss: 0.6811741352081299\n",
            "Epoch: 0, iteración;   2740 de 5354, Loss: 0.5343726634979248\n",
            "Epoch: 0, iteración;   2750 de 5354, Loss: 0.5322166442871094\n",
            "Epoch: 0, iteración;   2760 de 5354, Loss: 0.7221784591674805\n",
            "Epoch: 0, iteración;   2770 de 5354, Loss: 0.5441812038421631\n",
            "Epoch: 0, iteración;   2780 de 5354, Loss: 0.5866516590118408\n",
            "Epoch: 0, iteración;   2790 de 5354, Loss: 0.5871542930603028\n",
            "Epoch: 0, iteración;   2800 de 5354, Loss: 0.5221435546875\n",
            "Epoch: 0, iteración;   2810 de 5354, Loss: 0.6414953231811523\n",
            "Epoch: 0, iteración;   2820 de 5354, Loss: 0.6390098094940185\n",
            "Epoch: 0, iteración;   2830 de 5354, Loss: 0.5999473094940185\n",
            "Epoch: 0, iteración;   2840 de 5354, Loss: 0.5896800041198731\n",
            "Epoch: 0, iteración;   2850 de 5354, Loss: 0.6206041812896729\n",
            "Epoch: 0, iteración;   2860 de 5354, Loss: 0.5992669105529785\n",
            "Epoch: 0, iteración;   2870 de 5354, Loss: 0.5905817985534668\n",
            "Epoch: 0, iteración;   2880 de 5354, Loss: 0.5101728916168213\n",
            "Epoch: 0, iteración;   2890 de 5354, Loss: 0.594947338104248\n",
            "Epoch: 0, iteración;   2900 de 5354, Loss: 0.5736099720001221\n",
            "Epoch: 0, iteración;   2910 de 5354, Loss: 0.5913361072540283\n",
            "Epoch: 0, iteración;   2920 de 5354, Loss: 0.49070096015930176\n",
            "Epoch: 0, iteración;   2930 de 5354, Loss: 0.5765122413635254\n",
            "Epoch: 0, iteración;   2940 de 5354, Loss: 0.6039942264556885\n",
            "Epoch: 0, iteración;   2950 de 5354, Loss: 0.6015447616577149\n",
            "Epoch: 0, iteración;   2960 de 5354, Loss: 0.5973161220550537\n",
            "Epoch: 0, iteración;   2970 de 5354, Loss: 0.5700223445892334\n",
            "Epoch: 0, iteración;   2980 de 5354, Loss: 0.5970998287200928\n",
            "Epoch: 0, iteración;   2990 de 5354, Loss: 0.5509049892425537\n",
            "Epoch: 0, iteración;   3000 de 5354, Loss: 0.5498667240142823\n",
            "Epoch: 0, iteración;   3010 de 5354, Loss: 0.6816365242004394\n",
            "Epoch: 0, iteración;   3020 de 5354, Loss: 0.5597227096557618\n",
            "Epoch: 0, iteración;   3030 de 5354, Loss: 0.6639580249786377\n",
            "Epoch: 0, iteración;   3040 de 5354, Loss: 0.6164264678955078\n",
            "Epoch: 0, iteración;   3050 de 5354, Loss: 0.607023811340332\n",
            "Epoch: 0, iteración;   3060 de 5354, Loss: 0.5679915904998779\n",
            "Epoch: 0, iteración;   3070 de 5354, Loss: 0.6446020603179932\n",
            "Epoch: 0, iteración;   3080 de 5354, Loss: 0.6220785617828369\n",
            "Epoch: 0, iteración;   3090 de 5354, Loss: 0.6197661399841309\n",
            "Epoch: 0, iteración;   3100 de 5354, Loss: 0.6576467990875244\n",
            "Epoch: 0, iteración;   3110 de 5354, Loss: 0.5939528465270996\n",
            "Epoch: 0, iteración;   3120 de 5354, Loss: 0.6079737186431885\n",
            "Epoch: 0, iteración;   3130 de 5354, Loss: 0.550571346282959\n",
            "Epoch: 0, iteración;   3140 de 5354, Loss: 0.6138425827026367\n",
            "Epoch: 0, iteración;   3150 de 5354, Loss: 0.6154623031616211\n",
            "Epoch: 0, iteración;   3160 de 5354, Loss: 0.6070187091827393\n",
            "Epoch: 0, iteración;   3170 de 5354, Loss: 0.6029653072357177\n",
            "Epoch: 0, iteración;   3180 de 5354, Loss: 0.6353080749511719\n",
            "Epoch: 0, iteración;   3190 de 5354, Loss: 0.584959602355957\n",
            "Epoch: 0, iteración;   3200 de 5354, Loss: 0.5471726894378662\n",
            "Epoch: 0, iteración;   3210 de 5354, Loss: 0.6425949096679687\n",
            "Epoch: 0, iteración;   3220 de 5354, Loss: 0.6197551250457763\n",
            "Epoch: 0, iteración;   3230 de 5354, Loss: 0.6698714256286621\n",
            "Epoch: 0, iteración;   3240 de 5354, Loss: 0.6093222618103027\n",
            "Epoch: 0, iteración;   3250 de 5354, Loss: 0.5960212707519531\n",
            "Epoch: 0, iteración;   3260 de 5354, Loss: 0.6291104793548584\n",
            "Epoch: 0, iteración;   3270 de 5354, Loss: 0.6021667957305908\n",
            "Epoch: 0, iteración;   3280 de 5354, Loss: 0.6307879447937011\n",
            "Epoch: 0, iteración;   3290 de 5354, Loss: 0.5942981243133545\n",
            "Epoch: 0, iteración;   3300 de 5354, Loss: 0.5584496974945068\n",
            "Epoch: 0, iteración;   3310 de 5354, Loss: 0.4490823268890381\n",
            "Epoch: 0, iteración;   3320 de 5354, Loss: 0.6576507091522217\n",
            "Epoch: 0, iteración;   3330 de 5354, Loss: 0.6050291538238526\n",
            "Epoch: 0, iteración;   3340 de 5354, Loss: 0.6414371967315674\n",
            "Epoch: 0, iteración;   3350 de 5354, Loss: 0.6625176429748535\n",
            "Epoch: 0, iteración;   3360 de 5354, Loss: 0.585884952545166\n",
            "Epoch: 0, iteración;   3370 de 5354, Loss: 0.5714706897735595\n",
            "Epoch: 0, iteración;   3380 de 5354, Loss: 0.5104245185852051\n",
            "Epoch: 0, iteración;   3390 de 5354, Loss: 0.5554888725280762\n",
            "Epoch: 0, iteración;   3400 de 5354, Loss: 0.5494033813476562\n",
            "Epoch: 0, iteración;   3410 de 5354, Loss: 0.6379981517791748\n",
            "Epoch: 0, iteración;   3420 de 5354, Loss: 0.549466609954834\n",
            "Epoch: 0, iteración;   3430 de 5354, Loss: 0.46642231941223145\n",
            "Epoch: 0, iteración;   3440 de 5354, Loss: 0.5113183498382569\n",
            "Epoch: 0, iteración;   3450 de 5354, Loss: 0.6175417423248291\n",
            "Epoch: 0, iteración;   3460 de 5354, Loss: 0.6322527885437011\n",
            "Epoch: 0, iteración;   3470 de 5354, Loss: 0.6813299179077148\n",
            "Epoch: 0, iteración;   3480 de 5354, Loss: 0.6182227611541748\n",
            "Epoch: 0, iteración;   3490 de 5354, Loss: 0.5652227878570557\n",
            "Epoch: 0, iteración;   3500 de 5354, Loss: 0.5740334987640381\n",
            "Epoch: 0, iteración;   3510 de 5354, Loss: 0.5313264846801757\n",
            "Epoch: 0, iteración;   3520 de 5354, Loss: 0.4745917797088623\n",
            "Epoch: 0, iteración;   3530 de 5354, Loss: 0.4987215042114258\n",
            "Epoch: 0, iteración;   3540 de 5354, Loss: 0.7404718399047852\n",
            "Epoch: 0, iteración;   3550 de 5354, Loss: 0.48325228691101074\n",
            "Epoch: 0, iteración;   3560 de 5354, Loss: 0.6830245971679687\n",
            "Epoch: 0, iteración;   3570 de 5354, Loss: 0.6142484664916992\n",
            "Epoch: 0, iteración;   3580 de 5354, Loss: 0.675870132446289\n",
            "Epoch: 0, iteración;   3590 de 5354, Loss: 0.6070886611938476\n",
            "Epoch: 0, iteración;   3600 de 5354, Loss: 0.5183302879333496\n",
            "Epoch: 0, iteración;   3610 de 5354, Loss: 0.5499191761016846\n",
            "Epoch: 0, iteración;   3620 de 5354, Loss: 0.6406270027160644\n",
            "Epoch: 0, iteración;   3630 de 5354, Loss: 0.5933602333068848\n",
            "Epoch: 0, iteración;   3640 de 5354, Loss: 0.6272547245025635\n",
            "Epoch: 0, iteración;   3650 de 5354, Loss: 0.5815445899963378\n",
            "Epoch: 0, iteración;   3660 de 5354, Loss: 0.5719994068145752\n",
            "Epoch: 0, iteración;   3670 de 5354, Loss: 0.5541909217834473\n",
            "Epoch: 0, iteración;   3680 de 5354, Loss: 0.6442958831787109\n",
            "Epoch: 0, iteración;   3690 de 5354, Loss: 0.5446531295776367\n",
            "Epoch: 0, iteración;   3700 de 5354, Loss: 0.615947961807251\n",
            "Epoch: 0, iteración;   3710 de 5354, Loss: 0.6017637252807617\n",
            "Epoch: 0, iteración;   3720 de 5354, Loss: 0.5666004657745362\n",
            "Epoch: 0, iteración;   3730 de 5354, Loss: 0.6207072257995605\n",
            "Epoch: 0, iteración;   3740 de 5354, Loss: 0.47501702308654786\n",
            "Epoch: 0, iteración;   3750 de 5354, Loss: 0.615529727935791\n",
            "Epoch: 0, iteración;   3760 de 5354, Loss: 0.5933619022369385\n",
            "Epoch: 0, iteración;   3770 de 5354, Loss: 0.5638328552246094\n",
            "Epoch: 0, iteración;   3780 de 5354, Loss: 0.6006828784942627\n",
            "Epoch: 0, iteración;   3790 de 5354, Loss: 0.6136377334594727\n",
            "Epoch: 0, iteración;   3800 de 5354, Loss: 0.6246576309204102\n",
            "Epoch: 0, iteración;   3810 de 5354, Loss: 0.5677196502685546\n",
            "Epoch: 0, iteración;   3820 de 5354, Loss: 0.6330292701721192\n",
            "Epoch: 0, iteración;   3830 de 5354, Loss: 0.600747013092041\n",
            "Epoch: 0, iteración;   3840 de 5354, Loss: 0.6010951995849609\n",
            "Epoch: 0, iteración;   3850 de 5354, Loss: 0.5908540248870849\n",
            "Epoch: 0, iteración;   3860 de 5354, Loss: 0.6397415637969971\n",
            "Epoch: 0, iteración;   3870 de 5354, Loss: 0.5352173805236816\n",
            "Epoch: 0, iteración;   3880 de 5354, Loss: 0.5511063575744629\n",
            "Epoch: 0, iteración;   3890 de 5354, Loss: 0.5714803695678711\n",
            "Epoch: 0, iteración;   3900 de 5354, Loss: 0.5825820922851562\n",
            "Epoch: 0, iteración;   3910 de 5354, Loss: 0.5617458820343018\n",
            "Epoch: 0, iteración;   3920 de 5354, Loss: 0.5490434169769287\n",
            "Epoch: 0, iteración;   3930 de 5354, Loss: 0.5582713603973388\n",
            "Epoch: 0, iteración;   3940 de 5354, Loss: 0.62342848777771\n",
            "Epoch: 0, iteración;   3950 de 5354, Loss: 0.5578135013580322\n",
            "Epoch: 0, iteración;   3960 de 5354, Loss: 0.5009694576263428\n",
            "Epoch: 0, iteración;   3970 de 5354, Loss: 0.7206196308135986\n",
            "Epoch: 0, iteración;   3980 de 5354, Loss: 0.6106451034545899\n",
            "Epoch: 0, iteración;   3990 de 5354, Loss: 0.5892097473144531\n",
            "Epoch: 0, iteración;   4000 de 5354, Loss: 0.6487017631530761\n",
            "Epoch: 0, iteración;   4010 de 5354, Loss: 0.5882444381713867\n",
            "Epoch: 0, iteración;   4020 de 5354, Loss: 0.714621114730835\n",
            "Epoch: 0, iteración;   4030 de 5354, Loss: 0.5960187435150146\n",
            "Epoch: 0, iteración;   4040 de 5354, Loss: 0.6037223815917969\n",
            "Epoch: 0, iteración;   4050 de 5354, Loss: 0.6457448959350586\n",
            "Epoch: 0, iteración;   4060 de 5354, Loss: 0.5435178756713868\n",
            "Epoch: 0, iteración;   4070 de 5354, Loss: 0.5766671180725098\n",
            "Epoch: 0, iteración;   4080 de 5354, Loss: 0.606717300415039\n",
            "Epoch: 0, iteración;   4090 de 5354, Loss: 0.7113399505615234\n",
            "Epoch: 0, iteración;   4100 de 5354, Loss: 0.6039137363433837\n",
            "Epoch: 0, iteración;   4110 de 5354, Loss: 0.6277256011962891\n",
            "Epoch: 0, iteración;   4120 de 5354, Loss: 0.6220196723937989\n",
            "Epoch: 0, iteración;   4130 de 5354, Loss: 0.6044291496276856\n",
            "Epoch: 0, iteración;   4140 de 5354, Loss: 0.5222824096679688\n",
            "Epoch: 0, iteración;   4150 de 5354, Loss: 0.5282424926757813\n",
            "Epoch: 0, iteración;   4160 de 5354, Loss: 0.6174514293670654\n",
            "Epoch: 0, iteración;   4170 de 5354, Loss: 0.5708736896514892\n",
            "Epoch: 0, iteración;   4180 de 5354, Loss: 0.5925908565521241\n",
            "Epoch: 0, iteración;   4190 de 5354, Loss: 0.5366918087005615\n",
            "Epoch: 0, iteración;   4200 de 5354, Loss: 0.6455286502838135\n",
            "Epoch: 0, iteración;   4210 de 5354, Loss: 0.5542641639709472\n",
            "Epoch: 0, iteración;   4220 de 5354, Loss: 0.6699056625366211\n",
            "Epoch: 0, iteración;   4230 de 5354, Loss: 0.6103289127349854\n",
            "Epoch: 0, iteración;   4240 de 5354, Loss: 0.5606889724731445\n",
            "Epoch: 0, iteración;   4250 de 5354, Loss: 0.6644821166992188\n",
            "Epoch: 0, iteración;   4260 de 5354, Loss: 0.6185113430023194\n",
            "Epoch: 0, iteración;   4270 de 5354, Loss: 0.590828800201416\n",
            "Epoch: 0, iteración;   4280 de 5354, Loss: 0.7102621078491211\n",
            "Epoch: 0, iteración;   4290 de 5354, Loss: 0.629917049407959\n",
            "Epoch: 0, iteración;   4300 de 5354, Loss: 0.5847545146942139\n",
            "Epoch: 0, iteración;   4310 de 5354, Loss: 0.6575398445129395\n",
            "Epoch: 0, iteración;   4320 de 5354, Loss: 0.569457721710205\n",
            "Epoch: 0, iteración;   4330 de 5354, Loss: 0.6602269172668457\n",
            "Epoch: 0, iteración;   4340 de 5354, Loss: 0.5641910552978515\n",
            "Epoch: 0, iteración;   4350 de 5354, Loss: 0.5572971820831298\n",
            "Epoch: 0, iteración;   4360 de 5354, Loss: 0.6929749965667724\n",
            "Epoch: 0, iteración;   4370 de 5354, Loss: 0.6735883712768554\n",
            "Epoch: 0, iteración;   4380 de 5354, Loss: 0.5464259624481201\n",
            "Epoch: 0, iteración;   4390 de 5354, Loss: 0.607129430770874\n",
            "Epoch: 0, iteración;   4400 de 5354, Loss: 0.6934187412261963\n",
            "Epoch: 0, iteración;   4410 de 5354, Loss: 0.5918856620788574\n",
            "Epoch: 0, iteración;   4420 de 5354, Loss: 0.5041964054107666\n",
            "Epoch: 0, iteración;   4430 de 5354, Loss: 0.6276175022125244\n",
            "Epoch: 0, iteración;   4440 de 5354, Loss: 0.5958544254302979\n",
            "Epoch: 0, iteración;   4450 de 5354, Loss: 0.5894361972808838\n",
            "Epoch: 0, iteración;   4460 de 5354, Loss: 0.6547280788421631\n",
            "Epoch: 0, iteración;   4470 de 5354, Loss: 0.5690825939178467\n",
            "Epoch: 0, iteración;   4480 de 5354, Loss: 0.580582571029663\n",
            "Epoch: 0, iteración;   4490 de 5354, Loss: 0.6322543621063232\n",
            "Epoch: 0, iteración;   4500 de 5354, Loss: 0.5625980377197266\n",
            "Epoch: 0, iteración;   4510 de 5354, Loss: 0.6112396240234375\n",
            "Epoch: 0, iteración;   4520 de 5354, Loss: 0.5861911773681641\n",
            "Epoch: 0, iteración;   4530 de 5354, Loss: 0.5327314376831055\n",
            "Epoch: 0, iteración;   4540 de 5354, Loss: 0.5270275115966797\n",
            "Epoch: 0, iteración;   4550 de 5354, Loss: 0.6573112487792969\n",
            "Epoch: 0, iteración;   4560 de 5354, Loss: 0.6654678344726562\n",
            "Epoch: 0, iteración;   4570 de 5354, Loss: 0.5681772232055664\n",
            "Epoch: 0, iteración;   4580 de 5354, Loss: 0.5430405616760254\n",
            "Epoch: 0, iteración;   4590 de 5354, Loss: 0.6092358112335206\n",
            "Epoch: 0, iteración;   4600 de 5354, Loss: 0.5287932872772216\n",
            "Epoch: 0, iteración;   4610 de 5354, Loss: 0.6632082462310791\n",
            "Epoch: 0, iteración;   4620 de 5354, Loss: 0.5314481258392334\n",
            "Epoch: 0, iteración;   4630 de 5354, Loss: 0.5544230461120605\n",
            "Epoch: 0, iteración;   4640 de 5354, Loss: 0.5612054824829101\n",
            "Epoch: 0, iteración;   4650 de 5354, Loss: 0.579134178161621\n",
            "Epoch: 0, iteración;   4660 de 5354, Loss: 0.5242910861968995\n",
            "Epoch: 0, iteración;   4670 de 5354, Loss: 0.6088839530944824\n",
            "Epoch: 0, iteración;   4680 de 5354, Loss: 0.6421263694763184\n",
            "Epoch: 0, iteración;   4690 de 5354, Loss: 0.5838667392730713\n",
            "Epoch: 0, iteración;   4700 de 5354, Loss: 0.5918574810028077\n",
            "Epoch: 0, iteración;   4710 de 5354, Loss: 0.6391261100769043\n",
            "Epoch: 0, iteración;   4720 de 5354, Loss: 0.6237397193908691\n",
            "Epoch: 0, iteración;   4730 de 5354, Loss: 0.619036865234375\n",
            "Epoch: 0, iteración;   4740 de 5354, Loss: 0.6374026775360108\n",
            "Epoch: 0, iteración;   4750 de 5354, Loss: 0.647819995880127\n",
            "Epoch: 0, iteración;   4760 de 5354, Loss: 0.5884955883026123\n",
            "Epoch: 0, iteración;   4770 de 5354, Loss: 0.5271736145019531\n",
            "Epoch: 0, iteración;   4780 de 5354, Loss: 0.5259072780609131\n",
            "Epoch: 0, iteración;   4790 de 5354, Loss: 0.614310359954834\n",
            "Epoch: 0, iteración;   4800 de 5354, Loss: 0.5934659004211426\n",
            "Epoch: 0, iteración;   4810 de 5354, Loss: 0.6254764080047608\n",
            "Epoch: 0, iteración;   4820 de 5354, Loss: 0.5346229553222657\n",
            "Epoch: 0, iteración;   4830 de 5354, Loss: 0.514025068283081\n",
            "Epoch: 0, iteración;   4840 de 5354, Loss: 0.6128086566925048\n",
            "Epoch: 0, iteración;   4850 de 5354, Loss: 0.614152193069458\n",
            "Epoch: 0, iteración;   4860 de 5354, Loss: 0.661354398727417\n",
            "Epoch: 0, iteración;   4870 de 5354, Loss: 0.5706984519958496\n",
            "Epoch: 0, iteración;   4880 de 5354, Loss: 0.6672816276550293\n",
            "Epoch: 0, iteración;   4890 de 5354, Loss: 0.6250702857971191\n",
            "Epoch: 0, iteración;   4900 de 5354, Loss: 0.640201187133789\n",
            "Epoch: 0, iteración;   4910 de 5354, Loss: 0.5489439487457275\n",
            "Epoch: 0, iteración;   4920 de 5354, Loss: 0.5830388069152832\n",
            "Epoch: 0, iteración;   4930 de 5354, Loss: 0.6597391128540039\n",
            "Epoch: 0, iteración;   4940 de 5354, Loss: 0.5839335441589355\n",
            "Epoch: 0, iteración;   4950 de 5354, Loss: 0.6777899265289307\n",
            "Epoch: 0, iteración;   4960 de 5354, Loss: 0.5606641292572021\n",
            "Epoch: 0, iteración;   4970 de 5354, Loss: 0.6028423309326172\n",
            "Epoch: 0, iteración;   4980 de 5354, Loss: 0.6093159675598144\n",
            "Epoch: 0, iteración;   4990 de 5354, Loss: 0.560707426071167\n",
            "Epoch: 0, iteración;   5000 de 5354, Loss: 0.4851683616638184\n",
            "Epoch: 0, iteración;   5010 de 5354, Loss: 0.6654098987579345\n",
            "Epoch: 0, iteración;   5020 de 5354, Loss: 0.5107755661010742\n",
            "Epoch: 0, iteración;   5030 de 5354, Loss: 0.5916356563568115\n",
            "Epoch: 0, iteración;   5040 de 5354, Loss: 0.6968782901763916\n",
            "Epoch: 0, iteración;   5050 de 5354, Loss: 0.6050697326660156\n",
            "Epoch: 0, iteración;   5060 de 5354, Loss: 0.6149352073669434\n",
            "Epoch: 0, iteración;   5070 de 5354, Loss: 0.5775328636169433\n",
            "Epoch: 0, iteración;   5080 de 5354, Loss: 0.6167909622192382\n",
            "Epoch: 0, iteración;   5090 de 5354, Loss: 0.61424880027771\n",
            "Epoch: 0, iteración;   5100 de 5354, Loss: 0.5715142250061035\n",
            "Epoch: 0, iteración;   5110 de 5354, Loss: 0.5964803695678711\n",
            "Epoch: 0, iteración;   5120 de 5354, Loss: 0.57913236618042\n",
            "Epoch: 0, iteración;   5130 de 5354, Loss: 0.5771020889282227\n",
            "Epoch: 0, iteración;   5140 de 5354, Loss: 0.6063188076019287\n",
            "Epoch: 0, iteración;   5150 de 5354, Loss: 0.5834736824035645\n",
            "Epoch: 0, iteración;   5160 de 5354, Loss: 0.5412223815917969\n",
            "Epoch: 0, iteración;   5170 de 5354, Loss: 0.7125068187713623\n",
            "Epoch: 0, iteración;   5180 de 5354, Loss: 0.70801682472229\n",
            "Epoch: 0, iteración;   5190 de 5354, Loss: 0.6253952026367188\n",
            "Epoch: 0, iteración;   5200 de 5354, Loss: 0.5776038646697998\n",
            "Epoch: 0, iteración;   5210 de 5354, Loss: 0.5896492004394531\n",
            "Epoch: 0, iteración;   5220 de 5354, Loss: 0.5758507728576661\n",
            "Epoch: 0, iteración;   5230 de 5354, Loss: 0.5922762393951416\n",
            "Epoch: 0, iteración;   5240 de 5354, Loss: 0.6435315608978271\n",
            "Epoch: 0, iteración;   5250 de 5354, Loss: 0.6055938720703125\n",
            "Epoch: 0, iteración;   5260 de 5354, Loss: 0.6030665397644043\n",
            "Epoch: 0, iteración;   5270 de 5354, Loss: 0.6332460403442383\n",
            "Epoch: 0, iteración;   5280 de 5354, Loss: 0.5073390007019043\n",
            "Epoch: 0, iteración;   5290 de 5354, Loss: 0.5648658275604248\n",
            "Epoch: 0, iteración;   5300 de 5354, Loss: 0.569917631149292\n",
            "Epoch: 0, iteración;   5310 de 5354, Loss: 0.5365452289581298\n",
            "Epoch: 0, iteración;   5320 de 5354, Loss: 0.6090641975402832\n",
            "Epoch: 0, iteración;   5330 de 5354, Loss: 0.6691833972930908\n",
            "Epoch: 0, iteración;   5340 de 5354, Loss: 0.5963304996490478\n",
            "Epoch: 0, iteración;   5350 de 5354, Loss: 0.5514216899871827\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainRoberta(epoch)"
      ],
      "id": "5EamFBKVXNG0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2674e79-232e-4524-8eba-9c541190ff49",
        "id": "qdrFcauAXNG0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_30_separados.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "id": "qdrFcauAXNG0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVcQB42KXNG0"
      },
      "source": [
        "##### Evaluación del modelo"
      ],
      "id": "wVcQB42KXNG0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBEvgzZzXNG0"
      },
      "outputs": [],
      "source": [
        "def validationRoberta(epoch):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    num_iteraciones = len(testing_loader)\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device)\n",
        "            mask = data['mask'].to(device)\n",
        "            token_type_ids = data['token_type_ids'].to(device)\n",
        "            targets = data['target'].to(device)\n",
        "\n",
        "            print(f\"Iteración: {i:6} de {num_iteraciones}\")\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "id": "LBEvgzZzXNG0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "nnGsPeb4XNG0"
      },
      "id": "nnGsPeb4XNG0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETos186_XNG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05702147-95fa-42d9-c312-8bcf2137f310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado correctamente\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_30_separados.pth\"):\n",
        "  model = RobertaClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_30_separados.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_30_separados.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "id": "ETos186_XNG0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806f654a-7489-4631-c494-ee77f9cf66a0",
        "id": "zwL5miYUXNG0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración:      0 de 1562\n",
            "Iteración:      1 de 1562\n",
            "Iteración:      2 de 1562\n",
            "Iteración:      3 de 1562\n",
            "Iteración:      4 de 1562\n",
            "Iteración:      5 de 1562\n",
            "Iteración:      6 de 1562\n",
            "Iteración:      7 de 1562\n",
            "Iteración:      8 de 1562\n",
            "Iteración:      9 de 1562\n",
            "Iteración:     10 de 1562\n",
            "Iteración:     11 de 1562\n",
            "Iteración:     12 de 1562\n",
            "Iteración:     13 de 1562\n",
            "Iteración:     14 de 1562\n",
            "Iteración:     15 de 1562\n",
            "Iteración:     16 de 1562\n",
            "Iteración:     17 de 1562\n",
            "Iteración:     18 de 1562\n",
            "Iteración:     19 de 1562\n",
            "Iteración:     20 de 1562\n",
            "Iteración:     21 de 1562\n",
            "Iteración:     22 de 1562\n",
            "Iteración:     23 de 1562\n",
            "Iteración:     24 de 1562\n",
            "Iteración:     25 de 1562\n",
            "Iteración:     26 de 1562\n",
            "Iteración:     27 de 1562\n",
            "Iteración:     28 de 1562\n",
            "Iteración:     29 de 1562\n",
            "Iteración:     30 de 1562\n",
            "Iteración:     31 de 1562\n",
            "Iteración:     32 de 1562\n",
            "Iteración:     33 de 1562\n",
            "Iteración:     34 de 1562\n",
            "Iteración:     35 de 1562\n",
            "Iteración:     36 de 1562\n",
            "Iteración:     37 de 1562\n",
            "Iteración:     38 de 1562\n",
            "Iteración:     39 de 1562\n",
            "Iteración:     40 de 1562\n",
            "Iteración:     41 de 1562\n",
            "Iteración:     42 de 1562\n",
            "Iteración:     43 de 1562\n",
            "Iteración:     44 de 1562\n",
            "Iteración:     45 de 1562\n",
            "Iteración:     46 de 1562\n",
            "Iteración:     47 de 1562\n",
            "Iteración:     48 de 1562\n",
            "Iteración:     49 de 1562\n",
            "Iteración:     50 de 1562\n",
            "Iteración:     51 de 1562\n",
            "Iteración:     52 de 1562\n",
            "Iteración:     53 de 1562\n",
            "Iteración:     54 de 1562\n",
            "Iteración:     55 de 1562\n",
            "Iteración:     56 de 1562\n",
            "Iteración:     57 de 1562\n",
            "Iteración:     58 de 1562\n",
            "Iteración:     59 de 1562\n",
            "Iteración:     60 de 1562\n",
            "Iteración:     61 de 1562\n",
            "Iteración:     62 de 1562\n",
            "Iteración:     63 de 1562\n",
            "Iteración:     64 de 1562\n",
            "Iteración:     65 de 1562\n",
            "Iteración:     66 de 1562\n",
            "Iteración:     67 de 1562\n",
            "Iteración:     68 de 1562\n",
            "Iteración:     69 de 1562\n",
            "Iteración:     70 de 1562\n",
            "Iteración:     71 de 1562\n",
            "Iteración:     72 de 1562\n",
            "Iteración:     73 de 1562\n",
            "Iteración:     74 de 1562\n",
            "Iteración:     75 de 1562\n",
            "Iteración:     76 de 1562\n",
            "Iteración:     77 de 1562\n",
            "Iteración:     78 de 1562\n",
            "Iteración:     79 de 1562\n",
            "Iteración:     80 de 1562\n",
            "Iteración:     81 de 1562\n",
            "Iteración:     82 de 1562\n",
            "Iteración:     83 de 1562\n",
            "Iteración:     84 de 1562\n",
            "Iteración:     85 de 1562\n",
            "Iteración:     86 de 1562\n",
            "Iteración:     87 de 1562\n",
            "Iteración:     88 de 1562\n",
            "Iteración:     89 de 1562\n",
            "Iteración:     90 de 1562\n",
            "Iteración:     91 de 1562\n",
            "Iteración:     92 de 1562\n",
            "Iteración:     93 de 1562\n",
            "Iteración:     94 de 1562\n",
            "Iteración:     95 de 1562\n",
            "Iteración:     96 de 1562\n",
            "Iteración:     97 de 1562\n",
            "Iteración:     98 de 1562\n",
            "Iteración:     99 de 1562\n",
            "Iteración:    100 de 1562\n",
            "Iteración:    101 de 1562\n",
            "Iteración:    102 de 1562\n",
            "Iteración:    103 de 1562\n",
            "Iteración:    104 de 1562\n",
            "Iteración:    105 de 1562\n",
            "Iteración:    106 de 1562\n",
            "Iteración:    107 de 1562\n",
            "Iteración:    108 de 1562\n",
            "Iteración:    109 de 1562\n",
            "Iteración:    110 de 1562\n",
            "Iteración:    111 de 1562\n",
            "Iteración:    112 de 1562\n",
            "Iteración:    113 de 1562\n",
            "Iteración:    114 de 1562\n",
            "Iteración:    115 de 1562\n",
            "Iteración:    116 de 1562\n",
            "Iteración:    117 de 1562\n",
            "Iteración:    118 de 1562\n",
            "Iteración:    119 de 1562\n",
            "Iteración:    120 de 1562\n",
            "Iteración:    121 de 1562\n",
            "Iteración:    122 de 1562\n",
            "Iteración:    123 de 1562\n",
            "Iteración:    124 de 1562\n",
            "Iteración:    125 de 1562\n",
            "Iteración:    126 de 1562\n",
            "Iteración:    127 de 1562\n",
            "Iteración:    128 de 1562\n",
            "Iteración:    129 de 1562\n",
            "Iteración:    130 de 1562\n",
            "Iteración:    131 de 1562\n",
            "Iteración:    132 de 1562\n",
            "Iteración:    133 de 1562\n",
            "Iteración:    134 de 1562\n",
            "Iteración:    135 de 1562\n",
            "Iteración:    136 de 1562\n",
            "Iteración:    137 de 1562\n",
            "Iteración:    138 de 1562\n",
            "Iteración:    139 de 1562\n",
            "Iteración:    140 de 1562\n",
            "Iteración:    141 de 1562\n",
            "Iteración:    142 de 1562\n",
            "Iteración:    143 de 1562\n",
            "Iteración:    144 de 1562\n",
            "Iteración:    145 de 1562\n",
            "Iteración:    146 de 1562\n",
            "Iteración:    147 de 1562\n",
            "Iteración:    148 de 1562\n",
            "Iteración:    149 de 1562\n",
            "Iteración:    150 de 1562\n",
            "Iteración:    151 de 1562\n",
            "Iteración:    152 de 1562\n",
            "Iteración:    153 de 1562\n",
            "Iteración:    154 de 1562\n",
            "Iteración:    155 de 1562\n",
            "Iteración:    156 de 1562\n",
            "Iteración:    157 de 1562\n",
            "Iteración:    158 de 1562\n",
            "Iteración:    159 de 1562\n",
            "Iteración:    160 de 1562\n",
            "Iteración:    161 de 1562\n",
            "Iteración:    162 de 1562\n",
            "Iteración:    163 de 1562\n",
            "Iteración:    164 de 1562\n",
            "Iteración:    165 de 1562\n",
            "Iteración:    166 de 1562\n",
            "Iteración:    167 de 1562\n",
            "Iteración:    168 de 1562\n",
            "Iteración:    169 de 1562\n",
            "Iteración:    170 de 1562\n",
            "Iteración:    171 de 1562\n",
            "Iteración:    172 de 1562\n",
            "Iteración:    173 de 1562\n",
            "Iteración:    174 de 1562\n",
            "Iteración:    175 de 1562\n",
            "Iteración:    176 de 1562\n",
            "Iteración:    177 de 1562\n",
            "Iteración:    178 de 1562\n",
            "Iteración:    179 de 1562\n",
            "Iteración:    180 de 1562\n",
            "Iteración:    181 de 1562\n",
            "Iteración:    182 de 1562\n",
            "Iteración:    183 de 1562\n",
            "Iteración:    184 de 1562\n",
            "Iteración:    185 de 1562\n",
            "Iteración:    186 de 1562\n",
            "Iteración:    187 de 1562\n",
            "Iteración:    188 de 1562\n",
            "Iteración:    189 de 1562\n",
            "Iteración:    190 de 1562\n",
            "Iteración:    191 de 1562\n",
            "Iteración:    192 de 1562\n",
            "Iteración:    193 de 1562\n",
            "Iteración:    194 de 1562\n",
            "Iteración:    195 de 1562\n",
            "Iteración:    196 de 1562\n",
            "Iteración:    197 de 1562\n",
            "Iteración:    198 de 1562\n",
            "Iteración:    199 de 1562\n",
            "Iteración:    200 de 1562\n",
            "Iteración:    201 de 1562\n",
            "Iteración:    202 de 1562\n",
            "Iteración:    203 de 1562\n",
            "Iteración:    204 de 1562\n",
            "Iteración:    205 de 1562\n",
            "Iteración:    206 de 1562\n",
            "Iteración:    207 de 1562\n",
            "Iteración:    208 de 1562\n",
            "Iteración:    209 de 1562\n",
            "Iteración:    210 de 1562\n",
            "Iteración:    211 de 1562\n",
            "Iteración:    212 de 1562\n",
            "Iteración:    213 de 1562\n",
            "Iteración:    214 de 1562\n",
            "Iteración:    215 de 1562\n",
            "Iteración:    216 de 1562\n",
            "Iteración:    217 de 1562\n",
            "Iteración:    218 de 1562\n",
            "Iteración:    219 de 1562\n",
            "Iteración:    220 de 1562\n",
            "Iteración:    221 de 1562\n",
            "Iteración:    222 de 1562\n",
            "Iteración:    223 de 1562\n",
            "Iteración:    224 de 1562\n",
            "Iteración:    225 de 1562\n",
            "Iteración:    226 de 1562\n",
            "Iteración:    227 de 1562\n",
            "Iteración:    228 de 1562\n",
            "Iteración:    229 de 1562\n",
            "Iteración:    230 de 1562\n",
            "Iteración:    231 de 1562\n",
            "Iteración:    232 de 1562\n",
            "Iteración:    233 de 1562\n",
            "Iteración:    234 de 1562\n",
            "Iteración:    235 de 1562\n",
            "Iteración:    236 de 1562\n",
            "Iteración:    237 de 1562\n",
            "Iteración:    238 de 1562\n",
            "Iteración:    239 de 1562\n",
            "Iteración:    240 de 1562\n",
            "Iteración:    241 de 1562\n",
            "Iteración:    242 de 1562\n",
            "Iteración:    243 de 1562\n",
            "Iteración:    244 de 1562\n",
            "Iteración:    245 de 1562\n",
            "Iteración:    246 de 1562\n",
            "Iteración:    247 de 1562\n",
            "Iteración:    248 de 1562\n",
            "Iteración:    249 de 1562\n",
            "Iteración:    250 de 1562\n",
            "Iteración:    251 de 1562\n",
            "Iteración:    252 de 1562\n",
            "Iteración:    253 de 1562\n",
            "Iteración:    254 de 1562\n",
            "Iteración:    255 de 1562\n",
            "Iteración:    256 de 1562\n",
            "Iteración:    257 de 1562\n",
            "Iteración:    258 de 1562\n",
            "Iteración:    259 de 1562\n",
            "Iteración:    260 de 1562\n",
            "Iteración:    261 de 1562\n",
            "Iteración:    262 de 1562\n",
            "Iteración:    263 de 1562\n",
            "Iteración:    264 de 1562\n",
            "Iteración:    265 de 1562\n",
            "Iteración:    266 de 1562\n",
            "Iteración:    267 de 1562\n",
            "Iteración:    268 de 1562\n",
            "Iteración:    269 de 1562\n",
            "Iteración:    270 de 1562\n",
            "Iteración:    271 de 1562\n",
            "Iteración:    272 de 1562\n",
            "Iteración:    273 de 1562\n",
            "Iteración:    274 de 1562\n",
            "Iteración:    275 de 1562\n",
            "Iteración:    276 de 1562\n",
            "Iteración:    277 de 1562\n",
            "Iteración:    278 de 1562\n",
            "Iteración:    279 de 1562\n",
            "Iteración:    280 de 1562\n",
            "Iteración:    281 de 1562\n",
            "Iteración:    282 de 1562\n",
            "Iteración:    283 de 1562\n",
            "Iteración:    284 de 1562\n",
            "Iteración:    285 de 1562\n",
            "Iteración:    286 de 1562\n",
            "Iteración:    287 de 1562\n",
            "Iteración:    288 de 1562\n",
            "Iteración:    289 de 1562\n",
            "Iteración:    290 de 1562\n",
            "Iteración:    291 de 1562\n",
            "Iteración:    292 de 1562\n",
            "Iteración:    293 de 1562\n",
            "Iteración:    294 de 1562\n",
            "Iteración:    295 de 1562\n",
            "Iteración:    296 de 1562\n",
            "Iteración:    297 de 1562\n",
            "Iteración:    298 de 1562\n",
            "Iteración:    299 de 1562\n",
            "Iteración:    300 de 1562\n",
            "Iteración:    301 de 1562\n",
            "Iteración:    302 de 1562\n",
            "Iteración:    303 de 1562\n",
            "Iteración:    304 de 1562\n",
            "Iteración:    305 de 1562\n",
            "Iteración:    306 de 1562\n",
            "Iteración:    307 de 1562\n",
            "Iteración:    308 de 1562\n",
            "Iteración:    309 de 1562\n",
            "Iteración:    310 de 1562\n",
            "Iteración:    311 de 1562\n",
            "Iteración:    312 de 1562\n",
            "Iteración:    313 de 1562\n",
            "Iteración:    314 de 1562\n",
            "Iteración:    315 de 1562\n",
            "Iteración:    316 de 1562\n",
            "Iteración:    317 de 1562\n",
            "Iteración:    318 de 1562\n",
            "Iteración:    319 de 1562\n",
            "Iteración:    320 de 1562\n",
            "Iteración:    321 de 1562\n",
            "Iteración:    322 de 1562\n",
            "Iteración:    323 de 1562\n",
            "Iteración:    324 de 1562\n",
            "Iteración:    325 de 1562\n",
            "Iteración:    326 de 1562\n",
            "Iteración:    327 de 1562\n",
            "Iteración:    328 de 1562\n",
            "Iteración:    329 de 1562\n",
            "Iteración:    330 de 1562\n",
            "Iteración:    331 de 1562\n",
            "Iteración:    332 de 1562\n",
            "Iteración:    333 de 1562\n",
            "Iteración:    334 de 1562\n",
            "Iteración:    335 de 1562\n",
            "Iteración:    336 de 1562\n",
            "Iteración:    337 de 1562\n",
            "Iteración:    338 de 1562\n",
            "Iteración:    339 de 1562\n",
            "Iteración:    340 de 1562\n",
            "Iteración:    341 de 1562\n",
            "Iteración:    342 de 1562\n",
            "Iteración:    343 de 1562\n",
            "Iteración:    344 de 1562\n",
            "Iteración:    345 de 1562\n",
            "Iteración:    346 de 1562\n",
            "Iteración:    347 de 1562\n",
            "Iteración:    348 de 1562\n",
            "Iteración:    349 de 1562\n",
            "Iteración:    350 de 1562\n",
            "Iteración:    351 de 1562\n",
            "Iteración:    352 de 1562\n",
            "Iteración:    353 de 1562\n",
            "Iteración:    354 de 1562\n",
            "Iteración:    355 de 1562\n",
            "Iteración:    356 de 1562\n",
            "Iteración:    357 de 1562\n",
            "Iteración:    358 de 1562\n",
            "Iteración:    359 de 1562\n",
            "Iteración:    360 de 1562\n",
            "Iteración:    361 de 1562\n",
            "Iteración:    362 de 1562\n",
            "Iteración:    363 de 1562\n",
            "Iteración:    364 de 1562\n",
            "Iteración:    365 de 1562\n",
            "Iteración:    366 de 1562\n",
            "Iteración:    367 de 1562\n",
            "Iteración:    368 de 1562\n",
            "Iteración:    369 de 1562\n",
            "Iteración:    370 de 1562\n",
            "Iteración:    371 de 1562\n",
            "Iteración:    372 de 1562\n",
            "Iteración:    373 de 1562\n",
            "Iteración:    374 de 1562\n",
            "Iteración:    375 de 1562\n",
            "Iteración:    376 de 1562\n",
            "Iteración:    377 de 1562\n",
            "Iteración:    378 de 1562\n",
            "Iteración:    379 de 1562\n",
            "Iteración:    380 de 1562\n",
            "Iteración:    381 de 1562\n",
            "Iteración:    382 de 1562\n",
            "Iteración:    383 de 1562\n",
            "Iteración:    384 de 1562\n",
            "Iteración:    385 de 1562\n",
            "Iteración:    386 de 1562\n",
            "Iteración:    387 de 1562\n",
            "Iteración:    388 de 1562\n",
            "Iteración:    389 de 1562\n",
            "Iteración:    390 de 1562\n",
            "Iteración:    391 de 1562\n",
            "Iteración:    392 de 1562\n",
            "Iteración:    393 de 1562\n",
            "Iteración:    394 de 1562\n",
            "Iteración:    395 de 1562\n",
            "Iteración:    396 de 1562\n",
            "Iteración:    397 de 1562\n",
            "Iteración:    398 de 1562\n",
            "Iteración:    399 de 1562\n",
            "Iteración:    400 de 1562\n",
            "Iteración:    401 de 1562\n",
            "Iteración:    402 de 1562\n",
            "Iteración:    403 de 1562\n",
            "Iteración:    404 de 1562\n",
            "Iteración:    405 de 1562\n",
            "Iteración:    406 de 1562\n",
            "Iteración:    407 de 1562\n",
            "Iteración:    408 de 1562\n",
            "Iteración:    409 de 1562\n",
            "Iteración:    410 de 1562\n",
            "Iteración:    411 de 1562\n",
            "Iteración:    412 de 1562\n",
            "Iteración:    413 de 1562\n",
            "Iteración:    414 de 1562\n",
            "Iteración:    415 de 1562\n",
            "Iteración:    416 de 1562\n",
            "Iteración:    417 de 1562\n",
            "Iteración:    418 de 1562\n",
            "Iteración:    419 de 1562\n",
            "Iteración:    420 de 1562\n",
            "Iteración:    421 de 1562\n",
            "Iteración:    422 de 1562\n",
            "Iteración:    423 de 1562\n",
            "Iteración:    424 de 1562\n",
            "Iteración:    425 de 1562\n",
            "Iteración:    426 de 1562\n",
            "Iteración:    427 de 1562\n",
            "Iteración:    428 de 1562\n",
            "Iteración:    429 de 1562\n",
            "Iteración:    430 de 1562\n",
            "Iteración:    431 de 1562\n",
            "Iteración:    432 de 1562\n",
            "Iteración:    433 de 1562\n",
            "Iteración:    434 de 1562\n",
            "Iteración:    435 de 1562\n",
            "Iteración:    436 de 1562\n",
            "Iteración:    437 de 1562\n",
            "Iteración:    438 de 1562\n",
            "Iteración:    439 de 1562\n",
            "Iteración:    440 de 1562\n",
            "Iteración:    441 de 1562\n",
            "Iteración:    442 de 1562\n",
            "Iteración:    443 de 1562\n",
            "Iteración:    444 de 1562\n",
            "Iteración:    445 de 1562\n",
            "Iteración:    446 de 1562\n",
            "Iteración:    447 de 1562\n",
            "Iteración:    448 de 1562\n",
            "Iteración:    449 de 1562\n",
            "Iteración:    450 de 1562\n",
            "Iteración:    451 de 1562\n",
            "Iteración:    452 de 1562\n",
            "Iteración:    453 de 1562\n",
            "Iteración:    454 de 1562\n",
            "Iteración:    455 de 1562\n",
            "Iteración:    456 de 1562\n",
            "Iteración:    457 de 1562\n",
            "Iteración:    458 de 1562\n",
            "Iteración:    459 de 1562\n",
            "Iteración:    460 de 1562\n",
            "Iteración:    461 de 1562\n",
            "Iteración:    462 de 1562\n",
            "Iteración:    463 de 1562\n",
            "Iteración:    464 de 1562\n",
            "Iteración:    465 de 1562\n",
            "Iteración:    466 de 1562\n",
            "Iteración:    467 de 1562\n",
            "Iteración:    468 de 1562\n",
            "Iteración:    469 de 1562\n",
            "Iteración:    470 de 1562\n",
            "Iteración:    471 de 1562\n",
            "Iteración:    472 de 1562\n",
            "Iteración:    473 de 1562\n",
            "Iteración:    474 de 1562\n",
            "Iteración:    475 de 1562\n",
            "Iteración:    476 de 1562\n",
            "Iteración:    477 de 1562\n",
            "Iteración:    478 de 1562\n",
            "Iteración:    479 de 1562\n",
            "Iteración:    480 de 1562\n",
            "Iteración:    481 de 1562\n",
            "Iteración:    482 de 1562\n",
            "Iteración:    483 de 1562\n",
            "Iteración:    484 de 1562\n",
            "Iteración:    485 de 1562\n",
            "Iteración:    486 de 1562\n",
            "Iteración:    487 de 1562\n",
            "Iteración:    488 de 1562\n",
            "Iteración:    489 de 1562\n",
            "Iteración:    490 de 1562\n",
            "Iteración:    491 de 1562\n",
            "Iteración:    492 de 1562\n",
            "Iteración:    493 de 1562\n",
            "Iteración:    494 de 1562\n",
            "Iteración:    495 de 1562\n",
            "Iteración:    496 de 1562\n",
            "Iteración:    497 de 1562\n",
            "Iteración:    498 de 1562\n",
            "Iteración:    499 de 1562\n",
            "Iteración:    500 de 1562\n",
            "Iteración:    501 de 1562\n",
            "Iteración:    502 de 1562\n",
            "Iteración:    503 de 1562\n",
            "Iteración:    504 de 1562\n",
            "Iteración:    505 de 1562\n",
            "Iteración:    506 de 1562\n",
            "Iteración:    507 de 1562\n",
            "Iteración:    508 de 1562\n",
            "Iteración:    509 de 1562\n",
            "Iteración:    510 de 1562\n",
            "Iteración:    511 de 1562\n",
            "Iteración:    512 de 1562\n",
            "Iteración:    513 de 1562\n",
            "Iteración:    514 de 1562\n",
            "Iteración:    515 de 1562\n",
            "Iteración:    516 de 1562\n",
            "Iteración:    517 de 1562\n",
            "Iteración:    518 de 1562\n",
            "Iteración:    519 de 1562\n",
            "Iteración:    520 de 1562\n",
            "Iteración:    521 de 1562\n",
            "Iteración:    522 de 1562\n",
            "Iteración:    523 de 1562\n",
            "Iteración:    524 de 1562\n",
            "Iteración:    525 de 1562\n",
            "Iteración:    526 de 1562\n",
            "Iteración:    527 de 1562\n",
            "Iteración:    528 de 1562\n",
            "Iteración:    529 de 1562\n",
            "Iteración:    530 de 1562\n",
            "Iteración:    531 de 1562\n",
            "Iteración:    532 de 1562\n",
            "Iteración:    533 de 1562\n",
            "Iteración:    534 de 1562\n",
            "Iteración:    535 de 1562\n",
            "Iteración:    536 de 1562\n",
            "Iteración:    537 de 1562\n",
            "Iteración:    538 de 1562\n",
            "Iteración:    539 de 1562\n",
            "Iteración:    540 de 1562\n",
            "Iteración:    541 de 1562\n",
            "Iteración:    542 de 1562\n",
            "Iteración:    543 de 1562\n",
            "Iteración:    544 de 1562\n",
            "Iteración:    545 de 1562\n",
            "Iteración:    546 de 1562\n",
            "Iteración:    547 de 1562\n",
            "Iteración:    548 de 1562\n",
            "Iteración:    549 de 1562\n",
            "Iteración:    550 de 1562\n",
            "Iteración:    551 de 1562\n",
            "Iteración:    552 de 1562\n",
            "Iteración:    553 de 1562\n",
            "Iteración:    554 de 1562\n",
            "Iteración:    555 de 1562\n",
            "Iteración:    556 de 1562\n",
            "Iteración:    557 de 1562\n",
            "Iteración:    558 de 1562\n",
            "Iteración:    559 de 1562\n",
            "Iteración:    560 de 1562\n",
            "Iteración:    561 de 1562\n",
            "Iteración:    562 de 1562\n",
            "Iteración:    563 de 1562\n",
            "Iteración:    564 de 1562\n",
            "Iteración:    565 de 1562\n",
            "Iteración:    566 de 1562\n",
            "Iteración:    567 de 1562\n",
            "Iteración:    568 de 1562\n",
            "Iteración:    569 de 1562\n",
            "Iteración:    570 de 1562\n",
            "Iteración:    571 de 1562\n",
            "Iteración:    572 de 1562\n",
            "Iteración:    573 de 1562\n",
            "Iteración:    574 de 1562\n",
            "Iteración:    575 de 1562\n",
            "Iteración:    576 de 1562\n",
            "Iteración:    577 de 1562\n",
            "Iteración:    578 de 1562\n",
            "Iteración:    579 de 1562\n",
            "Iteración:    580 de 1562\n",
            "Iteración:    581 de 1562\n",
            "Iteración:    582 de 1562\n",
            "Iteración:    583 de 1562\n",
            "Iteración:    584 de 1562\n",
            "Iteración:    585 de 1562\n",
            "Iteración:    586 de 1562\n",
            "Iteración:    587 de 1562\n",
            "Iteración:    588 de 1562\n",
            "Iteración:    589 de 1562\n",
            "Iteración:    590 de 1562\n",
            "Iteración:    591 de 1562\n",
            "Iteración:    592 de 1562\n",
            "Iteración:    593 de 1562\n",
            "Iteración:    594 de 1562\n",
            "Iteración:    595 de 1562\n",
            "Iteración:    596 de 1562\n",
            "Iteración:    597 de 1562\n",
            "Iteración:    598 de 1562\n",
            "Iteración:    599 de 1562\n",
            "Iteración:    600 de 1562\n",
            "Iteración:    601 de 1562\n",
            "Iteración:    602 de 1562\n",
            "Iteración:    603 de 1562\n",
            "Iteración:    604 de 1562\n",
            "Iteración:    605 de 1562\n",
            "Iteración:    606 de 1562\n",
            "Iteración:    607 de 1562\n",
            "Iteración:    608 de 1562\n",
            "Iteración:    609 de 1562\n",
            "Iteración:    610 de 1562\n",
            "Iteración:    611 de 1562\n",
            "Iteración:    612 de 1562\n",
            "Iteración:    613 de 1562\n",
            "Iteración:    614 de 1562\n",
            "Iteración:    615 de 1562\n",
            "Iteración:    616 de 1562\n",
            "Iteración:    617 de 1562\n",
            "Iteración:    618 de 1562\n",
            "Iteración:    619 de 1562\n",
            "Iteración:    620 de 1562\n",
            "Iteración:    621 de 1562\n",
            "Iteración:    622 de 1562\n",
            "Iteración:    623 de 1562\n",
            "Iteración:    624 de 1562\n",
            "Iteración:    625 de 1562\n",
            "Iteración:    626 de 1562\n",
            "Iteración:    627 de 1562\n",
            "Iteración:    628 de 1562\n",
            "Iteración:    629 de 1562\n",
            "Iteración:    630 de 1562\n",
            "Iteración:    631 de 1562\n",
            "Iteración:    632 de 1562\n",
            "Iteración:    633 de 1562\n",
            "Iteración:    634 de 1562\n",
            "Iteración:    635 de 1562\n",
            "Iteración:    636 de 1562\n",
            "Iteración:    637 de 1562\n",
            "Iteración:    638 de 1562\n",
            "Iteración:    639 de 1562\n",
            "Iteración:    640 de 1562\n",
            "Iteración:    641 de 1562\n",
            "Iteración:    642 de 1562\n",
            "Iteración:    643 de 1562\n",
            "Iteración:    644 de 1562\n",
            "Iteración:    645 de 1562\n",
            "Iteración:    646 de 1562\n",
            "Iteración:    647 de 1562\n",
            "Iteración:    648 de 1562\n",
            "Iteración:    649 de 1562\n",
            "Iteración:    650 de 1562\n",
            "Iteración:    651 de 1562\n",
            "Iteración:    652 de 1562\n",
            "Iteración:    653 de 1562\n",
            "Iteración:    654 de 1562\n",
            "Iteración:    655 de 1562\n",
            "Iteración:    656 de 1562\n",
            "Iteración:    657 de 1562\n",
            "Iteración:    658 de 1562\n",
            "Iteración:    659 de 1562\n",
            "Iteración:    660 de 1562\n",
            "Iteración:    661 de 1562\n",
            "Iteración:    662 de 1562\n",
            "Iteración:    663 de 1562\n",
            "Iteración:    664 de 1562\n",
            "Iteración:    665 de 1562\n",
            "Iteración:    666 de 1562\n",
            "Iteración:    667 de 1562\n",
            "Iteración:    668 de 1562\n",
            "Iteración:    669 de 1562\n",
            "Iteración:    670 de 1562\n",
            "Iteración:    671 de 1562\n",
            "Iteración:    672 de 1562\n",
            "Iteración:    673 de 1562\n",
            "Iteración:    674 de 1562\n",
            "Iteración:    675 de 1562\n",
            "Iteración:    676 de 1562\n",
            "Iteración:    677 de 1562\n",
            "Iteración:    678 de 1562\n",
            "Iteración:    679 de 1562\n",
            "Iteración:    680 de 1562\n",
            "Iteración:    681 de 1562\n",
            "Iteración:    682 de 1562\n",
            "Iteración:    683 de 1562\n",
            "Iteración:    684 de 1562\n",
            "Iteración:    685 de 1562\n",
            "Iteración:    686 de 1562\n",
            "Iteración:    687 de 1562\n",
            "Iteración:    688 de 1562\n",
            "Iteración:    689 de 1562\n",
            "Iteración:    690 de 1562\n",
            "Iteración:    691 de 1562\n",
            "Iteración:    692 de 1562\n",
            "Iteración:    693 de 1562\n",
            "Iteración:    694 de 1562\n",
            "Iteración:    695 de 1562\n",
            "Iteración:    696 de 1562\n",
            "Iteración:    697 de 1562\n",
            "Iteración:    698 de 1562\n",
            "Iteración:    699 de 1562\n",
            "Iteración:    700 de 1562\n",
            "Iteración:    701 de 1562\n",
            "Iteración:    702 de 1562\n",
            "Iteración:    703 de 1562\n",
            "Iteración:    704 de 1562\n",
            "Iteración:    705 de 1562\n",
            "Iteración:    706 de 1562\n",
            "Iteración:    707 de 1562\n",
            "Iteración:    708 de 1562\n",
            "Iteración:    709 de 1562\n",
            "Iteración:    710 de 1562\n",
            "Iteración:    711 de 1562\n",
            "Iteración:    712 de 1562\n",
            "Iteración:    713 de 1562\n",
            "Iteración:    714 de 1562\n",
            "Iteración:    715 de 1562\n",
            "Iteración:    716 de 1562\n",
            "Iteración:    717 de 1562\n",
            "Iteración:    718 de 1562\n",
            "Iteración:    719 de 1562\n",
            "Iteración:    720 de 1562\n",
            "Iteración:    721 de 1562\n",
            "Iteración:    722 de 1562\n",
            "Iteración:    723 de 1562\n",
            "Iteración:    724 de 1562\n",
            "Iteración:    725 de 1562\n",
            "Iteración:    726 de 1562\n",
            "Iteración:    727 de 1562\n",
            "Iteración:    728 de 1562\n",
            "Iteración:    729 de 1562\n",
            "Iteración:    730 de 1562\n",
            "Iteración:    731 de 1562\n",
            "Iteración:    732 de 1562\n",
            "Iteración:    733 de 1562\n",
            "Iteración:    734 de 1562\n",
            "Iteración:    735 de 1562\n",
            "Iteración:    736 de 1562\n",
            "Iteración:    737 de 1562\n",
            "Iteración:    738 de 1562\n",
            "Iteración:    739 de 1562\n",
            "Iteración:    740 de 1562\n",
            "Iteración:    741 de 1562\n",
            "Iteración:    742 de 1562\n",
            "Iteración:    743 de 1562\n",
            "Iteración:    744 de 1562\n",
            "Iteración:    745 de 1562\n",
            "Iteración:    746 de 1562\n",
            "Iteración:    747 de 1562\n",
            "Iteración:    748 de 1562\n",
            "Iteración:    749 de 1562\n",
            "Iteración:    750 de 1562\n",
            "Iteración:    751 de 1562\n",
            "Iteración:    752 de 1562\n",
            "Iteración:    753 de 1562\n",
            "Iteración:    754 de 1562\n",
            "Iteración:    755 de 1562\n",
            "Iteración:    756 de 1562\n",
            "Iteración:    757 de 1562\n",
            "Iteración:    758 de 1562\n",
            "Iteración:    759 de 1562\n",
            "Iteración:    760 de 1562\n",
            "Iteración:    761 de 1562\n",
            "Iteración:    762 de 1562\n",
            "Iteración:    763 de 1562\n",
            "Iteración:    764 de 1562\n",
            "Iteración:    765 de 1562\n",
            "Iteración:    766 de 1562\n",
            "Iteración:    767 de 1562\n",
            "Iteración:    768 de 1562\n",
            "Iteración:    769 de 1562\n",
            "Iteración:    770 de 1562\n",
            "Iteración:    771 de 1562\n",
            "Iteración:    772 de 1562\n",
            "Iteración:    773 de 1562\n",
            "Iteración:    774 de 1562\n",
            "Iteración:    775 de 1562\n",
            "Iteración:    776 de 1562\n",
            "Iteración:    777 de 1562\n",
            "Iteración:    778 de 1562\n",
            "Iteración:    779 de 1562\n",
            "Iteración:    780 de 1562\n",
            "Iteración:    781 de 1562\n",
            "Iteración:    782 de 1562\n",
            "Iteración:    783 de 1562\n",
            "Iteración:    784 de 1562\n",
            "Iteración:    785 de 1562\n",
            "Iteración:    786 de 1562\n",
            "Iteración:    787 de 1562\n",
            "Iteración:    788 de 1562\n",
            "Iteración:    789 de 1562\n",
            "Iteración:    790 de 1562\n",
            "Iteración:    791 de 1562\n",
            "Iteración:    792 de 1562\n",
            "Iteración:    793 de 1562\n",
            "Iteración:    794 de 1562\n",
            "Iteración:    795 de 1562\n",
            "Iteración:    796 de 1562\n",
            "Iteración:    797 de 1562\n",
            "Iteración:    798 de 1562\n",
            "Iteración:    799 de 1562\n",
            "Iteración:    800 de 1562\n",
            "Iteración:    801 de 1562\n",
            "Iteración:    802 de 1562\n",
            "Iteración:    803 de 1562\n",
            "Iteración:    804 de 1562\n",
            "Iteración:    805 de 1562\n",
            "Iteración:    806 de 1562\n",
            "Iteración:    807 de 1562\n",
            "Iteración:    808 de 1562\n",
            "Iteración:    809 de 1562\n",
            "Iteración:    810 de 1562\n",
            "Iteración:    811 de 1562\n",
            "Iteración:    812 de 1562\n",
            "Iteración:    813 de 1562\n",
            "Iteración:    814 de 1562\n",
            "Iteración:    815 de 1562\n",
            "Iteración:    816 de 1562\n",
            "Iteración:    817 de 1562\n",
            "Iteración:    818 de 1562\n",
            "Iteración:    819 de 1562\n",
            "Iteración:    820 de 1562\n",
            "Iteración:    821 de 1562\n",
            "Iteración:    822 de 1562\n",
            "Iteración:    823 de 1562\n",
            "Iteración:    824 de 1562\n",
            "Iteración:    825 de 1562\n",
            "Iteración:    826 de 1562\n",
            "Iteración:    827 de 1562\n",
            "Iteración:    828 de 1562\n",
            "Iteración:    829 de 1562\n",
            "Iteración:    830 de 1562\n",
            "Iteración:    831 de 1562\n",
            "Iteración:    832 de 1562\n",
            "Iteración:    833 de 1562\n",
            "Iteración:    834 de 1562\n",
            "Iteración:    835 de 1562\n",
            "Iteración:    836 de 1562\n",
            "Iteración:    837 de 1562\n",
            "Iteración:    838 de 1562\n",
            "Iteración:    839 de 1562\n",
            "Iteración:    840 de 1562\n",
            "Iteración:    841 de 1562\n",
            "Iteración:    842 de 1562\n",
            "Iteración:    843 de 1562\n",
            "Iteración:    844 de 1562\n",
            "Iteración:    845 de 1562\n",
            "Iteración:    846 de 1562\n",
            "Iteración:    847 de 1562\n",
            "Iteración:    848 de 1562\n",
            "Iteración:    849 de 1562\n",
            "Iteración:    850 de 1562\n",
            "Iteración:    851 de 1562\n",
            "Iteración:    852 de 1562\n",
            "Iteración:    853 de 1562\n",
            "Iteración:    854 de 1562\n",
            "Iteración:    855 de 1562\n",
            "Iteración:    856 de 1562\n",
            "Iteración:    857 de 1562\n",
            "Iteración:    858 de 1562\n",
            "Iteración:    859 de 1562\n",
            "Iteración:    860 de 1562\n",
            "Iteración:    861 de 1562\n",
            "Iteración:    862 de 1562\n",
            "Iteración:    863 de 1562\n",
            "Iteración:    864 de 1562\n",
            "Iteración:    865 de 1562\n",
            "Iteración:    866 de 1562\n",
            "Iteración:    867 de 1562\n",
            "Iteración:    868 de 1562\n",
            "Iteración:    869 de 1562\n",
            "Iteración:    870 de 1562\n",
            "Iteración:    871 de 1562\n",
            "Iteración:    872 de 1562\n",
            "Iteración:    873 de 1562\n",
            "Iteración:    874 de 1562\n",
            "Iteración:    875 de 1562\n",
            "Iteración:    876 de 1562\n",
            "Iteración:    877 de 1562\n",
            "Iteración:    878 de 1562\n",
            "Iteración:    879 de 1562\n",
            "Iteración:    880 de 1562\n",
            "Iteración:    881 de 1562\n",
            "Iteración:    882 de 1562\n",
            "Iteración:    883 de 1562\n",
            "Iteración:    884 de 1562\n",
            "Iteración:    885 de 1562\n",
            "Iteración:    886 de 1562\n",
            "Iteración:    887 de 1562\n",
            "Iteración:    888 de 1562\n",
            "Iteración:    889 de 1562\n",
            "Iteración:    890 de 1562\n",
            "Iteración:    891 de 1562\n",
            "Iteración:    892 de 1562\n",
            "Iteración:    893 de 1562\n",
            "Iteración:    894 de 1562\n",
            "Iteración:    895 de 1562\n",
            "Iteración:    896 de 1562\n",
            "Iteración:    897 de 1562\n",
            "Iteración:    898 de 1562\n",
            "Iteración:    899 de 1562\n",
            "Iteración:    900 de 1562\n",
            "Iteración:    901 de 1562\n",
            "Iteración:    902 de 1562\n",
            "Iteración:    903 de 1562\n",
            "Iteración:    904 de 1562\n",
            "Iteración:    905 de 1562\n",
            "Iteración:    906 de 1562\n",
            "Iteración:    907 de 1562\n",
            "Iteración:    908 de 1562\n",
            "Iteración:    909 de 1562\n",
            "Iteración:    910 de 1562\n",
            "Iteración:    911 de 1562\n",
            "Iteración:    912 de 1562\n",
            "Iteración:    913 de 1562\n",
            "Iteración:    914 de 1562\n",
            "Iteración:    915 de 1562\n",
            "Iteración:    916 de 1562\n",
            "Iteración:    917 de 1562\n",
            "Iteración:    918 de 1562\n",
            "Iteración:    919 de 1562\n",
            "Iteración:    920 de 1562\n",
            "Iteración:    921 de 1562\n",
            "Iteración:    922 de 1562\n",
            "Iteración:    923 de 1562\n",
            "Iteración:    924 de 1562\n",
            "Iteración:    925 de 1562\n",
            "Iteración:    926 de 1562\n",
            "Iteración:    927 de 1562\n",
            "Iteración:    928 de 1562\n",
            "Iteración:    929 de 1562\n",
            "Iteración:    930 de 1562\n",
            "Iteración:    931 de 1562\n",
            "Iteración:    932 de 1562\n",
            "Iteración:    933 de 1562\n",
            "Iteración:    934 de 1562\n",
            "Iteración:    935 de 1562\n",
            "Iteración:    936 de 1562\n",
            "Iteración:    937 de 1562\n",
            "Iteración:    938 de 1562\n",
            "Iteración:    939 de 1562\n",
            "Iteración:    940 de 1562\n",
            "Iteración:    941 de 1562\n",
            "Iteración:    942 de 1562\n",
            "Iteración:    943 de 1562\n",
            "Iteración:    944 de 1562\n",
            "Iteración:    945 de 1562\n",
            "Iteración:    946 de 1562\n",
            "Iteración:    947 de 1562\n",
            "Iteración:    948 de 1562\n",
            "Iteración:    949 de 1562\n",
            "Iteración:    950 de 1562\n",
            "Iteración:    951 de 1562\n",
            "Iteración:    952 de 1562\n",
            "Iteración:    953 de 1562\n",
            "Iteración:    954 de 1562\n",
            "Iteración:    955 de 1562\n",
            "Iteración:    956 de 1562\n",
            "Iteración:    957 de 1562\n",
            "Iteración:    958 de 1562\n",
            "Iteración:    959 de 1562\n",
            "Iteración:    960 de 1562\n",
            "Iteración:    961 de 1562\n",
            "Iteración:    962 de 1562\n",
            "Iteración:    963 de 1562\n",
            "Iteración:    964 de 1562\n",
            "Iteración:    965 de 1562\n",
            "Iteración:    966 de 1562\n",
            "Iteración:    967 de 1562\n",
            "Iteración:    968 de 1562\n",
            "Iteración:    969 de 1562\n",
            "Iteración:    970 de 1562\n",
            "Iteración:    971 de 1562\n",
            "Iteración:    972 de 1562\n",
            "Iteración:    973 de 1562\n",
            "Iteración:    974 de 1562\n",
            "Iteración:    975 de 1562\n",
            "Iteración:    976 de 1562\n",
            "Iteración:    977 de 1562\n",
            "Iteración:    978 de 1562\n",
            "Iteración:    979 de 1562\n",
            "Iteración:    980 de 1562\n",
            "Iteración:    981 de 1562\n",
            "Iteración:    982 de 1562\n",
            "Iteración:    983 de 1562\n",
            "Iteración:    984 de 1562\n",
            "Iteración:    985 de 1562\n",
            "Iteración:    986 de 1562\n",
            "Iteración:    987 de 1562\n",
            "Iteración:    988 de 1562\n",
            "Iteración:    989 de 1562\n",
            "Iteración:    990 de 1562\n",
            "Iteración:    991 de 1562\n",
            "Iteración:    992 de 1562\n",
            "Iteración:    993 de 1562\n",
            "Iteración:    994 de 1562\n",
            "Iteración:    995 de 1562\n",
            "Iteración:    996 de 1562\n",
            "Iteración:    997 de 1562\n",
            "Iteración:    998 de 1562\n",
            "Iteración:    999 de 1562\n",
            "Iteración:   1000 de 1562\n",
            "Iteración:   1001 de 1562\n",
            "Iteración:   1002 de 1562\n",
            "Iteración:   1003 de 1562\n",
            "Iteración:   1004 de 1562\n",
            "Iteración:   1005 de 1562\n",
            "Iteración:   1006 de 1562\n",
            "Iteración:   1007 de 1562\n",
            "Iteración:   1008 de 1562\n",
            "Iteración:   1009 de 1562\n",
            "Iteración:   1010 de 1562\n",
            "Iteración:   1011 de 1562\n",
            "Iteración:   1012 de 1562\n",
            "Iteración:   1013 de 1562\n",
            "Iteración:   1014 de 1562\n",
            "Iteración:   1015 de 1562\n",
            "Iteración:   1016 de 1562\n",
            "Iteración:   1017 de 1562\n",
            "Iteración:   1018 de 1562\n",
            "Iteración:   1019 de 1562\n",
            "Iteración:   1020 de 1562\n",
            "Iteración:   1021 de 1562\n",
            "Iteración:   1022 de 1562\n",
            "Iteración:   1023 de 1562\n",
            "Iteración:   1024 de 1562\n",
            "Iteración:   1025 de 1562\n",
            "Iteración:   1026 de 1562\n",
            "Iteración:   1027 de 1562\n",
            "Iteración:   1028 de 1562\n",
            "Iteración:   1029 de 1562\n",
            "Iteración:   1030 de 1562\n",
            "Iteración:   1031 de 1562\n",
            "Iteración:   1032 de 1562\n",
            "Iteración:   1033 de 1562\n",
            "Iteración:   1034 de 1562\n",
            "Iteración:   1035 de 1562\n",
            "Iteración:   1036 de 1562\n",
            "Iteración:   1037 de 1562\n",
            "Iteración:   1038 de 1562\n",
            "Iteración:   1039 de 1562\n",
            "Iteración:   1040 de 1562\n",
            "Iteración:   1041 de 1562\n",
            "Iteración:   1042 de 1562\n",
            "Iteración:   1043 de 1562\n",
            "Iteración:   1044 de 1562\n",
            "Iteración:   1045 de 1562\n",
            "Iteración:   1046 de 1562\n",
            "Iteración:   1047 de 1562\n",
            "Iteración:   1048 de 1562\n",
            "Iteración:   1049 de 1562\n",
            "Iteración:   1050 de 1562\n",
            "Iteración:   1051 de 1562\n",
            "Iteración:   1052 de 1562\n",
            "Iteración:   1053 de 1562\n",
            "Iteración:   1054 de 1562\n",
            "Iteración:   1055 de 1562\n",
            "Iteración:   1056 de 1562\n",
            "Iteración:   1057 de 1562\n",
            "Iteración:   1058 de 1562\n",
            "Iteración:   1059 de 1562\n",
            "Iteración:   1060 de 1562\n",
            "Iteración:   1061 de 1562\n",
            "Iteración:   1062 de 1562\n",
            "Iteración:   1063 de 1562\n",
            "Iteración:   1064 de 1562\n",
            "Iteración:   1065 de 1562\n",
            "Iteración:   1066 de 1562\n",
            "Iteración:   1067 de 1562\n",
            "Iteración:   1068 de 1562\n",
            "Iteración:   1069 de 1562\n",
            "Iteración:   1070 de 1562\n",
            "Iteración:   1071 de 1562\n",
            "Iteración:   1072 de 1562\n",
            "Iteración:   1073 de 1562\n",
            "Iteración:   1074 de 1562\n",
            "Iteración:   1075 de 1562\n",
            "Iteración:   1076 de 1562\n",
            "Iteración:   1077 de 1562\n",
            "Iteración:   1078 de 1562\n",
            "Iteración:   1079 de 1562\n",
            "Iteración:   1080 de 1562\n",
            "Iteración:   1081 de 1562\n",
            "Iteración:   1082 de 1562\n",
            "Iteración:   1083 de 1562\n",
            "Iteración:   1084 de 1562\n",
            "Iteración:   1085 de 1562\n",
            "Iteración:   1086 de 1562\n",
            "Iteración:   1087 de 1562\n",
            "Iteración:   1088 de 1562\n",
            "Iteración:   1089 de 1562\n",
            "Iteración:   1090 de 1562\n",
            "Iteración:   1091 de 1562\n",
            "Iteración:   1092 de 1562\n",
            "Iteración:   1093 de 1562\n",
            "Iteración:   1094 de 1562\n",
            "Iteración:   1095 de 1562\n",
            "Iteración:   1096 de 1562\n",
            "Iteración:   1097 de 1562\n",
            "Iteración:   1098 de 1562\n",
            "Iteración:   1099 de 1562\n",
            "Iteración:   1100 de 1562\n",
            "Iteración:   1101 de 1562\n",
            "Iteración:   1102 de 1562\n",
            "Iteración:   1103 de 1562\n",
            "Iteración:   1104 de 1562\n",
            "Iteración:   1105 de 1562\n",
            "Iteración:   1106 de 1562\n",
            "Iteración:   1107 de 1562\n",
            "Iteración:   1108 de 1562\n",
            "Iteración:   1109 de 1562\n",
            "Iteración:   1110 de 1562\n",
            "Iteración:   1111 de 1562\n",
            "Iteración:   1112 de 1562\n",
            "Iteración:   1113 de 1562\n",
            "Iteración:   1114 de 1562\n",
            "Iteración:   1115 de 1562\n",
            "Iteración:   1116 de 1562\n",
            "Iteración:   1117 de 1562\n",
            "Iteración:   1118 de 1562\n",
            "Iteración:   1119 de 1562\n",
            "Iteración:   1120 de 1562\n",
            "Iteración:   1121 de 1562\n",
            "Iteración:   1122 de 1562\n",
            "Iteración:   1123 de 1562\n",
            "Iteración:   1124 de 1562\n",
            "Iteración:   1125 de 1562\n",
            "Iteración:   1126 de 1562\n",
            "Iteración:   1127 de 1562\n",
            "Iteración:   1128 de 1562\n",
            "Iteración:   1129 de 1562\n",
            "Iteración:   1130 de 1562\n",
            "Iteración:   1131 de 1562\n",
            "Iteración:   1132 de 1562\n",
            "Iteración:   1133 de 1562\n",
            "Iteración:   1134 de 1562\n",
            "Iteración:   1135 de 1562\n",
            "Iteración:   1136 de 1562\n",
            "Iteración:   1137 de 1562\n",
            "Iteración:   1138 de 1562\n",
            "Iteración:   1139 de 1562\n",
            "Iteración:   1140 de 1562\n",
            "Iteración:   1141 de 1562\n",
            "Iteración:   1142 de 1562\n",
            "Iteración:   1143 de 1562\n",
            "Iteración:   1144 de 1562\n",
            "Iteración:   1145 de 1562\n",
            "Iteración:   1146 de 1562\n",
            "Iteración:   1147 de 1562\n",
            "Iteración:   1148 de 1562\n",
            "Iteración:   1149 de 1562\n",
            "Iteración:   1150 de 1562\n",
            "Iteración:   1151 de 1562\n",
            "Iteración:   1152 de 1562\n",
            "Iteración:   1153 de 1562\n",
            "Iteración:   1154 de 1562\n",
            "Iteración:   1155 de 1562\n",
            "Iteración:   1156 de 1562\n",
            "Iteración:   1157 de 1562\n",
            "Iteración:   1158 de 1562\n",
            "Iteración:   1159 de 1562\n",
            "Iteración:   1160 de 1562\n",
            "Iteración:   1161 de 1562\n",
            "Iteración:   1162 de 1562\n",
            "Iteración:   1163 de 1562\n",
            "Iteración:   1164 de 1562\n",
            "Iteración:   1165 de 1562\n",
            "Iteración:   1166 de 1562\n",
            "Iteración:   1167 de 1562\n",
            "Iteración:   1168 de 1562\n",
            "Iteración:   1169 de 1562\n",
            "Iteración:   1170 de 1562\n",
            "Iteración:   1171 de 1562\n",
            "Iteración:   1172 de 1562\n",
            "Iteración:   1173 de 1562\n",
            "Iteración:   1174 de 1562\n",
            "Iteración:   1175 de 1562\n",
            "Iteración:   1176 de 1562\n",
            "Iteración:   1177 de 1562\n",
            "Iteración:   1178 de 1562\n",
            "Iteración:   1179 de 1562\n",
            "Iteración:   1180 de 1562\n",
            "Iteración:   1181 de 1562\n",
            "Iteración:   1182 de 1562\n",
            "Iteración:   1183 de 1562\n",
            "Iteración:   1184 de 1562\n",
            "Iteración:   1185 de 1562\n",
            "Iteración:   1186 de 1562\n",
            "Iteración:   1187 de 1562\n",
            "Iteración:   1188 de 1562\n",
            "Iteración:   1189 de 1562\n",
            "Iteración:   1190 de 1562\n",
            "Iteración:   1191 de 1562\n",
            "Iteración:   1192 de 1562\n",
            "Iteración:   1193 de 1562\n",
            "Iteración:   1194 de 1562\n",
            "Iteración:   1195 de 1562\n",
            "Iteración:   1196 de 1562\n",
            "Iteración:   1197 de 1562\n",
            "Iteración:   1198 de 1562\n",
            "Iteración:   1199 de 1562\n",
            "Iteración:   1200 de 1562\n",
            "Iteración:   1201 de 1562\n",
            "Iteración:   1202 de 1562\n",
            "Iteración:   1203 de 1562\n",
            "Iteración:   1204 de 1562\n",
            "Iteración:   1205 de 1562\n",
            "Iteración:   1206 de 1562\n",
            "Iteración:   1207 de 1562\n",
            "Iteración:   1208 de 1562\n",
            "Iteración:   1209 de 1562\n",
            "Iteración:   1210 de 1562\n",
            "Iteración:   1211 de 1562\n",
            "Iteración:   1212 de 1562\n",
            "Iteración:   1213 de 1562\n",
            "Iteración:   1214 de 1562\n",
            "Iteración:   1215 de 1562\n",
            "Iteración:   1216 de 1562\n",
            "Iteración:   1217 de 1562\n",
            "Iteración:   1218 de 1562\n",
            "Iteración:   1219 de 1562\n",
            "Iteración:   1220 de 1562\n",
            "Iteración:   1221 de 1562\n",
            "Iteración:   1222 de 1562\n",
            "Iteración:   1223 de 1562\n",
            "Iteración:   1224 de 1562\n",
            "Iteración:   1225 de 1562\n",
            "Iteración:   1226 de 1562\n",
            "Iteración:   1227 de 1562\n",
            "Iteración:   1228 de 1562\n",
            "Iteración:   1229 de 1562\n",
            "Iteración:   1230 de 1562\n",
            "Iteración:   1231 de 1562\n",
            "Iteración:   1232 de 1562\n",
            "Iteración:   1233 de 1562\n",
            "Iteración:   1234 de 1562\n",
            "Iteración:   1235 de 1562\n",
            "Iteración:   1236 de 1562\n",
            "Iteración:   1237 de 1562\n",
            "Iteración:   1238 de 1562\n",
            "Iteración:   1239 de 1562\n",
            "Iteración:   1240 de 1562\n",
            "Iteración:   1241 de 1562\n",
            "Iteración:   1242 de 1562\n",
            "Iteración:   1243 de 1562\n",
            "Iteración:   1244 de 1562\n",
            "Iteración:   1245 de 1562\n",
            "Iteración:   1246 de 1562\n",
            "Iteración:   1247 de 1562\n",
            "Iteración:   1248 de 1562\n",
            "Iteración:   1249 de 1562\n",
            "Iteración:   1250 de 1562\n",
            "Iteración:   1251 de 1562\n",
            "Iteración:   1252 de 1562\n",
            "Iteración:   1253 de 1562\n",
            "Iteración:   1254 de 1562\n",
            "Iteración:   1255 de 1562\n",
            "Iteración:   1256 de 1562\n",
            "Iteración:   1257 de 1562\n",
            "Iteración:   1258 de 1562\n",
            "Iteración:   1259 de 1562\n",
            "Iteración:   1260 de 1562\n",
            "Iteración:   1261 de 1562\n",
            "Iteración:   1262 de 1562\n",
            "Iteración:   1263 de 1562\n",
            "Iteración:   1264 de 1562\n",
            "Iteración:   1265 de 1562\n",
            "Iteración:   1266 de 1562\n",
            "Iteración:   1267 de 1562\n",
            "Iteración:   1268 de 1562\n",
            "Iteración:   1269 de 1562\n",
            "Iteración:   1270 de 1562\n",
            "Iteración:   1271 de 1562\n",
            "Iteración:   1272 de 1562\n",
            "Iteración:   1273 de 1562\n",
            "Iteración:   1274 de 1562\n",
            "Iteración:   1275 de 1562\n",
            "Iteración:   1276 de 1562\n",
            "Iteración:   1277 de 1562\n",
            "Iteración:   1278 de 1562\n",
            "Iteración:   1279 de 1562\n",
            "Iteración:   1280 de 1562\n",
            "Iteración:   1281 de 1562\n",
            "Iteración:   1282 de 1562\n",
            "Iteración:   1283 de 1562\n",
            "Iteración:   1284 de 1562\n",
            "Iteración:   1285 de 1562\n",
            "Iteración:   1286 de 1562\n",
            "Iteración:   1287 de 1562\n",
            "Iteración:   1288 de 1562\n",
            "Iteración:   1289 de 1562\n",
            "Iteración:   1290 de 1562\n",
            "Iteración:   1291 de 1562\n",
            "Iteración:   1292 de 1562\n",
            "Iteración:   1293 de 1562\n",
            "Iteración:   1294 de 1562\n",
            "Iteración:   1295 de 1562\n",
            "Iteración:   1296 de 1562\n",
            "Iteración:   1297 de 1562\n",
            "Iteración:   1298 de 1562\n",
            "Iteración:   1299 de 1562\n",
            "Iteración:   1300 de 1562\n",
            "Iteración:   1301 de 1562\n",
            "Iteración:   1302 de 1562\n",
            "Iteración:   1303 de 1562\n",
            "Iteración:   1304 de 1562\n",
            "Iteración:   1305 de 1562\n",
            "Iteración:   1306 de 1562\n",
            "Iteración:   1307 de 1562\n",
            "Iteración:   1308 de 1562\n",
            "Iteración:   1309 de 1562\n",
            "Iteración:   1310 de 1562\n",
            "Iteración:   1311 de 1562\n",
            "Iteración:   1312 de 1562\n",
            "Iteración:   1313 de 1562\n",
            "Iteración:   1314 de 1562\n",
            "Iteración:   1315 de 1562\n",
            "Iteración:   1316 de 1562\n",
            "Iteración:   1317 de 1562\n",
            "Iteración:   1318 de 1562\n",
            "Iteración:   1319 de 1562\n",
            "Iteración:   1320 de 1562\n",
            "Iteración:   1321 de 1562\n",
            "Iteración:   1322 de 1562\n",
            "Iteración:   1323 de 1562\n",
            "Iteración:   1324 de 1562\n",
            "Iteración:   1325 de 1562\n",
            "Iteración:   1326 de 1562\n",
            "Iteración:   1327 de 1562\n",
            "Iteración:   1328 de 1562\n",
            "Iteración:   1329 de 1562\n",
            "Iteración:   1330 de 1562\n",
            "Iteración:   1331 de 1562\n",
            "Iteración:   1332 de 1562\n",
            "Iteración:   1333 de 1562\n",
            "Iteración:   1334 de 1562\n",
            "Iteración:   1335 de 1562\n",
            "Iteración:   1336 de 1562\n",
            "Iteración:   1337 de 1562\n",
            "Iteración:   1338 de 1562\n",
            "Iteración:   1339 de 1562\n",
            "Iteración:   1340 de 1562\n",
            "Iteración:   1341 de 1562\n",
            "Iteración:   1342 de 1562\n",
            "Iteración:   1343 de 1562\n",
            "Iteración:   1344 de 1562\n",
            "Iteración:   1345 de 1562\n",
            "Iteración:   1346 de 1562\n",
            "Iteración:   1347 de 1562\n",
            "Iteración:   1348 de 1562\n",
            "Iteración:   1349 de 1562\n",
            "Iteración:   1350 de 1562\n",
            "Iteración:   1351 de 1562\n",
            "Iteración:   1352 de 1562\n",
            "Iteración:   1353 de 1562\n",
            "Iteración:   1354 de 1562\n",
            "Iteración:   1355 de 1562\n",
            "Iteración:   1356 de 1562\n",
            "Iteración:   1357 de 1562\n",
            "Iteración:   1358 de 1562\n",
            "Iteración:   1359 de 1562\n",
            "Iteración:   1360 de 1562\n",
            "Iteración:   1361 de 1562\n",
            "Iteración:   1362 de 1562\n",
            "Iteración:   1363 de 1562\n",
            "Iteración:   1364 de 1562\n",
            "Iteración:   1365 de 1562\n",
            "Iteración:   1366 de 1562\n",
            "Iteración:   1367 de 1562\n",
            "Iteración:   1368 de 1562\n",
            "Iteración:   1369 de 1562\n",
            "Iteración:   1370 de 1562\n",
            "Iteración:   1371 de 1562\n",
            "Iteración:   1372 de 1562\n",
            "Iteración:   1373 de 1562\n",
            "Iteración:   1374 de 1562\n",
            "Iteración:   1375 de 1562\n",
            "Iteración:   1376 de 1562\n",
            "Iteración:   1377 de 1562\n",
            "Iteración:   1378 de 1562\n",
            "Iteración:   1379 de 1562\n",
            "Iteración:   1380 de 1562\n",
            "Iteración:   1381 de 1562\n",
            "Iteración:   1382 de 1562\n",
            "Iteración:   1383 de 1562\n",
            "Iteración:   1384 de 1562\n",
            "Iteración:   1385 de 1562\n",
            "Iteración:   1386 de 1562\n",
            "Iteración:   1387 de 1562\n",
            "Iteración:   1388 de 1562\n",
            "Iteración:   1389 de 1562\n",
            "Iteración:   1390 de 1562\n",
            "Iteración:   1391 de 1562\n",
            "Iteración:   1392 de 1562\n",
            "Iteración:   1393 de 1562\n",
            "Iteración:   1394 de 1562\n",
            "Iteración:   1395 de 1562\n",
            "Iteración:   1396 de 1562\n",
            "Iteración:   1397 de 1562\n",
            "Iteración:   1398 de 1562\n",
            "Iteración:   1399 de 1562\n",
            "Iteración:   1400 de 1562\n",
            "Iteración:   1401 de 1562\n",
            "Iteración:   1402 de 1562\n",
            "Iteración:   1403 de 1562\n",
            "Iteración:   1404 de 1562\n",
            "Iteración:   1405 de 1562\n",
            "Iteración:   1406 de 1562\n",
            "Iteración:   1407 de 1562\n",
            "Iteración:   1408 de 1562\n",
            "Iteración:   1409 de 1562\n",
            "Iteración:   1410 de 1562\n",
            "Iteración:   1411 de 1562\n",
            "Iteración:   1412 de 1562\n",
            "Iteración:   1413 de 1562\n",
            "Iteración:   1414 de 1562\n",
            "Iteración:   1415 de 1562\n",
            "Iteración:   1416 de 1562\n",
            "Iteración:   1417 de 1562\n",
            "Iteración:   1418 de 1562\n",
            "Iteración:   1419 de 1562\n",
            "Iteración:   1420 de 1562\n",
            "Iteración:   1421 de 1562\n",
            "Iteración:   1422 de 1562\n",
            "Iteración:   1423 de 1562\n",
            "Iteración:   1424 de 1562\n",
            "Iteración:   1425 de 1562\n",
            "Iteración:   1426 de 1562\n",
            "Iteración:   1427 de 1562\n",
            "Iteración:   1428 de 1562\n",
            "Iteración:   1429 de 1562\n",
            "Iteración:   1430 de 1562\n",
            "Iteración:   1431 de 1562\n",
            "Iteración:   1432 de 1562\n",
            "Iteración:   1433 de 1562\n",
            "Iteración:   1434 de 1562\n",
            "Iteración:   1435 de 1562\n",
            "Iteración:   1436 de 1562\n",
            "Iteración:   1437 de 1562\n",
            "Iteración:   1438 de 1562\n",
            "Iteración:   1439 de 1562\n",
            "Iteración:   1440 de 1562\n",
            "Iteración:   1441 de 1562\n",
            "Iteración:   1442 de 1562\n",
            "Iteración:   1443 de 1562\n",
            "Iteración:   1444 de 1562\n",
            "Iteración:   1445 de 1562\n",
            "Iteración:   1446 de 1562\n",
            "Iteración:   1447 de 1562\n",
            "Iteración:   1448 de 1562\n",
            "Iteración:   1449 de 1562\n",
            "Iteración:   1450 de 1562\n",
            "Iteración:   1451 de 1562\n",
            "Iteración:   1452 de 1562\n",
            "Iteración:   1453 de 1562\n",
            "Iteración:   1454 de 1562\n",
            "Iteración:   1455 de 1562\n",
            "Iteración:   1456 de 1562\n",
            "Iteración:   1457 de 1562\n",
            "Iteración:   1458 de 1562\n",
            "Iteración:   1459 de 1562\n",
            "Iteración:   1460 de 1562\n",
            "Iteración:   1461 de 1562\n",
            "Iteración:   1462 de 1562\n",
            "Iteración:   1463 de 1562\n",
            "Iteración:   1464 de 1562\n",
            "Iteración:   1465 de 1562\n",
            "Iteración:   1466 de 1562\n",
            "Iteración:   1467 de 1562\n",
            "Iteración:   1468 de 1562\n",
            "Iteración:   1469 de 1562\n",
            "Iteración:   1470 de 1562\n",
            "Iteración:   1471 de 1562\n",
            "Iteración:   1472 de 1562\n",
            "Iteración:   1473 de 1562\n",
            "Iteración:   1474 de 1562\n",
            "Iteración:   1475 de 1562\n",
            "Iteración:   1476 de 1562\n",
            "Iteración:   1477 de 1562\n",
            "Iteración:   1478 de 1562\n",
            "Iteración:   1479 de 1562\n",
            "Iteración:   1480 de 1562\n",
            "Iteración:   1481 de 1562\n",
            "Iteración:   1482 de 1562\n",
            "Iteración:   1483 de 1562\n",
            "Iteración:   1484 de 1562\n",
            "Iteración:   1485 de 1562\n",
            "Iteración:   1486 de 1562\n",
            "Iteración:   1487 de 1562\n",
            "Iteración:   1488 de 1562\n",
            "Iteración:   1489 de 1562\n",
            "Iteración:   1490 de 1562\n",
            "Iteración:   1491 de 1562\n",
            "Iteración:   1492 de 1562\n",
            "Iteración:   1493 de 1562\n",
            "Iteración:   1494 de 1562\n",
            "Iteración:   1495 de 1562\n",
            "Iteración:   1496 de 1562\n",
            "Iteración:   1497 de 1562\n",
            "Iteración:   1498 de 1562\n",
            "Iteración:   1499 de 1562\n",
            "Iteración:   1500 de 1562\n",
            "Iteración:   1501 de 1562\n",
            "Iteración:   1502 de 1562\n",
            "Iteración:   1503 de 1562\n",
            "Iteración:   1504 de 1562\n",
            "Iteración:   1505 de 1562\n",
            "Iteración:   1506 de 1562\n",
            "Iteración:   1507 de 1562\n",
            "Iteración:   1508 de 1562\n",
            "Iteración:   1509 de 1562\n",
            "Iteración:   1510 de 1562\n",
            "Iteración:   1511 de 1562\n",
            "Iteración:   1512 de 1562\n",
            "Iteración:   1513 de 1562\n",
            "Iteración:   1514 de 1562\n",
            "Iteración:   1515 de 1562\n",
            "Iteración:   1516 de 1562\n",
            "Iteración:   1517 de 1562\n",
            "Iteración:   1518 de 1562\n",
            "Iteración:   1519 de 1562\n",
            "Iteración:   1520 de 1562\n",
            "Iteración:   1521 de 1562\n",
            "Iteración:   1522 de 1562\n",
            "Iteración:   1523 de 1562\n",
            "Iteración:   1524 de 1562\n",
            "Iteración:   1525 de 1562\n",
            "Iteración:   1526 de 1562\n",
            "Iteración:   1527 de 1562\n",
            "Iteración:   1528 de 1562\n",
            "Iteración:   1529 de 1562\n",
            "Iteración:   1530 de 1562\n",
            "Iteración:   1531 de 1562\n",
            "Iteración:   1532 de 1562\n",
            "Iteración:   1533 de 1562\n",
            "Iteración:   1534 de 1562\n",
            "Iteración:   1535 de 1562\n",
            "Iteración:   1536 de 1562\n",
            "Iteración:   1537 de 1562\n",
            "Iteración:   1538 de 1562\n",
            "Iteración:   1539 de 1562\n",
            "Iteración:   1540 de 1562\n",
            "Iteración:   1541 de 1562\n",
            "Iteración:   1542 de 1562\n",
            "Iteración:   1543 de 1562\n",
            "Iteración:   1544 de 1562\n",
            "Iteración:   1545 de 1562\n",
            "Iteración:   1546 de 1562\n",
            "Iteración:   1547 de 1562\n",
            "Iteración:   1548 de 1562\n",
            "Iteración:   1549 de 1562\n",
            "Iteración:   1550 de 1562\n",
            "Iteración:   1551 de 1562\n",
            "Iteración:   1552 de 1562\n",
            "Iteración:   1553 de 1562\n",
            "Iteración:   1554 de 1562\n",
            "Iteración:   1555 de 1562\n",
            "Iteración:   1556 de 1562\n",
            "Iteración:   1557 de 1562\n",
            "Iteración:   1558 de 1562\n",
            "Iteración:   1559 de 1562\n",
            "Iteración:   1560 de 1562\n",
            "Iteración:   1561 de 1562\n",
            "Accuracy Score = 0.7216674338089616\n",
            "F1 Score (Micro) = 0.7216674338089616\n",
            "F1 Score (Macro) = 0.4191677321864466\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationRoberta(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "id": "zwL5miYUXNG0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGwnRAp3XNG1"
      },
      "source": [
        "##### Entrenamiento del modelo (50% de datos)"
      ],
      "id": "XGwnRAp3XNG1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-3\n",
        "- weight_decay=0.01\n",
        "- Dropout + Linear + Sigmoid"
      ],
      "metadata": {
        "id": "B9QugWvgR2PY"
      },
      "id": "B9QugWvgR2PY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edcf002e-7907-481b-d202-ee7e0e0bc30f",
        "id": "giqwgCkwXNG1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración;      0 de 8923, Loss: 0.06986327767372132\n",
            "Epoch: 0, iteración;     10 de 8923, Loss: 0.9611250877380371\n",
            "Epoch: 0, iteración;     20 de 8923, Loss: 0.6159377574920655\n",
            "Epoch: 0, iteración;     30 de 8923, Loss: 0.6526411533355713\n",
            "Epoch: 0, iteración;     40 de 8923, Loss: 0.7130374431610107\n",
            "Epoch: 0, iteración;     50 de 8923, Loss: 0.6282275676727295\n",
            "Epoch: 0, iteración;     60 de 8923, Loss: 0.5872012138366699\n",
            "Epoch: 0, iteración;     70 de 8923, Loss: 0.6208059310913085\n",
            "Epoch: 0, iteración;     80 de 8923, Loss: 0.5693597316741943\n",
            "Epoch: 0, iteración;     90 de 8923, Loss: 0.522758960723877\n",
            "Epoch: 0, iteración;    100 de 8923, Loss: 0.6788860321044922\n",
            "Epoch: 0, iteración;    110 de 8923, Loss: 0.6283106803894043\n",
            "Epoch: 0, iteración;    120 de 8923, Loss: 0.5955969333648682\n",
            "Epoch: 0, iteración;    130 de 8923, Loss: 0.5371477127075195\n",
            "Epoch: 0, iteración;    140 de 8923, Loss: 0.5649879932403564\n",
            "Epoch: 0, iteración;    150 de 8923, Loss: 0.45634145736694337\n",
            "Epoch: 0, iteración;    160 de 8923, Loss: 0.5673019409179687\n",
            "Epoch: 0, iteración;    170 de 8923, Loss: 0.57965087890625\n",
            "Epoch: 0, iteración;    180 de 8923, Loss: 0.577309513092041\n",
            "Epoch: 0, iteración;    190 de 8923, Loss: 0.5803935050964355\n",
            "Epoch: 0, iteración;    200 de 8923, Loss: 0.5747917652130127\n",
            "Epoch: 0, iteración;    210 de 8923, Loss: 0.593656587600708\n",
            "Epoch: 0, iteración;    220 de 8923, Loss: 0.6414041519165039\n",
            "Epoch: 0, iteración;    230 de 8923, Loss: 0.570566463470459\n",
            "Epoch: 0, iteración;    240 de 8923, Loss: 0.5968984603881836\n",
            "Epoch: 0, iteración;    250 de 8923, Loss: 0.6039108753204345\n",
            "Epoch: 0, iteración;    260 de 8923, Loss: 0.45688982009887696\n",
            "Epoch: 0, iteración;    270 de 8923, Loss: 0.6679047584533692\n",
            "Epoch: 0, iteración;    280 de 8923, Loss: 0.6265041351318359\n",
            "Epoch: 0, iteración;    290 de 8923, Loss: 0.5665831565856934\n",
            "Epoch: 0, iteración;    300 de 8923, Loss: 0.5877172946929932\n",
            "Epoch: 0, iteración;    310 de 8923, Loss: 0.5691065788269043\n",
            "Epoch: 0, iteración;    320 de 8923, Loss: 0.6409638881683349\n",
            "Epoch: 0, iteración;    330 de 8923, Loss: 0.5295334815979004\n",
            "Epoch: 0, iteración;    340 de 8923, Loss: 0.5601973533630371\n",
            "Epoch: 0, iteración;    350 de 8923, Loss: 0.6701014518737793\n",
            "Epoch: 0, iteración;    360 de 8923, Loss: 0.5281833648681641\n",
            "Epoch: 0, iteración;    370 de 8923, Loss: 0.5613223075866699\n",
            "Epoch: 0, iteración;    380 de 8923, Loss: 0.5957420825958252\n",
            "Epoch: 0, iteración;    390 de 8923, Loss: 0.6451876163482666\n",
            "Epoch: 0, iteración;    400 de 8923, Loss: 0.5777526378631592\n",
            "Epoch: 0, iteración;    410 de 8923, Loss: 0.600123119354248\n",
            "Epoch: 0, iteración;    420 de 8923, Loss: 0.5753389358520508\n",
            "Epoch: 0, iteración;    430 de 8923, Loss: 0.5325300216674804\n",
            "Epoch: 0, iteración;    440 de 8923, Loss: 0.6809987545013427\n",
            "Epoch: 0, iteración;    450 de 8923, Loss: 0.5553377151489258\n",
            "Epoch: 0, iteración;    460 de 8923, Loss: 0.5591782569885254\n",
            "Epoch: 0, iteración;    470 de 8923, Loss: 0.637946605682373\n",
            "Epoch: 0, iteración;    480 de 8923, Loss: 0.674104118347168\n",
            "Epoch: 0, iteración;    490 de 8923, Loss: 0.6512022018432617\n",
            "Epoch: 0, iteración;    500 de 8923, Loss: 0.6119709968566894\n",
            "Epoch: 0, iteración;    510 de 8923, Loss: 0.5372983932495117\n",
            "Epoch: 0, iteración;    520 de 8923, Loss: 0.6917913436889649\n",
            "Epoch: 0, iteración;    530 de 8923, Loss: 0.6779851913452148\n",
            "Epoch: 0, iteración;    540 de 8923, Loss: 0.6775394439697265\n",
            "Epoch: 0, iteración;    550 de 8923, Loss: 0.5676042556762695\n",
            "Epoch: 0, iteración;    560 de 8923, Loss: 0.6251366138458252\n",
            "Epoch: 0, iteración;    570 de 8923, Loss: 0.5821342945098877\n",
            "Epoch: 0, iteración;    580 de 8923, Loss: 0.6100657463073731\n",
            "Epoch: 0, iteración;    590 de 8923, Loss: 0.6004045009613037\n",
            "Epoch: 0, iteración;    600 de 8923, Loss: 0.5844563007354736\n",
            "Epoch: 0, iteración;    610 de 8923, Loss: 0.6450592517852783\n",
            "Epoch: 0, iteración;    620 de 8923, Loss: 0.6593647003173828\n",
            "Epoch: 0, iteración;    630 de 8923, Loss: 0.6384857654571533\n",
            "Epoch: 0, iteración;    640 de 8923, Loss: 0.6225077629089355\n",
            "Epoch: 0, iteración;    650 de 8923, Loss: 0.6143890857696533\n",
            "Epoch: 0, iteración;    660 de 8923, Loss: 0.5711997509002685\n",
            "Epoch: 0, iteración;    670 de 8923, Loss: 0.593773889541626\n",
            "Epoch: 0, iteración;    680 de 8923, Loss: 0.547725248336792\n",
            "Epoch: 0, iteración;    690 de 8923, Loss: 0.6259329795837403\n",
            "Epoch: 0, iteración;    700 de 8923, Loss: 0.5718201637268067\n",
            "Epoch: 0, iteración;    710 de 8923, Loss: 0.5775163173675537\n",
            "Epoch: 0, iteración;    720 de 8923, Loss: 0.5568913459777832\n",
            "Epoch: 0, iteración;    730 de 8923, Loss: 0.673267936706543\n",
            "Epoch: 0, iteración;    740 de 8923, Loss: 0.580359411239624\n",
            "Epoch: 0, iteración;    750 de 8923, Loss: 0.5878810882568359\n",
            "Epoch: 0, iteración;    760 de 8923, Loss: 0.5582572460174561\n",
            "Epoch: 0, iteración;    770 de 8923, Loss: 0.5354629516601562\n",
            "Epoch: 0, iteración;    780 de 8923, Loss: 0.5511085510253906\n",
            "Epoch: 0, iteración;    790 de 8923, Loss: 0.5933818340301513\n",
            "Epoch: 0, iteración;    800 de 8923, Loss: 0.578264856338501\n",
            "Epoch: 0, iteración;    810 de 8923, Loss: 0.4658006191253662\n",
            "Epoch: 0, iteración;    820 de 8923, Loss: 0.5999539852142334\n",
            "Epoch: 0, iteración;    830 de 8923, Loss: 0.6461225509643554\n",
            "Epoch: 0, iteración;    840 de 8923, Loss: 0.5948561668395996\n",
            "Epoch: 0, iteración;    850 de 8923, Loss: 0.6311417579650879\n",
            "Epoch: 0, iteración;    860 de 8923, Loss: 0.5848480224609375\n",
            "Epoch: 0, iteración;    870 de 8923, Loss: 0.6849420070648193\n",
            "Epoch: 0, iteración;    880 de 8923, Loss: 0.5550696372985839\n",
            "Epoch: 0, iteración;    890 de 8923, Loss: 0.6467730522155761\n",
            "Epoch: 0, iteración;    900 de 8923, Loss: 0.5739851951599121\n",
            "Epoch: 0, iteración;    910 de 8923, Loss: 0.6511884212493897\n",
            "Epoch: 0, iteración;    920 de 8923, Loss: 0.6301362991333008\n",
            "Epoch: 0, iteración;    930 de 8923, Loss: 0.6193358898162842\n",
            "Epoch: 0, iteración;    940 de 8923, Loss: 0.5498377799987793\n",
            "Epoch: 0, iteración;    950 de 8923, Loss: 0.6243108749389649\n",
            "Epoch: 0, iteración;    960 de 8923, Loss: 0.5228098869323731\n",
            "Epoch: 0, iteración;    970 de 8923, Loss: 0.6176645278930664\n",
            "Epoch: 0, iteración;    980 de 8923, Loss: 0.5861738681793213\n",
            "Epoch: 0, iteración;    990 de 8923, Loss: 0.6023175239562988\n",
            "Epoch: 0, iteración;   1000 de 8923, Loss: 0.6060752391815185\n",
            "Epoch: 0, iteración;   1010 de 8923, Loss: 0.6506568431854248\n",
            "Epoch: 0, iteración;   1020 de 8923, Loss: 0.6704315185546875\n",
            "Epoch: 0, iteración;   1030 de 8923, Loss: 0.5761269569396973\n",
            "Epoch: 0, iteración;   1040 de 8923, Loss: 0.6222182273864746\n",
            "Epoch: 0, iteración;   1050 de 8923, Loss: 0.6237524032592774\n",
            "Epoch: 0, iteración;   1060 de 8923, Loss: 0.5701111316680908\n",
            "Epoch: 0, iteración;   1070 de 8923, Loss: 0.6968488216400146\n",
            "Epoch: 0, iteración;   1080 de 8923, Loss: 0.5550907135009766\n",
            "Epoch: 0, iteración;   1090 de 8923, Loss: 0.6024774074554443\n",
            "Epoch: 0, iteración;   1100 de 8923, Loss: 0.6207374095916748\n",
            "Epoch: 0, iteración;   1110 de 8923, Loss: 0.5753879547119141\n",
            "Epoch: 0, iteración;   1120 de 8923, Loss: 0.6153265476226807\n",
            "Epoch: 0, iteración;   1130 de 8923, Loss: 0.5815828800201416\n",
            "Epoch: 0, iteración;   1140 de 8923, Loss: 0.5938112735748291\n",
            "Epoch: 0, iteración;   1150 de 8923, Loss: 0.560917329788208\n",
            "Epoch: 0, iteración;   1160 de 8923, Loss: 0.6121524333953857\n",
            "Epoch: 0, iteración;   1170 de 8923, Loss: 0.6101921081542969\n",
            "Epoch: 0, iteración;   1180 de 8923, Loss: 0.49218287467956545\n",
            "Epoch: 0, iteración;   1190 de 8923, Loss: 0.5631732940673828\n",
            "Epoch: 0, iteración;   1200 de 8923, Loss: 0.5868074893951416\n",
            "Epoch: 0, iteración;   1210 de 8923, Loss: 0.5999309539794921\n",
            "Epoch: 0, iteración;   1220 de 8923, Loss: 0.5971356391906738\n",
            "Epoch: 0, iteración;   1230 de 8923, Loss: 0.6090086936950684\n",
            "Epoch: 0, iteración;   1240 de 8923, Loss: 0.5677046298980712\n",
            "Epoch: 0, iteración;   1250 de 8923, Loss: 0.6391442775726318\n",
            "Epoch: 0, iteración;   1260 de 8923, Loss: 0.5241795539855957\n",
            "Epoch: 0, iteración;   1270 de 8923, Loss: 0.6216894626617432\n",
            "Epoch: 0, iteración;   1280 de 8923, Loss: 0.5363118171691894\n",
            "Epoch: 0, iteración;   1290 de 8923, Loss: 0.6015836715698242\n",
            "Epoch: 0, iteración;   1300 de 8923, Loss: 0.4722434043884277\n",
            "Epoch: 0, iteración;   1310 de 8923, Loss: 0.7752023696899414\n",
            "Epoch: 0, iteración;   1320 de 8923, Loss: 0.615452241897583\n",
            "Epoch: 0, iteración;   1330 de 8923, Loss: 0.5236305236816406\n",
            "Epoch: 0, iteración;   1340 de 8923, Loss: 0.6356468200683594\n",
            "Epoch: 0, iteración;   1350 de 8923, Loss: 0.5862585067749023\n",
            "Epoch: 0, iteración;   1360 de 8923, Loss: 0.5535841464996338\n",
            "Epoch: 0, iteración;   1370 de 8923, Loss: 0.5336177825927735\n",
            "Epoch: 0, iteración;   1380 de 8923, Loss: 0.5983760356903076\n",
            "Epoch: 0, iteración;   1390 de 8923, Loss: 0.6913412570953369\n",
            "Epoch: 0, iteración;   1400 de 8923, Loss: 0.607941722869873\n",
            "Epoch: 0, iteración;   1410 de 8923, Loss: 0.5677964687347412\n",
            "Epoch: 0, iteración;   1420 de 8923, Loss: 0.6059727191925048\n",
            "Epoch: 0, iteración;   1430 de 8923, Loss: 0.5548040866851807\n",
            "Epoch: 0, iteración;   1440 de 8923, Loss: 0.6004090785980225\n",
            "Epoch: 0, iteración;   1450 de 8923, Loss: 0.5701624870300293\n",
            "Epoch: 0, iteración;   1460 de 8923, Loss: 0.6120523452758789\n",
            "Epoch: 0, iteración;   1470 de 8923, Loss: 0.6710288524627686\n",
            "Epoch: 0, iteración;   1480 de 8923, Loss: 0.5596544742584229\n",
            "Epoch: 0, iteración;   1490 de 8923, Loss: 0.5654088973999023\n",
            "Epoch: 0, iteración;   1500 de 8923, Loss: 0.6177359580993652\n",
            "Epoch: 0, iteración;   1510 de 8923, Loss: 0.5453502178192139\n",
            "Epoch: 0, iteración;   1520 de 8923, Loss: 0.6095973968505859\n",
            "Epoch: 0, iteración;   1530 de 8923, Loss: 0.6037849426269531\n",
            "Epoch: 0, iteración;   1540 de 8923, Loss: 0.5790121555328369\n",
            "Epoch: 0, iteración;   1550 de 8923, Loss: 0.5373714923858642\n",
            "Epoch: 0, iteración;   1560 de 8923, Loss: 0.5569371223449707\n",
            "Epoch: 0, iteración;   1570 de 8923, Loss: 0.5773196697235108\n",
            "Epoch: 0, iteración;   1580 de 8923, Loss: 0.6290819644927979\n",
            "Epoch: 0, iteración;   1590 de 8923, Loss: 0.6005320072174072\n",
            "Epoch: 0, iteración;   1600 de 8923, Loss: 0.5448095321655273\n",
            "Epoch: 0, iteración;   1610 de 8923, Loss: 0.5472689628601074\n",
            "Epoch: 0, iteración;   1620 de 8923, Loss: 0.6370967864990235\n",
            "Epoch: 0, iteración;   1630 de 8923, Loss: 0.4688018798828125\n",
            "Epoch: 0, iteración;   1640 de 8923, Loss: 0.5985228061676026\n",
            "Epoch: 0, iteración;   1650 de 8923, Loss: 0.7082603454589844\n",
            "Epoch: 0, iteración;   1660 de 8923, Loss: 0.6713495254516602\n",
            "Epoch: 0, iteración;   1670 de 8923, Loss: 0.5767702579498291\n",
            "Epoch: 0, iteración;   1680 de 8923, Loss: 0.5900485038757324\n",
            "Epoch: 0, iteración;   1690 de 8923, Loss: 0.5903058528900147\n",
            "Epoch: 0, iteración;   1700 de 8923, Loss: 0.6177042484283447\n",
            "Epoch: 0, iteración;   1710 de 8923, Loss: 0.5700616836547852\n",
            "Epoch: 0, iteración;   1720 de 8923, Loss: 0.5467355728149415\n",
            "Epoch: 0, iteración;   1730 de 8923, Loss: 0.6734060287475586\n",
            "Epoch: 0, iteración;   1740 de 8923, Loss: 0.6064672470092773\n",
            "Epoch: 0, iteración;   1750 de 8923, Loss: 0.5168337821960449\n",
            "Epoch: 0, iteración;   1760 de 8923, Loss: 0.595212173461914\n",
            "Epoch: 0, iteración;   1770 de 8923, Loss: 0.5688817501068115\n",
            "Epoch: 0, iteración;   1780 de 8923, Loss: 0.5660863399505616\n",
            "Epoch: 0, iteración;   1790 de 8923, Loss: 0.7058096408843995\n",
            "Epoch: 0, iteración;   1800 de 8923, Loss: 0.6403809547424316\n",
            "Epoch: 0, iteración;   1810 de 8923, Loss: 0.5625622749328614\n",
            "Epoch: 0, iteración;   1820 de 8923, Loss: 0.5872831821441651\n",
            "Epoch: 0, iteración;   1830 de 8923, Loss: 0.5665342807769775\n",
            "Epoch: 0, iteración;   1840 de 8923, Loss: 0.5493821620941162\n",
            "Epoch: 0, iteración;   1850 de 8923, Loss: 0.6191595077514649\n",
            "Epoch: 0, iteración;   1860 de 8923, Loss: 0.4784343719482422\n",
            "Epoch: 0, iteración;   1870 de 8923, Loss: 0.44545912742614746\n",
            "Epoch: 0, iteración;   1880 de 8923, Loss: 0.699113130569458\n",
            "Epoch: 0, iteración;   1890 de 8923, Loss: 0.6602315902709961\n",
            "Epoch: 0, iteración;   1900 de 8923, Loss: 0.5983237266540528\n",
            "Epoch: 0, iteración;   1910 de 8923, Loss: 0.5634159088134766\n",
            "Epoch: 0, iteración;   1920 de 8923, Loss: 0.5743861198425293\n",
            "Epoch: 0, iteración;   1930 de 8923, Loss: 0.6195630073547364\n",
            "Epoch: 0, iteración;   1940 de 8923, Loss: 0.583603048324585\n",
            "Epoch: 0, iteración;   1950 de 8923, Loss: 0.608145809173584\n",
            "Epoch: 0, iteración;   1960 de 8923, Loss: 0.4984117031097412\n",
            "Epoch: 0, iteración;   1970 de 8923, Loss: 0.6598705768585205\n",
            "Epoch: 0, iteración;   1980 de 8923, Loss: 0.6557806968688965\n",
            "Epoch: 0, iteración;   1990 de 8923, Loss: 0.5934813499450684\n",
            "Epoch: 0, iteración;   2000 de 8923, Loss: 0.6361650466918946\n",
            "Epoch: 0, iteración;   2010 de 8923, Loss: 0.5551392078399658\n",
            "Epoch: 0, iteración;   2020 de 8923, Loss: 0.648171854019165\n",
            "Epoch: 0, iteración;   2030 de 8923, Loss: 0.6082504749298095\n",
            "Epoch: 0, iteración;   2040 de 8923, Loss: 0.583098030090332\n",
            "Epoch: 0, iteración;   2050 de 8923, Loss: 0.6456645965576172\n",
            "Epoch: 0, iteración;   2060 de 8923, Loss: 0.6621572971343994\n",
            "Epoch: 0, iteración;   2070 de 8923, Loss: 0.6396610260009765\n",
            "Epoch: 0, iteración;   2080 de 8923, Loss: 0.5859344959259033\n",
            "Epoch: 0, iteración;   2090 de 8923, Loss: 0.5534176826477051\n",
            "Epoch: 0, iteración;   2100 de 8923, Loss: 0.5649079322814942\n",
            "Epoch: 0, iteración;   2110 de 8923, Loss: 0.6183466911315918\n",
            "Epoch: 0, iteración;   2120 de 8923, Loss: 0.5816198348999023\n",
            "Epoch: 0, iteración;   2130 de 8923, Loss: 0.6058951854705811\n",
            "Epoch: 0, iteración;   2140 de 8923, Loss: 0.5944746017456055\n",
            "Epoch: 0, iteración;   2150 de 8923, Loss: 0.591740894317627\n",
            "Epoch: 0, iteración;   2160 de 8923, Loss: 0.692563533782959\n",
            "Epoch: 0, iteración;   2170 de 8923, Loss: 0.6032287120819092\n",
            "Epoch: 0, iteración;   2180 de 8923, Loss: 0.618611192703247\n",
            "Epoch: 0, iteración;   2190 de 8923, Loss: 0.5669032573699951\n",
            "Epoch: 0, iteración;   2200 de 8923, Loss: 0.5629082679748535\n",
            "Epoch: 0, iteración;   2210 de 8923, Loss: 0.6402899742126464\n",
            "Epoch: 0, iteración;   2220 de 8923, Loss: 0.5352876663208008\n",
            "Epoch: 0, iteración;   2230 de 8923, Loss: 0.5876208305358886\n",
            "Epoch: 0, iteración;   2240 de 8923, Loss: 0.6222082614898682\n",
            "Epoch: 0, iteración;   2250 de 8923, Loss: 0.6374168395996094\n",
            "Epoch: 0, iteración;   2260 de 8923, Loss: 0.5762667179107666\n",
            "Epoch: 0, iteración;   2270 de 8923, Loss: 0.537404203414917\n",
            "Epoch: 0, iteración;   2280 de 8923, Loss: 0.562589454650879\n",
            "Epoch: 0, iteración;   2290 de 8923, Loss: 0.5366309642791748\n",
            "Epoch: 0, iteración;   2300 de 8923, Loss: 0.5978808879852295\n",
            "Epoch: 0, iteración;   2310 de 8923, Loss: 0.5505095958709717\n",
            "Epoch: 0, iteración;   2320 de 8923, Loss: 0.6092762470245361\n",
            "Epoch: 0, iteración;   2330 de 8923, Loss: 0.5301256656646729\n",
            "Epoch: 0, iteración;   2340 de 8923, Loss: 0.5455390453338623\n",
            "Epoch: 0, iteración;   2350 de 8923, Loss: 0.5630044937133789\n",
            "Epoch: 0, iteración;   2360 de 8923, Loss: 0.6149692535400391\n",
            "Epoch: 0, iteración;   2370 de 8923, Loss: 0.5750633239746094\n",
            "Epoch: 0, iteración;   2380 de 8923, Loss: 0.6318602085113525\n",
            "Epoch: 0, iteración;   2390 de 8923, Loss: 0.5484178066253662\n",
            "Epoch: 0, iteración;   2400 de 8923, Loss: 0.589097547531128\n",
            "Epoch: 0, iteración;   2410 de 8923, Loss: 0.511042594909668\n",
            "Epoch: 0, iteración;   2420 de 8923, Loss: 0.5913046836853028\n",
            "Epoch: 0, iteración;   2430 de 8923, Loss: 0.6509210586547851\n",
            "Epoch: 0, iteración;   2440 de 8923, Loss: 0.6081540584564209\n",
            "Epoch: 0, iteración;   2450 de 8923, Loss: 0.5333871364593505\n",
            "Epoch: 0, iteración;   2460 de 8923, Loss: 0.7025904655456543\n",
            "Epoch: 0, iteración;   2470 de 8923, Loss: 0.5945218086242676\n",
            "Epoch: 0, iteración;   2480 de 8923, Loss: 0.5820781707763671\n",
            "Epoch: 0, iteración;   2490 de 8923, Loss: 0.636048698425293\n",
            "Epoch: 0, iteración;   2500 de 8923, Loss: 0.5880872249603272\n",
            "Epoch: 0, iteración;   2510 de 8923, Loss: 0.5787605285644531\n",
            "Epoch: 0, iteración;   2520 de 8923, Loss: 0.5775243759155273\n",
            "Epoch: 0, iteración;   2530 de 8923, Loss: 0.569770622253418\n",
            "Epoch: 0, iteración;   2540 de 8923, Loss: 0.6160236835479737\n",
            "Epoch: 0, iteración;   2550 de 8923, Loss: 0.648388147354126\n",
            "Epoch: 0, iteración;   2560 de 8923, Loss: 0.5662299633026123\n",
            "Epoch: 0, iteración;   2570 de 8923, Loss: 0.5248405933380127\n",
            "Epoch: 0, iteración;   2580 de 8923, Loss: 0.6110166549682617\n",
            "Epoch: 0, iteración;   2590 de 8923, Loss: 0.6040003776550293\n",
            "Epoch: 0, iteración;   2600 de 8923, Loss: 0.5174253463745118\n",
            "Epoch: 0, iteración;   2610 de 8923, Loss: 0.5670651435852051\n",
            "Epoch: 0, iteración;   2620 de 8923, Loss: 0.6283848762512207\n",
            "Epoch: 0, iteración;   2630 de 8923, Loss: 0.5413268089294434\n",
            "Epoch: 0, iteración;   2640 de 8923, Loss: 0.6491944789886475\n",
            "Epoch: 0, iteración;   2650 de 8923, Loss: 0.6737422943115234\n",
            "Epoch: 0, iteración;   2660 de 8923, Loss: 0.578574275970459\n",
            "Epoch: 0, iteración;   2670 de 8923, Loss: 0.5205936431884766\n",
            "Epoch: 0, iteración;   2680 de 8923, Loss: 0.6279259204864502\n",
            "Epoch: 0, iteración;   2690 de 8923, Loss: 0.5574179649353027\n",
            "Epoch: 0, iteración;   2700 de 8923, Loss: 0.6120182037353515\n",
            "Epoch: 0, iteración;   2710 de 8923, Loss: 0.53031005859375\n",
            "Epoch: 0, iteración;   2720 de 8923, Loss: 0.5923534870147705\n",
            "Epoch: 0, iteración;   2730 de 8923, Loss: 0.6003514766693115\n",
            "Epoch: 0, iteración;   2740 de 8923, Loss: 0.6534296989440918\n",
            "Epoch: 0, iteración;   2750 de 8923, Loss: 0.5580214977264404\n",
            "Epoch: 0, iteración;   2760 de 8923, Loss: 0.6437088966369628\n",
            "Epoch: 0, iteración;   2770 de 8923, Loss: 0.605134105682373\n",
            "Epoch: 0, iteración;   2780 de 8923, Loss: 0.6535229682922363\n",
            "Epoch: 0, iteración;   2790 de 8923, Loss: 0.4891964912414551\n",
            "Epoch: 0, iteración;   2800 de 8923, Loss: 0.5642554283142089\n",
            "Epoch: 0, iteración;   2810 de 8923, Loss: 0.6906736373901368\n",
            "Epoch: 0, iteración;   2820 de 8923, Loss: 0.5401928901672364\n",
            "Epoch: 0, iteración;   2830 de 8923, Loss: 0.6134469985961915\n",
            "Epoch: 0, iteración;   2840 de 8923, Loss: 0.5835812568664551\n",
            "Epoch: 0, iteración;   2850 de 8923, Loss: 0.5441573143005372\n",
            "Epoch: 0, iteración;   2860 de 8923, Loss: 0.46923141479492186\n",
            "Epoch: 0, iteración;   2870 de 8923, Loss: 0.7217244625091552\n",
            "Epoch: 0, iteración;   2880 de 8923, Loss: 0.5792268276214599\n",
            "Epoch: 0, iteración;   2890 de 8923, Loss: 0.5830313682556152\n",
            "Epoch: 0, iteración;   2900 de 8923, Loss: 0.6165907859802247\n",
            "Epoch: 0, iteración;   2910 de 8923, Loss: 0.5225796699523926\n",
            "Epoch: 0, iteración;   2920 de 8923, Loss: 0.6122833251953125\n",
            "Epoch: 0, iteración;   2930 de 8923, Loss: 0.5776895523071289\n",
            "Epoch: 0, iteración;   2940 de 8923, Loss: 0.5811186790466308\n",
            "Epoch: 0, iteración;   2950 de 8923, Loss: 0.6495944023132324\n",
            "Epoch: 0, iteración;   2960 de 8923, Loss: 0.620194387435913\n",
            "Epoch: 0, iteración;   2970 de 8923, Loss: 0.5939957141876221\n",
            "Epoch: 0, iteración;   2980 de 8923, Loss: 0.5917984485626221\n",
            "Epoch: 0, iteración;   2990 de 8923, Loss: 0.5986795425415039\n",
            "Epoch: 0, iteración;   3000 de 8923, Loss: 0.5885242462158203\n",
            "Epoch: 0, iteración;   3010 de 8923, Loss: 0.5592698574066162\n",
            "Epoch: 0, iteración;   3020 de 8923, Loss: 0.6143206596374512\n",
            "Epoch: 0, iteración;   3030 de 8923, Loss: 0.6109916687011718\n",
            "Epoch: 0, iteración;   3040 de 8923, Loss: 0.6320579051971436\n",
            "Epoch: 0, iteración;   3050 de 8923, Loss: 0.6530515193939209\n",
            "Epoch: 0, iteración;   3060 de 8923, Loss: 0.6169154644012451\n",
            "Epoch: 0, iteración;   3070 de 8923, Loss: 0.6026379108428955\n",
            "Epoch: 0, iteración;   3080 de 8923, Loss: 0.6452237129211426\n",
            "Epoch: 0, iteración;   3090 de 8923, Loss: 0.5610519409179687\n",
            "Epoch: 0, iteración;   3100 de 8923, Loss: 0.6007506370544433\n",
            "Epoch: 0, iteración;   3110 de 8923, Loss: 0.5432698726654053\n",
            "Epoch: 0, iteración;   3120 de 8923, Loss: 0.5499108791351318\n",
            "Epoch: 0, iteración;   3130 de 8923, Loss: 0.6647915363311767\n",
            "Epoch: 0, iteración;   3140 de 8923, Loss: 0.5495471477508544\n",
            "Epoch: 0, iteración;   3150 de 8923, Loss: 0.5433863639831543\n",
            "Epoch: 0, iteración;   3160 de 8923, Loss: 0.5363057136535645\n",
            "Epoch: 0, iteración;   3170 de 8923, Loss: 0.5525962352752686\n",
            "Epoch: 0, iteración;   3180 de 8923, Loss: 0.6729820728302002\n",
            "Epoch: 0, iteración;   3190 de 8923, Loss: 0.6416909217834472\n",
            "Epoch: 0, iteración;   3200 de 8923, Loss: 0.6157104969024658\n",
            "Epoch: 0, iteración;   3210 de 8923, Loss: 0.6127479553222657\n",
            "Epoch: 0, iteración;   3220 de 8923, Loss: 0.6711508750915527\n",
            "Epoch: 0, iteración;   3230 de 8923, Loss: 0.6531519889831543\n",
            "Epoch: 0, iteración;   3240 de 8923, Loss: 0.5575658321380615\n",
            "Epoch: 0, iteración;   3250 de 8923, Loss: 0.5903782367706298\n",
            "Epoch: 0, iteración;   3260 de 8923, Loss: 0.5811861038208008\n",
            "Epoch: 0, iteración;   3270 de 8923, Loss: 0.5272092819213867\n",
            "Epoch: 0, iteración;   3280 de 8923, Loss: 0.6463534832000732\n",
            "Epoch: 0, iteración;   3290 de 8923, Loss: 0.5252218246459961\n",
            "Epoch: 0, iteración;   3300 de 8923, Loss: 0.6691638946533203\n",
            "Epoch: 0, iteración;   3310 de 8923, Loss: 0.6620675563812256\n",
            "Epoch: 0, iteración;   3320 de 8923, Loss: 0.6506573677062988\n",
            "Epoch: 0, iteración;   3330 de 8923, Loss: 0.580297327041626\n",
            "Epoch: 0, iteración;   3340 de 8923, Loss: 0.5629331111907959\n",
            "Epoch: 0, iteración;   3350 de 8923, Loss: 0.5783188819885254\n",
            "Epoch: 0, iteración;   3360 de 8923, Loss: 0.5867898464202881\n",
            "Epoch: 0, iteración;   3370 de 8923, Loss: 0.5694088935852051\n",
            "Epoch: 0, iteración;   3380 de 8923, Loss: 0.6055935382843017\n",
            "Epoch: 0, iteración;   3390 de 8923, Loss: 0.5444595336914062\n",
            "Epoch: 0, iteración;   3400 de 8923, Loss: 0.5002194404602051\n",
            "Epoch: 0, iteración;   3410 de 8923, Loss: 0.4827558517456055\n",
            "Epoch: 0, iteración;   3420 de 8923, Loss: 0.5941773891448975\n",
            "Epoch: 0, iteración;   3430 de 8923, Loss: 0.6380817890167236\n",
            "Epoch: 0, iteración;   3440 de 8923, Loss: 0.5969659805297851\n",
            "Epoch: 0, iteración;   3450 de 8923, Loss: 0.5852646827697754\n",
            "Epoch: 0, iteración;   3460 de 8923, Loss: 0.5666107654571533\n",
            "Epoch: 0, iteración;   3470 de 8923, Loss: 0.6084027290344238\n",
            "Epoch: 0, iteración;   3480 de 8923, Loss: 0.4833198547363281\n",
            "Epoch: 0, iteración;   3490 de 8923, Loss: 0.6387796401977539\n",
            "Epoch: 0, iteración;   3500 de 8923, Loss: 0.5862200260162354\n",
            "Epoch: 0, iteración;   3510 de 8923, Loss: 0.5993431568145752\n",
            "Epoch: 0, iteración;   3520 de 8923, Loss: 0.6156269073486328\n",
            "Epoch: 0, iteración;   3530 de 8923, Loss: 0.5587337970733642\n",
            "Epoch: 0, iteración;   3540 de 8923, Loss: 0.6275317668914795\n",
            "Epoch: 0, iteración;   3550 de 8923, Loss: 0.5936086177825928\n",
            "Epoch: 0, iteración;   3560 de 8923, Loss: 0.6217792987823486\n",
            "Epoch: 0, iteración;   3570 de 8923, Loss: 0.5099602222442627\n",
            "Epoch: 0, iteración;   3580 de 8923, Loss: 0.6021093845367431\n",
            "Epoch: 0, iteración;   3590 de 8923, Loss: 0.6975089073181152\n",
            "Epoch: 0, iteración;   3600 de 8923, Loss: 0.632875919342041\n",
            "Epoch: 0, iteración;   3610 de 8923, Loss: 0.6091824531555176\n",
            "Epoch: 0, iteración;   3620 de 8923, Loss: 0.5989984512329102\n",
            "Epoch: 0, iteración;   3630 de 8923, Loss: 0.5197816848754883\n",
            "Epoch: 0, iteración;   3640 de 8923, Loss: 0.5573997497558594\n",
            "Epoch: 0, iteración;   3650 de 8923, Loss: 0.4624058723449707\n",
            "Epoch: 0, iteración;   3660 de 8923, Loss: 0.6205410957336426\n",
            "Epoch: 0, iteración;   3670 de 8923, Loss: 0.5657886028289795\n",
            "Epoch: 0, iteración;   3680 de 8923, Loss: 0.5565639495849609\n",
            "Epoch: 0, iteración;   3690 de 8923, Loss: 0.6298945426940918\n",
            "Epoch: 0, iteración;   3700 de 8923, Loss: 0.5966261863708496\n",
            "Epoch: 0, iteración;   3710 de 8923, Loss: 0.5196106910705567\n",
            "Epoch: 0, iteración;   3720 de 8923, Loss: 0.660727071762085\n",
            "Epoch: 0, iteración;   3730 de 8923, Loss: 0.6341199398040771\n",
            "Epoch: 0, iteración;   3740 de 8923, Loss: 0.579655933380127\n",
            "Epoch: 0, iteración;   3750 de 8923, Loss: 0.5175643920898437\n",
            "Epoch: 0, iteración;   3760 de 8923, Loss: 0.5478725910186768\n",
            "Epoch: 0, iteración;   3770 de 8923, Loss: 0.6273149490356446\n",
            "Epoch: 0, iteración;   3780 de 8923, Loss: 0.5638468265533447\n",
            "Epoch: 0, iteración;   3790 de 8923, Loss: 0.6045691013336182\n",
            "Epoch: 0, iteración;   3800 de 8923, Loss: 0.6501579284667969\n",
            "Epoch: 0, iteración;   3810 de 8923, Loss: 0.7014668941497803\n",
            "Epoch: 0, iteración;   3820 de 8923, Loss: 0.6102338790893554\n",
            "Epoch: 0, iteración;   3830 de 8923, Loss: 0.6046665191650391\n",
            "Epoch: 0, iteración;   3840 de 8923, Loss: 0.5962019920349121\n",
            "Epoch: 0, iteración;   3850 de 8923, Loss: 0.6092422485351563\n",
            "Epoch: 0, iteración;   3860 de 8923, Loss: 0.6083584785461426\n",
            "Epoch: 0, iteración;   3870 de 8923, Loss: 0.6060094833374023\n",
            "Epoch: 0, iteración;   3880 de 8923, Loss: 0.5575775623321533\n",
            "Epoch: 0, iteración;   3890 de 8923, Loss: 0.5817132949829101\n",
            "Epoch: 0, iteración;   3900 de 8923, Loss: 0.5548874855041503\n",
            "Epoch: 0, iteración;   3910 de 8923, Loss: 0.5138531684875488\n",
            "Epoch: 0, iteración;   3920 de 8923, Loss: 0.5645442485809327\n",
            "Epoch: 0, iteración;   3930 de 8923, Loss: 0.5704545021057129\n",
            "Epoch: 0, iteración;   3940 de 8923, Loss: 0.6615188121795654\n",
            "Epoch: 0, iteración;   3950 de 8923, Loss: 0.6297520637512207\n",
            "Epoch: 0, iteración;   3960 de 8923, Loss: 0.6430929183959961\n",
            "Epoch: 0, iteración;   3970 de 8923, Loss: 0.6643801212310791\n",
            "Epoch: 0, iteración;   3980 de 8923, Loss: 0.6691765308380127\n",
            "Epoch: 0, iteración;   3990 de 8923, Loss: 0.6074173927307129\n",
            "Epoch: 0, iteración;   4000 de 8923, Loss: 0.5876569747924805\n",
            "Epoch: 0, iteración;   4010 de 8923, Loss: 0.5747189521789551\n",
            "Epoch: 0, iteración;   4020 de 8923, Loss: 0.5660422325134278\n",
            "Epoch: 0, iteración;   4030 de 8923, Loss: 0.553757905960083\n",
            "Epoch: 0, iteración;   4040 de 8923, Loss: 0.6471654415130615\n",
            "Epoch: 0, iteración;   4050 de 8923, Loss: 0.6039551734924317\n",
            "Epoch: 0, iteración;   4060 de 8923, Loss: 0.5797908782958985\n",
            "Epoch: 0, iteración;   4070 de 8923, Loss: 0.6130180358886719\n",
            "Epoch: 0, iteración;   4080 de 8923, Loss: 0.6335416793823242\n",
            "Epoch: 0, iteración;   4090 de 8923, Loss: 0.6418407440185547\n",
            "Epoch: 0, iteración;   4100 de 8923, Loss: 0.5193347930908203\n",
            "Epoch: 0, iteración;   4110 de 8923, Loss: 0.5580882549285888\n",
            "Epoch: 0, iteración;   4120 de 8923, Loss: 0.5670044422149658\n",
            "Epoch: 0, iteración;   4130 de 8923, Loss: 0.6243497848510742\n",
            "Epoch: 0, iteración;   4140 de 8923, Loss: 0.5717834949493408\n",
            "Epoch: 0, iteración;   4150 de 8923, Loss: 0.7222926139831543\n",
            "Epoch: 0, iteración;   4160 de 8923, Loss: 0.5672967433929443\n",
            "Epoch: 0, iteración;   4170 de 8923, Loss: 0.48428974151611326\n",
            "Epoch: 0, iteración;   4180 de 8923, Loss: 0.6903663635253906\n",
            "Epoch: 0, iteración;   4190 de 8923, Loss: 0.5900491714477539\n",
            "Epoch: 0, iteración;   4200 de 8923, Loss: 0.6507916927337647\n",
            "Epoch: 0, iteración;   4210 de 8923, Loss: 0.5618610858917237\n",
            "Epoch: 0, iteración;   4220 de 8923, Loss: 0.5349105358123779\n",
            "Epoch: 0, iteración;   4230 de 8923, Loss: 0.6443994045257568\n",
            "Epoch: 0, iteración;   4240 de 8923, Loss: 0.5135738372802734\n",
            "Epoch: 0, iteración;   4250 de 8923, Loss: 0.6283393383026123\n",
            "Epoch: 0, iteración;   4260 de 8923, Loss: 0.5944998264312744\n",
            "Epoch: 0, iteración;   4270 de 8923, Loss: 0.6509446620941162\n",
            "Epoch: 0, iteración;   4280 de 8923, Loss: 0.6343912124633789\n",
            "Epoch: 0, iteración;   4290 de 8923, Loss: 0.5885802745819092\n",
            "Epoch: 0, iteración;   4300 de 8923, Loss: 0.6352505207061767\n",
            "Epoch: 0, iteración;   4310 de 8923, Loss: 0.5758668899536132\n",
            "Epoch: 0, iteración;   4320 de 8923, Loss: 0.646916389465332\n",
            "Epoch: 0, iteración;   4330 de 8923, Loss: 0.5662826538085938\n",
            "Epoch: 0, iteración;   4340 de 8923, Loss: 0.7065776824951172\n",
            "Epoch: 0, iteración;   4350 de 8923, Loss: 0.5549667358398438\n",
            "Epoch: 0, iteración;   4360 de 8923, Loss: 0.5644918918609619\n",
            "Epoch: 0, iteración;   4370 de 8923, Loss: 0.5636252403259278\n",
            "Epoch: 0, iteración;   4380 de 8923, Loss: 0.6145534515380859\n",
            "Epoch: 0, iteración;   4390 de 8923, Loss: 0.6046198844909668\n",
            "Epoch: 0, iteración;   4400 de 8923, Loss: 0.575706148147583\n",
            "Epoch: 0, iteración;   4410 de 8923, Loss: 0.5718605995178223\n",
            "Epoch: 0, iteración;   4420 de 8923, Loss: 0.5660303592681885\n",
            "Epoch: 0, iteración;   4430 de 8923, Loss: 0.6239419937133789\n",
            "Epoch: 0, iteración;   4440 de 8923, Loss: 0.5771924495697022\n",
            "Epoch: 0, iteración;   4450 de 8923, Loss: 0.5948879718780518\n",
            "Epoch: 0, iteración;   4460 de 8923, Loss: 0.556673526763916\n",
            "Epoch: 0, iteración;   4470 de 8923, Loss: 0.5482623100280761\n",
            "Epoch: 0, iteración;   4480 de 8923, Loss: 0.6754792213439942\n",
            "Epoch: 0, iteración;   4490 de 8923, Loss: 0.6156501770019531\n",
            "Epoch: 0, iteración;   4500 de 8923, Loss: 0.5687172412872314\n",
            "Epoch: 0, iteración;   4510 de 8923, Loss: 0.5789885520935059\n",
            "Epoch: 0, iteración;   4520 de 8923, Loss: 0.5106850624084472\n",
            "Epoch: 0, iteración;   4530 de 8923, Loss: 0.5893900871276856\n",
            "Epoch: 0, iteración;   4540 de 8923, Loss: 0.5830352783203125\n",
            "Epoch: 0, iteración;   4550 de 8923, Loss: 0.5791316986083984\n",
            "Epoch: 0, iteración;   4560 de 8923, Loss: 0.593463134765625\n",
            "Epoch: 0, iteración;   4570 de 8923, Loss: 0.6097927570343018\n",
            "Epoch: 0, iteración;   4580 de 8923, Loss: 0.6152793407440186\n",
            "Epoch: 0, iteración;   4590 de 8923, Loss: 0.5753373622894287\n",
            "Epoch: 0, iteración;   4600 de 8923, Loss: 0.5714796543121338\n",
            "Epoch: 0, iteración;   4610 de 8923, Loss: 0.5935495376586915\n",
            "Epoch: 0, iteración;   4620 de 8923, Loss: 0.5519184589385986\n",
            "Epoch: 0, iteración;   4630 de 8923, Loss: 0.5832402229309082\n",
            "Epoch: 0, iteración;   4640 de 8923, Loss: 0.4979142189025879\n",
            "Epoch: 0, iteración;   4650 de 8923, Loss: 0.5106780529022217\n",
            "Epoch: 0, iteración;   4660 de 8923, Loss: 0.6180763721466065\n",
            "Epoch: 0, iteración;   4670 de 8923, Loss: 0.6825348377227783\n",
            "Epoch: 0, iteración;   4680 de 8923, Loss: 0.572873878479004\n",
            "Epoch: 0, iteración;   4690 de 8923, Loss: 0.6679922103881836\n",
            "Epoch: 0, iteración;   4700 de 8923, Loss: 0.5627243518829346\n",
            "Epoch: 0, iteración;   4710 de 8923, Loss: 0.5565121650695801\n",
            "Epoch: 0, iteración;   4720 de 8923, Loss: 0.6244773864746094\n",
            "Epoch: 0, iteración;   4730 de 8923, Loss: 0.5950397491455078\n",
            "Epoch: 0, iteración;   4740 de 8923, Loss: 0.6534414291381836\n",
            "Epoch: 0, iteración;   4750 de 8923, Loss: 0.5780852317810059\n",
            "Epoch: 0, iteración;   4760 de 8923, Loss: 0.5060686111450196\n",
            "Epoch: 0, iteración;   4770 de 8923, Loss: 0.48459744453430176\n",
            "Epoch: 0, iteración;   4780 de 8923, Loss: 0.639030933380127\n",
            "Epoch: 0, iteración;   4790 de 8923, Loss: 0.5955777168273926\n",
            "Epoch: 0, iteración;   4800 de 8923, Loss: 0.6925138473510742\n",
            "Epoch: 0, iteración;   4810 de 8923, Loss: 0.6514211177825928\n",
            "Epoch: 0, iteración;   4820 de 8923, Loss: 0.6397188663482666\n",
            "Epoch: 0, iteración;   4830 de 8923, Loss: 0.5987383842468261\n",
            "Epoch: 0, iteración;   4840 de 8923, Loss: 0.6375316619873047\n",
            "Epoch: 0, iteración;   4850 de 8923, Loss: 0.5797330379486084\n",
            "Epoch: 0, iteración;   4860 de 8923, Loss: 0.5008930206298828\n",
            "Epoch: 0, iteración;   4870 de 8923, Loss: 0.6842801094055175\n",
            "Epoch: 0, iteración;   4880 de 8923, Loss: 0.5726197719573974\n",
            "Epoch: 0, iteración;   4890 de 8923, Loss: 0.5582652568817139\n",
            "Epoch: 0, iteración;   4900 de 8923, Loss: 0.5642000675201416\n",
            "Epoch: 0, iteración;   4910 de 8923, Loss: 0.5471280574798584\n",
            "Epoch: 0, iteración;   4920 de 8923, Loss: 0.5823200225830079\n",
            "Epoch: 0, iteración;   4930 de 8923, Loss: 0.5197513580322266\n",
            "Epoch: 0, iteración;   4940 de 8923, Loss: 0.5251355171203613\n",
            "Epoch: 0, iteración;   4950 de 8923, Loss: 0.6882692813873291\n",
            "Epoch: 0, iteración;   4960 de 8923, Loss: 0.5581273555755615\n",
            "Epoch: 0, iteración;   4970 de 8923, Loss: 0.6549409389495849\n",
            "Epoch: 0, iteración;   4980 de 8923, Loss: 0.5975300312042237\n",
            "Epoch: 0, iteración;   4990 de 8923, Loss: 0.5837431907653808\n",
            "Epoch: 0, iteración;   5000 de 8923, Loss: 0.6379865646362305\n",
            "Epoch: 0, iteración;   5010 de 8923, Loss: 0.5697460174560547\n",
            "Epoch: 0, iteración;   5020 de 8923, Loss: 0.579158878326416\n",
            "Epoch: 0, iteración;   5030 de 8923, Loss: 0.6319089412689209\n",
            "Epoch: 0, iteración;   5040 de 8923, Loss: 0.6256208419799805\n",
            "Epoch: 0, iteración;   5050 de 8923, Loss: 0.6364889144897461\n",
            "Epoch: 0, iteración;   5060 de 8923, Loss: 0.5722644805908204\n",
            "Epoch: 0, iteración;   5070 de 8923, Loss: 0.5498219966888428\n",
            "Epoch: 0, iteración;   5080 de 8923, Loss: 0.5677642345428466\n",
            "Epoch: 0, iteración;   5090 de 8923, Loss: 0.6197771072387696\n",
            "Epoch: 0, iteración;   5100 de 8923, Loss: 0.49721527099609375\n",
            "Epoch: 0, iteración;   5110 de 8923, Loss: 0.5801480770111084\n",
            "Epoch: 0, iteración;   5120 de 8923, Loss: 0.6301617622375488\n",
            "Epoch: 0, iteración;   5130 de 8923, Loss: 0.6261035442352295\n",
            "Epoch: 0, iteración;   5140 de 8923, Loss: 0.6475044250488281\n",
            "Epoch: 0, iteración;   5150 de 8923, Loss: 0.5955849647521972\n",
            "Epoch: 0, iteración;   5160 de 8923, Loss: 0.5684651374816895\n",
            "Epoch: 0, iteración;   5170 de 8923, Loss: 0.5502758026123047\n",
            "Epoch: 0, iteración;   5180 de 8923, Loss: 0.5056972980499268\n",
            "Epoch: 0, iteración;   5190 de 8923, Loss: 0.6145565032958984\n",
            "Epoch: 0, iteración;   5200 de 8923, Loss: 0.5672534942626953\n",
            "Epoch: 0, iteración;   5210 de 8923, Loss: 0.6140253067016601\n",
            "Epoch: 0, iteración;   5220 de 8923, Loss: 0.5478395462036133\n",
            "Epoch: 0, iteración;   5230 de 8923, Loss: 0.5884986877441406\n",
            "Epoch: 0, iteración;   5240 de 8923, Loss: 0.539523696899414\n",
            "Epoch: 0, iteración;   5250 de 8923, Loss: 0.6309357643127441\n",
            "Epoch: 0, iteración;   5260 de 8923, Loss: 0.6385677337646485\n",
            "Epoch: 0, iteración;   5270 de 8923, Loss: 0.5456759452819824\n",
            "Epoch: 0, iteración;   5280 de 8923, Loss: 0.6115911960601806\n",
            "Epoch: 0, iteración;   5290 de 8923, Loss: 0.6124939441680908\n",
            "Epoch: 0, iteración;   5300 de 8923, Loss: 0.6022732734680176\n",
            "Epoch: 0, iteración;   5310 de 8923, Loss: 0.49669189453125\n",
            "Epoch: 0, iteración;   5320 de 8923, Loss: 0.5524006366729737\n",
            "Epoch: 0, iteración;   5330 de 8923, Loss: 0.5642080783843995\n",
            "Epoch: 0, iteración;   5340 de 8923, Loss: 0.6506568908691406\n",
            "Epoch: 0, iteración;   5350 de 8923, Loss: 0.5595057487487793\n",
            "Epoch: 0, iteración;   5360 de 8923, Loss: 0.619577693939209\n",
            "Epoch: 0, iteración;   5370 de 8923, Loss: 0.7230127811431885\n",
            "Epoch: 0, iteración;   5380 de 8923, Loss: 0.6021483898162842\n",
            "Epoch: 0, iteración;   5390 de 8923, Loss: 0.6320340633392334\n",
            "Epoch: 0, iteración;   5400 de 8923, Loss: 0.6064093112945557\n",
            "Epoch: 0, iteración;   5410 de 8923, Loss: 0.5542524814605713\n",
            "Epoch: 0, iteración;   5420 de 8923, Loss: 0.6251113891601563\n",
            "Epoch: 0, iteración;   5430 de 8923, Loss: 0.575577974319458\n",
            "Epoch: 0, iteración;   5440 de 8923, Loss: 0.4619490146636963\n",
            "Epoch: 0, iteración;   5450 de 8923, Loss: 0.6321193695068359\n",
            "Epoch: 0, iteración;   5460 de 8923, Loss: 0.5875186443328857\n",
            "Epoch: 0, iteración;   5470 de 8923, Loss: 0.5750533103942871\n",
            "Epoch: 0, iteración;   5480 de 8923, Loss: 0.5904685497283936\n",
            "Epoch: 0, iteración;   5490 de 8923, Loss: 0.5979313850402832\n",
            "Epoch: 0, iteración;   5500 de 8923, Loss: 0.6118845462799072\n",
            "Epoch: 0, iteración;   5510 de 8923, Loss: 0.5513235092163086\n",
            "Epoch: 0, iteración;   5520 de 8923, Loss: 0.6264143466949463\n",
            "Epoch: 0, iteración;   5530 de 8923, Loss: 0.5688342094421387\n",
            "Epoch: 0, iteración;   5540 de 8923, Loss: 0.6151527881622314\n",
            "Epoch: 0, iteración;   5550 de 8923, Loss: 0.5715086460113525\n",
            "Epoch: 0, iteración;   5560 de 8923, Loss: 0.6160940647125244\n",
            "Epoch: 0, iteración;   5570 de 8923, Loss: 0.5511000633239747\n",
            "Epoch: 0, iteración;   5580 de 8923, Loss: 0.5842985153198242\n",
            "Epoch: 0, iteración;   5590 de 8923, Loss: 0.5399724960327148\n",
            "Epoch: 0, iteración;   5600 de 8923, Loss: 0.5265870571136475\n",
            "Epoch: 0, iteración;   5610 de 8923, Loss: 0.7227406024932861\n",
            "Epoch: 0, iteración;   5620 de 8923, Loss: 0.5687105655670166\n",
            "Epoch: 0, iteración;   5630 de 8923, Loss: 0.5721376419067383\n",
            "Epoch: 0, iteración;   5640 de 8923, Loss: 0.6225899696350098\n",
            "Epoch: 0, iteración;   5650 de 8923, Loss: 0.6382428169250488\n",
            "Epoch: 0, iteración;   5660 de 8923, Loss: 0.5767560958862304\n",
            "Epoch: 0, iteración;   5670 de 8923, Loss: 0.6145518779754638\n",
            "Epoch: 0, iteración;   5680 de 8923, Loss: 0.5417285442352295\n",
            "Epoch: 0, iteración;   5690 de 8923, Loss: 0.6854671955108642\n",
            "Epoch: 0, iteración;   5700 de 8923, Loss: 0.6377203464508057\n",
            "Epoch: 0, iteración;   5710 de 8923, Loss: 0.6357614517211914\n",
            "Epoch: 0, iteración;   5720 de 8923, Loss: 0.5400427341461181\n",
            "Epoch: 0, iteración;   5730 de 8923, Loss: 0.6080386161804199\n",
            "Epoch: 0, iteración;   5740 de 8923, Loss: 0.6184915542602539\n",
            "Epoch: 0, iteración;   5750 de 8923, Loss: 0.6466831684112548\n",
            "Epoch: 0, iteración;   5760 de 8923, Loss: 0.5911299705505371\n",
            "Epoch: 0, iteración;   5770 de 8923, Loss: 0.6732647895812989\n",
            "Epoch: 0, iteración;   5780 de 8923, Loss: 0.6134817600250244\n",
            "Epoch: 0, iteración;   5790 de 8923, Loss: 0.5762985706329345\n",
            "Epoch: 0, iteración;   5800 de 8923, Loss: 0.6524287223815918\n",
            "Epoch: 0, iteración;   5810 de 8923, Loss: 0.6079792976379395\n",
            "Epoch: 0, iteración;   5820 de 8923, Loss: 0.6181675910949707\n",
            "Epoch: 0, iteración;   5830 de 8923, Loss: 0.5530096054077148\n",
            "Epoch: 0, iteración;   5840 de 8923, Loss: 0.5618611812591553\n",
            "Epoch: 0, iteración;   5850 de 8923, Loss: 0.5386997699737549\n",
            "Epoch: 0, iteración;   5860 de 8923, Loss: 0.5888651847839356\n",
            "Epoch: 0, iteración;   5870 de 8923, Loss: 0.6697053909301758\n",
            "Epoch: 0, iteración;   5880 de 8923, Loss: 0.5729480743408203\n",
            "Epoch: 0, iteración;   5890 de 8923, Loss: 0.6385069370269776\n",
            "Epoch: 0, iteración;   5900 de 8923, Loss: 0.6676461219787597\n",
            "Epoch: 0, iteración;   5910 de 8923, Loss: 0.6173566818237305\n",
            "Epoch: 0, iteración;   5920 de 8923, Loss: 0.5985873222351075\n",
            "Epoch: 0, iteración;   5930 de 8923, Loss: 0.6434597969055176\n",
            "Epoch: 0, iteración;   5940 de 8923, Loss: 0.661838150024414\n",
            "Epoch: 0, iteración;   5950 de 8923, Loss: 0.6457013130187989\n",
            "Epoch: 0, iteración;   5960 de 8923, Loss: 0.5930111885070801\n",
            "Epoch: 0, iteración;   5970 de 8923, Loss: 0.5937747001647949\n",
            "Epoch: 0, iteración;   5980 de 8923, Loss: 0.5741384983062744\n",
            "Epoch: 0, iteración;   5990 de 8923, Loss: 0.5866302013397217\n",
            "Epoch: 0, iteración;   6000 de 8923, Loss: 0.582942008972168\n",
            "Epoch: 0, iteración;   6010 de 8923, Loss: 0.6544191837310791\n",
            "Epoch: 0, iteración;   6020 de 8923, Loss: 0.617244815826416\n",
            "Epoch: 0, iteración;   6030 de 8923, Loss: 0.5859969615936279\n",
            "Epoch: 0, iteración;   6040 de 8923, Loss: 0.6010046005249023\n",
            "Epoch: 0, iteración;   6050 de 8923, Loss: 0.5602970600128174\n",
            "Epoch: 0, iteración;   6060 de 8923, Loss: 0.7268388748168946\n",
            "Epoch: 0, iteración;   6070 de 8923, Loss: 0.5792610168457031\n",
            "Epoch: 0, iteración;   6080 de 8923, Loss: 0.5799363136291504\n",
            "Epoch: 0, iteración;   6090 de 8923, Loss: 0.5860851287841797\n",
            "Epoch: 0, iteración;   6100 de 8923, Loss: 0.584053373336792\n",
            "Epoch: 0, iteración;   6110 de 8923, Loss: 0.5751399517059326\n",
            "Epoch: 0, iteración;   6120 de 8923, Loss: 0.5852935314178467\n",
            "Epoch: 0, iteración;   6130 de 8923, Loss: 0.4894073963165283\n",
            "Epoch: 0, iteración;   6140 de 8923, Loss: 0.5828639030456543\n",
            "Epoch: 0, iteración;   6150 de 8923, Loss: 0.5311508655548096\n",
            "Epoch: 0, iteración;   6160 de 8923, Loss: 0.5808128833770752\n",
            "Epoch: 0, iteración;   6170 de 8923, Loss: 0.5836052894592285\n",
            "Epoch: 0, iteración;   6180 de 8923, Loss: 0.6030696868896485\n",
            "Epoch: 0, iteración;   6190 de 8923, Loss: 0.5611215114593506\n",
            "Epoch: 0, iteración;   6200 de 8923, Loss: 0.6744400501251221\n",
            "Epoch: 0, iteración;   6210 de 8923, Loss: 0.5829607009887695\n",
            "Epoch: 0, iteración;   6220 de 8923, Loss: 0.6018553733825683\n",
            "Epoch: 0, iteración;   6230 de 8923, Loss: 0.5815908908843994\n",
            "Epoch: 0, iteración;   6240 de 8923, Loss: 0.5867167472839355\n",
            "Epoch: 0, iteración;   6250 de 8923, Loss: 0.604499340057373\n",
            "Epoch: 0, iteración;   6260 de 8923, Loss: 0.6349937915802002\n",
            "Epoch: 0, iteración;   6270 de 8923, Loss: 0.5875866413116455\n",
            "Epoch: 0, iteración;   6280 de 8923, Loss: 0.6898410320281982\n",
            "Epoch: 0, iteración;   6290 de 8923, Loss: 0.6980241298675537\n",
            "Epoch: 0, iteración;   6300 de 8923, Loss: 0.6261715412139892\n",
            "Epoch: 0, iteración;   6310 de 8923, Loss: 0.6045926570892334\n",
            "Epoch: 0, iteración;   6320 de 8923, Loss: 0.5530791282653809\n",
            "Epoch: 0, iteración;   6330 de 8923, Loss: 0.5718249320983887\n",
            "Epoch: 0, iteración;   6340 de 8923, Loss: 0.5410043239593506\n",
            "Epoch: 0, iteración;   6350 de 8923, Loss: 0.48734149932861326\n",
            "Epoch: 0, iteración;   6360 de 8923, Loss: 0.7018995761871338\n",
            "Epoch: 0, iteración;   6370 de 8923, Loss: 0.6711578845977784\n",
            "Epoch: 0, iteración;   6380 de 8923, Loss: 0.5621992111206054\n",
            "Epoch: 0, iteración;   6390 de 8923, Loss: 0.6103129386901855\n",
            "Epoch: 0, iteración;   6400 de 8923, Loss: 0.5988015174865723\n",
            "Epoch: 0, iteración;   6410 de 8923, Loss: 0.5870087623596192\n",
            "Epoch: 0, iteración;   6420 de 8923, Loss: 0.6426551818847657\n",
            "Epoch: 0, iteración;   6430 de 8923, Loss: 0.618545389175415\n",
            "Epoch: 0, iteración;   6440 de 8923, Loss: 0.618777847290039\n",
            "Epoch: 0, iteración;   6450 de 8923, Loss: 0.5901727199554443\n",
            "Epoch: 0, iteración;   6460 de 8923, Loss: 0.6466997146606446\n",
            "Epoch: 0, iteración;   6470 de 8923, Loss: 0.6010149478912353\n",
            "Epoch: 0, iteración;   6480 de 8923, Loss: 0.6299211025238037\n",
            "Epoch: 0, iteración;   6490 de 8923, Loss: 0.6263646602630615\n",
            "Epoch: 0, iteración;   6500 de 8923, Loss: 0.6105720043182373\n",
            "Epoch: 0, iteración;   6510 de 8923, Loss: 0.61579270362854\n",
            "Epoch: 0, iteración;   6520 de 8923, Loss: 0.5517899036407471\n",
            "Epoch: 0, iteración;   6530 de 8923, Loss: 0.5825129985809326\n",
            "Epoch: 0, iteración;   6540 de 8923, Loss: 0.4763054370880127\n",
            "Epoch: 0, iteración;   6550 de 8923, Loss: 0.7321821212768554\n",
            "Epoch: 0, iteración;   6560 de 8923, Loss: 0.5092253684997559\n",
            "Epoch: 0, iteración;   6570 de 8923, Loss: 0.5519163131713867\n",
            "Epoch: 0, iteración;   6580 de 8923, Loss: 0.677146053314209\n",
            "Epoch: 0, iteración;   6590 de 8923, Loss: 0.600798511505127\n",
            "Epoch: 0, iteración;   6600 de 8923, Loss: 0.5722054958343505\n",
            "Epoch: 0, iteración;   6610 de 8923, Loss: 0.5656270503997802\n",
            "Epoch: 0, iteración;   6620 de 8923, Loss: 0.6066071510314941\n",
            "Epoch: 0, iteración;   6630 de 8923, Loss: 0.5139603614807129\n",
            "Epoch: 0, iteración;   6640 de 8923, Loss: 0.53115873336792\n",
            "Epoch: 0, iteración;   6650 de 8923, Loss: 0.5467475414276123\n",
            "Epoch: 0, iteración;   6660 de 8923, Loss: 0.6654098033905029\n",
            "Epoch: 0, iteración;   6670 de 8923, Loss: 0.5717185497283935\n",
            "Epoch: 0, iteración;   6680 de 8923, Loss: 0.5441466808319092\n",
            "Epoch: 0, iteración;   6690 de 8923, Loss: 0.5086664676666259\n",
            "Epoch: 0, iteración;   6700 de 8923, Loss: 0.6009881973266602\n",
            "Epoch: 0, iteración;   6710 de 8923, Loss: 0.5953400611877442\n",
            "Epoch: 0, iteración;   6720 de 8923, Loss: 0.6652186870574951\n",
            "Epoch: 0, iteración;   6730 de 8923, Loss: 0.5747740745544434\n",
            "Epoch: 0, iteración;   6740 de 8923, Loss: 0.5938767910003662\n",
            "Epoch: 0, iteración;   6750 de 8923, Loss: 0.5642998218536377\n",
            "Epoch: 0, iteración;   6760 de 8923, Loss: 0.4718888759613037\n",
            "Epoch: 0, iteración;   6770 de 8923, Loss: 0.6121966361999511\n",
            "Epoch: 0, iteración;   6780 de 8923, Loss: 0.6013336181640625\n",
            "Epoch: 0, iteración;   6790 de 8923, Loss: 0.5957971572875976\n",
            "Epoch: 0, iteración;   6800 de 8923, Loss: 0.6493734836578369\n",
            "Epoch: 0, iteración;   6810 de 8923, Loss: 0.5631246089935302\n",
            "Epoch: 0, iteración;   6820 de 8923, Loss: 0.5743959426879883\n",
            "Epoch: 0, iteración;   6830 de 8923, Loss: 0.6416633605957032\n",
            "Epoch: 0, iteración;   6840 de 8923, Loss: 0.5162390232086181\n",
            "Epoch: 0, iteración;   6850 de 8923, Loss: 0.46684703826904295\n",
            "Epoch: 0, iteración;   6860 de 8923, Loss: 0.6381887912750244\n",
            "Epoch: 0, iteración;   6870 de 8923, Loss: 0.6007748126983643\n",
            "Epoch: 0, iteración;   6880 de 8923, Loss: 0.5837319374084473\n",
            "Epoch: 0, iteración;   6890 de 8923, Loss: 0.5442314147949219\n",
            "Epoch: 0, iteración;   6900 de 8923, Loss: 0.6452980518341065\n",
            "Epoch: 0, iteración;   6910 de 8923, Loss: 0.5723623275756836\n",
            "Epoch: 0, iteración;   6920 de 8923, Loss: 0.5966248989105225\n",
            "Epoch: 0, iteración;   6930 de 8923, Loss: 0.522777795791626\n",
            "Epoch: 0, iteración;   6940 de 8923, Loss: 0.6175820350646972\n",
            "Epoch: 0, iteración;   6950 de 8923, Loss: 0.5836918830871582\n",
            "Epoch: 0, iteración;   6960 de 8923, Loss: 0.5676255226135254\n",
            "Epoch: 0, iteración;   6970 de 8923, Loss: 0.5379867076873779\n",
            "Epoch: 0, iteración;   6980 de 8923, Loss: 0.6006781101226807\n",
            "Epoch: 0, iteración;   6990 de 8923, Loss: 0.6070933818817139\n",
            "Epoch: 0, iteración;   7000 de 8923, Loss: 0.5856143951416015\n",
            "Epoch: 0, iteración;   7010 de 8923, Loss: 0.5777949333190918\n",
            "Epoch: 0, iteración;   7020 de 8923, Loss: 0.6089570999145508\n",
            "Epoch: 0, iteración;   7030 de 8923, Loss: 0.5858508110046386\n",
            "Epoch: 0, iteración;   7040 de 8923, Loss: 0.6444669723510742\n",
            "Epoch: 0, iteración;   7050 de 8923, Loss: 0.5776149749755859\n",
            "Epoch: 0, iteración;   7060 de 8923, Loss: 0.6670463562011719\n",
            "Epoch: 0, iteración;   7070 de 8923, Loss: 0.567951774597168\n",
            "Epoch: 0, iteración;   7080 de 8923, Loss: 0.5644385814666748\n",
            "Epoch: 0, iteración;   7090 de 8923, Loss: 0.5686981201171875\n",
            "Epoch: 0, iteración;   7100 de 8923, Loss: 0.7159236431121826\n",
            "Epoch: 0, iteración;   7110 de 8923, Loss: 0.6004409313201904\n",
            "Epoch: 0, iteración;   7120 de 8923, Loss: 0.6080415725708008\n",
            "Epoch: 0, iteración;   7130 de 8923, Loss: 0.629270362854004\n",
            "Epoch: 0, iteración;   7140 de 8923, Loss: 0.6131853103637696\n",
            "Epoch: 0, iteración;   7150 de 8923, Loss: 0.5813050270080566\n",
            "Epoch: 0, iteración;   7160 de 8923, Loss: 0.5203563213348389\n",
            "Epoch: 0, iteración;   7170 de 8923, Loss: 0.5584554672241211\n",
            "Epoch: 0, iteración;   7180 de 8923, Loss: 0.7245712280273438\n",
            "Epoch: 0, iteración;   7190 de 8923, Loss: 0.6564888954162598\n",
            "Epoch: 0, iteración;   7200 de 8923, Loss: 0.5673958778381347\n",
            "Epoch: 0, iteración;   7210 de 8923, Loss: 0.6197474479675293\n",
            "Epoch: 0, iteración;   7220 de 8923, Loss: 0.6052858352661132\n",
            "Epoch: 0, iteración;   7230 de 8923, Loss: 0.5937216758728028\n",
            "Epoch: 0, iteración;   7240 de 8923, Loss: 0.5278151035308838\n",
            "Epoch: 0, iteración;   7250 de 8923, Loss: 0.580956220626831\n",
            "Epoch: 0, iteración;   7260 de 8923, Loss: 0.5855614185333252\n",
            "Epoch: 0, iteración;   7270 de 8923, Loss: 0.5671361923217774\n",
            "Epoch: 0, iteración;   7280 de 8923, Loss: 0.5279388427734375\n",
            "Epoch: 0, iteración;   7290 de 8923, Loss: 0.6264420509338379\n",
            "Epoch: 0, iteración;   7300 de 8923, Loss: 0.5845180988311768\n",
            "Epoch: 0, iteración;   7310 de 8923, Loss: 0.6856605052947998\n",
            "Epoch: 0, iteración;   7320 de 8923, Loss: 0.6300407886505127\n",
            "Epoch: 0, iteración;   7330 de 8923, Loss: 0.5938693046569824\n",
            "Epoch: 0, iteración;   7340 de 8923, Loss: 0.5987796783447266\n",
            "Epoch: 0, iteración;   7350 de 8923, Loss: 0.5933880805969238\n",
            "Epoch: 0, iteración;   7360 de 8923, Loss: 0.5953709602355957\n",
            "Epoch: 0, iteración;   7370 de 8923, Loss: 0.6063089847564698\n",
            "Epoch: 0, iteración;   7380 de 8923, Loss: 0.5338403224945069\n",
            "Epoch: 0, iteración;   7390 de 8923, Loss: 0.5644094467163085\n",
            "Epoch: 0, iteración;   7400 de 8923, Loss: 0.5560076236724854\n",
            "Epoch: 0, iteración;   7410 de 8923, Loss: 0.6115719318389893\n",
            "Epoch: 0, iteración;   7420 de 8923, Loss: 0.6592458724975586\n",
            "Epoch: 0, iteración;   7430 de 8923, Loss: 0.5781578540802002\n",
            "Epoch: 0, iteración;   7440 de 8923, Loss: 0.5910303115844726\n",
            "Epoch: 0, iteración;   7450 de 8923, Loss: 0.5922630310058594\n",
            "Epoch: 0, iteración;   7460 de 8923, Loss: 0.5398175716400146\n",
            "Epoch: 0, iteración;   7470 de 8923, Loss: 0.5584159851074219\n",
            "Epoch: 0, iteración;   7480 de 8923, Loss: 0.6370820045471192\n",
            "Epoch: 0, iteración;   7490 de 8923, Loss: 0.5708788871765137\n",
            "Epoch: 0, iteración;   7500 de 8923, Loss: 0.6129621982574462\n",
            "Epoch: 0, iteración;   7510 de 8923, Loss: 0.6227861404418945\n",
            "Epoch: 0, iteración;   7520 de 8923, Loss: 0.5819912433624268\n",
            "Epoch: 0, iteración;   7530 de 8923, Loss: 0.5843880653381348\n",
            "Epoch: 0, iteración;   7540 de 8923, Loss: 0.5422022342681885\n",
            "Epoch: 0, iteración;   7550 de 8923, Loss: 0.5186676025390625\n",
            "Epoch: 0, iteración;   7560 de 8923, Loss: 0.5730503559112549\n",
            "Epoch: 0, iteración;   7570 de 8923, Loss: 0.56105055809021\n",
            "Epoch: 0, iteración;   7580 de 8923, Loss: 0.5286157608032227\n",
            "Epoch: 0, iteración;   7590 de 8923, Loss: 0.6159616470336914\n",
            "Epoch: 0, iteración;   7600 de 8923, Loss: 0.6779205799102783\n",
            "Epoch: 0, iteración;   7610 de 8923, Loss: 0.630801010131836\n",
            "Epoch: 0, iteración;   7620 de 8923, Loss: 0.5322095394134522\n",
            "Epoch: 0, iteración;   7630 de 8923, Loss: 0.5585861682891846\n",
            "Epoch: 0, iteración;   7640 de 8923, Loss: 0.5544389247894287\n",
            "Epoch: 0, iteración;   7650 de 8923, Loss: 0.6754251480102539\n",
            "Epoch: 0, iteración;   7660 de 8923, Loss: 0.5784571170806885\n",
            "Epoch: 0, iteración;   7670 de 8923, Loss: 0.5755506038665772\n",
            "Epoch: 0, iteración;   7680 de 8923, Loss: 0.6394197940826416\n",
            "Epoch: 0, iteración;   7690 de 8923, Loss: 0.6501974105834961\n",
            "Epoch: 0, iteración;   7700 de 8923, Loss: 0.6012975215911865\n",
            "Epoch: 0, iteración;   7710 de 8923, Loss: 0.6532288074493409\n",
            "Epoch: 0, iteración;   7720 de 8923, Loss: 0.5904390811920166\n",
            "Epoch: 0, iteración;   7730 de 8923, Loss: 0.5965534210205078\n",
            "Epoch: 0, iteración;   7740 de 8923, Loss: 0.6002171516418457\n",
            "Epoch: 0, iteración;   7750 de 8923, Loss: 0.6118625640869141\n",
            "Epoch: 0, iteración;   7760 de 8923, Loss: 0.5394818305969238\n",
            "Epoch: 0, iteración;   7770 de 8923, Loss: 0.6270237445831299\n",
            "Epoch: 0, iteración;   7780 de 8923, Loss: 0.6309096336364746\n",
            "Epoch: 0, iteración;   7790 de 8923, Loss: 0.5496957302093506\n",
            "Epoch: 0, iteración;   7800 de 8923, Loss: 0.5785536766052246\n",
            "Epoch: 0, iteración;   7810 de 8923, Loss: 0.5921473503112793\n",
            "Epoch: 0, iteración;   7820 de 8923, Loss: 0.5763821125030517\n",
            "Epoch: 0, iteración;   7830 de 8923, Loss: 0.6239413738250732\n",
            "Epoch: 0, iteración;   7840 de 8923, Loss: 0.5407347679138184\n",
            "Epoch: 0, iteración;   7850 de 8923, Loss: 0.5967443466186524\n",
            "Epoch: 0, iteración;   7860 de 8923, Loss: 0.6025026798248291\n",
            "Epoch: 0, iteración;   7870 de 8923, Loss: 0.5887224197387695\n",
            "Epoch: 0, iteración;   7880 de 8923, Loss: 0.6495993137359619\n",
            "Epoch: 0, iteración;   7890 de 8923, Loss: 0.6426330089569092\n",
            "Epoch: 0, iteración;   7900 de 8923, Loss: 0.6256429195404053\n",
            "Epoch: 0, iteración;   7910 de 8923, Loss: 0.5947334289550781\n",
            "Epoch: 0, iteración;   7920 de 8923, Loss: 0.5563982009887696\n",
            "Epoch: 0, iteración;   7930 de 8923, Loss: 0.5770917415618897\n",
            "Epoch: 0, iteración;   7940 de 8923, Loss: 0.5496639251708985\n",
            "Epoch: 0, iteración;   7950 de 8923, Loss: 0.5134961128234863\n",
            "Epoch: 0, iteración;   7960 de 8923, Loss: 0.49089508056640624\n",
            "Epoch: 0, iteración;   7970 de 8923, Loss: 0.5803812980651856\n",
            "Epoch: 0, iteración;   7980 de 8923, Loss: 0.5639404773712158\n",
            "Epoch: 0, iteración;   7990 de 8923, Loss: 0.6160151481628418\n",
            "Epoch: 0, iteración;   8000 de 8923, Loss: 0.55052490234375\n",
            "Epoch: 0, iteración;   8010 de 8923, Loss: 0.6015984535217285\n",
            "Epoch: 0, iteración;   8020 de 8923, Loss: 0.6804942131042481\n",
            "Epoch: 0, iteración;   8030 de 8923, Loss: 0.5789052009582519\n",
            "Epoch: 0, iteración;   8040 de 8923, Loss: 0.6116622924804688\n",
            "Epoch: 0, iteración;   8050 de 8923, Loss: 0.6235523223876953\n",
            "Epoch: 0, iteración;   8060 de 8923, Loss: 0.6716737747192383\n",
            "Epoch: 0, iteración;   8070 de 8923, Loss: 0.5963747501373291\n",
            "Epoch: 0, iteración;   8080 de 8923, Loss: 0.5722229480743408\n",
            "Epoch: 0, iteración;   8090 de 8923, Loss: 0.6128118991851806\n",
            "Epoch: 0, iteración;   8100 de 8923, Loss: 0.5907261371612549\n",
            "Epoch: 0, iteración;   8110 de 8923, Loss: 0.5393237590789794\n",
            "Epoch: 0, iteración;   8120 de 8923, Loss: 0.6169566154479981\n",
            "Epoch: 0, iteración;   8130 de 8923, Loss: 0.5923199653625488\n",
            "Epoch: 0, iteración;   8140 de 8923, Loss: 0.571561622619629\n",
            "Epoch: 0, iteración;   8150 de 8923, Loss: 0.6230584144592285\n",
            "Epoch: 0, iteración;   8160 de 8923, Loss: 0.613505744934082\n",
            "Epoch: 0, iteración;   8170 de 8923, Loss: 0.5637325286865235\n",
            "Epoch: 0, iteración;   8180 de 8923, Loss: 0.6102890491485595\n",
            "Epoch: 0, iteración;   8190 de 8923, Loss: 0.5901312828063965\n",
            "Epoch: 0, iteración;   8200 de 8923, Loss: 0.6247487545013428\n",
            "Epoch: 0, iteración;   8210 de 8923, Loss: 0.6047512531280518\n",
            "Epoch: 0, iteración;   8220 de 8923, Loss: 0.6489256858825684\n",
            "Epoch: 0, iteración;   8230 de 8923, Loss: 0.598109769821167\n",
            "Epoch: 0, iteración;   8240 de 8923, Loss: 0.5662989616394043\n",
            "Epoch: 0, iteración;   8250 de 8923, Loss: 0.6028491497039795\n",
            "Epoch: 0, iteración;   8260 de 8923, Loss: 0.6264853954315186\n",
            "Epoch: 0, iteración;   8270 de 8923, Loss: 0.6342147827148438\n",
            "Epoch: 0, iteración;   8280 de 8923, Loss: 0.5535650730133057\n",
            "Epoch: 0, iteración;   8290 de 8923, Loss: 0.5871042728424072\n",
            "Epoch: 0, iteración;   8300 de 8923, Loss: 0.6123086929321289\n",
            "Epoch: 0, iteración;   8310 de 8923, Loss: 0.5899160861968994\n",
            "Epoch: 0, iteración;   8320 de 8923, Loss: 0.5150429248809815\n",
            "Epoch: 0, iteración;   8330 de 8923, Loss: 0.5881879329681396\n",
            "Epoch: 0, iteración;   8340 de 8923, Loss: 0.6687736511230469\n",
            "Epoch: 0, iteración;   8350 de 8923, Loss: 0.6052555561065673\n",
            "Epoch: 0, iteración;   8360 de 8923, Loss: 0.615819263458252\n",
            "Epoch: 0, iteración;   8370 de 8923, Loss: 0.5601099014282227\n",
            "Epoch: 0, iteración;   8380 de 8923, Loss: 0.602115249633789\n",
            "Epoch: 0, iteración;   8390 de 8923, Loss: 0.6455120086669922\n",
            "Epoch: 0, iteración;   8400 de 8923, Loss: 0.5784114360809326\n",
            "Epoch: 0, iteración;   8410 de 8923, Loss: 0.6398688793182373\n",
            "Epoch: 0, iteración;   8420 de 8923, Loss: 0.5642658233642578\n",
            "Epoch: 0, iteración;   8430 de 8923, Loss: 0.5752165794372559\n",
            "Epoch: 0, iteración;   8440 de 8923, Loss: 0.5700924396514893\n",
            "Epoch: 0, iteración;   8450 de 8923, Loss: 0.580197525024414\n",
            "Epoch: 0, iteración;   8460 de 8923, Loss: 0.5305284976959228\n",
            "Epoch: 0, iteración;   8470 de 8923, Loss: 0.5394333839416504\n",
            "Epoch: 0, iteración;   8480 de 8923, Loss: 0.551882266998291\n",
            "Epoch: 0, iteración;   8490 de 8923, Loss: 0.6260478019714355\n",
            "Epoch: 0, iteración;   8500 de 8923, Loss: 0.46593456268310546\n",
            "Epoch: 0, iteración;   8510 de 8923, Loss: 0.5549026012420655\n",
            "Epoch: 0, iteración;   8520 de 8923, Loss: 0.5373034954071045\n",
            "Epoch: 0, iteración;   8530 de 8923, Loss: 0.5983133316040039\n",
            "Epoch: 0, iteración;   8540 de 8923, Loss: 0.5309868812561035\n",
            "Epoch: 0, iteración;   8550 de 8923, Loss: 0.6116683959960938\n",
            "Epoch: 0, iteración;   8560 de 8923, Loss: 0.6473660469055176\n",
            "Epoch: 0, iteración;   8570 de 8923, Loss: 0.6470012664794922\n",
            "Epoch: 0, iteración;   8580 de 8923, Loss: 0.5969310760498047\n",
            "Epoch: 0, iteración;   8590 de 8923, Loss: 0.6459392070770263\n",
            "Epoch: 0, iteración;   8600 de 8923, Loss: 0.5445468902587891\n",
            "Epoch: 0, iteración;   8610 de 8923, Loss: 0.5718543529510498\n",
            "Epoch: 0, iteración;   8620 de 8923, Loss: 0.560893440246582\n",
            "Epoch: 0, iteración;   8630 de 8923, Loss: 0.5465794563293457\n",
            "Epoch: 0, iteración;   8640 de 8923, Loss: 0.5301508903503418\n",
            "Epoch: 0, iteración;   8650 de 8923, Loss: 0.5758668899536132\n",
            "Epoch: 0, iteración;   8660 de 8923, Loss: 0.5352757453918457\n",
            "Epoch: 0, iteración;   8670 de 8923, Loss: 0.6348602294921875\n",
            "Epoch: 0, iteración;   8680 de 8923, Loss: 0.6142234802246094\n",
            "Epoch: 0, iteración;   8690 de 8923, Loss: 0.6489064693450928\n",
            "Epoch: 0, iteración;   8700 de 8923, Loss: 0.6030145645141601\n",
            "Epoch: 0, iteración;   8710 de 8923, Loss: 0.5906035900115967\n",
            "Epoch: 0, iteración;   8720 de 8923, Loss: 0.6175775527954102\n",
            "Epoch: 0, iteración;   8730 de 8923, Loss: 0.5362059116363526\n",
            "Epoch: 0, iteración;   8740 de 8923, Loss: 0.5709302425384521\n",
            "Epoch: 0, iteración;   8750 de 8923, Loss: 0.627334451675415\n",
            "Epoch: 0, iteración;   8760 de 8923, Loss: 0.6259323120117187\n",
            "Epoch: 0, iteración;   8770 de 8923, Loss: 0.5439450740814209\n",
            "Epoch: 0, iteración;   8780 de 8923, Loss: 0.5777616500854492\n",
            "Epoch: 0, iteración;   8790 de 8923, Loss: 0.6783754348754882\n",
            "Epoch: 0, iteración;   8800 de 8923, Loss: 0.578528356552124\n",
            "Epoch: 0, iteración;   8810 de 8923, Loss: 0.6029721736907959\n",
            "Epoch: 0, iteración;   8820 de 8923, Loss: 0.6941246509552002\n",
            "Epoch: 0, iteración;   8830 de 8923, Loss: 0.5977194786071778\n",
            "Epoch: 0, iteración;   8840 de 8923, Loss: 0.5833184242248535\n",
            "Epoch: 0, iteración;   8850 de 8923, Loss: 0.5771020889282227\n",
            "Epoch: 0, iteración;   8860 de 8923, Loss: 0.5500460624694824\n",
            "Epoch: 0, iteración;   8870 de 8923, Loss: 0.724839735031128\n",
            "Epoch: 0, iteración;   8880 de 8923, Loss: 0.6044140815734863\n",
            "Epoch: 0, iteración;   8890 de 8923, Loss: 0.6532279491424561\n",
            "Epoch: 0, iteración;   8900 de 8923, Loss: 0.6165209293365479\n",
            "Epoch: 0, iteración;   8910 de 8923, Loss: 0.5743402481079102\n",
            "Epoch: 0, iteración;   8920 de 8923, Loss: 0.5821816444396972\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainRoberta(epoch)"
      ],
      "id": "giqwgCkwXNG1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fed5ddd-0778-4cce-af2e-32f117919290",
        "id": "uN1oNB8oXNG1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_50_separados.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "id": "uN1oNB8oXNG1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhTjLi4nXNG1"
      },
      "source": [
        "##### Evaluación del modelo"
      ],
      "id": "GhTjLi4nXNG1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPM_rraNXNG1"
      },
      "outputs": [],
      "source": [
        "def validationRoberta(epoch):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    num_iteraciones = len(testing_loader)\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device)\n",
        "            mask = data['mask'].to(device)\n",
        "            token_type_ids = data['token_type_ids'].to(device)\n",
        "            targets = data['target'].to(device)\n",
        "\n",
        "            print(f\"Iteración: {i:6} de {num_iteraciones}\")\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "id": "fPM_rraNXNG1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "CHHji3zaXNG1"
      },
      "id": "CHHji3zaXNG1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt73M72CXNG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4bb4a25-773a-41fb-a5f3-2a7bb9c188ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado correctamente\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_50_separados.pth\"):\n",
        "  model = RobertaClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_50_separados.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_roberta_50_separados.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "id": "dt73M72CXNG1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36e0bc1-0541-4067-fb2f-b864a2faecdb",
        "id": "Pp35VP5-XNG1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración:      0 de 1116\n",
            "Iteración:      1 de 1116\n",
            "Iteración:      2 de 1116\n",
            "Iteración:      3 de 1116\n",
            "Iteración:      4 de 1116\n",
            "Iteración:      5 de 1116\n",
            "Iteración:      6 de 1116\n",
            "Iteración:      7 de 1116\n",
            "Iteración:      8 de 1116\n",
            "Iteración:      9 de 1116\n",
            "Iteración:     10 de 1116\n",
            "Iteración:     11 de 1116\n",
            "Iteración:     12 de 1116\n",
            "Iteración:     13 de 1116\n",
            "Iteración:     14 de 1116\n",
            "Iteración:     15 de 1116\n",
            "Iteración:     16 de 1116\n",
            "Iteración:     17 de 1116\n",
            "Iteración:     18 de 1116\n",
            "Iteración:     19 de 1116\n",
            "Iteración:     20 de 1116\n",
            "Iteración:     21 de 1116\n",
            "Iteración:     22 de 1116\n",
            "Iteración:     23 de 1116\n",
            "Iteración:     24 de 1116\n",
            "Iteración:     25 de 1116\n",
            "Iteración:     26 de 1116\n",
            "Iteración:     27 de 1116\n",
            "Iteración:     28 de 1116\n",
            "Iteración:     29 de 1116\n",
            "Iteración:     30 de 1116\n",
            "Iteración:     31 de 1116\n",
            "Iteración:     32 de 1116\n",
            "Iteración:     33 de 1116\n",
            "Iteración:     34 de 1116\n",
            "Iteración:     35 de 1116\n",
            "Iteración:     36 de 1116\n",
            "Iteración:     37 de 1116\n",
            "Iteración:     38 de 1116\n",
            "Iteración:     39 de 1116\n",
            "Iteración:     40 de 1116\n",
            "Iteración:     41 de 1116\n",
            "Iteración:     42 de 1116\n",
            "Iteración:     43 de 1116\n",
            "Iteración:     44 de 1116\n",
            "Iteración:     45 de 1116\n",
            "Iteración:     46 de 1116\n",
            "Iteración:     47 de 1116\n",
            "Iteración:     48 de 1116\n",
            "Iteración:     49 de 1116\n",
            "Iteración:     50 de 1116\n",
            "Iteración:     51 de 1116\n",
            "Iteración:     52 de 1116\n",
            "Iteración:     53 de 1116\n",
            "Iteración:     54 de 1116\n",
            "Iteración:     55 de 1116\n",
            "Iteración:     56 de 1116\n",
            "Iteración:     57 de 1116\n",
            "Iteración:     58 de 1116\n",
            "Iteración:     59 de 1116\n",
            "Iteración:     60 de 1116\n",
            "Iteración:     61 de 1116\n",
            "Iteración:     62 de 1116\n",
            "Iteración:     63 de 1116\n",
            "Iteración:     64 de 1116\n",
            "Iteración:     65 de 1116\n",
            "Iteración:     66 de 1116\n",
            "Iteración:     67 de 1116\n",
            "Iteración:     68 de 1116\n",
            "Iteración:     69 de 1116\n",
            "Iteración:     70 de 1116\n",
            "Iteración:     71 de 1116\n",
            "Iteración:     72 de 1116\n",
            "Iteración:     73 de 1116\n",
            "Iteración:     74 de 1116\n",
            "Iteración:     75 de 1116\n",
            "Iteración:     76 de 1116\n",
            "Iteración:     77 de 1116\n",
            "Iteración:     78 de 1116\n",
            "Iteración:     79 de 1116\n",
            "Iteración:     80 de 1116\n",
            "Iteración:     81 de 1116\n",
            "Iteración:     82 de 1116\n",
            "Iteración:     83 de 1116\n",
            "Iteración:     84 de 1116\n",
            "Iteración:     85 de 1116\n",
            "Iteración:     86 de 1116\n",
            "Iteración:     87 de 1116\n",
            "Iteración:     88 de 1116\n",
            "Iteración:     89 de 1116\n",
            "Iteración:     90 de 1116\n",
            "Iteración:     91 de 1116\n",
            "Iteración:     92 de 1116\n",
            "Iteración:     93 de 1116\n",
            "Iteración:     94 de 1116\n",
            "Iteración:     95 de 1116\n",
            "Iteración:     96 de 1116\n",
            "Iteración:     97 de 1116\n",
            "Iteración:     98 de 1116\n",
            "Iteración:     99 de 1116\n",
            "Iteración:    100 de 1116\n",
            "Iteración:    101 de 1116\n",
            "Iteración:    102 de 1116\n",
            "Iteración:    103 de 1116\n",
            "Iteración:    104 de 1116\n",
            "Iteración:    105 de 1116\n",
            "Iteración:    106 de 1116\n",
            "Iteración:    107 de 1116\n",
            "Iteración:    108 de 1116\n",
            "Iteración:    109 de 1116\n",
            "Iteración:    110 de 1116\n",
            "Iteración:    111 de 1116\n",
            "Iteración:    112 de 1116\n",
            "Iteración:    113 de 1116\n",
            "Iteración:    114 de 1116\n",
            "Iteración:    115 de 1116\n",
            "Iteración:    116 de 1116\n",
            "Iteración:    117 de 1116\n",
            "Iteración:    118 de 1116\n",
            "Iteración:    119 de 1116\n",
            "Iteración:    120 de 1116\n",
            "Iteración:    121 de 1116\n",
            "Iteración:    122 de 1116\n",
            "Iteración:    123 de 1116\n",
            "Iteración:    124 de 1116\n",
            "Iteración:    125 de 1116\n",
            "Iteración:    126 de 1116\n",
            "Iteración:    127 de 1116\n",
            "Iteración:    128 de 1116\n",
            "Iteración:    129 de 1116\n",
            "Iteración:    130 de 1116\n",
            "Iteración:    131 de 1116\n",
            "Iteración:    132 de 1116\n",
            "Iteración:    133 de 1116\n",
            "Iteración:    134 de 1116\n",
            "Iteración:    135 de 1116\n",
            "Iteración:    136 de 1116\n",
            "Iteración:    137 de 1116\n",
            "Iteración:    138 de 1116\n",
            "Iteración:    139 de 1116\n",
            "Iteración:    140 de 1116\n",
            "Iteración:    141 de 1116\n",
            "Iteración:    142 de 1116\n",
            "Iteración:    143 de 1116\n",
            "Iteración:    144 de 1116\n",
            "Iteración:    145 de 1116\n",
            "Iteración:    146 de 1116\n",
            "Iteración:    147 de 1116\n",
            "Iteración:    148 de 1116\n",
            "Iteración:    149 de 1116\n",
            "Iteración:    150 de 1116\n",
            "Iteración:    151 de 1116\n",
            "Iteración:    152 de 1116\n",
            "Iteración:    153 de 1116\n",
            "Iteración:    154 de 1116\n",
            "Iteración:    155 de 1116\n",
            "Iteración:    156 de 1116\n",
            "Iteración:    157 de 1116\n",
            "Iteración:    158 de 1116\n",
            "Iteración:    159 de 1116\n",
            "Iteración:    160 de 1116\n",
            "Iteración:    161 de 1116\n",
            "Iteración:    162 de 1116\n",
            "Iteración:    163 de 1116\n",
            "Iteración:    164 de 1116\n",
            "Iteración:    165 de 1116\n",
            "Iteración:    166 de 1116\n",
            "Iteración:    167 de 1116\n",
            "Iteración:    168 de 1116\n",
            "Iteración:    169 de 1116\n",
            "Iteración:    170 de 1116\n",
            "Iteración:    171 de 1116\n",
            "Iteración:    172 de 1116\n",
            "Iteración:    173 de 1116\n",
            "Iteración:    174 de 1116\n",
            "Iteración:    175 de 1116\n",
            "Iteración:    176 de 1116\n",
            "Iteración:    177 de 1116\n",
            "Iteración:    178 de 1116\n",
            "Iteración:    179 de 1116\n",
            "Iteración:    180 de 1116\n",
            "Iteración:    181 de 1116\n",
            "Iteración:    182 de 1116\n",
            "Iteración:    183 de 1116\n",
            "Iteración:    184 de 1116\n",
            "Iteración:    185 de 1116\n",
            "Iteración:    186 de 1116\n",
            "Iteración:    187 de 1116\n",
            "Iteración:    188 de 1116\n",
            "Iteración:    189 de 1116\n",
            "Iteración:    190 de 1116\n",
            "Iteración:    191 de 1116\n",
            "Iteración:    192 de 1116\n",
            "Iteración:    193 de 1116\n",
            "Iteración:    194 de 1116\n",
            "Iteración:    195 de 1116\n",
            "Iteración:    196 de 1116\n",
            "Iteración:    197 de 1116\n",
            "Iteración:    198 de 1116\n",
            "Iteración:    199 de 1116\n",
            "Iteración:    200 de 1116\n",
            "Iteración:    201 de 1116\n",
            "Iteración:    202 de 1116\n",
            "Iteración:    203 de 1116\n",
            "Iteración:    204 de 1116\n",
            "Iteración:    205 de 1116\n",
            "Iteración:    206 de 1116\n",
            "Iteración:    207 de 1116\n",
            "Iteración:    208 de 1116\n",
            "Iteración:    209 de 1116\n",
            "Iteración:    210 de 1116\n",
            "Iteración:    211 de 1116\n",
            "Iteración:    212 de 1116\n",
            "Iteración:    213 de 1116\n",
            "Iteración:    214 de 1116\n",
            "Iteración:    215 de 1116\n",
            "Iteración:    216 de 1116\n",
            "Iteración:    217 de 1116\n",
            "Iteración:    218 de 1116\n",
            "Iteración:    219 de 1116\n",
            "Iteración:    220 de 1116\n",
            "Iteración:    221 de 1116\n",
            "Iteración:    222 de 1116\n",
            "Iteración:    223 de 1116\n",
            "Iteración:    224 de 1116\n",
            "Iteración:    225 de 1116\n",
            "Iteración:    226 de 1116\n",
            "Iteración:    227 de 1116\n",
            "Iteración:    228 de 1116\n",
            "Iteración:    229 de 1116\n",
            "Iteración:    230 de 1116\n",
            "Iteración:    231 de 1116\n",
            "Iteración:    232 de 1116\n",
            "Iteración:    233 de 1116\n",
            "Iteración:    234 de 1116\n",
            "Iteración:    235 de 1116\n",
            "Iteración:    236 de 1116\n",
            "Iteración:    237 de 1116\n",
            "Iteración:    238 de 1116\n",
            "Iteración:    239 de 1116\n",
            "Iteración:    240 de 1116\n",
            "Iteración:    241 de 1116\n",
            "Iteración:    242 de 1116\n",
            "Iteración:    243 de 1116\n",
            "Iteración:    244 de 1116\n",
            "Iteración:    245 de 1116\n",
            "Iteración:    246 de 1116\n",
            "Iteración:    247 de 1116\n",
            "Iteración:    248 de 1116\n",
            "Iteración:    249 de 1116\n",
            "Iteración:    250 de 1116\n",
            "Iteración:    251 de 1116\n",
            "Iteración:    252 de 1116\n",
            "Iteración:    253 de 1116\n",
            "Iteración:    254 de 1116\n",
            "Iteración:    255 de 1116\n",
            "Iteración:    256 de 1116\n",
            "Iteración:    257 de 1116\n",
            "Iteración:    258 de 1116\n",
            "Iteración:    259 de 1116\n",
            "Iteración:    260 de 1116\n",
            "Iteración:    261 de 1116\n",
            "Iteración:    262 de 1116\n",
            "Iteración:    263 de 1116\n",
            "Iteración:    264 de 1116\n",
            "Iteración:    265 de 1116\n",
            "Iteración:    266 de 1116\n",
            "Iteración:    267 de 1116\n",
            "Iteración:    268 de 1116\n",
            "Iteración:    269 de 1116\n",
            "Iteración:    270 de 1116\n",
            "Iteración:    271 de 1116\n",
            "Iteración:    272 de 1116\n",
            "Iteración:    273 de 1116\n",
            "Iteración:    274 de 1116\n",
            "Iteración:    275 de 1116\n",
            "Iteración:    276 de 1116\n",
            "Iteración:    277 de 1116\n",
            "Iteración:    278 de 1116\n",
            "Iteración:    279 de 1116\n",
            "Iteración:    280 de 1116\n",
            "Iteración:    281 de 1116\n",
            "Iteración:    282 de 1116\n",
            "Iteración:    283 de 1116\n",
            "Iteración:    284 de 1116\n",
            "Iteración:    285 de 1116\n",
            "Iteración:    286 de 1116\n",
            "Iteración:    287 de 1116\n",
            "Iteración:    288 de 1116\n",
            "Iteración:    289 de 1116\n",
            "Iteración:    290 de 1116\n",
            "Iteración:    291 de 1116\n",
            "Iteración:    292 de 1116\n",
            "Iteración:    293 de 1116\n",
            "Iteración:    294 de 1116\n",
            "Iteración:    295 de 1116\n",
            "Iteración:    296 de 1116\n",
            "Iteración:    297 de 1116\n",
            "Iteración:    298 de 1116\n",
            "Iteración:    299 de 1116\n",
            "Iteración:    300 de 1116\n",
            "Iteración:    301 de 1116\n",
            "Iteración:    302 de 1116\n",
            "Iteración:    303 de 1116\n",
            "Iteración:    304 de 1116\n",
            "Iteración:    305 de 1116\n",
            "Iteración:    306 de 1116\n",
            "Iteración:    307 de 1116\n",
            "Iteración:    308 de 1116\n",
            "Iteración:    309 de 1116\n",
            "Iteración:    310 de 1116\n",
            "Iteración:    311 de 1116\n",
            "Iteración:    312 de 1116\n",
            "Iteración:    313 de 1116\n",
            "Iteración:    314 de 1116\n",
            "Iteración:    315 de 1116\n",
            "Iteración:    316 de 1116\n",
            "Iteración:    317 de 1116\n",
            "Iteración:    318 de 1116\n",
            "Iteración:    319 de 1116\n",
            "Iteración:    320 de 1116\n",
            "Iteración:    321 de 1116\n",
            "Iteración:    322 de 1116\n",
            "Iteración:    323 de 1116\n",
            "Iteración:    324 de 1116\n",
            "Iteración:    325 de 1116\n",
            "Iteración:    326 de 1116\n",
            "Iteración:    327 de 1116\n",
            "Iteración:    328 de 1116\n",
            "Iteración:    329 de 1116\n",
            "Iteración:    330 de 1116\n",
            "Iteración:    331 de 1116\n",
            "Iteración:    332 de 1116\n",
            "Iteración:    333 de 1116\n",
            "Iteración:    334 de 1116\n",
            "Iteración:    335 de 1116\n",
            "Iteración:    336 de 1116\n",
            "Iteración:    337 de 1116\n",
            "Iteración:    338 de 1116\n",
            "Iteración:    339 de 1116\n",
            "Iteración:    340 de 1116\n",
            "Iteración:    341 de 1116\n",
            "Iteración:    342 de 1116\n",
            "Iteración:    343 de 1116\n",
            "Iteración:    344 de 1116\n",
            "Iteración:    345 de 1116\n",
            "Iteración:    346 de 1116\n",
            "Iteración:    347 de 1116\n",
            "Iteración:    348 de 1116\n",
            "Iteración:    349 de 1116\n",
            "Iteración:    350 de 1116\n",
            "Iteración:    351 de 1116\n",
            "Iteración:    352 de 1116\n",
            "Iteración:    353 de 1116\n",
            "Iteración:    354 de 1116\n",
            "Iteración:    355 de 1116\n",
            "Iteración:    356 de 1116\n",
            "Iteración:    357 de 1116\n",
            "Iteración:    358 de 1116\n",
            "Iteración:    359 de 1116\n",
            "Iteración:    360 de 1116\n",
            "Iteración:    361 de 1116\n",
            "Iteración:    362 de 1116\n",
            "Iteración:    363 de 1116\n",
            "Iteración:    364 de 1116\n",
            "Iteración:    365 de 1116\n",
            "Iteración:    366 de 1116\n",
            "Iteración:    367 de 1116\n",
            "Iteración:    368 de 1116\n",
            "Iteración:    369 de 1116\n",
            "Iteración:    370 de 1116\n",
            "Iteración:    371 de 1116\n",
            "Iteración:    372 de 1116\n",
            "Iteración:    373 de 1116\n",
            "Iteración:    374 de 1116\n",
            "Iteración:    375 de 1116\n",
            "Iteración:    376 de 1116\n",
            "Iteración:    377 de 1116\n",
            "Iteración:    378 de 1116\n",
            "Iteración:    379 de 1116\n",
            "Iteración:    380 de 1116\n",
            "Iteración:    381 de 1116\n",
            "Iteración:    382 de 1116\n",
            "Iteración:    383 de 1116\n",
            "Iteración:    384 de 1116\n",
            "Iteración:    385 de 1116\n",
            "Iteración:    386 de 1116\n",
            "Iteración:    387 de 1116\n",
            "Iteración:    388 de 1116\n",
            "Iteración:    389 de 1116\n",
            "Iteración:    390 de 1116\n",
            "Iteración:    391 de 1116\n",
            "Iteración:    392 de 1116\n",
            "Iteración:    393 de 1116\n",
            "Iteración:    394 de 1116\n",
            "Iteración:    395 de 1116\n",
            "Iteración:    396 de 1116\n",
            "Iteración:    397 de 1116\n",
            "Iteración:    398 de 1116\n",
            "Iteración:    399 de 1116\n",
            "Iteración:    400 de 1116\n",
            "Iteración:    401 de 1116\n",
            "Iteración:    402 de 1116\n",
            "Iteración:    403 de 1116\n",
            "Iteración:    404 de 1116\n",
            "Iteración:    405 de 1116\n",
            "Iteración:    406 de 1116\n",
            "Iteración:    407 de 1116\n",
            "Iteración:    408 de 1116\n",
            "Iteración:    409 de 1116\n",
            "Iteración:    410 de 1116\n",
            "Iteración:    411 de 1116\n",
            "Iteración:    412 de 1116\n",
            "Iteración:    413 de 1116\n",
            "Iteración:    414 de 1116\n",
            "Iteración:    415 de 1116\n",
            "Iteración:    416 de 1116\n",
            "Iteración:    417 de 1116\n",
            "Iteración:    418 de 1116\n",
            "Iteración:    419 de 1116\n",
            "Iteración:    420 de 1116\n",
            "Iteración:    421 de 1116\n",
            "Iteración:    422 de 1116\n",
            "Iteración:    423 de 1116\n",
            "Iteración:    424 de 1116\n",
            "Iteración:    425 de 1116\n",
            "Iteración:    426 de 1116\n",
            "Iteración:    427 de 1116\n",
            "Iteración:    428 de 1116\n",
            "Iteración:    429 de 1116\n",
            "Iteración:    430 de 1116\n",
            "Iteración:    431 de 1116\n",
            "Iteración:    432 de 1116\n",
            "Iteración:    433 de 1116\n",
            "Iteración:    434 de 1116\n",
            "Iteración:    435 de 1116\n",
            "Iteración:    436 de 1116\n",
            "Iteración:    437 de 1116\n",
            "Iteración:    438 de 1116\n",
            "Iteración:    439 de 1116\n",
            "Iteración:    440 de 1116\n",
            "Iteración:    441 de 1116\n",
            "Iteración:    442 de 1116\n",
            "Iteración:    443 de 1116\n",
            "Iteración:    444 de 1116\n",
            "Iteración:    445 de 1116\n",
            "Iteración:    446 de 1116\n",
            "Iteración:    447 de 1116\n",
            "Iteración:    448 de 1116\n",
            "Iteración:    449 de 1116\n",
            "Iteración:    450 de 1116\n",
            "Iteración:    451 de 1116\n",
            "Iteración:    452 de 1116\n",
            "Iteración:    453 de 1116\n",
            "Iteración:    454 de 1116\n",
            "Iteración:    455 de 1116\n",
            "Iteración:    456 de 1116\n",
            "Iteración:    457 de 1116\n",
            "Iteración:    458 de 1116\n",
            "Iteración:    459 de 1116\n",
            "Iteración:    460 de 1116\n",
            "Iteración:    461 de 1116\n",
            "Iteración:    462 de 1116\n",
            "Iteración:    463 de 1116\n",
            "Iteración:    464 de 1116\n",
            "Iteración:    465 de 1116\n",
            "Iteración:    466 de 1116\n",
            "Iteración:    467 de 1116\n",
            "Iteración:    468 de 1116\n",
            "Iteración:    469 de 1116\n",
            "Iteración:    470 de 1116\n",
            "Iteración:    471 de 1116\n",
            "Iteración:    472 de 1116\n",
            "Iteración:    473 de 1116\n",
            "Iteración:    474 de 1116\n",
            "Iteración:    475 de 1116\n",
            "Iteración:    476 de 1116\n",
            "Iteración:    477 de 1116\n",
            "Iteración:    478 de 1116\n",
            "Iteración:    479 de 1116\n",
            "Iteración:    480 de 1116\n",
            "Iteración:    481 de 1116\n",
            "Iteración:    482 de 1116\n",
            "Iteración:    483 de 1116\n",
            "Iteración:    484 de 1116\n",
            "Iteración:    485 de 1116\n",
            "Iteración:    486 de 1116\n",
            "Iteración:    487 de 1116\n",
            "Iteración:    488 de 1116\n",
            "Iteración:    489 de 1116\n",
            "Iteración:    490 de 1116\n",
            "Iteración:    491 de 1116\n",
            "Iteración:    492 de 1116\n",
            "Iteración:    493 de 1116\n",
            "Iteración:    494 de 1116\n",
            "Iteración:    495 de 1116\n",
            "Iteración:    496 de 1116\n",
            "Iteración:    497 de 1116\n",
            "Iteración:    498 de 1116\n",
            "Iteración:    499 de 1116\n",
            "Iteración:    500 de 1116\n",
            "Iteración:    501 de 1116\n",
            "Iteración:    502 de 1116\n",
            "Iteración:    503 de 1116\n",
            "Iteración:    504 de 1116\n",
            "Iteración:    505 de 1116\n",
            "Iteración:    506 de 1116\n",
            "Iteración:    507 de 1116\n",
            "Iteración:    508 de 1116\n",
            "Iteración:    509 de 1116\n",
            "Iteración:    510 de 1116\n",
            "Iteración:    511 de 1116\n",
            "Iteración:    512 de 1116\n",
            "Iteración:    513 de 1116\n",
            "Iteración:    514 de 1116\n",
            "Iteración:    515 de 1116\n",
            "Iteración:    516 de 1116\n",
            "Iteración:    517 de 1116\n",
            "Iteración:    518 de 1116\n",
            "Iteración:    519 de 1116\n",
            "Iteración:    520 de 1116\n",
            "Iteración:    521 de 1116\n",
            "Iteración:    522 de 1116\n",
            "Iteración:    523 de 1116\n",
            "Iteración:    524 de 1116\n",
            "Iteración:    525 de 1116\n",
            "Iteración:    526 de 1116\n",
            "Iteración:    527 de 1116\n",
            "Iteración:    528 de 1116\n",
            "Iteración:    529 de 1116\n",
            "Iteración:    530 de 1116\n",
            "Iteración:    531 de 1116\n",
            "Iteración:    532 de 1116\n",
            "Iteración:    533 de 1116\n",
            "Iteración:    534 de 1116\n",
            "Iteración:    535 de 1116\n",
            "Iteración:    536 de 1116\n",
            "Iteración:    537 de 1116\n",
            "Iteración:    538 de 1116\n",
            "Iteración:    539 de 1116\n",
            "Iteración:    540 de 1116\n",
            "Iteración:    541 de 1116\n",
            "Iteración:    542 de 1116\n",
            "Iteración:    543 de 1116\n",
            "Iteración:    544 de 1116\n",
            "Iteración:    545 de 1116\n",
            "Iteración:    546 de 1116\n",
            "Iteración:    547 de 1116\n",
            "Iteración:    548 de 1116\n",
            "Iteración:    549 de 1116\n",
            "Iteración:    550 de 1116\n",
            "Iteración:    551 de 1116\n",
            "Iteración:    552 de 1116\n",
            "Iteración:    553 de 1116\n",
            "Iteración:    554 de 1116\n",
            "Iteración:    555 de 1116\n",
            "Iteración:    556 de 1116\n",
            "Iteración:    557 de 1116\n",
            "Iteración:    558 de 1116\n",
            "Iteración:    559 de 1116\n",
            "Iteración:    560 de 1116\n",
            "Iteración:    561 de 1116\n",
            "Iteración:    562 de 1116\n",
            "Iteración:    563 de 1116\n",
            "Iteración:    564 de 1116\n",
            "Iteración:    565 de 1116\n",
            "Iteración:    566 de 1116\n",
            "Iteración:    567 de 1116\n",
            "Iteración:    568 de 1116\n",
            "Iteración:    569 de 1116\n",
            "Iteración:    570 de 1116\n",
            "Iteración:    571 de 1116\n",
            "Iteración:    572 de 1116\n",
            "Iteración:    573 de 1116\n",
            "Iteración:    574 de 1116\n",
            "Iteración:    575 de 1116\n",
            "Iteración:    576 de 1116\n",
            "Iteración:    577 de 1116\n",
            "Iteración:    578 de 1116\n",
            "Iteración:    579 de 1116\n",
            "Iteración:    580 de 1116\n",
            "Iteración:    581 de 1116\n",
            "Iteración:    582 de 1116\n",
            "Iteración:    583 de 1116\n",
            "Iteración:    584 de 1116\n",
            "Iteración:    585 de 1116\n",
            "Iteración:    586 de 1116\n",
            "Iteración:    587 de 1116\n",
            "Iteración:    588 de 1116\n",
            "Iteración:    589 de 1116\n",
            "Iteración:    590 de 1116\n",
            "Iteración:    591 de 1116\n",
            "Iteración:    592 de 1116\n",
            "Iteración:    593 de 1116\n",
            "Iteración:    594 de 1116\n",
            "Iteración:    595 de 1116\n",
            "Iteración:    596 de 1116\n",
            "Iteración:    597 de 1116\n",
            "Iteración:    598 de 1116\n",
            "Iteración:    599 de 1116\n",
            "Iteración:    600 de 1116\n",
            "Iteración:    601 de 1116\n",
            "Iteración:    602 de 1116\n",
            "Iteración:    603 de 1116\n",
            "Iteración:    604 de 1116\n",
            "Iteración:    605 de 1116\n",
            "Iteración:    606 de 1116\n",
            "Iteración:    607 de 1116\n",
            "Iteración:    608 de 1116\n",
            "Iteración:    609 de 1116\n",
            "Iteración:    610 de 1116\n",
            "Iteración:    611 de 1116\n",
            "Iteración:    612 de 1116\n",
            "Iteración:    613 de 1116\n",
            "Iteración:    614 de 1116\n",
            "Iteración:    615 de 1116\n",
            "Iteración:    616 de 1116\n",
            "Iteración:    617 de 1116\n",
            "Iteración:    618 de 1116\n",
            "Iteración:    619 de 1116\n",
            "Iteración:    620 de 1116\n",
            "Iteración:    621 de 1116\n",
            "Iteración:    622 de 1116\n",
            "Iteración:    623 de 1116\n",
            "Iteración:    624 de 1116\n",
            "Iteración:    625 de 1116\n",
            "Iteración:    626 de 1116\n",
            "Iteración:    627 de 1116\n",
            "Iteración:    628 de 1116\n",
            "Iteración:    629 de 1116\n",
            "Iteración:    630 de 1116\n",
            "Iteración:    631 de 1116\n",
            "Iteración:    632 de 1116\n",
            "Iteración:    633 de 1116\n",
            "Iteración:    634 de 1116\n",
            "Iteración:    635 de 1116\n",
            "Iteración:    636 de 1116\n",
            "Iteración:    637 de 1116\n",
            "Iteración:    638 de 1116\n",
            "Iteración:    639 de 1116\n",
            "Iteración:    640 de 1116\n",
            "Iteración:    641 de 1116\n",
            "Iteración:    642 de 1116\n",
            "Iteración:    643 de 1116\n",
            "Iteración:    644 de 1116\n",
            "Iteración:    645 de 1116\n",
            "Iteración:    646 de 1116\n",
            "Iteración:    647 de 1116\n",
            "Iteración:    648 de 1116\n",
            "Iteración:    649 de 1116\n",
            "Iteración:    650 de 1116\n",
            "Iteración:    651 de 1116\n",
            "Iteración:    652 de 1116\n",
            "Iteración:    653 de 1116\n",
            "Iteración:    654 de 1116\n",
            "Iteración:    655 de 1116\n",
            "Iteración:    656 de 1116\n",
            "Iteración:    657 de 1116\n",
            "Iteración:    658 de 1116\n",
            "Iteración:    659 de 1116\n",
            "Iteración:    660 de 1116\n",
            "Iteración:    661 de 1116\n",
            "Iteración:    662 de 1116\n",
            "Iteración:    663 de 1116\n",
            "Iteración:    664 de 1116\n",
            "Iteración:    665 de 1116\n",
            "Iteración:    666 de 1116\n",
            "Iteración:    667 de 1116\n",
            "Iteración:    668 de 1116\n",
            "Iteración:    669 de 1116\n",
            "Iteración:    670 de 1116\n",
            "Iteración:    671 de 1116\n",
            "Iteración:    672 de 1116\n",
            "Iteración:    673 de 1116\n",
            "Iteración:    674 de 1116\n",
            "Iteración:    675 de 1116\n",
            "Iteración:    676 de 1116\n",
            "Iteración:    677 de 1116\n",
            "Iteración:    678 de 1116\n",
            "Iteración:    679 de 1116\n",
            "Iteración:    680 de 1116\n",
            "Iteración:    681 de 1116\n",
            "Iteración:    682 de 1116\n",
            "Iteración:    683 de 1116\n",
            "Iteración:    684 de 1116\n",
            "Iteración:    685 de 1116\n",
            "Iteración:    686 de 1116\n",
            "Iteración:    687 de 1116\n",
            "Iteración:    688 de 1116\n",
            "Iteración:    689 de 1116\n",
            "Iteración:    690 de 1116\n",
            "Iteración:    691 de 1116\n",
            "Iteración:    692 de 1116\n",
            "Iteración:    693 de 1116\n",
            "Iteración:    694 de 1116\n",
            "Iteración:    695 de 1116\n",
            "Iteración:    696 de 1116\n",
            "Iteración:    697 de 1116\n",
            "Iteración:    698 de 1116\n",
            "Iteración:    699 de 1116\n",
            "Iteración:    700 de 1116\n",
            "Iteración:    701 de 1116\n",
            "Iteración:    702 de 1116\n",
            "Iteración:    703 de 1116\n",
            "Iteración:    704 de 1116\n",
            "Iteración:    705 de 1116\n",
            "Iteración:    706 de 1116\n",
            "Iteración:    707 de 1116\n",
            "Iteración:    708 de 1116\n",
            "Iteración:    709 de 1116\n",
            "Iteración:    710 de 1116\n",
            "Iteración:    711 de 1116\n",
            "Iteración:    712 de 1116\n",
            "Iteración:    713 de 1116\n",
            "Iteración:    714 de 1116\n",
            "Iteración:    715 de 1116\n",
            "Iteración:    716 de 1116\n",
            "Iteración:    717 de 1116\n",
            "Iteración:    718 de 1116\n",
            "Iteración:    719 de 1116\n",
            "Iteración:    720 de 1116\n",
            "Iteración:    721 de 1116\n",
            "Iteración:    722 de 1116\n",
            "Iteración:    723 de 1116\n",
            "Iteración:    724 de 1116\n",
            "Iteración:    725 de 1116\n",
            "Iteración:    726 de 1116\n",
            "Iteración:    727 de 1116\n",
            "Iteración:    728 de 1116\n",
            "Iteración:    729 de 1116\n",
            "Iteración:    730 de 1116\n",
            "Iteración:    731 de 1116\n",
            "Iteración:    732 de 1116\n",
            "Iteración:    733 de 1116\n",
            "Iteración:    734 de 1116\n",
            "Iteración:    735 de 1116\n",
            "Iteración:    736 de 1116\n",
            "Iteración:    737 de 1116\n",
            "Iteración:    738 de 1116\n",
            "Iteración:    739 de 1116\n",
            "Iteración:    740 de 1116\n",
            "Iteración:    741 de 1116\n",
            "Iteración:    742 de 1116\n",
            "Iteración:    743 de 1116\n",
            "Iteración:    744 de 1116\n",
            "Iteración:    745 de 1116\n",
            "Iteración:    746 de 1116\n",
            "Iteración:    747 de 1116\n",
            "Iteración:    748 de 1116\n",
            "Iteración:    749 de 1116\n",
            "Iteración:    750 de 1116\n",
            "Iteración:    751 de 1116\n",
            "Iteración:    752 de 1116\n",
            "Iteración:    753 de 1116\n",
            "Iteración:    754 de 1116\n",
            "Iteración:    755 de 1116\n",
            "Iteración:    756 de 1116\n",
            "Iteración:    757 de 1116\n",
            "Iteración:    758 de 1116\n",
            "Iteración:    759 de 1116\n",
            "Iteración:    760 de 1116\n",
            "Iteración:    761 de 1116\n",
            "Iteración:    762 de 1116\n",
            "Iteración:    763 de 1116\n",
            "Iteración:    764 de 1116\n",
            "Iteración:    765 de 1116\n",
            "Iteración:    766 de 1116\n",
            "Iteración:    767 de 1116\n",
            "Iteración:    768 de 1116\n",
            "Iteración:    769 de 1116\n",
            "Iteración:    770 de 1116\n",
            "Iteración:    771 de 1116\n",
            "Iteración:    772 de 1116\n",
            "Iteración:    773 de 1116\n",
            "Iteración:    774 de 1116\n",
            "Iteración:    775 de 1116\n",
            "Iteración:    776 de 1116\n",
            "Iteración:    777 de 1116\n",
            "Iteración:    778 de 1116\n",
            "Iteración:    779 de 1116\n",
            "Iteración:    780 de 1116\n",
            "Iteración:    781 de 1116\n",
            "Iteración:    782 de 1116\n",
            "Iteración:    783 de 1116\n",
            "Iteración:    784 de 1116\n",
            "Iteración:    785 de 1116\n",
            "Iteración:    786 de 1116\n",
            "Iteración:    787 de 1116\n",
            "Iteración:    788 de 1116\n",
            "Iteración:    789 de 1116\n",
            "Iteración:    790 de 1116\n",
            "Iteración:    791 de 1116\n",
            "Iteración:    792 de 1116\n",
            "Iteración:    793 de 1116\n",
            "Iteración:    794 de 1116\n",
            "Iteración:    795 de 1116\n",
            "Iteración:    796 de 1116\n",
            "Iteración:    797 de 1116\n",
            "Iteración:    798 de 1116\n",
            "Iteración:    799 de 1116\n",
            "Iteración:    800 de 1116\n",
            "Iteración:    801 de 1116\n",
            "Iteración:    802 de 1116\n",
            "Iteración:    803 de 1116\n",
            "Iteración:    804 de 1116\n",
            "Iteración:    805 de 1116\n",
            "Iteración:    806 de 1116\n",
            "Iteración:    807 de 1116\n",
            "Iteración:    808 de 1116\n",
            "Iteración:    809 de 1116\n",
            "Iteración:    810 de 1116\n",
            "Iteración:    811 de 1116\n",
            "Iteración:    812 de 1116\n",
            "Iteración:    813 de 1116\n",
            "Iteración:    814 de 1116\n",
            "Iteración:    815 de 1116\n",
            "Iteración:    816 de 1116\n",
            "Iteración:    817 de 1116\n",
            "Iteración:    818 de 1116\n",
            "Iteración:    819 de 1116\n",
            "Iteración:    820 de 1116\n",
            "Iteración:    821 de 1116\n",
            "Iteración:    822 de 1116\n",
            "Iteración:    823 de 1116\n",
            "Iteración:    824 de 1116\n",
            "Iteración:    825 de 1116\n",
            "Iteración:    826 de 1116\n",
            "Iteración:    827 de 1116\n",
            "Iteración:    828 de 1116\n",
            "Iteración:    829 de 1116\n",
            "Iteración:    830 de 1116\n",
            "Iteración:    831 de 1116\n",
            "Iteración:    832 de 1116\n",
            "Iteración:    833 de 1116\n",
            "Iteración:    834 de 1116\n",
            "Iteración:    835 de 1116\n",
            "Iteración:    836 de 1116\n",
            "Iteración:    837 de 1116\n",
            "Iteración:    838 de 1116\n",
            "Iteración:    839 de 1116\n",
            "Iteración:    840 de 1116\n",
            "Iteración:    841 de 1116\n",
            "Iteración:    842 de 1116\n",
            "Iteración:    843 de 1116\n",
            "Iteración:    844 de 1116\n",
            "Iteración:    845 de 1116\n",
            "Iteración:    846 de 1116\n",
            "Iteración:    847 de 1116\n",
            "Iteración:    848 de 1116\n",
            "Iteración:    849 de 1116\n",
            "Iteración:    850 de 1116\n",
            "Iteración:    851 de 1116\n",
            "Iteración:    852 de 1116\n",
            "Iteración:    853 de 1116\n",
            "Iteración:    854 de 1116\n",
            "Iteración:    855 de 1116\n",
            "Iteración:    856 de 1116\n",
            "Iteración:    857 de 1116\n",
            "Iteración:    858 de 1116\n",
            "Iteración:    859 de 1116\n",
            "Iteración:    860 de 1116\n",
            "Iteración:    861 de 1116\n",
            "Iteración:    862 de 1116\n",
            "Iteración:    863 de 1116\n",
            "Iteración:    864 de 1116\n",
            "Iteración:    865 de 1116\n",
            "Iteración:    866 de 1116\n",
            "Iteración:    867 de 1116\n",
            "Iteración:    868 de 1116\n",
            "Iteración:    869 de 1116\n",
            "Iteración:    870 de 1116\n",
            "Iteración:    871 de 1116\n",
            "Iteración:    872 de 1116\n",
            "Iteración:    873 de 1116\n",
            "Iteración:    874 de 1116\n",
            "Iteración:    875 de 1116\n",
            "Iteración:    876 de 1116\n",
            "Iteración:    877 de 1116\n",
            "Iteración:    878 de 1116\n",
            "Iteración:    879 de 1116\n",
            "Iteración:    880 de 1116\n",
            "Iteración:    881 de 1116\n",
            "Iteración:    882 de 1116\n",
            "Iteración:    883 de 1116\n",
            "Iteración:    884 de 1116\n",
            "Iteración:    885 de 1116\n",
            "Iteración:    886 de 1116\n",
            "Iteración:    887 de 1116\n",
            "Iteración:    888 de 1116\n",
            "Iteración:    889 de 1116\n",
            "Iteración:    890 de 1116\n",
            "Iteración:    891 de 1116\n",
            "Iteración:    892 de 1116\n",
            "Iteración:    893 de 1116\n",
            "Iteración:    894 de 1116\n",
            "Iteración:    895 de 1116\n",
            "Iteración:    896 de 1116\n",
            "Iteración:    897 de 1116\n",
            "Iteración:    898 de 1116\n",
            "Iteración:    899 de 1116\n",
            "Iteración:    900 de 1116\n",
            "Iteración:    901 de 1116\n",
            "Iteración:    902 de 1116\n",
            "Iteración:    903 de 1116\n",
            "Iteración:    904 de 1116\n",
            "Iteración:    905 de 1116\n",
            "Iteración:    906 de 1116\n",
            "Iteración:    907 de 1116\n",
            "Iteración:    908 de 1116\n",
            "Iteración:    909 de 1116\n",
            "Iteración:    910 de 1116\n",
            "Iteración:    911 de 1116\n",
            "Iteración:    912 de 1116\n",
            "Iteración:    913 de 1116\n",
            "Iteración:    914 de 1116\n",
            "Iteración:    915 de 1116\n",
            "Iteración:    916 de 1116\n",
            "Iteración:    917 de 1116\n",
            "Iteración:    918 de 1116\n",
            "Iteración:    919 de 1116\n",
            "Iteración:    920 de 1116\n",
            "Iteración:    921 de 1116\n",
            "Iteración:    922 de 1116\n",
            "Iteración:    923 de 1116\n",
            "Iteración:    924 de 1116\n",
            "Iteración:    925 de 1116\n",
            "Iteración:    926 de 1116\n",
            "Iteración:    927 de 1116\n",
            "Iteración:    928 de 1116\n",
            "Iteración:    929 de 1116\n",
            "Iteración:    930 de 1116\n",
            "Iteración:    931 de 1116\n",
            "Iteración:    932 de 1116\n",
            "Iteración:    933 de 1116\n",
            "Iteración:    934 de 1116\n",
            "Iteración:    935 de 1116\n",
            "Iteración:    936 de 1116\n",
            "Iteración:    937 de 1116\n",
            "Iteración:    938 de 1116\n",
            "Iteración:    939 de 1116\n",
            "Iteración:    940 de 1116\n",
            "Iteración:    941 de 1116\n",
            "Iteración:    942 de 1116\n",
            "Iteración:    943 de 1116\n",
            "Iteración:    944 de 1116\n",
            "Iteración:    945 de 1116\n",
            "Iteración:    946 de 1116\n",
            "Iteración:    947 de 1116\n",
            "Iteración:    948 de 1116\n",
            "Iteración:    949 de 1116\n",
            "Iteración:    950 de 1116\n",
            "Iteración:    951 de 1116\n",
            "Iteración:    952 de 1116\n",
            "Iteración:    953 de 1116\n",
            "Iteración:    954 de 1116\n",
            "Iteración:    955 de 1116\n",
            "Iteración:    956 de 1116\n",
            "Iteración:    957 de 1116\n",
            "Iteración:    958 de 1116\n",
            "Iteración:    959 de 1116\n",
            "Iteración:    960 de 1116\n",
            "Iteración:    961 de 1116\n",
            "Iteración:    962 de 1116\n",
            "Iteración:    963 de 1116\n",
            "Iteración:    964 de 1116\n",
            "Iteración:    965 de 1116\n",
            "Iteración:    966 de 1116\n",
            "Iteración:    967 de 1116\n",
            "Iteración:    968 de 1116\n",
            "Iteración:    969 de 1116\n",
            "Iteración:    970 de 1116\n",
            "Iteración:    971 de 1116\n",
            "Iteración:    972 de 1116\n",
            "Iteración:    973 de 1116\n",
            "Iteración:    974 de 1116\n",
            "Iteración:    975 de 1116\n",
            "Iteración:    976 de 1116\n",
            "Iteración:    977 de 1116\n",
            "Iteración:    978 de 1116\n",
            "Iteración:    979 de 1116\n",
            "Iteración:    980 de 1116\n",
            "Iteración:    981 de 1116\n",
            "Iteración:    982 de 1116\n",
            "Iteración:    983 de 1116\n",
            "Iteración:    984 de 1116\n",
            "Iteración:    985 de 1116\n",
            "Iteración:    986 de 1116\n",
            "Iteración:    987 de 1116\n",
            "Iteración:    988 de 1116\n",
            "Iteración:    989 de 1116\n",
            "Iteración:    990 de 1116\n",
            "Iteración:    991 de 1116\n",
            "Iteración:    992 de 1116\n",
            "Iteración:    993 de 1116\n",
            "Iteración:    994 de 1116\n",
            "Iteración:    995 de 1116\n",
            "Iteración:    996 de 1116\n",
            "Iteración:    997 de 1116\n",
            "Iteración:    998 de 1116\n",
            "Iteración:    999 de 1116\n",
            "Iteración:   1000 de 1116\n",
            "Iteración:   1001 de 1116\n",
            "Iteración:   1002 de 1116\n",
            "Iteración:   1003 de 1116\n",
            "Iteración:   1004 de 1116\n",
            "Iteración:   1005 de 1116\n",
            "Iteración:   1006 de 1116\n",
            "Iteración:   1007 de 1116\n",
            "Iteración:   1008 de 1116\n",
            "Iteración:   1009 de 1116\n",
            "Iteración:   1010 de 1116\n",
            "Iteración:   1011 de 1116\n",
            "Iteración:   1012 de 1116\n",
            "Iteración:   1013 de 1116\n",
            "Iteración:   1014 de 1116\n",
            "Iteración:   1015 de 1116\n",
            "Iteración:   1016 de 1116\n",
            "Iteración:   1017 de 1116\n",
            "Iteración:   1018 de 1116\n",
            "Iteración:   1019 de 1116\n",
            "Iteración:   1020 de 1116\n",
            "Iteración:   1021 de 1116\n",
            "Iteración:   1022 de 1116\n",
            "Iteración:   1023 de 1116\n",
            "Iteración:   1024 de 1116\n",
            "Iteración:   1025 de 1116\n",
            "Iteración:   1026 de 1116\n",
            "Iteración:   1027 de 1116\n",
            "Iteración:   1028 de 1116\n",
            "Iteración:   1029 de 1116\n",
            "Iteración:   1030 de 1116\n",
            "Iteración:   1031 de 1116\n",
            "Iteración:   1032 de 1116\n",
            "Iteración:   1033 de 1116\n",
            "Iteración:   1034 de 1116\n",
            "Iteración:   1035 de 1116\n",
            "Iteración:   1036 de 1116\n",
            "Iteración:   1037 de 1116\n",
            "Iteración:   1038 de 1116\n",
            "Iteración:   1039 de 1116\n",
            "Iteración:   1040 de 1116\n",
            "Iteración:   1041 de 1116\n",
            "Iteración:   1042 de 1116\n",
            "Iteración:   1043 de 1116\n",
            "Iteración:   1044 de 1116\n",
            "Iteración:   1045 de 1116\n",
            "Iteración:   1046 de 1116\n",
            "Iteración:   1047 de 1116\n",
            "Iteración:   1048 de 1116\n",
            "Iteración:   1049 de 1116\n",
            "Iteración:   1050 de 1116\n",
            "Iteración:   1051 de 1116\n",
            "Iteración:   1052 de 1116\n",
            "Iteración:   1053 de 1116\n",
            "Iteración:   1054 de 1116\n",
            "Iteración:   1055 de 1116\n",
            "Iteración:   1056 de 1116\n",
            "Iteración:   1057 de 1116\n",
            "Iteración:   1058 de 1116\n",
            "Iteración:   1059 de 1116\n",
            "Iteración:   1060 de 1116\n",
            "Iteración:   1061 de 1116\n",
            "Iteración:   1062 de 1116\n",
            "Iteración:   1063 de 1116\n",
            "Iteración:   1064 de 1116\n",
            "Iteración:   1065 de 1116\n",
            "Iteración:   1066 de 1116\n",
            "Iteración:   1067 de 1116\n",
            "Iteración:   1068 de 1116\n",
            "Iteración:   1069 de 1116\n",
            "Iteración:   1070 de 1116\n",
            "Iteración:   1071 de 1116\n",
            "Iteración:   1072 de 1116\n",
            "Iteración:   1073 de 1116\n",
            "Iteración:   1074 de 1116\n",
            "Iteración:   1075 de 1116\n",
            "Iteración:   1076 de 1116\n",
            "Iteración:   1077 de 1116\n",
            "Iteración:   1078 de 1116\n",
            "Iteración:   1079 de 1116\n",
            "Iteración:   1080 de 1116\n",
            "Iteración:   1081 de 1116\n",
            "Iteración:   1082 de 1116\n",
            "Iteración:   1083 de 1116\n",
            "Iteración:   1084 de 1116\n",
            "Iteración:   1085 de 1116\n",
            "Iteración:   1086 de 1116\n",
            "Iteración:   1087 de 1116\n",
            "Iteración:   1088 de 1116\n",
            "Iteración:   1089 de 1116\n",
            "Iteración:   1090 de 1116\n",
            "Iteración:   1091 de 1116\n",
            "Iteración:   1092 de 1116\n",
            "Iteración:   1093 de 1116\n",
            "Iteración:   1094 de 1116\n",
            "Iteración:   1095 de 1116\n",
            "Iteración:   1096 de 1116\n",
            "Iteración:   1097 de 1116\n",
            "Iteración:   1098 de 1116\n",
            "Iteración:   1099 de 1116\n",
            "Iteración:   1100 de 1116\n",
            "Iteración:   1101 de 1116\n",
            "Iteración:   1102 de 1116\n",
            "Iteración:   1103 de 1116\n",
            "Iteración:   1104 de 1116\n",
            "Iteración:   1105 de 1116\n",
            "Iteración:   1106 de 1116\n",
            "Iteración:   1107 de 1116\n",
            "Iteración:   1108 de 1116\n",
            "Iteración:   1109 de 1116\n",
            "Iteración:   1110 de 1116\n",
            "Iteración:   1111 de 1116\n",
            "Iteración:   1112 de 1116\n",
            "Iteración:   1113 de 1116\n",
            "Iteración:   1114 de 1116\n",
            "Iteración:   1115 de 1116\n",
            "Accuracy Score = 0.7224588143001233\n",
            "F1 Score (Micro) = 0.7224588143001233\n",
            "F1 Score (Macro) = 0.4194345944890855\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationRoberta(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "id": "Pp35VP5-XNG1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.6 Aproximación 3: Utilizando Siamese"
      ],
      "metadata": {
        "id": "pXnG_22GnC9s"
      },
      "id": "pXnG_22GnC9s"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta aproximación se plantean arquitecturas siamesas. Se obtendrán de manera independiente los *embeddings* de cada uno de los textos y estos *embeddings* serán lo que se usen para obtener las salidas bien sea mediante distancia coseno o alimentando directamente la red con la concatenación de los *embeddings*. Para este caso, se hará uso tanto de `Review1` como de `Review2` y `Sentimiento`."
      ],
      "metadata": {
        "id": "o0cX15NvgKFN"
      },
      "id": "o0cX15NvgKFN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.6.1 Carga de datos"
      ],
      "metadata": {
        "id": "XUvcylIZqwMj"
      },
      "id": "XUvcylIZqwMj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este punto, se cargan los datos preprocesados para esta tarea, es decir, los obtenidos del apartado 1.3."
      ],
      "metadata": {
        "id": "pmyHTug0IzsK"
      },
      "id": "pmyHTug0IzsK"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f46b06-3aa6-445d-e23b-6a96e18430f1",
        "id": "cs64gi0QqwMp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "id": "cs64gi0QqwMp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "29b49c50-5293-4a34-ab0f-cea7263b638b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IRGLdq6qwMp"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   Review1                      Review2  \\\n",
              "0                              Nice brunch                   Good place   \n",
              "1                Worlds best hot cocolate!                 Great place!   \n",
              "2                   Great food and service                Rated on 7,0!   \n",
              "3                   Delicious and friendly  Great little French Bistro!   \n",
              "4                              Late dinner             Very nice dinner   \n",
              "...                                    ...                          ...   \n",
              "65314       Very nice food, great location               Great calamari   \n",
              "65315  Great Bavarian food in a cozy place       Traditional restaurant   \n",
              "65316           Italy traditions in Vienna         Very nice restaurant   \n",
              "65317                 3 visits over 4 days      Great food & atmosphere   \n",
              "65318                Friendly little place         Depressing brasserie   \n",
              "\n",
              "       Sentimiento  \n",
              "0                1  \n",
              "1                1  \n",
              "2                1  \n",
              "3                0  \n",
              "4                0  \n",
              "...            ...  \n",
              "65314            1  \n",
              "65315            1  \n",
              "65316            1  \n",
              "65317            1  \n",
              "65318            1  \n",
              "\n",
              "[65319 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f9e27cf-dd3c-4264-95a3-f7cb59712656\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review1</th>\n",
              "      <th>Review2</th>\n",
              "      <th>Sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nice brunch</td>\n",
              "      <td>Good place</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Worlds best hot cocolate!</td>\n",
              "      <td>Great place!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great food and service</td>\n",
              "      <td>Rated on 7,0!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Delicious and friendly</td>\n",
              "      <td>Great little French Bistro!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Late dinner</td>\n",
              "      <td>Very nice dinner</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65314</th>\n",
              "      <td>Very nice food, great location</td>\n",
              "      <td>Great calamari</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65315</th>\n",
              "      <td>Great Bavarian food in a cozy place</td>\n",
              "      <td>Traditional restaurant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65316</th>\n",
              "      <td>Italy traditions in Vienna</td>\n",
              "      <td>Very nice restaurant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65317</th>\n",
              "      <td>3 visits over 4 days</td>\n",
              "      <td>Great food &amp; atmosphere</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65318</th>\n",
              "      <td>Friendly little place</td>\n",
              "      <td>Depressing brasserie</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65319 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f9e27cf-dd3c-4264-95a3-f7cb59712656')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7f9e27cf-dd3c-4264-95a3-f7cb59712656 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7f9e27cf-dd3c-4264-95a3-f7cb59712656');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-663b9117-798a-4efd-9609-81ce7a9423ac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-663b9117-798a-4efd-9609-81ce7a9423ac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-663b9117-798a-4efd-9609-81ce7a9423ac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "datos = pd.read_feather(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/valoraciones_Siamese_train.feather\")\n",
        "datos"
      ],
      "id": "0IRGLdq6qwMp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CPoi1eDNyOP"
      },
      "source": [
        "###2.6.2 Definición tokenizadores y modelos"
      ],
      "id": "4CPoi1eDNyOP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEenuhCXNyOY"
      },
      "outputs": [],
      "source": [
        "tokenizerB = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "modelB = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "configB = AutoConfig.from_pretrained(\"bert-base-uncased\")"
      ],
      "id": "qEenuhCXNyOY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.6.3 Función de generación de conjuntos de train y test: DataLoaders"
      ],
      "metadata": {
        "id": "n3Lo8Zl_P0U5"
      },
      "id": "n3Lo8Zl_P0U5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPNTqUtxP0VE"
      },
      "outputs": [],
      "source": [
        "def generate_loaders(dataframe, tokenizer, dataset, collator):\n",
        "  train_dataset = dataframe.sample(frac=TRAIN_SIZE, random_state=0)\n",
        "  test_dataset = dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
        "  train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "  print(f\"FULL Dataset:{dataframe.shape}\")\n",
        "  print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
        "  print(f\"TEST Dataset: {test_dataset.shape}\")\n",
        "\n",
        "  training_set = dataset(train_dataset, MAX_LEN)\n",
        "  testing_set = dataset(test_dataset, MAX_LEN)\n",
        "  dc = collator(tokenizer, MAX_LEN)\n",
        "\n",
        "\n",
        "  train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                  'shuffle': True,\n",
        "                  'num_workers': 0,\n",
        "                  'collate_fn': dc\n",
        "                  }\n",
        "\n",
        "  test_params = { 'batch_size': VALID_BATCH_SIZE,\n",
        "                  'shuffle': True,\n",
        "                  'num_workers': 0,\n",
        "                  'collate_fn': dc\n",
        "                }\n",
        "\n",
        "  training_loader = DataLoader(training_set, **train_params)\n",
        "  testing_loader = DataLoader(testing_set, **test_params)\n",
        "  return training_loader, testing_loader"
      ],
      "id": "gPNTqUtxP0VE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdV1_YRxL7AI"
      },
      "source": [
        "###2.6.4 Definición restaurantsSiameseDataset y DataCollatorSiamese"
      ],
      "id": "EdV1_YRxL7AI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntcKpFj3MADw"
      },
      "outputs": [],
      "source": [
        "class restaurantsSiameseDataset(Dataset):\n",
        "  def __init__(self, dataframe, max_len):\n",
        "    self.data = dataframe\n",
        "    self.texto1 = dataframe.Review1\n",
        "    self.texto2 = dataframe.Review2\n",
        "    self.targets = self.data.Sentimiento\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texto1)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    comment_text_1 = self.texto1[index]\n",
        "    comment_text_2 = self.texto2[index]\n",
        "    target = self.targets[index]\n",
        "\n",
        "    return {\n",
        "        \"texto1\": comment_text_1,\n",
        "        \"texto2\": comment_text_2,\n",
        "        \"target\": target\n",
        "    }"
      ],
      "id": "ntcKpFj3MADw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxPQ8lGYM1Yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5bffdb-160d-4e62-f528-75f01c0177d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'texto1': 'Nice brunch', 'texto2': 'Good place', 'target': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "datasetSiamese = restaurantsSiameseDataset(datos, MAX_LEN)\n",
        "datasetSiamese.__getitem__(0)"
      ],
      "id": "FxPQ8lGYM1Yc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW0xdGHyP2Cw"
      },
      "outputs": [],
      "source": [
        "class DataCollatorSiamese:\n",
        "    def __init__(self, tokenizer, max_len=512):\n",
        "      self.tokenizer = tokenizer\n",
        "      self.max_len = max_len\n",
        "\n",
        "    def __call__(self, input_batch):\n",
        "      data_frame = pd.DataFrame(input_batch)\n",
        "      batch_dict = {column: data_frame[column].tolist() for column in data_frame}\n",
        "\n",
        "      encoder_input1 = self.tokenizer(\n",
        "          batch_dict[\"texto1\"],\n",
        "          None,\n",
        "          add_special_tokens=True,\n",
        "          truncation=True,\n",
        "          max_length=self.max_len,\n",
        "          pad_to_max_length=True,\n",
        "          return_tensors = \"pt\",\n",
        "          return_token_type_ids=True\n",
        "          )\n",
        "      encoder_input2 = self.tokenizer(\n",
        "          batch_dict[\"texto2\"],\n",
        "          None,\n",
        "          add_special_tokens=True,\n",
        "          truncation=True,\n",
        "          max_length=self.max_len,\n",
        "          pad_to_max_length=True,\n",
        "          return_tensors = \"pt\",\n",
        "          return_token_type_ids=True\n",
        "          )\n",
        "\n",
        "      return {\n",
        "      'ids1': encoder_input1[\"input_ids\"],\n",
        "      'mask1': encoder_input1[\"attention_mask\"],\n",
        "      \"token_type_ids1\": encoder_input1[\"token_type_ids\"],\n",
        "      'ids2': encoder_input2[\"input_ids\"],\n",
        "      'mask2': encoder_input2[\"attention_mask\"],\n",
        "      \"token_type_ids2\": encoder_input2[\"token_type_ids\"],\n",
        "      \"target\": torch.Tensor(batch_dict[\"target\"]),\n",
        "    }"
      ],
      "id": "NW0xdGHyP2Cw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltcPkvnsCKDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ada17e-c795-4478-cd53-374e3b8b358a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset:(65319, 3)\n",
            "TRAIN Dataset: (32660, 3)\n",
            "TEST Dataset: (32659, 3)\n"
          ]
        }
      ],
      "source": [
        "training_loader, testing_loader = generate_loaders(datos, tokenizerB,\n",
        "                                                   restaurantsSiameseDataset,\n",
        "                                                   DataCollatorSiamese\n",
        "                                                   )"
      ],
      "id": "ltcPkvnsCKDj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.6.5 CosineSimilarity Approach"
      ],
      "metadata": {
        "id": "h1jRUvqNEeRL"
      },
      "id": "h1jRUvqNEeRL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta aproximación, se emplea la distancia coseno como característica de similaridad para que el modelo aprenda. Asimismo, mencionar que se utiliza BERT como modelo preentrenado."
      ],
      "metadata": {
        "id": "qYjhowOXiPnV"
      },
      "id": "qYjhowOXiPnV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk73KhLtVfPP"
      },
      "source": [
        "###### Definición del modelo"
      ],
      "id": "wk73KhLtVfPP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6__JOGE8VZEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348e1747-c182-4874-91cc-1b3fa2eb6d78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClassSiamese(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (l3): Dropout(p=0.2, inplace=False)\n",
              "  (l4): CosineSimilarity()\n",
              "  (l5): Linear(in_features=1, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "class BERTClassSiamese(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BERTClassSiamese, self).__init__()\n",
        "    self.dropout = 0.2\n",
        "    self.hidden_embd = 768\n",
        "    self.output_layer = 1\n",
        "\n",
        "    # Layers\n",
        "    self.l1 = BertModel.from_pretrained('bert-base-uncased')\n",
        "    self.l2 = torch.nn.Linear(self.hidden_embd, self.hidden_embd)\n",
        "    self.l3 = torch.nn.Dropout(self.dropout)\n",
        "    self.l4 = torch.nn.CosineSimilarity(dim=1)\n",
        "    self.l5 = torch.nn.Linear(1, self.output_layer)\n",
        "\n",
        "  def forward(self, ids_1, mask_1, token_type_ids_1, ids_2, mask_2, token_type_ids_2):\n",
        "    _, last_hidden_state_b = self.l1(ids_2, attention_mask=mask_2, token_type_ids=token_type_ids_2, return_dict=False)\n",
        "    _, last_hidden_state_a = self.l1(ids_1, attention_mask=mask_1, token_type_ids=token_type_ids_1, return_dict=False)\n",
        "\n",
        "    x_a, x_b = self.l2(last_hidden_state_a), self.l2(last_hidden_state_b)\n",
        "    x_a, x_b = F.gelu(self.l3(x_a)), F.gelu(self.l3(x_b))\n",
        "    sem_sim = self.l4(x_a, x_b).unsqueeze(-1) # Mejor hacer un concat\n",
        "    weighted_sem_sim = self.l5(sem_sim)\n",
        "    return weighted_sem_sim\n",
        "\n",
        "model = BERTClassSiamese()\n",
        "model.to(device)"
      ],
      "id": "6__JOGE8VZEg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0xJ8vuLXRem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46704c9e-7696-4a2a-b285-41b2ce7139d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 0.01\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE,\n",
        "                             weight_decay=0.01)\n",
        "optimizer"
      ],
      "id": "Z0xJ8vuLXRem"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu2RPx0GXJ7u"
      },
      "source": [
        "###### Entrenamiento del modelo"
      ],
      "id": "wu2RPx0GXJ7u"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-3\n",
        "- weight_decay=0.01\n",
        "- Linear + Dropout + CosineSimilarity + Linear"
      ],
      "metadata": {
        "id": "3hjilKynJZdi"
      },
      "id": "3hjilKynJZdi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCSogNnEXTct"
      },
      "outputs": [],
      "source": [
        "def trainBERTSiamese(epoch):\n",
        "  model.train()\n",
        "  loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "  num_iteraciones = len(training_loader)\n",
        "  sum_loss = 0\n",
        "\n",
        "  for iteracion,data in enumerate(training_loader, 0):\n",
        "    ids1 = data['ids1'].to(device)\n",
        "    ids2 = data['ids2'].to(device)\n",
        "    mask1 = data['mask1'].to(device)\n",
        "    mask2 = data['mask2'].to(device)\n",
        "    token_type_ids1 = data[\"token_type_ids1\"].to(device)\n",
        "    token_type_ids2 = data[\"token_type_ids2\"].to(device)\n",
        "    targets = data['target'].to(device)\n",
        "\n",
        "    output = model(ids1, mask1, token_type_ids1, ids2, mask2, token_type_ids2)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    perdida = loss_fn(output.squeeze(), targets)\n",
        "    with torch.no_grad():\n",
        "      sum_loss+=perdida\n",
        "      if iteracion % PASOS_POR_INTERVALO == 0:\n",
        "        print(f'Epoch: {epoch}, iteración; {iteracion:6} de {num_iteraciones}, Loss: {sum_loss.cpu().numpy()/PASOS_POR_INTERVALO}')\n",
        "        sum_loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    perdida.backward()\n",
        "    optimizer.step()"
      ],
      "id": "DCSogNnEXTct"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3D90MptXVsN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "096fe4ad-60db-45d8-f005-92390dc4894e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración;      0 de 2450, Loss: 0.08972876071929932\n",
            "Epoch: 0, iteración;     10 de 2450, Loss: 0.8161079406738281\n",
            "Epoch: 0, iteración;     20 de 2450, Loss: 0.8100442886352539\n",
            "Epoch: 0, iteración;     30 de 2450, Loss: 0.8250888824462891\n",
            "Epoch: 0, iteración;     40 de 2450, Loss: 0.7858126640319825\n",
            "Epoch: 0, iteración;     50 de 2450, Loss: 0.7962770938873291\n",
            "Epoch: 0, iteración;     60 de 2450, Loss: 0.8124420166015625\n",
            "Epoch: 0, iteración;     70 de 2450, Loss: 0.7808439254760742\n",
            "Epoch: 0, iteración;     80 de 2450, Loss: 0.771768045425415\n",
            "Epoch: 0, iteración;     90 de 2450, Loss: 0.7912948131561279\n",
            "Epoch: 0, iteración;    100 de 2450, Loss: 0.7919481277465821\n",
            "Epoch: 0, iteración;    110 de 2450, Loss: 0.7901940822601319\n",
            "Epoch: 0, iteración;    120 de 2450, Loss: 0.7357278823852539\n",
            "Epoch: 0, iteración;    130 de 2450, Loss: 0.7539856910705567\n",
            "Epoch: 0, iteración;    140 de 2450, Loss: 0.7280426502227784\n",
            "Epoch: 0, iteración;    150 de 2450, Loss: 0.7667979240417481\n",
            "Epoch: 0, iteración;    160 de 2450, Loss: 0.7237939834594727\n",
            "Epoch: 0, iteración;    170 de 2450, Loss: 0.7604118824005127\n",
            "Epoch: 0, iteración;    180 de 2450, Loss: 0.719766902923584\n",
            "Epoch: 0, iteración;    190 de 2450, Loss: 0.7339762687683106\n",
            "Epoch: 0, iteración;    200 de 2450, Loss: 0.6962858676910401\n",
            "Epoch: 0, iteración;    210 de 2450, Loss: 0.7422163963317872\n",
            "Epoch: 0, iteración;    220 de 2450, Loss: 0.7341378211975098\n",
            "Epoch: 0, iteración;    230 de 2450, Loss: 0.7349453449249268\n",
            "Epoch: 0, iteración;    240 de 2450, Loss: 0.7112913608551026\n",
            "Epoch: 0, iteración;    250 de 2450, Loss: 0.7234033584594727\n",
            "Epoch: 0, iteración;    260 de 2450, Loss: 0.7080213546752929\n",
            "Epoch: 0, iteración;    270 de 2450, Loss: 0.7275027275085449\n",
            "Epoch: 0, iteración;    280 de 2450, Loss: 0.7011104106903077\n",
            "Epoch: 0, iteración;    290 de 2450, Loss: 0.7048093795776367\n",
            "Epoch: 0, iteración;    300 de 2450, Loss: 0.6923527717590332\n",
            "Epoch: 0, iteración;    310 de 2450, Loss: 0.659390926361084\n",
            "Epoch: 0, iteración;    320 de 2450, Loss: 0.7007392883300781\n",
            "Epoch: 0, iteración;    330 de 2450, Loss: 0.6715277671813965\n",
            "Epoch: 0, iteración;    340 de 2450, Loss: 0.6975919723510742\n",
            "Epoch: 0, iteración;    350 de 2450, Loss: 0.6747808933258057\n",
            "Epoch: 0, iteración;    360 de 2450, Loss: 0.6943554878234863\n",
            "Epoch: 0, iteración;    370 de 2450, Loss: 0.6791013717651367\n",
            "Epoch: 0, iteración;    380 de 2450, Loss: 0.6868642807006836\n",
            "Epoch: 0, iteración;    390 de 2450, Loss: 0.6699550151824951\n",
            "Epoch: 0, iteración;    400 de 2450, Loss: 0.6688659191131592\n",
            "Epoch: 0, iteración;    410 de 2450, Loss: 0.6542490959167481\n",
            "Epoch: 0, iteración;    420 de 2450, Loss: 0.680221700668335\n",
            "Epoch: 0, iteración;    430 de 2450, Loss: 0.6741667270660401\n",
            "Epoch: 0, iteración;    440 de 2450, Loss: 0.6679208278656006\n",
            "Epoch: 0, iteración;    450 de 2450, Loss: 0.6681798934936524\n",
            "Epoch: 0, iteración;    460 de 2450, Loss: 0.6533444881439209\n",
            "Epoch: 0, iteración;    470 de 2450, Loss: 0.6520264148712158\n",
            "Epoch: 0, iteración;    480 de 2450, Loss: 0.6634471416473389\n",
            "Epoch: 0, iteración;    490 de 2450, Loss: 0.6549649238586426\n",
            "Epoch: 0, iteración;    500 de 2450, Loss: 0.6537651062011719\n",
            "Epoch: 0, iteración;    510 de 2450, Loss: 0.6460738182067871\n",
            "Epoch: 0, iteración;    520 de 2450, Loss: 0.6522860050201416\n",
            "Epoch: 0, iteración;    530 de 2450, Loss: 0.672040319442749\n",
            "Epoch: 0, iteración;    540 de 2450, Loss: 0.6273416519165039\n",
            "Epoch: 0, iteración;    550 de 2450, Loss: 0.6582802295684814\n",
            "Epoch: 0, iteración;    560 de 2450, Loss: 0.6349959373474121\n",
            "Epoch: 0, iteración;    570 de 2450, Loss: 0.6419826507568359\n",
            "Epoch: 0, iteración;    580 de 2450, Loss: 0.6539496421813965\n",
            "Epoch: 0, iteración;    590 de 2450, Loss: 0.6300070285797119\n",
            "Epoch: 0, iteración;    600 de 2450, Loss: 0.622032642364502\n",
            "Epoch: 0, iteración;    610 de 2450, Loss: 0.6064117431640625\n",
            "Epoch: 0, iteración;    620 de 2450, Loss: 0.637959623336792\n",
            "Epoch: 0, iteración;    630 de 2450, Loss: 0.6090847969055175\n",
            "Epoch: 0, iteración;    640 de 2450, Loss: 0.6248532295227051\n",
            "Epoch: 0, iteración;    650 de 2450, Loss: 0.6289831638336182\n",
            "Epoch: 0, iteración;    660 de 2450, Loss: 0.6352232933044434\n",
            "Epoch: 0, iteración;    670 de 2450, Loss: 0.6030244827270508\n",
            "Epoch: 0, iteración;    680 de 2450, Loss: 0.6361143112182617\n",
            "Epoch: 0, iteración;    690 de 2450, Loss: 0.6258674144744873\n",
            "Epoch: 0, iteración;    700 de 2450, Loss: 0.6141105651855469\n",
            "Epoch: 0, iteración;    710 de 2450, Loss: 0.6480540275573731\n",
            "Epoch: 0, iteración;    720 de 2450, Loss: 0.5960405826568603\n",
            "Epoch: 0, iteración;    730 de 2450, Loss: 0.6208188533782959\n",
            "Epoch: 0, iteración;    740 de 2450, Loss: 0.5870105743408203\n",
            "Epoch: 0, iteración;    750 de 2450, Loss: 0.6406206607818603\n",
            "Epoch: 0, iteración;    760 de 2450, Loss: 0.6399870395660401\n",
            "Epoch: 0, iteración;    770 de 2450, Loss: 0.6275223731994629\n",
            "Epoch: 0, iteración;    780 de 2450, Loss: 0.6554554462432861\n",
            "Epoch: 0, iteración;    790 de 2450, Loss: 0.641201400756836\n",
            "Epoch: 0, iteración;    800 de 2450, Loss: 0.62685546875\n",
            "Epoch: 0, iteración;    810 de 2450, Loss: 0.6476408004760742\n",
            "Epoch: 0, iteración;    820 de 2450, Loss: 0.6329171180725097\n",
            "Epoch: 0, iteración;    830 de 2450, Loss: 0.6181100845336914\n",
            "Epoch: 0, iteración;    840 de 2450, Loss: 0.6138158798217773\n",
            "Epoch: 0, iteración;    850 de 2450, Loss: 0.6028688430786133\n",
            "Epoch: 0, iteración;    860 de 2450, Loss: 0.6345068931579589\n",
            "Epoch: 0, iteración;    870 de 2450, Loss: 0.6509254932403564\n",
            "Epoch: 0, iteración;    880 de 2450, Loss: 0.600845193862915\n",
            "Epoch: 0, iteración;    890 de 2450, Loss: 0.6198354721069336\n",
            "Epoch: 0, iteración;    900 de 2450, Loss: 0.6011767387390137\n",
            "Epoch: 0, iteración;    910 de 2450, Loss: 0.6491811752319336\n",
            "Epoch: 0, iteración;    920 de 2450, Loss: 0.6384679794311523\n",
            "Epoch: 0, iteración;    930 de 2450, Loss: 0.5780638694763184\n",
            "Epoch: 0, iteración;    940 de 2450, Loss: 0.6328107357025147\n",
            "Epoch: 0, iteración;    950 de 2450, Loss: 0.6008790969848633\n",
            "Epoch: 0, iteración;    960 de 2450, Loss: 0.6414885997772217\n",
            "Epoch: 0, iteración;    970 de 2450, Loss: 0.5860089778900146\n",
            "Epoch: 0, iteración;    980 de 2450, Loss: 0.5842253684997558\n",
            "Epoch: 0, iteración;    990 de 2450, Loss: 0.5979786872863769\n",
            "Epoch: 0, iteración;   1000 de 2450, Loss: 0.5655495643615722\n",
            "Epoch: 0, iteración;   1010 de 2450, Loss: 0.6021007061004638\n",
            "Epoch: 0, iteración;   1020 de 2450, Loss: 0.6274699687957763\n",
            "Epoch: 0, iteración;   1030 de 2450, Loss: 0.614772367477417\n",
            "Epoch: 0, iteración;   1040 de 2450, Loss: 0.6273501873016357\n",
            "Epoch: 0, iteración;   1050 de 2450, Loss: 0.6412422180175781\n",
            "Epoch: 0, iteración;   1060 de 2450, Loss: 0.572674560546875\n",
            "Epoch: 0, iteración;   1070 de 2450, Loss: 0.5853973388671875\n",
            "Epoch: 0, iteración;   1080 de 2450, Loss: 0.619840669631958\n",
            "Epoch: 0, iteración;   1090 de 2450, Loss: 0.5421079635620117\n",
            "Epoch: 0, iteración;   1100 de 2450, Loss: 0.6408818244934082\n",
            "Epoch: 0, iteración;   1110 de 2450, Loss: 0.5470811367034912\n",
            "Epoch: 0, iteración;   1120 de 2450, Loss: 0.6403322219848633\n",
            "Epoch: 0, iteración;   1130 de 2450, Loss: 0.6326196670532227\n",
            "Epoch: 0, iteración;   1140 de 2450, Loss: 0.6545022487640381\n",
            "Epoch: 0, iteración;   1150 de 2450, Loss: 0.6403073310852051\n",
            "Epoch: 0, iteración;   1160 de 2450, Loss: 0.6474365234375\n",
            "Epoch: 0, iteración;   1170 de 2450, Loss: 0.6177850723266601\n",
            "Epoch: 0, iteración;   1180 de 2450, Loss: 0.617521095275879\n",
            "Epoch: 0, iteración;   1190 de 2450, Loss: 0.6173127174377442\n",
            "Epoch: 0, iteración;   1200 de 2450, Loss: 0.6779205322265625\n",
            "Epoch: 0, iteración;   1210 de 2450, Loss: 0.5792605876922607\n",
            "Epoch: 0, iteración;   1220 de 2450, Loss: 0.5714868068695068\n",
            "Epoch: 0, iteración;   1230 de 2450, Loss: 0.6400099277496338\n",
            "Epoch: 0, iteración;   1240 de 2450, Loss: 0.6084699630737305\n",
            "Epoch: 0, iteración;   1250 de 2450, Loss: 0.6315145015716552\n",
            "Epoch: 0, iteración;   1260 de 2450, Loss: 0.5533477306365967\n",
            "Epoch: 0, iteración;   1270 de 2450, Loss: 0.631807804107666\n",
            "Epoch: 0, iteración;   1280 de 2450, Loss: 0.6155932426452637\n",
            "Epoch: 0, iteración;   1290 de 2450, Loss: 0.5839074134826661\n",
            "Epoch: 0, iteración;   1300 de 2450, Loss: 0.6640932083129882\n",
            "Epoch: 0, iteración;   1310 de 2450, Loss: 0.6148537158966064\n",
            "Epoch: 0, iteración;   1320 de 2450, Loss: 0.5825236320495606\n",
            "Epoch: 0, iteración;   1330 de 2450, Loss: 0.5896677017211914\n",
            "Epoch: 0, iteración;   1340 de 2450, Loss: 0.6147760868072509\n",
            "Epoch: 0, iteración;   1350 de 2450, Loss: 0.6062630653381348\n",
            "Epoch: 0, iteración;   1360 de 2450, Loss: 0.6645500183105468\n",
            "Epoch: 0, iteración;   1370 de 2450, Loss: 0.5900822639465332\n",
            "Epoch: 0, iteración;   1380 de 2450, Loss: 0.6309408664703369\n",
            "Epoch: 0, iteración;   1390 de 2450, Loss: 0.6217985630035401\n",
            "Epoch: 0, iteración;   1400 de 2450, Loss: 0.6143435001373291\n",
            "Epoch: 0, iteración;   1410 de 2450, Loss: 0.5890137672424316\n",
            "Epoch: 0, iteración;   1420 de 2450, Loss: 0.6399478912353516\n",
            "Epoch: 0, iteración;   1430 de 2450, Loss: 0.5623093605041504\n",
            "Epoch: 0, iteración;   1440 de 2450, Loss: 0.5705913066864013\n",
            "Epoch: 0, iteración;   1450 de 2450, Loss: 0.5431622982025146\n",
            "Epoch: 0, iteración;   1460 de 2450, Loss: 0.6030219554901123\n",
            "Epoch: 0, iteración;   1470 de 2450, Loss: 0.577763843536377\n",
            "Epoch: 0, iteración;   1480 de 2450, Loss: 0.5662459373474121\n",
            "Epoch: 0, iteración;   1490 de 2450, Loss: 0.5821546077728271\n",
            "Epoch: 0, iteración;   1500 de 2450, Loss: 0.5662396430969239\n",
            "Epoch: 0, iteración;   1510 de 2450, Loss: 0.5830486297607422\n",
            "Epoch: 0, iteración;   1520 de 2450, Loss: 0.6124900341033935\n",
            "Epoch: 0, iteración;   1530 de 2450, Loss: 0.5555480480194092\n",
            "Epoch: 0, iteración;   1540 de 2450, Loss: 0.5934108257293701\n",
            "Epoch: 0, iteración;   1550 de 2450, Loss: 0.6109074592590332\n",
            "Epoch: 0, iteración;   1560 de 2450, Loss: 0.5832437038421631\n",
            "Epoch: 0, iteración;   1570 de 2450, Loss: 0.6407084465026855\n",
            "Epoch: 0, iteración;   1580 de 2450, Loss: 0.5926499843597413\n",
            "Epoch: 0, iteración;   1590 de 2450, Loss: 0.5923884391784668\n",
            "Epoch: 0, iteración;   1600 de 2450, Loss: 0.6210031032562255\n",
            "Epoch: 0, iteración;   1610 de 2450, Loss: 0.639993953704834\n",
            "Epoch: 0, iteración;   1620 de 2450, Loss: 0.5916599750518798\n",
            "Epoch: 0, iteración;   1630 de 2450, Loss: 0.5625814437866211\n",
            "Epoch: 0, iteración;   1640 de 2450, Loss: 0.5527605056762696\n",
            "Epoch: 0, iteración;   1650 de 2450, Loss: 0.6600478172302247\n",
            "Epoch: 0, iteración;   1660 de 2450, Loss: 0.6603237152099609\n",
            "Epoch: 0, iteración;   1670 de 2450, Loss: 0.5239266395568848\n",
            "Epoch: 0, iteración;   1680 de 2450, Loss: 0.5431388854980469\n",
            "Epoch: 0, iteración;   1690 de 2450, Loss: 0.6110636234283447\n",
            "Epoch: 0, iteración;   1700 de 2450, Loss: 0.6205046653747559\n",
            "Epoch: 0, iteración;   1710 de 2450, Loss: 0.6694248199462891\n",
            "Epoch: 0, iteración;   1720 de 2450, Loss: 0.5804309844970703\n",
            "Epoch: 0, iteración;   1730 de 2450, Loss: 0.5915523529052734\n",
            "Epoch: 0, iteración;   1740 de 2450, Loss: 0.6300711154937744\n",
            "Epoch: 0, iteración;   1750 de 2450, Loss: 0.6004936695098877\n",
            "Epoch: 0, iteración;   1760 de 2450, Loss: 0.6019011974334717\n",
            "Epoch: 0, iteración;   1770 de 2450, Loss: 0.5609617710113526\n",
            "Epoch: 0, iteración;   1780 de 2450, Loss: 0.5707690715789795\n",
            "Epoch: 0, iteración;   1790 de 2450, Loss: 0.6412707805633545\n",
            "Epoch: 0, iteración;   1800 de 2450, Loss: 0.5809228897094727\n",
            "Epoch: 0, iteración;   1810 de 2450, Loss: 0.5471531867980957\n",
            "Epoch: 0, iteración;   1820 de 2450, Loss: 0.5268572807312012\n",
            "Epoch: 0, iteración;   1830 de 2450, Loss: 0.5288125038146972\n",
            "Epoch: 0, iteración;   1840 de 2450, Loss: 0.5270125389099121\n",
            "Epoch: 0, iteración;   1850 de 2450, Loss: 0.6210102558135986\n",
            "Epoch: 0, iteración;   1860 de 2450, Loss: 0.6425321578979493\n",
            "Epoch: 0, iteración;   1870 de 2450, Loss: 0.6225920200347901\n",
            "Epoch: 0, iteración;   1880 de 2450, Loss: 0.5908955097198486\n",
            "Epoch: 0, iteración;   1890 de 2450, Loss: 0.6431004524230957\n",
            "Epoch: 0, iteración;   1900 de 2450, Loss: 0.5368165016174317\n",
            "Epoch: 0, iteración;   1910 de 2450, Loss: 0.5831726551055908\n",
            "Epoch: 0, iteración;   1920 de 2450, Loss: 0.5237855911254883\n",
            "Epoch: 0, iteración;   1930 de 2450, Loss: 0.5584479808807373\n",
            "Epoch: 0, iteración;   1940 de 2450, Loss: 0.5791991233825684\n",
            "Epoch: 0, iteración;   1950 de 2450, Loss: 0.6238760471343994\n",
            "Epoch: 0, iteración;   1960 de 2450, Loss: 0.6183146476745606\n",
            "Epoch: 0, iteración;   1970 de 2450, Loss: 0.5800670623779297\n",
            "Epoch: 0, iteración;   1980 de 2450, Loss: 0.5918991088867187\n",
            "Epoch: 0, iteración;   1990 de 2450, Loss: 0.6117005348205566\n",
            "Epoch: 0, iteración;   2000 de 2450, Loss: 0.5574171543121338\n",
            "Epoch: 0, iteración;   2010 de 2450, Loss: 0.5687942981719971\n",
            "Epoch: 0, iteración;   2020 de 2450, Loss: 0.6015721321105957\n",
            "Epoch: 0, iteración;   2030 de 2450, Loss: 0.5683517932891846\n",
            "Epoch: 0, iteración;   2040 de 2450, Loss: 0.5892863750457764\n",
            "Epoch: 0, iteración;   2050 de 2450, Loss: 0.5903481006622314\n",
            "Epoch: 0, iteración;   2060 de 2450, Loss: 0.6444132804870606\n",
            "Epoch: 0, iteración;   2070 de 2450, Loss: 0.6024922370910645\n",
            "Epoch: 0, iteración;   2080 de 2450, Loss: 0.5468201637268066\n",
            "Epoch: 0, iteración;   2090 de 2450, Loss: 0.6211346626281739\n",
            "Epoch: 0, iteración;   2100 de 2450, Loss: 0.5977053642272949\n",
            "Epoch: 0, iteración;   2110 de 2450, Loss: 0.5859462738037109\n",
            "Epoch: 0, iteración;   2120 de 2450, Loss: 0.667729377746582\n",
            "Epoch: 0, iteración;   2130 de 2450, Loss: 0.666628646850586\n",
            "Epoch: 0, iteración;   2140 de 2450, Loss: 0.6338405132293701\n",
            "Epoch: 0, iteración;   2150 de 2450, Loss: 0.5885194778442383\n",
            "Epoch: 0, iteración;   2160 de 2450, Loss: 0.5588926792144775\n",
            "Epoch: 0, iteración;   2170 de 2450, Loss: 0.5678895950317383\n",
            "Epoch: 0, iteración;   2180 de 2450, Loss: 0.5789399147033691\n",
            "Epoch: 0, iteración;   2190 de 2450, Loss: 0.622190284729004\n",
            "Epoch: 0, iteración;   2200 de 2450, Loss: 0.5855213165283203\n",
            "Epoch: 0, iteración;   2210 de 2450, Loss: 0.5606894016265869\n",
            "Epoch: 0, iteración;   2220 de 2450, Loss: 0.5581313133239746\n",
            "Epoch: 0, iteración;   2230 de 2450, Loss: 0.5673013687133789\n",
            "Epoch: 0, iteración;   2240 de 2450, Loss: 0.4886772155761719\n",
            "Epoch: 0, iteración;   2250 de 2450, Loss: 0.555240535736084\n",
            "Epoch: 0, iteración;   2260 de 2450, Loss: 0.5444412231445312\n",
            "Epoch: 0, iteración;   2270 de 2450, Loss: 0.5779641628265381\n",
            "Epoch: 0, iteración;   2280 de 2450, Loss: 0.5988736629486084\n",
            "Epoch: 0, iteración;   2290 de 2450, Loss: 0.5745094776153564\n",
            "Epoch: 0, iteración;   2300 de 2450, Loss: 0.5678182125091553\n",
            "Epoch: 0, iteración;   2310 de 2450, Loss: 0.5538232803344727\n",
            "Epoch: 0, iteración;   2320 de 2450, Loss: 0.6131760597229003\n",
            "Epoch: 0, iteración;   2330 de 2450, Loss: 0.5881746292114258\n",
            "Epoch: 0, iteración;   2340 de 2450, Loss: 0.7156445980072021\n",
            "Epoch: 0, iteración;   2350 de 2450, Loss: 0.5439540863037109\n",
            "Epoch: 0, iteración;   2360 de 2450, Loss: 0.4978391170501709\n",
            "Epoch: 0, iteración;   2370 de 2450, Loss: 0.5660881996154785\n",
            "Epoch: 0, iteración;   2380 de 2450, Loss: 0.6216125965118409\n",
            "Epoch: 0, iteración;   2390 de 2450, Loss: 0.6233613967895508\n",
            "Epoch: 0, iteración;   2400 de 2450, Loss: 0.584776782989502\n",
            "Epoch: 0, iteración;   2410 de 2450, Loss: 0.5620977401733398\n",
            "Epoch: 0, iteración;   2420 de 2450, Loss: 0.5734281539916992\n",
            "Epoch: 0, iteración;   2430 de 2450, Loss: 0.6107424259185791\n",
            "Epoch: 0, iteración;   2440 de 2450, Loss: 0.5904045104980469\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainBERTSiamese(epoch)"
      ],
      "id": "R3D90MptXVsN"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_cosine_30.pth\")\n",
        "    print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "metadata": {
        "id": "G3jwVJiRbz2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4929e4fc-f1c7-4817-987a-2b4065a0b2ba"
      },
      "id": "G3jwVJiRbz2N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7Hwx74FXZ7t"
      },
      "source": [
        "###### Evaluación"
      ],
      "id": "g7Hwx74FXZ7t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6GZoAvxXbpe"
      },
      "outputs": [],
      "source": [
        "def validationSiamese(epoch):\n",
        "  model.eval()\n",
        "  fin_targets=[]\n",
        "  fin_outputs=[]\n",
        "  num_iteraciones = len(testing_loader)\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testing_loader, 0):\n",
        "      ids1 = data['ids1'].to(device)\n",
        "      ids2 = data['ids2'].to(device)\n",
        "      mask1 = data['mask1'].to(device)\n",
        "      mask2 = data['mask2'].to(device)\n",
        "      token_type_ids1 = data[\"token_type_ids1\"].to(device)\n",
        "      token_type_ids2 = data[\"token_type_ids2\"].to(device)\n",
        "      targets = data['target'].to(device)\n",
        "\n",
        "      print(f\"Iteración: {i:6} de {num_iteraciones}\")\n",
        "\n",
        "      outputs = model(ids1, mask1, token_type_ids1, ids2, mask2, token_type_ids2)\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "  return fin_outputs, fin_targets"
      ],
      "id": "e6GZoAvxXbpe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "uLfbrMwlPj9A"
      },
      "id": "uLfbrMwlPj9A"
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_cosine_30.pth\"):\n",
        "  model = BERTClassSiamese()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_cosine_30.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_cosine_30.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "metadata": {
        "id": "3xZN0aY8lW5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a87cf8-9dcf-4da9-ad77-9bad0c8db8c8"
      },
      "id": "3xZN0aY8lW5g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationSiamese(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17qVCTKQlW2N",
        "outputId": "009d5b05-d84e-4047-c3d9-cef1a44fd0dc"
      },
      "id": "17qVCTKQlW2N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración:      0 de 715\n",
            "Iteración:      1 de 715\n",
            "Iteración:      2 de 715\n",
            "Iteración:      3 de 715\n",
            "Iteración:      4 de 715\n",
            "Iteración:      5 de 715\n",
            "Iteración:      6 de 715\n",
            "Iteración:      7 de 715\n",
            "Iteración:      8 de 715\n",
            "Iteración:      9 de 715\n",
            "Iteración:     10 de 715\n",
            "Iteración:     11 de 715\n",
            "Iteración:     12 de 715\n",
            "Iteración:     13 de 715\n",
            "Iteración:     14 de 715\n",
            "Iteración:     15 de 715\n",
            "Iteración:     16 de 715\n",
            "Iteración:     17 de 715\n",
            "Iteración:     18 de 715\n",
            "Iteración:     19 de 715\n",
            "Iteración:     20 de 715\n",
            "Iteración:     21 de 715\n",
            "Iteración:     22 de 715\n",
            "Iteración:     23 de 715\n",
            "Iteración:     24 de 715\n",
            "Iteración:     25 de 715\n",
            "Iteración:     26 de 715\n",
            "Iteración:     27 de 715\n",
            "Iteración:     28 de 715\n",
            "Iteración:     29 de 715\n",
            "Iteración:     30 de 715\n",
            "Iteración:     31 de 715\n",
            "Iteración:     32 de 715\n",
            "Iteración:     33 de 715\n",
            "Iteración:     34 de 715\n",
            "Iteración:     35 de 715\n",
            "Iteración:     36 de 715\n",
            "Iteración:     37 de 715\n",
            "Iteración:     38 de 715\n",
            "Iteración:     39 de 715\n",
            "Iteración:     40 de 715\n",
            "Iteración:     41 de 715\n",
            "Iteración:     42 de 715\n",
            "Iteración:     43 de 715\n",
            "Iteración:     44 de 715\n",
            "Iteración:     45 de 715\n",
            "Iteración:     46 de 715\n",
            "Iteración:     47 de 715\n",
            "Iteración:     48 de 715\n",
            "Iteración:     49 de 715\n",
            "Iteración:     50 de 715\n",
            "Iteración:     51 de 715\n",
            "Iteración:     52 de 715\n",
            "Iteración:     53 de 715\n",
            "Iteración:     54 de 715\n",
            "Iteración:     55 de 715\n",
            "Iteración:     56 de 715\n",
            "Iteración:     57 de 715\n",
            "Iteración:     58 de 715\n",
            "Iteración:     59 de 715\n",
            "Iteración:     60 de 715\n",
            "Iteración:     61 de 715\n",
            "Iteración:     62 de 715\n",
            "Iteración:     63 de 715\n",
            "Iteración:     64 de 715\n",
            "Iteración:     65 de 715\n",
            "Iteración:     66 de 715\n",
            "Iteración:     67 de 715\n",
            "Iteración:     68 de 715\n",
            "Iteración:     69 de 715\n",
            "Iteración:     70 de 715\n",
            "Iteración:     71 de 715\n",
            "Iteración:     72 de 715\n",
            "Iteración:     73 de 715\n",
            "Iteración:     74 de 715\n",
            "Iteración:     75 de 715\n",
            "Iteración:     76 de 715\n",
            "Iteración:     77 de 715\n",
            "Iteración:     78 de 715\n",
            "Iteración:     79 de 715\n",
            "Iteración:     80 de 715\n",
            "Iteración:     81 de 715\n",
            "Iteración:     82 de 715\n",
            "Iteración:     83 de 715\n",
            "Iteración:     84 de 715\n",
            "Iteración:     85 de 715\n",
            "Iteración:     86 de 715\n",
            "Iteración:     87 de 715\n",
            "Iteración:     88 de 715\n",
            "Iteración:     89 de 715\n",
            "Iteración:     90 de 715\n",
            "Iteración:     91 de 715\n",
            "Iteración:     92 de 715\n",
            "Iteración:     93 de 715\n",
            "Iteración:     94 de 715\n",
            "Iteración:     95 de 715\n",
            "Iteración:     96 de 715\n",
            "Iteración:     97 de 715\n",
            "Iteración:     98 de 715\n",
            "Iteración:     99 de 715\n",
            "Iteración:    100 de 715\n",
            "Iteración:    101 de 715\n",
            "Iteración:    102 de 715\n",
            "Iteración:    103 de 715\n",
            "Iteración:    104 de 715\n",
            "Iteración:    105 de 715\n",
            "Iteración:    106 de 715\n",
            "Iteración:    107 de 715\n",
            "Iteración:    108 de 715\n",
            "Iteración:    109 de 715\n",
            "Iteración:    110 de 715\n",
            "Iteración:    111 de 715\n",
            "Iteración:    112 de 715\n",
            "Iteración:    113 de 715\n",
            "Iteración:    114 de 715\n",
            "Iteración:    115 de 715\n",
            "Iteración:    116 de 715\n",
            "Iteración:    117 de 715\n",
            "Iteración:    118 de 715\n",
            "Iteración:    119 de 715\n",
            "Iteración:    120 de 715\n",
            "Iteración:    121 de 715\n",
            "Iteración:    122 de 715\n",
            "Iteración:    123 de 715\n",
            "Iteración:    124 de 715\n",
            "Iteración:    125 de 715\n",
            "Iteración:    126 de 715\n",
            "Iteración:    127 de 715\n",
            "Iteración:    128 de 715\n",
            "Iteración:    129 de 715\n",
            "Iteración:    130 de 715\n",
            "Iteración:    131 de 715\n",
            "Iteración:    132 de 715\n",
            "Iteración:    133 de 715\n",
            "Iteración:    134 de 715\n",
            "Iteración:    135 de 715\n",
            "Iteración:    136 de 715\n",
            "Iteración:    137 de 715\n",
            "Iteración:    138 de 715\n",
            "Iteración:    139 de 715\n",
            "Iteración:    140 de 715\n",
            "Iteración:    141 de 715\n",
            "Iteración:    142 de 715\n",
            "Iteración:    143 de 715\n",
            "Iteración:    144 de 715\n",
            "Iteración:    145 de 715\n",
            "Iteración:    146 de 715\n",
            "Iteración:    147 de 715\n",
            "Iteración:    148 de 715\n",
            "Iteración:    149 de 715\n",
            "Iteración:    150 de 715\n",
            "Iteración:    151 de 715\n",
            "Iteración:    152 de 715\n",
            "Iteración:    153 de 715\n",
            "Iteración:    154 de 715\n",
            "Iteración:    155 de 715\n",
            "Iteración:    156 de 715\n",
            "Iteración:    157 de 715\n",
            "Iteración:    158 de 715\n",
            "Iteración:    159 de 715\n",
            "Iteración:    160 de 715\n",
            "Iteración:    161 de 715\n",
            "Iteración:    162 de 715\n",
            "Iteración:    163 de 715\n",
            "Iteración:    164 de 715\n",
            "Iteración:    165 de 715\n",
            "Iteración:    166 de 715\n",
            "Iteración:    167 de 715\n",
            "Iteración:    168 de 715\n",
            "Iteración:    169 de 715\n",
            "Iteración:    170 de 715\n",
            "Iteración:    171 de 715\n",
            "Iteración:    172 de 715\n",
            "Iteración:    173 de 715\n",
            "Iteración:    174 de 715\n",
            "Iteración:    175 de 715\n",
            "Iteración:    176 de 715\n",
            "Iteración:    177 de 715\n",
            "Iteración:    178 de 715\n",
            "Iteración:    179 de 715\n",
            "Iteración:    180 de 715\n",
            "Iteración:    181 de 715\n",
            "Iteración:    182 de 715\n",
            "Iteración:    183 de 715\n",
            "Iteración:    184 de 715\n",
            "Iteración:    185 de 715\n",
            "Iteración:    186 de 715\n",
            "Iteración:    187 de 715\n",
            "Iteración:    188 de 715\n",
            "Iteración:    189 de 715\n",
            "Iteración:    190 de 715\n",
            "Iteración:    191 de 715\n",
            "Iteración:    192 de 715\n",
            "Iteración:    193 de 715\n",
            "Iteración:    194 de 715\n",
            "Iteración:    195 de 715\n",
            "Iteración:    196 de 715\n",
            "Iteración:    197 de 715\n",
            "Iteración:    198 de 715\n",
            "Iteración:    199 de 715\n",
            "Iteración:    200 de 715\n",
            "Iteración:    201 de 715\n",
            "Iteración:    202 de 715\n",
            "Iteración:    203 de 715\n",
            "Iteración:    204 de 715\n",
            "Iteración:    205 de 715\n",
            "Iteración:    206 de 715\n",
            "Iteración:    207 de 715\n",
            "Iteración:    208 de 715\n",
            "Iteración:    209 de 715\n",
            "Iteración:    210 de 715\n",
            "Iteración:    211 de 715\n",
            "Iteración:    212 de 715\n",
            "Iteración:    213 de 715\n",
            "Iteración:    214 de 715\n",
            "Iteración:    215 de 715\n",
            "Iteración:    216 de 715\n",
            "Iteración:    217 de 715\n",
            "Iteración:    218 de 715\n",
            "Iteración:    219 de 715\n",
            "Iteración:    220 de 715\n",
            "Iteración:    221 de 715\n",
            "Iteración:    222 de 715\n",
            "Iteración:    223 de 715\n",
            "Iteración:    224 de 715\n",
            "Iteración:    225 de 715\n",
            "Iteración:    226 de 715\n",
            "Iteración:    227 de 715\n",
            "Iteración:    228 de 715\n",
            "Iteración:    229 de 715\n",
            "Iteración:    230 de 715\n",
            "Iteración:    231 de 715\n",
            "Iteración:    232 de 715\n",
            "Iteración:    233 de 715\n",
            "Iteración:    234 de 715\n",
            "Iteración:    235 de 715\n",
            "Iteración:    236 de 715\n",
            "Iteración:    237 de 715\n",
            "Iteración:    238 de 715\n",
            "Iteración:    239 de 715\n",
            "Iteración:    240 de 715\n",
            "Iteración:    241 de 715\n",
            "Iteración:    242 de 715\n",
            "Iteración:    243 de 715\n",
            "Iteración:    244 de 715\n",
            "Iteración:    245 de 715\n",
            "Iteración:    246 de 715\n",
            "Iteración:    247 de 715\n",
            "Iteración:    248 de 715\n",
            "Iteración:    249 de 715\n",
            "Iteración:    250 de 715\n",
            "Iteración:    251 de 715\n",
            "Iteración:    252 de 715\n",
            "Iteración:    253 de 715\n",
            "Iteración:    254 de 715\n",
            "Iteración:    255 de 715\n",
            "Iteración:    256 de 715\n",
            "Iteración:    257 de 715\n",
            "Iteración:    258 de 715\n",
            "Iteración:    259 de 715\n",
            "Iteración:    260 de 715\n",
            "Iteración:    261 de 715\n",
            "Iteración:    262 de 715\n",
            "Iteración:    263 de 715\n",
            "Iteración:    264 de 715\n",
            "Iteración:    265 de 715\n",
            "Iteración:    266 de 715\n",
            "Iteración:    267 de 715\n",
            "Iteración:    268 de 715\n",
            "Iteración:    269 de 715\n",
            "Iteración:    270 de 715\n",
            "Iteración:    271 de 715\n",
            "Iteración:    272 de 715\n",
            "Iteración:    273 de 715\n",
            "Iteración:    274 de 715\n",
            "Iteración:    275 de 715\n",
            "Iteración:    276 de 715\n",
            "Iteración:    277 de 715\n",
            "Iteración:    278 de 715\n",
            "Iteración:    279 de 715\n",
            "Iteración:    280 de 715\n",
            "Iteración:    281 de 715\n",
            "Iteración:    282 de 715\n",
            "Iteración:    283 de 715\n",
            "Iteración:    284 de 715\n",
            "Iteración:    285 de 715\n",
            "Iteración:    286 de 715\n",
            "Iteración:    287 de 715\n",
            "Iteración:    288 de 715\n",
            "Iteración:    289 de 715\n",
            "Iteración:    290 de 715\n",
            "Iteración:    291 de 715\n",
            "Iteración:    292 de 715\n",
            "Iteración:    293 de 715\n",
            "Iteración:    294 de 715\n",
            "Iteración:    295 de 715\n",
            "Iteración:    296 de 715\n",
            "Iteración:    297 de 715\n",
            "Iteración:    298 de 715\n",
            "Iteración:    299 de 715\n",
            "Iteración:    300 de 715\n",
            "Iteración:    301 de 715\n",
            "Iteración:    302 de 715\n",
            "Iteración:    303 de 715\n",
            "Iteración:    304 de 715\n",
            "Iteración:    305 de 715\n",
            "Iteración:    306 de 715\n",
            "Iteración:    307 de 715\n",
            "Iteración:    308 de 715\n",
            "Iteración:    309 de 715\n",
            "Iteración:    310 de 715\n",
            "Iteración:    311 de 715\n",
            "Iteración:    312 de 715\n",
            "Iteración:    313 de 715\n",
            "Iteración:    314 de 715\n",
            "Iteración:    315 de 715\n",
            "Iteración:    316 de 715\n",
            "Iteración:    317 de 715\n",
            "Iteración:    318 de 715\n",
            "Iteración:    319 de 715\n",
            "Iteración:    320 de 715\n",
            "Iteración:    321 de 715\n",
            "Iteración:    322 de 715\n",
            "Iteración:    323 de 715\n",
            "Iteración:    324 de 715\n",
            "Iteración:    325 de 715\n",
            "Iteración:    326 de 715\n",
            "Iteración:    327 de 715\n",
            "Iteración:    328 de 715\n",
            "Iteración:    329 de 715\n",
            "Iteración:    330 de 715\n",
            "Iteración:    331 de 715\n",
            "Iteración:    332 de 715\n",
            "Iteración:    333 de 715\n",
            "Iteración:    334 de 715\n",
            "Iteración:    335 de 715\n",
            "Iteración:    336 de 715\n",
            "Iteración:    337 de 715\n",
            "Iteración:    338 de 715\n",
            "Iteración:    339 de 715\n",
            "Iteración:    340 de 715\n",
            "Iteración:    341 de 715\n",
            "Iteración:    342 de 715\n",
            "Iteración:    343 de 715\n",
            "Iteración:    344 de 715\n",
            "Iteración:    345 de 715\n",
            "Iteración:    346 de 715\n",
            "Iteración:    347 de 715\n",
            "Iteración:    348 de 715\n",
            "Iteración:    349 de 715\n",
            "Iteración:    350 de 715\n",
            "Iteración:    351 de 715\n",
            "Iteración:    352 de 715\n",
            "Iteración:    353 de 715\n",
            "Iteración:    354 de 715\n",
            "Iteración:    355 de 715\n",
            "Iteración:    356 de 715\n",
            "Iteración:    357 de 715\n",
            "Iteración:    358 de 715\n",
            "Iteración:    359 de 715\n",
            "Iteración:    360 de 715\n",
            "Iteración:    361 de 715\n",
            "Iteración:    362 de 715\n",
            "Iteración:    363 de 715\n",
            "Iteración:    364 de 715\n",
            "Iteración:    365 de 715\n",
            "Iteración:    366 de 715\n",
            "Iteración:    367 de 715\n",
            "Iteración:    368 de 715\n",
            "Iteración:    369 de 715\n",
            "Iteración:    370 de 715\n",
            "Iteración:    371 de 715\n",
            "Iteración:    372 de 715\n",
            "Iteración:    373 de 715\n",
            "Iteración:    374 de 715\n",
            "Iteración:    375 de 715\n",
            "Iteración:    376 de 715\n",
            "Iteración:    377 de 715\n",
            "Iteración:    378 de 715\n",
            "Iteración:    379 de 715\n",
            "Iteración:    380 de 715\n",
            "Iteración:    381 de 715\n",
            "Iteración:    382 de 715\n",
            "Iteración:    383 de 715\n",
            "Iteración:    384 de 715\n",
            "Iteración:    385 de 715\n",
            "Iteración:    386 de 715\n",
            "Iteración:    387 de 715\n",
            "Iteración:    388 de 715\n",
            "Iteración:    389 de 715\n",
            "Iteración:    390 de 715\n",
            "Iteración:    391 de 715\n",
            "Iteración:    392 de 715\n",
            "Iteración:    393 de 715\n",
            "Iteración:    394 de 715\n",
            "Iteración:    395 de 715\n",
            "Iteración:    396 de 715\n",
            "Iteración:    397 de 715\n",
            "Iteración:    398 de 715\n",
            "Iteración:    399 de 715\n",
            "Iteración:    400 de 715\n",
            "Iteración:    401 de 715\n",
            "Iteración:    402 de 715\n",
            "Iteración:    403 de 715\n",
            "Iteración:    404 de 715\n",
            "Iteración:    405 de 715\n",
            "Iteración:    406 de 715\n",
            "Iteración:    407 de 715\n",
            "Iteración:    408 de 715\n",
            "Iteración:    409 de 715\n",
            "Iteración:    410 de 715\n",
            "Iteración:    411 de 715\n",
            "Iteración:    412 de 715\n",
            "Iteración:    413 de 715\n",
            "Iteración:    414 de 715\n",
            "Iteración:    415 de 715\n",
            "Iteración:    416 de 715\n",
            "Iteración:    417 de 715\n",
            "Iteración:    418 de 715\n",
            "Iteración:    419 de 715\n",
            "Iteración:    420 de 715\n",
            "Iteración:    421 de 715\n",
            "Iteración:    422 de 715\n",
            "Iteración:    423 de 715\n",
            "Iteración:    424 de 715\n",
            "Iteración:    425 de 715\n",
            "Iteración:    426 de 715\n",
            "Iteración:    427 de 715\n",
            "Iteración:    428 de 715\n",
            "Iteración:    429 de 715\n",
            "Iteración:    430 de 715\n",
            "Iteración:    431 de 715\n",
            "Iteración:    432 de 715\n",
            "Iteración:    433 de 715\n",
            "Iteración:    434 de 715\n",
            "Iteración:    435 de 715\n",
            "Iteración:    436 de 715\n",
            "Iteración:    437 de 715\n",
            "Iteración:    438 de 715\n",
            "Iteración:    439 de 715\n",
            "Iteración:    440 de 715\n",
            "Iteración:    441 de 715\n",
            "Iteración:    442 de 715\n",
            "Iteración:    443 de 715\n",
            "Iteración:    444 de 715\n",
            "Iteración:    445 de 715\n",
            "Iteración:    446 de 715\n",
            "Iteración:    447 de 715\n",
            "Iteración:    448 de 715\n",
            "Iteración:    449 de 715\n",
            "Iteración:    450 de 715\n",
            "Iteración:    451 de 715\n",
            "Iteración:    452 de 715\n",
            "Iteración:    453 de 715\n",
            "Iteración:    454 de 715\n",
            "Iteración:    455 de 715\n",
            "Iteración:    456 de 715\n",
            "Iteración:    457 de 715\n",
            "Iteración:    458 de 715\n",
            "Iteración:    459 de 715\n",
            "Iteración:    460 de 715\n",
            "Iteración:    461 de 715\n",
            "Iteración:    462 de 715\n",
            "Iteración:    463 de 715\n",
            "Iteración:    464 de 715\n",
            "Iteración:    465 de 715\n",
            "Iteración:    466 de 715\n",
            "Iteración:    467 de 715\n",
            "Iteración:    468 de 715\n",
            "Iteración:    469 de 715\n",
            "Iteración:    470 de 715\n",
            "Iteración:    471 de 715\n",
            "Iteración:    472 de 715\n",
            "Iteración:    473 de 715\n",
            "Iteración:    474 de 715\n",
            "Iteración:    475 de 715\n",
            "Iteración:    476 de 715\n",
            "Iteración:    477 de 715\n",
            "Iteración:    478 de 715\n",
            "Iteración:    479 de 715\n",
            "Iteración:    480 de 715\n",
            "Iteración:    481 de 715\n",
            "Iteración:    482 de 715\n",
            "Iteración:    483 de 715\n",
            "Iteración:    484 de 715\n",
            "Iteración:    485 de 715\n",
            "Iteración:    486 de 715\n",
            "Iteración:    487 de 715\n",
            "Iteración:    488 de 715\n",
            "Iteración:    489 de 715\n",
            "Iteración:    490 de 715\n",
            "Iteración:    491 de 715\n",
            "Iteración:    492 de 715\n",
            "Iteración:    493 de 715\n",
            "Iteración:    494 de 715\n",
            "Iteración:    495 de 715\n",
            "Iteración:    496 de 715\n",
            "Iteración:    497 de 715\n",
            "Iteración:    498 de 715\n",
            "Iteración:    499 de 715\n",
            "Iteración:    500 de 715\n",
            "Iteración:    501 de 715\n",
            "Iteración:    502 de 715\n",
            "Iteración:    503 de 715\n",
            "Iteración:    504 de 715\n",
            "Iteración:    505 de 715\n",
            "Iteración:    506 de 715\n",
            "Iteración:    507 de 715\n",
            "Iteración:    508 de 715\n",
            "Iteración:    509 de 715\n",
            "Iteración:    510 de 715\n",
            "Iteración:    511 de 715\n",
            "Iteración:    512 de 715\n",
            "Iteración:    513 de 715\n",
            "Iteración:    514 de 715\n",
            "Iteración:    515 de 715\n",
            "Iteración:    516 de 715\n",
            "Iteración:    517 de 715\n",
            "Iteración:    518 de 715\n",
            "Iteración:    519 de 715\n",
            "Iteración:    520 de 715\n",
            "Iteración:    521 de 715\n",
            "Iteración:    522 de 715\n",
            "Iteración:    523 de 715\n",
            "Iteración:    524 de 715\n",
            "Iteración:    525 de 715\n",
            "Iteración:    526 de 715\n",
            "Iteración:    527 de 715\n",
            "Iteración:    528 de 715\n",
            "Iteración:    529 de 715\n",
            "Iteración:    530 de 715\n",
            "Iteración:    531 de 715\n",
            "Iteración:    532 de 715\n",
            "Iteración:    533 de 715\n",
            "Iteración:    534 de 715\n",
            "Iteración:    535 de 715\n",
            "Iteración:    536 de 715\n",
            "Iteración:    537 de 715\n",
            "Iteración:    538 de 715\n",
            "Iteración:    539 de 715\n",
            "Iteración:    540 de 715\n",
            "Iteración:    541 de 715\n",
            "Iteración:    542 de 715\n",
            "Iteración:    543 de 715\n",
            "Iteración:    544 de 715\n",
            "Iteración:    545 de 715\n",
            "Iteración:    546 de 715\n",
            "Iteración:    547 de 715\n",
            "Iteración:    548 de 715\n",
            "Iteración:    549 de 715\n",
            "Iteración:    550 de 715\n",
            "Iteración:    551 de 715\n",
            "Iteración:    552 de 715\n",
            "Iteración:    553 de 715\n",
            "Iteración:    554 de 715\n",
            "Iteración:    555 de 715\n",
            "Iteración:    556 de 715\n",
            "Iteración:    557 de 715\n",
            "Iteración:    558 de 715\n",
            "Iteración:    559 de 715\n",
            "Iteración:    560 de 715\n",
            "Iteración:    561 de 715\n",
            "Iteración:    562 de 715\n",
            "Iteración:    563 de 715\n",
            "Iteración:    564 de 715\n",
            "Iteración:    565 de 715\n",
            "Iteración:    566 de 715\n",
            "Iteración:    567 de 715\n",
            "Iteración:    568 de 715\n",
            "Iteración:    569 de 715\n",
            "Iteración:    570 de 715\n",
            "Iteración:    571 de 715\n",
            "Iteración:    572 de 715\n",
            "Iteración:    573 de 715\n",
            "Iteración:    574 de 715\n",
            "Iteración:    575 de 715\n",
            "Iteración:    576 de 715\n",
            "Iteración:    577 de 715\n",
            "Iteración:    578 de 715\n",
            "Iteración:    579 de 715\n",
            "Iteración:    580 de 715\n",
            "Iteración:    581 de 715\n",
            "Iteración:    582 de 715\n",
            "Iteración:    583 de 715\n",
            "Iteración:    584 de 715\n",
            "Iteración:    585 de 715\n",
            "Iteración:    586 de 715\n",
            "Iteración:    587 de 715\n",
            "Iteración:    588 de 715\n",
            "Iteración:    589 de 715\n",
            "Iteración:    590 de 715\n",
            "Iteración:    591 de 715\n",
            "Iteración:    592 de 715\n",
            "Iteración:    593 de 715\n",
            "Iteración:    594 de 715\n",
            "Iteración:    595 de 715\n",
            "Iteración:    596 de 715\n",
            "Iteración:    597 de 715\n",
            "Iteración:    598 de 715\n",
            "Iteración:    599 de 715\n",
            "Iteración:    600 de 715\n",
            "Iteración:    601 de 715\n",
            "Iteración:    602 de 715\n",
            "Iteración:    603 de 715\n",
            "Iteración:    604 de 715\n",
            "Iteración:    605 de 715\n",
            "Iteración:    606 de 715\n",
            "Iteración:    607 de 715\n",
            "Iteración:    608 de 715\n",
            "Iteración:    609 de 715\n",
            "Iteración:    610 de 715\n",
            "Iteración:    611 de 715\n",
            "Iteración:    612 de 715\n",
            "Iteración:    613 de 715\n",
            "Iteración:    614 de 715\n",
            "Iteración:    615 de 715\n",
            "Iteración:    616 de 715\n",
            "Iteración:    617 de 715\n",
            "Iteración:    618 de 715\n",
            "Iteración:    619 de 715\n",
            "Iteración:    620 de 715\n",
            "Iteración:    621 de 715\n",
            "Iteración:    622 de 715\n",
            "Iteración:    623 de 715\n",
            "Iteración:    624 de 715\n",
            "Iteración:    625 de 715\n",
            "Iteración:    626 de 715\n",
            "Iteración:    627 de 715\n",
            "Iteración:    628 de 715\n",
            "Iteración:    629 de 715\n",
            "Iteración:    630 de 715\n",
            "Iteración:    631 de 715\n",
            "Iteración:    632 de 715\n",
            "Iteración:    633 de 715\n",
            "Iteración:    634 de 715\n",
            "Iteración:    635 de 715\n",
            "Iteración:    636 de 715\n",
            "Iteración:    637 de 715\n",
            "Iteración:    638 de 715\n",
            "Iteración:    639 de 715\n",
            "Iteración:    640 de 715\n",
            "Iteración:    641 de 715\n",
            "Iteración:    642 de 715\n",
            "Iteración:    643 de 715\n",
            "Iteración:    644 de 715\n",
            "Iteración:    645 de 715\n",
            "Iteración:    646 de 715\n",
            "Iteración:    647 de 715\n",
            "Iteración:    648 de 715\n",
            "Iteración:    649 de 715\n",
            "Iteración:    650 de 715\n",
            "Iteración:    651 de 715\n",
            "Iteración:    652 de 715\n",
            "Iteración:    653 de 715\n",
            "Iteración:    654 de 715\n",
            "Iteración:    655 de 715\n",
            "Iteración:    656 de 715\n",
            "Iteración:    657 de 715\n",
            "Iteración:    658 de 715\n",
            "Iteración:    659 de 715\n",
            "Iteración:    660 de 715\n",
            "Iteración:    661 de 715\n",
            "Iteración:    662 de 715\n",
            "Iteración:    663 de 715\n",
            "Iteración:    664 de 715\n",
            "Iteración:    665 de 715\n",
            "Iteración:    666 de 715\n",
            "Iteración:    667 de 715\n",
            "Iteración:    668 de 715\n",
            "Iteración:    669 de 715\n",
            "Iteración:    670 de 715\n",
            "Iteración:    671 de 715\n",
            "Iteración:    672 de 715\n",
            "Iteración:    673 de 715\n",
            "Iteración:    674 de 715\n",
            "Iteración:    675 de 715\n",
            "Iteración:    676 de 715\n",
            "Iteración:    677 de 715\n",
            "Iteración:    678 de 715\n",
            "Iteración:    679 de 715\n",
            "Iteración:    680 de 715\n",
            "Iteración:    681 de 715\n",
            "Iteración:    682 de 715\n",
            "Iteración:    683 de 715\n",
            "Iteración:    684 de 715\n",
            "Iteración:    685 de 715\n",
            "Iteración:    686 de 715\n",
            "Iteración:    687 de 715\n",
            "Iteración:    688 de 715\n",
            "Iteración:    689 de 715\n",
            "Iteración:    690 de 715\n",
            "Iteración:    691 de 715\n",
            "Iteración:    692 de 715\n",
            "Iteración:    693 de 715\n",
            "Iteración:    694 de 715\n",
            "Iteración:    695 de 715\n",
            "Iteración:    696 de 715\n",
            "Iteración:    697 de 715\n",
            "Iteración:    698 de 715\n",
            "Iteración:    699 de 715\n",
            "Iteración:    700 de 715\n",
            "Iteración:    701 de 715\n",
            "Iteración:    702 de 715\n",
            "Iteración:    703 de 715\n",
            "Iteración:    704 de 715\n",
            "Iteración:    705 de 715\n",
            "Iteración:    706 de 715\n",
            "Iteración:    707 de 715\n",
            "Iteración:    708 de 715\n",
            "Iteración:    709 de 715\n",
            "Iteración:    710 de 715\n",
            "Iteración:    711 de 715\n",
            "Iteración:    712 de 715\n",
            "Iteración:    713 de 715\n",
            "Iteración:    714 de 715\n",
            "Accuracy Score = 0.7260241016556219\n",
            "F1 Score (Micro) = 0.7260241016556219\n",
            "F1 Score (Macro) = 0.42063381441731396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.6.6 ConcatEmbeddings Approach"
      ],
      "metadata": {
        "id": "iJaI12mBE9W0"
      },
      "id": "iJaI12mBE9W0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta aproximación no se emplea la distancia coseno ni ninguna otra medida, si no que, en su lugar, se alimenta directamente la cabeza clasificadora con la concatenación de los dos *embeddings*."
      ],
      "metadata": {
        "id": "gOHxjwYNi4Cz"
      },
      "id": "gOHxjwYNi4Cz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Definición del modelo"
      ],
      "metadata": {
        "id": "zAJPsa7QFSh5"
      },
      "id": "zAJPsa7QFSh5"
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTSiameseConcat(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BERTSiameseConcat, self).__init__()\n",
        "    self.dropout = 0.2\n",
        "    self.hidden_embd = 768\n",
        "    self.output_layer = 1\n",
        "\n",
        "    # Layers\n",
        "    self.l1 = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    self.l2 = torch.nn.Linear(self.hidden_embd  * 2, self.hidden_embd)\n",
        "    self.a2 = torch.nn.LeakyReLU()\n",
        "    self.l3 = torch.nn.Dropout(self.dropout)\n",
        "\n",
        "    self.l4 = torch.nn.Linear(self.hidden_embd, 512)\n",
        "    self.a4 = torch.nn.LeakyReLU()\n",
        "\n",
        "    self.l5 = torch.nn.Linear(512, self.output_layer)\n",
        "    self.a5 = torch.nn.Sigmoid()\n",
        "\n",
        "  def forward(self, ids_1, mask_1, token_type_ids_1, ids_2, mask_2, token_type_ids_2):\n",
        "    _, last_hidden_state_b = self.l1(ids_2, attention_mask=mask_2, token_type_ids=token_type_ids_2, return_dict=False)\n",
        "    _, last_hidden_state_a = self.l1(ids_1, attention_mask=mask_1, token_type_ids=token_type_ids_1, return_dict=False)\n",
        "    last_hidden_state_final = torch.cat([last_hidden_state_a, last_hidden_state_b], dim=1)\n",
        "\n",
        "    outputl2 = self.l2(last_hidden_state_final)\n",
        "    outputa2 = self.a2(outputl2)\n",
        "\n",
        "    #outputl3 = self.l3(outputl2)\n",
        "    outputl3 = self.l3(outputa2)\n",
        "\n",
        "    outputl4 = self.l4(outputl3)\n",
        "    outputa4 = self.a4(outputl4)\n",
        "\n",
        "    #outputl5 = self.l5(outputl4)\n",
        "    outputl5 = self.l5(outputa4)\n",
        "    outputa5 = self.a5(outputl5)\n",
        "\n",
        "    #return outputl5\n",
        "    return outputa5\n",
        "\n",
        "model = BERTSiameseConcat()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "cLDwuoZEFVca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc18cf2f-bd36-4158-eed0-9e08c67a0ad2"
      },
      "id": "cLDwuoZEFVca",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTSiameseConcat(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l2): Linear(in_features=1536, out_features=768, bias=True)\n",
              "  (a2): LeakyReLU(negative_slope=0.01)\n",
              "  (l3): Dropout(p=0.2, inplace=False)\n",
              "  (l4): Linear(in_features=768, out_features=512, bias=True)\n",
              "  (a4): LeakyReLU(negative_slope=0.01)\n",
              "  (l5): Linear(in_features=512, out_features=1, bias=True)\n",
              "  (a5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE,\n",
        "                             weight_decay=0.001)\n",
        "optimizer"
      ],
      "metadata": {
        "id": "Rs0qXgRRFY95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7d34f2-e066-467b-b834-7506f3b694b7"
      },
      "id": "Rs0qXgRRFY95",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 1e-07\n",
              "    maximize: False\n",
              "    weight_decay: 0.001\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Función de entrenamiento"
      ],
      "metadata": {
        "id": "mdwhRYyQFguy"
      },
      "id": "mdwhRYyQFguy"
    },
    {
      "cell_type": "code",
      "source": [
        "def trainBERTSiameseConcat(epoch):\n",
        "  model.train()\n",
        "  #loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "  #loss_fn = torch.nn.CrossEntropyLoss()\n",
        "  #loss_fn = torch.nn.MSELoss()\n",
        "  loss_fn = torch.nn.BCELoss()\n",
        "  num_iteraciones = len(training_loader)\n",
        "  sum_loss = 0\n",
        "\n",
        "  for iteracion,data in enumerate(training_loader, 0):\n",
        "    ids1 = data['ids1'].to(device)\n",
        "    ids2 = data['ids2'].to(device)\n",
        "    mask1 = data['mask1'].to(device)\n",
        "    mask2 = data['mask2'].to(device)\n",
        "    token_type_ids1 = data[\"token_type_ids1\"].to(device)\n",
        "    token_type_ids2 = data[\"token_type_ids2\"].to(device)\n",
        "    targets = data['target'].to(device)\n",
        "\n",
        "    output = model(ids1, mask1, token_type_ids1, ids2, mask2, token_type_ids2)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    perdida = loss_fn(output.squeeze(), targets)\n",
        "    with torch.no_grad():\n",
        "      sum_loss+=perdida\n",
        "      if iteracion % PASOS_POR_INTERVALO == 0:\n",
        "        print(f'Epoch: {epoch}, iteración: {iteracion} de {num_iteraciones}, Loss: {sum_loss.cpu().numpy()/PASOS_POR_INTERVALO}')\n",
        "        sum_loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    perdida.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "aNc0flqEF3E3"
      },
      "id": "aNc0flqEF3E3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Entrenamiento del modelo (30% de datos)"
      ],
      "metadata": {
        "id": "8MlPEA0kRmIT"
      },
      "id": "8MlPEA0kRmIT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza:\n",
        "- LR 1e-3\n",
        "- weight_decay=0.001\n",
        "- Linear + Dropout + Linear + Linear + Sigmoid"
      ],
      "metadata": {
        "id": "dq1eWXg0RwhA"
      },
      "id": "dq1eWXg0RwhA"
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainBERTSiameseConcat(epoch)"
      ],
      "metadata": {
        "id": "VQDq2_ryRi7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0767b499-b78c-48dd-9704-4343fe2fbaa9"
      },
      "id": "VQDq2_ryRi7q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración: 0 de 2450, Loss: 0.0777856945991516\n",
            "Epoch: 0, iteración: 10 de 2450, Loss: 2.2393213272094727\n",
            "Epoch: 0, iteración: 20 de 2450, Loss: 0.8985054969787598\n",
            "Epoch: 0, iteración: 30 de 2450, Loss: 0.7053309440612793\n",
            "Epoch: 0, iteración: 40 de 2450, Loss: 0.6196593284606934\n",
            "Epoch: 0, iteración: 50 de 2450, Loss: 0.6945080280303955\n",
            "Epoch: 0, iteración: 60 de 2450, Loss: 0.5722953796386718\n",
            "Epoch: 0, iteración: 70 de 2450, Loss: 0.6320746421813965\n",
            "Epoch: 0, iteración: 80 de 2450, Loss: 0.6995283126831054\n",
            "Epoch: 0, iteración: 90 de 2450, Loss: 0.5264666080474854\n",
            "Epoch: 0, iteración: 100 de 2450, Loss: 0.5602176666259766\n",
            "Epoch: 0, iteración: 110 de 2450, Loss: 0.5656137943267823\n",
            "Epoch: 0, iteración: 120 de 2450, Loss: 0.5682831764221191\n",
            "Epoch: 0, iteración: 130 de 2450, Loss: 0.6760453701019287\n",
            "Epoch: 0, iteración: 140 de 2450, Loss: 0.634089994430542\n",
            "Epoch: 0, iteración: 150 de 2450, Loss: 0.5047501564025879\n",
            "Epoch: 0, iteración: 160 de 2450, Loss: 0.6530325412750244\n",
            "Epoch: 0, iteración: 170 de 2450, Loss: 0.6254320621490479\n",
            "Epoch: 0, iteración: 180 de 2450, Loss: 0.5023268222808838\n",
            "Epoch: 0, iteración: 190 de 2450, Loss: 0.6074860095977783\n",
            "Epoch: 0, iteración: 200 de 2450, Loss: 0.5889445304870605\n",
            "Epoch: 0, iteración: 210 de 2450, Loss: 0.6188493728637695\n",
            "Epoch: 0, iteración: 220 de 2450, Loss: 0.628304386138916\n",
            "Epoch: 0, iteración: 230 de 2450, Loss: 0.5811803340911865\n",
            "Epoch: 0, iteración: 240 de 2450, Loss: 0.6147870063781739\n",
            "Epoch: 0, iteración: 250 de 2450, Loss: 0.5838518142700195\n",
            "Epoch: 0, iteración: 260 de 2450, Loss: 0.5620256423950195\n",
            "Epoch: 0, iteración: 270 de 2450, Loss: 0.6048743724822998\n",
            "Epoch: 0, iteración: 280 de 2450, Loss: 0.6151235580444336\n",
            "Epoch: 0, iteración: 290 de 2450, Loss: 0.6446418285369873\n",
            "Epoch: 0, iteración: 300 de 2450, Loss: 0.6102243423461914\n",
            "Epoch: 0, iteración: 310 de 2450, Loss: 0.6273448467254639\n",
            "Epoch: 0, iteración: 320 de 2450, Loss: 0.5917491912841797\n",
            "Epoch: 0, iteración: 330 de 2450, Loss: 0.6381453514099121\n",
            "Epoch: 0, iteración: 340 de 2450, Loss: 0.498180627822876\n",
            "Epoch: 0, iteración: 350 de 2450, Loss: 0.6083871364593506\n",
            "Epoch: 0, iteración: 360 de 2450, Loss: 0.5916080951690674\n",
            "Epoch: 0, iteración: 370 de 2450, Loss: 0.6263176441192627\n",
            "Epoch: 0, iteración: 380 de 2450, Loss: 0.555850601196289\n",
            "Epoch: 0, iteración: 390 de 2450, Loss: 0.4888571262359619\n",
            "Epoch: 0, iteración: 400 de 2450, Loss: 0.5991139888763428\n",
            "Epoch: 0, iteración: 410 de 2450, Loss: 0.6272903442382812\n",
            "Epoch: 0, iteración: 420 de 2450, Loss: 0.6905483722686767\n",
            "Epoch: 0, iteración: 430 de 2450, Loss: 0.5852367401123046\n",
            "Epoch: 0, iteración: 440 de 2450, Loss: 0.6249548435211182\n",
            "Epoch: 0, iteración: 450 de 2450, Loss: 0.6300556182861328\n",
            "Epoch: 0, iteración: 460 de 2450, Loss: 0.567448091506958\n",
            "Epoch: 0, iteración: 470 de 2450, Loss: 0.6445596218109131\n",
            "Epoch: 0, iteración: 480 de 2450, Loss: 0.6213212966918945\n",
            "Epoch: 0, iteración: 490 de 2450, Loss: 0.6168352127075195\n",
            "Epoch: 0, iteración: 500 de 2450, Loss: 0.5692526817321777\n",
            "Epoch: 0, iteración: 510 de 2450, Loss: 0.6073999881744385\n",
            "Epoch: 0, iteración: 520 de 2450, Loss: 0.6631553649902344\n",
            "Epoch: 0, iteración: 530 de 2450, Loss: 0.6763200759887695\n",
            "Epoch: 0, iteración: 540 de 2450, Loss: 0.6102422714233399\n",
            "Epoch: 0, iteración: 550 de 2450, Loss: 0.6336309909820557\n",
            "Epoch: 0, iteración: 560 de 2450, Loss: 0.571673583984375\n",
            "Epoch: 0, iteración: 570 de 2450, Loss: 0.5415091991424561\n",
            "Epoch: 0, iteración: 580 de 2450, Loss: 0.5768308162689209\n",
            "Epoch: 0, iteración: 590 de 2450, Loss: 0.5916428089141845\n",
            "Epoch: 0, iteración: 600 de 2450, Loss: 0.5884583950042724\n",
            "Epoch: 0, iteración: 610 de 2450, Loss: 0.5528923511505127\n",
            "Epoch: 0, iteración: 620 de 2450, Loss: 0.5875222206115722\n",
            "Epoch: 0, iteración: 630 de 2450, Loss: 0.5686259269714355\n",
            "Epoch: 0, iteración: 640 de 2450, Loss: 0.541261863708496\n",
            "Epoch: 0, iteración: 650 de 2450, Loss: 0.6136604309082031\n",
            "Epoch: 0, iteración: 660 de 2450, Loss: 0.6069694519042969\n",
            "Epoch: 0, iteración: 670 de 2450, Loss: 0.5156899929046631\n",
            "Epoch: 0, iteración: 680 de 2450, Loss: 0.6030751228332519\n",
            "Epoch: 0, iteración: 690 de 2450, Loss: 0.594409704208374\n",
            "Epoch: 0, iteración: 700 de 2450, Loss: 0.5697113513946533\n",
            "Epoch: 0, iteración: 710 de 2450, Loss: 0.6337584018707275\n",
            "Epoch: 0, iteración: 720 de 2450, Loss: 0.6344098091125489\n",
            "Epoch: 0, iteración: 730 de 2450, Loss: 0.6429291248321534\n",
            "Epoch: 0, iteración: 740 de 2450, Loss: 0.6133235931396485\n",
            "Epoch: 0, iteración: 750 de 2450, Loss: 0.6257212638854981\n",
            "Epoch: 0, iteración: 760 de 2450, Loss: 0.6618134498596191\n",
            "Epoch: 0, iteración: 770 de 2450, Loss: 0.673714017868042\n",
            "Epoch: 0, iteración: 780 de 2450, Loss: 0.5958784103393555\n",
            "Epoch: 0, iteración: 790 de 2450, Loss: 0.5889552116394043\n",
            "Epoch: 0, iteración: 800 de 2450, Loss: 0.611745023727417\n",
            "Epoch: 0, iteración: 810 de 2450, Loss: 0.6280231475830078\n",
            "Epoch: 0, iteración: 820 de 2450, Loss: 0.6050782203674316\n",
            "Epoch: 0, iteración: 830 de 2450, Loss: 0.6114709377288818\n",
            "Epoch: 0, iteración: 840 de 2450, Loss: 0.614381217956543\n",
            "Epoch: 0, iteración: 850 de 2450, Loss: 0.565935754776001\n",
            "Epoch: 0, iteración: 860 de 2450, Loss: 0.635584545135498\n",
            "Epoch: 0, iteración: 870 de 2450, Loss: 0.5840981960296631\n",
            "Epoch: 0, iteración: 880 de 2450, Loss: 0.5754857540130616\n",
            "Epoch: 0, iteración: 890 de 2450, Loss: 0.5484081268310547\n",
            "Epoch: 0, iteración: 900 de 2450, Loss: 0.5935988903045655\n",
            "Epoch: 0, iteración: 910 de 2450, Loss: 0.6495573997497559\n",
            "Epoch: 0, iteración: 920 de 2450, Loss: 0.6004766941070556\n",
            "Epoch: 0, iteración: 930 de 2450, Loss: 0.6395745277404785\n",
            "Epoch: 0, iteración: 940 de 2450, Loss: 0.5329716205596924\n",
            "Epoch: 0, iteración: 950 de 2450, Loss: 0.6062423706054687\n",
            "Epoch: 0, iteración: 960 de 2450, Loss: 0.5882668018341064\n",
            "Epoch: 0, iteración: 970 de 2450, Loss: 0.467901611328125\n",
            "Epoch: 0, iteración: 980 de 2450, Loss: 0.6464474678039551\n",
            "Epoch: 0, iteración: 990 de 2450, Loss: 0.4238245487213135\n",
            "Epoch: 0, iteración: 1000 de 2450, Loss: 0.5551069259643555\n",
            "Epoch: 0, iteración: 1010 de 2450, Loss: 0.673022985458374\n",
            "Epoch: 0, iteración: 1020 de 2450, Loss: 0.5817899703979492\n",
            "Epoch: 0, iteración: 1030 de 2450, Loss: 0.4676029205322266\n",
            "Epoch: 0, iteración: 1040 de 2450, Loss: 0.6175124168395996\n",
            "Epoch: 0, iteración: 1050 de 2450, Loss: 0.6358048915863037\n",
            "Epoch: 0, iteración: 1060 de 2450, Loss: 0.5849841594696045\n",
            "Epoch: 0, iteración: 1070 de 2450, Loss: 0.5767130851745605\n",
            "Epoch: 0, iteración: 1080 de 2450, Loss: 0.5737974643707275\n",
            "Epoch: 0, iteración: 1090 de 2450, Loss: 0.5935855388641358\n",
            "Epoch: 0, iteración: 1100 de 2450, Loss: 0.6413197040557861\n",
            "Epoch: 0, iteración: 1110 de 2450, Loss: 0.6300236701965332\n",
            "Epoch: 0, iteración: 1120 de 2450, Loss: 0.643961238861084\n",
            "Epoch: 0, iteración: 1130 de 2450, Loss: 0.6366851329803467\n",
            "Epoch: 0, iteración: 1140 de 2450, Loss: 0.5794556617736817\n",
            "Epoch: 0, iteración: 1150 de 2450, Loss: 0.49775047302246095\n",
            "Epoch: 0, iteración: 1160 de 2450, Loss: 0.6396464347839356\n",
            "Epoch: 0, iteración: 1170 de 2450, Loss: 0.6365580558776855\n",
            "Epoch: 0, iteración: 1180 de 2450, Loss: 0.5533501148223877\n",
            "Epoch: 0, iteración: 1190 de 2450, Loss: 0.6020147800445557\n",
            "Epoch: 0, iteración: 1200 de 2450, Loss: 0.5627788066864013\n",
            "Epoch: 0, iteración: 1210 de 2450, Loss: 0.6021405696868897\n",
            "Epoch: 0, iteración: 1220 de 2450, Loss: 0.5731713771820068\n",
            "Epoch: 0, iteración: 1230 de 2450, Loss: 0.6774971961975098\n",
            "Epoch: 0, iteración: 1240 de 2450, Loss: 0.6478113651275634\n",
            "Epoch: 0, iteración: 1250 de 2450, Loss: 0.5846830368041992\n",
            "Epoch: 0, iteración: 1260 de 2450, Loss: 0.5739199638366699\n",
            "Epoch: 0, iteración: 1270 de 2450, Loss: 0.6093185424804688\n",
            "Epoch: 0, iteración: 1280 de 2450, Loss: 0.652670431137085\n",
            "Epoch: 0, iteración: 1290 de 2450, Loss: 0.6154749870300293\n",
            "Epoch: 0, iteración: 1300 de 2450, Loss: 0.6039068222045898\n",
            "Epoch: 0, iteración: 1310 de 2450, Loss: 0.6115720748901368\n",
            "Epoch: 0, iteración: 1320 de 2450, Loss: 0.5864105224609375\n",
            "Epoch: 0, iteración: 1330 de 2450, Loss: 0.6381103515625\n",
            "Epoch: 0, iteración: 1340 de 2450, Loss: 0.5524259567260742\n",
            "Epoch: 0, iteración: 1350 de 2450, Loss: 0.5664191246032715\n",
            "Epoch: 0, iteración: 1360 de 2450, Loss: 0.6485075950622559\n",
            "Epoch: 0, iteración: 1370 de 2450, Loss: 0.5830146789550781\n",
            "Epoch: 0, iteración: 1380 de 2450, Loss: 0.613696813583374\n",
            "Epoch: 0, iteración: 1390 de 2450, Loss: 0.6289034366607666\n",
            "Epoch: 0, iteración: 1400 de 2450, Loss: 0.58104567527771\n",
            "Epoch: 0, iteración: 1410 de 2450, Loss: 0.5175556182861328\n",
            "Epoch: 0, iteración: 1420 de 2450, Loss: 0.6959637641906739\n",
            "Epoch: 0, iteración: 1430 de 2450, Loss: 0.5922762870788574\n",
            "Epoch: 0, iteración: 1440 de 2450, Loss: 0.5559684753417968\n",
            "Epoch: 0, iteración: 1450 de 2450, Loss: 0.6701436042785645\n",
            "Epoch: 0, iteración: 1460 de 2450, Loss: 0.636757230758667\n",
            "Epoch: 0, iteración: 1470 de 2450, Loss: 0.6484516620635986\n",
            "Epoch: 0, iteración: 1480 de 2450, Loss: 0.6321685314178467\n",
            "Epoch: 0, iteración: 1490 de 2450, Loss: 0.6216074466705322\n",
            "Epoch: 0, iteración: 1500 de 2450, Loss: 0.5959770202636718\n",
            "Epoch: 0, iteración: 1510 de 2450, Loss: 0.5777424335479736\n",
            "Epoch: 0, iteración: 1520 de 2450, Loss: 0.5266077518463135\n",
            "Epoch: 0, iteración: 1530 de 2450, Loss: 0.5168879508972168\n",
            "Epoch: 0, iteración: 1540 de 2450, Loss: 0.587160301208496\n",
            "Epoch: 0, iteración: 1550 de 2450, Loss: 0.5891743659973144\n",
            "Epoch: 0, iteración: 1560 de 2450, Loss: 0.6159204483032227\n",
            "Epoch: 0, iteración: 1570 de 2450, Loss: 0.5606583595275879\n",
            "Epoch: 0, iteración: 1580 de 2450, Loss: 0.5907835960388184\n",
            "Epoch: 0, iteración: 1590 de 2450, Loss: 0.592176103591919\n",
            "Epoch: 0, iteración: 1600 de 2450, Loss: 0.5772560596466064\n",
            "Epoch: 0, iteración: 1610 de 2450, Loss: 0.49345998764038085\n",
            "Epoch: 0, iteración: 1620 de 2450, Loss: 0.6480221748352051\n",
            "Epoch: 0, iteración: 1630 de 2450, Loss: 0.6124011993408203\n",
            "Epoch: 0, iteración: 1640 de 2450, Loss: 0.5854045391082764\n",
            "Epoch: 0, iteración: 1650 de 2450, Loss: 0.5539003372192383\n",
            "Epoch: 0, iteración: 1660 de 2450, Loss: 0.594517993927002\n",
            "Epoch: 0, iteración: 1670 de 2450, Loss: 0.6263768672943115\n",
            "Epoch: 0, iteración: 1680 de 2450, Loss: 0.6183822631835938\n",
            "Epoch: 0, iteración: 1690 de 2450, Loss: 0.637085247039795\n",
            "Epoch: 0, iteración: 1700 de 2450, Loss: 0.5618560791015625\n",
            "Epoch: 0, iteración: 1710 de 2450, Loss: 0.6271295547485352\n",
            "Epoch: 0, iteración: 1720 de 2450, Loss: 0.6552656173706055\n",
            "Epoch: 0, iteración: 1730 de 2450, Loss: 0.578219223022461\n",
            "Epoch: 0, iteración: 1740 de 2450, Loss: 0.5583876609802246\n",
            "Epoch: 0, iteración: 1750 de 2450, Loss: 0.4863297939300537\n",
            "Epoch: 0, iteración: 1760 de 2450, Loss: 0.6613519191741943\n",
            "Epoch: 0, iteración: 1770 de 2450, Loss: 0.5678242206573486\n",
            "Epoch: 0, iteración: 1780 de 2450, Loss: 0.4526646614074707\n",
            "Epoch: 0, iteración: 1790 de 2450, Loss: 0.5625738143920899\n",
            "Epoch: 0, iteración: 1800 de 2450, Loss: 0.5333732604980469\n",
            "Epoch: 0, iteración: 1810 de 2450, Loss: 0.5928508281707764\n",
            "Epoch: 0, iteración: 1820 de 2450, Loss: 0.5462116718292236\n",
            "Epoch: 0, iteración: 1830 de 2450, Loss: 0.531944751739502\n",
            "Epoch: 0, iteración: 1840 de 2450, Loss: 0.64595046043396\n",
            "Epoch: 0, iteración: 1850 de 2450, Loss: 0.6178673267364502\n",
            "Epoch: 0, iteración: 1860 de 2450, Loss: 0.6462481021881104\n",
            "Epoch: 0, iteración: 1870 de 2450, Loss: 0.5657658100128173\n",
            "Epoch: 0, iteración: 1880 de 2450, Loss: 0.63316330909729\n",
            "Epoch: 0, iteración: 1890 de 2450, Loss: 0.6591561317443848\n",
            "Epoch: 0, iteración: 1900 de 2450, Loss: 0.5495988845825195\n",
            "Epoch: 0, iteración: 1910 de 2450, Loss: 0.5715398788452148\n",
            "Epoch: 0, iteración: 1920 de 2450, Loss: 0.7083055019378662\n",
            "Epoch: 0, iteración: 1930 de 2450, Loss: 0.6298544883728028\n",
            "Epoch: 0, iteración: 1940 de 2450, Loss: 0.6262265205383301\n",
            "Epoch: 0, iteración: 1950 de 2450, Loss: 0.6310542106628418\n",
            "Epoch: 0, iteración: 1960 de 2450, Loss: 0.5812983989715577\n",
            "Epoch: 0, iteración: 1970 de 2450, Loss: 0.6066888332366943\n",
            "Epoch: 0, iteración: 1980 de 2450, Loss: 0.5174459934234619\n",
            "Epoch: 0, iteración: 1990 de 2450, Loss: 0.59168381690979\n",
            "Epoch: 0, iteración: 2000 de 2450, Loss: 0.5436402797698975\n",
            "Epoch: 0, iteración: 2010 de 2450, Loss: 0.6047430038452148\n",
            "Epoch: 0, iteración: 2020 de 2450, Loss: 0.6668519020080567\n",
            "Epoch: 0, iteración: 2030 de 2450, Loss: 0.5805961608886718\n",
            "Epoch: 0, iteración: 2040 de 2450, Loss: 0.538651704788208\n",
            "Epoch: 0, iteración: 2050 de 2450, Loss: 0.7232056140899659\n",
            "Epoch: 0, iteración: 2060 de 2450, Loss: 0.5843733310699463\n",
            "Epoch: 0, iteración: 2070 de 2450, Loss: 0.6363169193267822\n",
            "Epoch: 0, iteración: 2080 de 2450, Loss: 0.5960992336273193\n",
            "Epoch: 0, iteración: 2090 de 2450, Loss: 0.44447946548461914\n",
            "Epoch: 0, iteración: 2100 de 2450, Loss: 0.6657296180725097\n",
            "Epoch: 0, iteración: 2110 de 2450, Loss: 0.5784406185150146\n",
            "Epoch: 0, iteración: 2120 de 2450, Loss: 0.5897882461547852\n",
            "Epoch: 0, iteración: 2130 de 2450, Loss: 0.587666130065918\n",
            "Epoch: 0, iteración: 2140 de 2450, Loss: 0.5708575248718262\n",
            "Epoch: 0, iteración: 2150 de 2450, Loss: 0.6083752632141113\n",
            "Epoch: 0, iteración: 2160 de 2450, Loss: 0.6604365348815918\n",
            "Epoch: 0, iteración: 2170 de 2450, Loss: 0.573897123336792\n",
            "Epoch: 0, iteración: 2180 de 2450, Loss: 0.5334392547607422\n",
            "Epoch: 0, iteración: 2190 de 2450, Loss: 0.5039267063140869\n",
            "Epoch: 0, iteración: 2200 de 2450, Loss: 0.571270227432251\n",
            "Epoch: 0, iteración: 2210 de 2450, Loss: 0.5939685821533203\n",
            "Epoch: 0, iteración: 2220 de 2450, Loss: 0.5811491966247558\n",
            "Epoch: 0, iteración: 2230 de 2450, Loss: 0.6116816997528076\n",
            "Epoch: 0, iteración: 2240 de 2450, Loss: 0.7004704475402832\n",
            "Epoch: 0, iteración: 2250 de 2450, Loss: 0.5699627876281739\n",
            "Epoch: 0, iteración: 2260 de 2450, Loss: 0.5886341094970703\n",
            "Epoch: 0, iteración: 2270 de 2450, Loss: 0.5535571098327636\n",
            "Epoch: 0, iteración: 2280 de 2450, Loss: 0.5966479301452636\n",
            "Epoch: 0, iteración: 2290 de 2450, Loss: 0.5534626960754394\n",
            "Epoch: 0, iteración: 2300 de 2450, Loss: 0.6300154685974121\n",
            "Epoch: 0, iteración: 2310 de 2450, Loss: 0.6309432983398438\n",
            "Epoch: 0, iteración: 2320 de 2450, Loss: 0.6151078701019287\n",
            "Epoch: 0, iteración: 2330 de 2450, Loss: 0.5694104671478272\n",
            "Epoch: 0, iteración: 2340 de 2450, Loss: 0.5287208557128906\n",
            "Epoch: 0, iteración: 2350 de 2450, Loss: 0.5947275638580323\n",
            "Epoch: 0, iteración: 2360 de 2450, Loss: 0.5607270240783692\n",
            "Epoch: 0, iteración: 2370 de 2450, Loss: 0.5807835578918457\n",
            "Epoch: 0, iteración: 2380 de 2450, Loss: 0.7128721237182617\n",
            "Epoch: 0, iteración: 2390 de 2450, Loss: 0.6417936325073242\n",
            "Epoch: 0, iteración: 2400 de 2450, Loss: 0.6154635429382325\n",
            "Epoch: 0, iteración: 2410 de 2450, Loss: 0.5782639980316162\n",
            "Epoch: 0, iteración: 2420 de 2450, Loss: 0.6687390327453613\n",
            "Epoch: 0, iteración: 2430 de 2450, Loss: 0.5730233669281006\n",
            "Epoch: 0, iteración: 2440 de 2450, Loss: 0.6557635307312012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_30.pth\")\n",
        "  print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "metadata": {
        "id": "lyQ3MbOqJ5Ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf49454-0beb-4740-812a-d3d993f44d39"
      },
      "id": "lyQ3MbOqJ5Ac",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Evaluación del modelo"
      ],
      "metadata": {
        "id": "MzuD-XEySqCu"
      },
      "id": "MzuD-XEySqCu"
    },
    {
      "cell_type": "code",
      "source": [
        "def validationBERTSiameseConcat(epoch):\n",
        "  model.eval()\n",
        "  fin_targets=[]\n",
        "  fin_outputs=[]\n",
        "  num_iteraciones = len(testing_loader)\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testing_loader, 0):\n",
        "      ids1 = data['ids1'].to(device)\n",
        "      ids2 = data['ids2'].to(device)\n",
        "      mask1 = data['mask1'].to(device)\n",
        "      mask2 = data['mask2'].to(device)\n",
        "      token_type_ids1 = data[\"token_type_ids1\"].to(device)\n",
        "      token_type_ids2 = data[\"token_type_ids2\"].to(device)\n",
        "      targets = data['target'].to(device)\n",
        "\n",
        "      print(f\"Iteración: {i} de {num_iteraciones}\")\n",
        "\n",
        "      outputs = model(ids1, mask1, token_type_ids1, ids2, mask2, token_type_ids2)\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "  return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "67B8QIu9SqC3"
      },
      "execution_count": null,
      "outputs": [],
      "id": "67B8QIu9SqC3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "94s3nWkGSqC4"
      },
      "id": "94s3nWkGSqC4"
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_30.pth\"):\n",
        "  model = BERTSiameseConcat()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_30.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_30.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "metadata": {
        "id": "-u0ffVg0SqC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6634a98f-8170-4df2-c6f7-d4afd4a7abfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado correctamente\n"
          ]
        }
      ],
      "id": "-u0ffVg0SqC4"
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationBERTSiameseConcat(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "metadata": {
        "id": "uarltMpiSqC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf7dea6-c21b-4a42-a0bd-35d83f14a993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración: 0 de 715\n",
            "Iteración: 1 de 715\n",
            "Iteración: 2 de 715\n",
            "Iteración: 3 de 715\n",
            "Iteración: 4 de 715\n",
            "Iteración: 5 de 715\n",
            "Iteración: 6 de 715\n",
            "Iteración: 7 de 715\n",
            "Iteración: 8 de 715\n",
            "Iteración: 9 de 715\n",
            "Iteración: 10 de 715\n",
            "Iteración: 11 de 715\n",
            "Iteración: 12 de 715\n",
            "Iteración: 13 de 715\n",
            "Iteración: 14 de 715\n",
            "Iteración: 15 de 715\n",
            "Iteración: 16 de 715\n",
            "Iteración: 17 de 715\n",
            "Iteración: 18 de 715\n",
            "Iteración: 19 de 715\n",
            "Iteración: 20 de 715\n",
            "Iteración: 21 de 715\n",
            "Iteración: 22 de 715\n",
            "Iteración: 23 de 715\n",
            "Iteración: 24 de 715\n",
            "Iteración: 25 de 715\n",
            "Iteración: 26 de 715\n",
            "Iteración: 27 de 715\n",
            "Iteración: 28 de 715\n",
            "Iteración: 29 de 715\n",
            "Iteración: 30 de 715\n",
            "Iteración: 31 de 715\n",
            "Iteración: 32 de 715\n",
            "Iteración: 33 de 715\n",
            "Iteración: 34 de 715\n",
            "Iteración: 35 de 715\n",
            "Iteración: 36 de 715\n",
            "Iteración: 37 de 715\n",
            "Iteración: 38 de 715\n",
            "Iteración: 39 de 715\n",
            "Iteración: 40 de 715\n",
            "Iteración: 41 de 715\n",
            "Iteración: 42 de 715\n",
            "Iteración: 43 de 715\n",
            "Iteración: 44 de 715\n",
            "Iteración: 45 de 715\n",
            "Iteración: 46 de 715\n",
            "Iteración: 47 de 715\n",
            "Iteración: 48 de 715\n",
            "Iteración: 49 de 715\n",
            "Iteración: 50 de 715\n",
            "Iteración: 51 de 715\n",
            "Iteración: 52 de 715\n",
            "Iteración: 53 de 715\n",
            "Iteración: 54 de 715\n",
            "Iteración: 55 de 715\n",
            "Iteración: 56 de 715\n",
            "Iteración: 57 de 715\n",
            "Iteración: 58 de 715\n",
            "Iteración: 59 de 715\n",
            "Iteración: 60 de 715\n",
            "Iteración: 61 de 715\n",
            "Iteración: 62 de 715\n",
            "Iteración: 63 de 715\n",
            "Iteración: 64 de 715\n",
            "Iteración: 65 de 715\n",
            "Iteración: 66 de 715\n",
            "Iteración: 67 de 715\n",
            "Iteración: 68 de 715\n",
            "Iteración: 69 de 715\n",
            "Iteración: 70 de 715\n",
            "Iteración: 71 de 715\n",
            "Iteración: 72 de 715\n",
            "Iteración: 73 de 715\n",
            "Iteración: 74 de 715\n",
            "Iteración: 75 de 715\n",
            "Iteración: 76 de 715\n",
            "Iteración: 77 de 715\n",
            "Iteración: 78 de 715\n",
            "Iteración: 79 de 715\n",
            "Iteración: 80 de 715\n",
            "Iteración: 81 de 715\n",
            "Iteración: 82 de 715\n",
            "Iteración: 83 de 715\n",
            "Iteración: 84 de 715\n",
            "Iteración: 85 de 715\n",
            "Iteración: 86 de 715\n",
            "Iteración: 87 de 715\n",
            "Iteración: 88 de 715\n",
            "Iteración: 89 de 715\n",
            "Iteración: 90 de 715\n",
            "Iteración: 91 de 715\n",
            "Iteración: 92 de 715\n",
            "Iteración: 93 de 715\n",
            "Iteración: 94 de 715\n",
            "Iteración: 95 de 715\n",
            "Iteración: 96 de 715\n",
            "Iteración: 97 de 715\n",
            "Iteración: 98 de 715\n",
            "Iteración: 99 de 715\n",
            "Iteración: 100 de 715\n",
            "Iteración: 101 de 715\n",
            "Iteración: 102 de 715\n",
            "Iteración: 103 de 715\n",
            "Iteración: 104 de 715\n",
            "Iteración: 105 de 715\n",
            "Iteración: 106 de 715\n",
            "Iteración: 107 de 715\n",
            "Iteración: 108 de 715\n",
            "Iteración: 109 de 715\n",
            "Iteración: 110 de 715\n",
            "Iteración: 111 de 715\n",
            "Iteración: 112 de 715\n",
            "Iteración: 113 de 715\n",
            "Iteración: 114 de 715\n",
            "Iteración: 115 de 715\n",
            "Iteración: 116 de 715\n",
            "Iteración: 117 de 715\n",
            "Iteración: 118 de 715\n",
            "Iteración: 119 de 715\n",
            "Iteración: 120 de 715\n",
            "Iteración: 121 de 715\n",
            "Iteración: 122 de 715\n",
            "Iteración: 123 de 715\n",
            "Iteración: 124 de 715\n",
            "Iteración: 125 de 715\n",
            "Iteración: 126 de 715\n",
            "Iteración: 127 de 715\n",
            "Iteración: 128 de 715\n",
            "Iteración: 129 de 715\n",
            "Iteración: 130 de 715\n",
            "Iteración: 131 de 715\n",
            "Iteración: 132 de 715\n",
            "Iteración: 133 de 715\n",
            "Iteración: 134 de 715\n",
            "Iteración: 135 de 715\n",
            "Iteración: 136 de 715\n",
            "Iteración: 137 de 715\n",
            "Iteración: 138 de 715\n",
            "Iteración: 139 de 715\n",
            "Iteración: 140 de 715\n",
            "Iteración: 141 de 715\n",
            "Iteración: 142 de 715\n",
            "Iteración: 143 de 715\n",
            "Iteración: 144 de 715\n",
            "Iteración: 145 de 715\n",
            "Iteración: 146 de 715\n",
            "Iteración: 147 de 715\n",
            "Iteración: 148 de 715\n",
            "Iteración: 149 de 715\n",
            "Iteración: 150 de 715\n",
            "Iteración: 151 de 715\n",
            "Iteración: 152 de 715\n",
            "Iteración: 153 de 715\n",
            "Iteración: 154 de 715\n",
            "Iteración: 155 de 715\n",
            "Iteración: 156 de 715\n",
            "Iteración: 157 de 715\n",
            "Iteración: 158 de 715\n",
            "Iteración: 159 de 715\n",
            "Iteración: 160 de 715\n",
            "Iteración: 161 de 715\n",
            "Iteración: 162 de 715\n",
            "Iteración: 163 de 715\n",
            "Iteración: 164 de 715\n",
            "Iteración: 165 de 715\n",
            "Iteración: 166 de 715\n",
            "Iteración: 167 de 715\n",
            "Iteración: 168 de 715\n",
            "Iteración: 169 de 715\n",
            "Iteración: 170 de 715\n",
            "Iteración: 171 de 715\n",
            "Iteración: 172 de 715\n",
            "Iteración: 173 de 715\n",
            "Iteración: 174 de 715\n",
            "Iteración: 175 de 715\n",
            "Iteración: 176 de 715\n",
            "Iteración: 177 de 715\n",
            "Iteración: 178 de 715\n",
            "Iteración: 179 de 715\n",
            "Iteración: 180 de 715\n",
            "Iteración: 181 de 715\n",
            "Iteración: 182 de 715\n",
            "Iteración: 183 de 715\n",
            "Iteración: 184 de 715\n",
            "Iteración: 185 de 715\n",
            "Iteración: 186 de 715\n",
            "Iteración: 187 de 715\n",
            "Iteración: 188 de 715\n",
            "Iteración: 189 de 715\n",
            "Iteración: 190 de 715\n",
            "Iteración: 191 de 715\n",
            "Iteración: 192 de 715\n",
            "Iteración: 193 de 715\n",
            "Iteración: 194 de 715\n",
            "Iteración: 195 de 715\n",
            "Iteración: 196 de 715\n",
            "Iteración: 197 de 715\n",
            "Iteración: 198 de 715\n",
            "Iteración: 199 de 715\n",
            "Iteración: 200 de 715\n",
            "Iteración: 201 de 715\n",
            "Iteración: 202 de 715\n",
            "Iteración: 203 de 715\n",
            "Iteración: 204 de 715\n",
            "Iteración: 205 de 715\n",
            "Iteración: 206 de 715\n",
            "Iteración: 207 de 715\n",
            "Iteración: 208 de 715\n",
            "Iteración: 209 de 715\n",
            "Iteración: 210 de 715\n",
            "Iteración: 211 de 715\n",
            "Iteración: 212 de 715\n",
            "Iteración: 213 de 715\n",
            "Iteración: 214 de 715\n",
            "Iteración: 215 de 715\n",
            "Iteración: 216 de 715\n",
            "Iteración: 217 de 715\n",
            "Iteración: 218 de 715\n",
            "Iteración: 219 de 715\n",
            "Iteración: 220 de 715\n",
            "Iteración: 221 de 715\n",
            "Iteración: 222 de 715\n",
            "Iteración: 223 de 715\n",
            "Iteración: 224 de 715\n",
            "Iteración: 225 de 715\n",
            "Iteración: 226 de 715\n",
            "Iteración: 227 de 715\n",
            "Iteración: 228 de 715\n",
            "Iteración: 229 de 715\n",
            "Iteración: 230 de 715\n",
            "Iteración: 231 de 715\n",
            "Iteración: 232 de 715\n",
            "Iteración: 233 de 715\n",
            "Iteración: 234 de 715\n",
            "Iteración: 235 de 715\n",
            "Iteración: 236 de 715\n",
            "Iteración: 237 de 715\n",
            "Iteración: 238 de 715\n",
            "Iteración: 239 de 715\n",
            "Iteración: 240 de 715\n",
            "Iteración: 241 de 715\n",
            "Iteración: 242 de 715\n",
            "Iteración: 243 de 715\n",
            "Iteración: 244 de 715\n",
            "Iteración: 245 de 715\n",
            "Iteración: 246 de 715\n",
            "Iteración: 247 de 715\n",
            "Iteración: 248 de 715\n",
            "Iteración: 249 de 715\n",
            "Iteración: 250 de 715\n",
            "Iteración: 251 de 715\n",
            "Iteración: 252 de 715\n",
            "Iteración: 253 de 715\n",
            "Iteración: 254 de 715\n",
            "Iteración: 255 de 715\n",
            "Iteración: 256 de 715\n",
            "Iteración: 257 de 715\n",
            "Iteración: 258 de 715\n",
            "Iteración: 259 de 715\n",
            "Iteración: 260 de 715\n",
            "Iteración: 261 de 715\n",
            "Iteración: 262 de 715\n",
            "Iteración: 263 de 715\n",
            "Iteración: 264 de 715\n",
            "Iteración: 265 de 715\n",
            "Iteración: 266 de 715\n",
            "Iteración: 267 de 715\n",
            "Iteración: 268 de 715\n",
            "Iteración: 269 de 715\n",
            "Iteración: 270 de 715\n",
            "Iteración: 271 de 715\n",
            "Iteración: 272 de 715\n",
            "Iteración: 273 de 715\n",
            "Iteración: 274 de 715\n",
            "Iteración: 275 de 715\n",
            "Iteración: 276 de 715\n",
            "Iteración: 277 de 715\n",
            "Iteración: 278 de 715\n",
            "Iteración: 279 de 715\n",
            "Iteración: 280 de 715\n",
            "Iteración: 281 de 715\n",
            "Iteración: 282 de 715\n",
            "Iteración: 283 de 715\n",
            "Iteración: 284 de 715\n",
            "Iteración: 285 de 715\n",
            "Iteración: 286 de 715\n",
            "Iteración: 287 de 715\n",
            "Iteración: 288 de 715\n",
            "Iteración: 289 de 715\n",
            "Iteración: 290 de 715\n",
            "Iteración: 291 de 715\n",
            "Iteración: 292 de 715\n",
            "Iteración: 293 de 715\n",
            "Iteración: 294 de 715\n",
            "Iteración: 295 de 715\n",
            "Iteración: 296 de 715\n",
            "Iteración: 297 de 715\n",
            "Iteración: 298 de 715\n",
            "Iteración: 299 de 715\n",
            "Iteración: 300 de 715\n",
            "Iteración: 301 de 715\n",
            "Iteración: 302 de 715\n",
            "Iteración: 303 de 715\n",
            "Iteración: 304 de 715\n",
            "Iteración: 305 de 715\n",
            "Iteración: 306 de 715\n",
            "Iteración: 307 de 715\n",
            "Iteración: 308 de 715\n",
            "Iteración: 309 de 715\n",
            "Iteración: 310 de 715\n",
            "Iteración: 311 de 715\n",
            "Iteración: 312 de 715\n",
            "Iteración: 313 de 715\n",
            "Iteración: 314 de 715\n",
            "Iteración: 315 de 715\n",
            "Iteración: 316 de 715\n",
            "Iteración: 317 de 715\n",
            "Iteración: 318 de 715\n",
            "Iteración: 319 de 715\n",
            "Iteración: 320 de 715\n",
            "Iteración: 321 de 715\n",
            "Iteración: 322 de 715\n",
            "Iteración: 323 de 715\n",
            "Iteración: 324 de 715\n",
            "Iteración: 325 de 715\n",
            "Iteración: 326 de 715\n",
            "Iteración: 327 de 715\n",
            "Iteración: 328 de 715\n",
            "Iteración: 329 de 715\n",
            "Iteración: 330 de 715\n",
            "Iteración: 331 de 715\n",
            "Iteración: 332 de 715\n",
            "Iteración: 333 de 715\n",
            "Iteración: 334 de 715\n",
            "Iteración: 335 de 715\n",
            "Iteración: 336 de 715\n",
            "Iteración: 337 de 715\n",
            "Iteración: 338 de 715\n",
            "Iteración: 339 de 715\n",
            "Iteración: 340 de 715\n",
            "Iteración: 341 de 715\n",
            "Iteración: 342 de 715\n",
            "Iteración: 343 de 715\n",
            "Iteración: 344 de 715\n",
            "Iteración: 345 de 715\n",
            "Iteración: 346 de 715\n",
            "Iteración: 347 de 715\n",
            "Iteración: 348 de 715\n",
            "Iteración: 349 de 715\n",
            "Iteración: 350 de 715\n",
            "Iteración: 351 de 715\n",
            "Iteración: 352 de 715\n",
            "Iteración: 353 de 715\n",
            "Iteración: 354 de 715\n",
            "Iteración: 355 de 715\n",
            "Iteración: 356 de 715\n",
            "Iteración: 357 de 715\n",
            "Iteración: 358 de 715\n",
            "Iteración: 359 de 715\n",
            "Iteración: 360 de 715\n",
            "Iteración: 361 de 715\n",
            "Iteración: 362 de 715\n",
            "Iteración: 363 de 715\n",
            "Iteración: 364 de 715\n",
            "Iteración: 365 de 715\n",
            "Iteración: 366 de 715\n",
            "Iteración: 367 de 715\n",
            "Iteración: 368 de 715\n",
            "Iteración: 369 de 715\n",
            "Iteración: 370 de 715\n",
            "Iteración: 371 de 715\n",
            "Iteración: 372 de 715\n",
            "Iteración: 373 de 715\n",
            "Iteración: 374 de 715\n",
            "Iteración: 375 de 715\n",
            "Iteración: 376 de 715\n",
            "Iteración: 377 de 715\n",
            "Iteración: 378 de 715\n",
            "Iteración: 379 de 715\n",
            "Iteración: 380 de 715\n",
            "Iteración: 381 de 715\n",
            "Iteración: 382 de 715\n",
            "Iteración: 383 de 715\n",
            "Iteración: 384 de 715\n",
            "Iteración: 385 de 715\n",
            "Iteración: 386 de 715\n",
            "Iteración: 387 de 715\n",
            "Iteración: 388 de 715\n",
            "Iteración: 389 de 715\n",
            "Iteración: 390 de 715\n",
            "Iteración: 391 de 715\n",
            "Iteración: 392 de 715\n",
            "Iteración: 393 de 715\n",
            "Iteración: 394 de 715\n",
            "Iteración: 395 de 715\n",
            "Iteración: 396 de 715\n",
            "Iteración: 397 de 715\n",
            "Iteración: 398 de 715\n",
            "Iteración: 399 de 715\n",
            "Iteración: 400 de 715\n",
            "Iteración: 401 de 715\n",
            "Iteración: 402 de 715\n",
            "Iteración: 403 de 715\n",
            "Iteración: 404 de 715\n",
            "Iteración: 405 de 715\n",
            "Iteración: 406 de 715\n",
            "Iteración: 407 de 715\n",
            "Iteración: 408 de 715\n",
            "Iteración: 409 de 715\n",
            "Iteración: 410 de 715\n",
            "Iteración: 411 de 715\n",
            "Iteración: 412 de 715\n",
            "Iteración: 413 de 715\n",
            "Iteración: 414 de 715\n",
            "Iteración: 415 de 715\n",
            "Iteración: 416 de 715\n",
            "Iteración: 417 de 715\n",
            "Iteración: 418 de 715\n",
            "Iteración: 419 de 715\n",
            "Iteración: 420 de 715\n",
            "Iteración: 421 de 715\n",
            "Iteración: 422 de 715\n",
            "Iteración: 423 de 715\n",
            "Iteración: 424 de 715\n",
            "Iteración: 425 de 715\n",
            "Iteración: 426 de 715\n",
            "Iteración: 427 de 715\n",
            "Iteración: 428 de 715\n",
            "Iteración: 429 de 715\n",
            "Iteración: 430 de 715\n",
            "Iteración: 431 de 715\n",
            "Iteración: 432 de 715\n",
            "Iteración: 433 de 715\n",
            "Iteración: 434 de 715\n",
            "Iteración: 435 de 715\n",
            "Iteración: 436 de 715\n",
            "Iteración: 437 de 715\n",
            "Iteración: 438 de 715\n",
            "Iteración: 439 de 715\n",
            "Iteración: 440 de 715\n",
            "Iteración: 441 de 715\n",
            "Iteración: 442 de 715\n",
            "Iteración: 443 de 715\n",
            "Iteración: 444 de 715\n",
            "Iteración: 445 de 715\n",
            "Iteración: 446 de 715\n",
            "Iteración: 447 de 715\n",
            "Iteración: 448 de 715\n",
            "Iteración: 449 de 715\n",
            "Iteración: 450 de 715\n",
            "Iteración: 451 de 715\n",
            "Iteración: 452 de 715\n",
            "Iteración: 453 de 715\n",
            "Iteración: 454 de 715\n",
            "Iteración: 455 de 715\n",
            "Iteración: 456 de 715\n",
            "Iteración: 457 de 715\n",
            "Iteración: 458 de 715\n",
            "Iteración: 459 de 715\n",
            "Iteración: 460 de 715\n",
            "Iteración: 461 de 715\n",
            "Iteración: 462 de 715\n",
            "Iteración: 463 de 715\n",
            "Iteración: 464 de 715\n",
            "Iteración: 465 de 715\n",
            "Iteración: 466 de 715\n",
            "Iteración: 467 de 715\n",
            "Iteración: 468 de 715\n",
            "Iteración: 469 de 715\n",
            "Iteración: 470 de 715\n",
            "Iteración: 471 de 715\n",
            "Iteración: 472 de 715\n",
            "Iteración: 473 de 715\n",
            "Iteración: 474 de 715\n",
            "Iteración: 475 de 715\n",
            "Iteración: 476 de 715\n",
            "Iteración: 477 de 715\n",
            "Iteración: 478 de 715\n",
            "Iteración: 479 de 715\n",
            "Iteración: 480 de 715\n",
            "Iteración: 481 de 715\n",
            "Iteración: 482 de 715\n",
            "Iteración: 483 de 715\n",
            "Iteración: 484 de 715\n",
            "Iteración: 485 de 715\n",
            "Iteración: 486 de 715\n",
            "Iteración: 487 de 715\n",
            "Iteración: 488 de 715\n",
            "Iteración: 489 de 715\n",
            "Iteración: 490 de 715\n",
            "Iteración: 491 de 715\n",
            "Iteración: 492 de 715\n",
            "Iteración: 493 de 715\n",
            "Iteración: 494 de 715\n",
            "Iteración: 495 de 715\n",
            "Iteración: 496 de 715\n",
            "Iteración: 497 de 715\n",
            "Iteración: 498 de 715\n",
            "Iteración: 499 de 715\n",
            "Iteración: 500 de 715\n",
            "Iteración: 501 de 715\n",
            "Iteración: 502 de 715\n",
            "Iteración: 503 de 715\n",
            "Iteración: 504 de 715\n",
            "Iteración: 505 de 715\n",
            "Iteración: 506 de 715\n",
            "Iteración: 507 de 715\n",
            "Iteración: 508 de 715\n",
            "Iteración: 509 de 715\n",
            "Iteración: 510 de 715\n",
            "Iteración: 511 de 715\n",
            "Iteración: 512 de 715\n",
            "Iteración: 513 de 715\n",
            "Iteración: 514 de 715\n",
            "Iteración: 515 de 715\n",
            "Iteración: 516 de 715\n",
            "Iteración: 517 de 715\n",
            "Iteración: 518 de 715\n",
            "Iteración: 519 de 715\n",
            "Iteración: 520 de 715\n",
            "Iteración: 521 de 715\n",
            "Iteración: 522 de 715\n",
            "Iteración: 523 de 715\n",
            "Iteración: 524 de 715\n",
            "Iteración: 525 de 715\n",
            "Iteración: 526 de 715\n",
            "Iteración: 527 de 715\n",
            "Iteración: 528 de 715\n",
            "Iteración: 529 de 715\n",
            "Iteración: 530 de 715\n",
            "Iteración: 531 de 715\n",
            "Iteración: 532 de 715\n",
            "Iteración: 533 de 715\n",
            "Iteración: 534 de 715\n",
            "Iteración: 535 de 715\n",
            "Iteración: 536 de 715\n",
            "Iteración: 537 de 715\n",
            "Iteración: 538 de 715\n",
            "Iteración: 539 de 715\n",
            "Iteración: 540 de 715\n",
            "Iteración: 541 de 715\n",
            "Iteración: 542 de 715\n",
            "Iteración: 543 de 715\n",
            "Iteración: 544 de 715\n",
            "Iteración: 545 de 715\n",
            "Iteración: 546 de 715\n",
            "Iteración: 547 de 715\n",
            "Iteración: 548 de 715\n",
            "Iteración: 549 de 715\n",
            "Iteración: 550 de 715\n",
            "Iteración: 551 de 715\n",
            "Iteración: 552 de 715\n",
            "Iteración: 553 de 715\n",
            "Iteración: 554 de 715\n",
            "Iteración: 555 de 715\n",
            "Iteración: 556 de 715\n",
            "Iteración: 557 de 715\n",
            "Iteración: 558 de 715\n",
            "Iteración: 559 de 715\n",
            "Iteración: 560 de 715\n",
            "Iteración: 561 de 715\n",
            "Iteración: 562 de 715\n",
            "Iteración: 563 de 715\n",
            "Iteración: 564 de 715\n",
            "Iteración: 565 de 715\n",
            "Iteración: 566 de 715\n",
            "Iteración: 567 de 715\n",
            "Iteración: 568 de 715\n",
            "Iteración: 569 de 715\n",
            "Iteración: 570 de 715\n",
            "Iteración: 571 de 715\n",
            "Iteración: 572 de 715\n",
            "Iteración: 573 de 715\n",
            "Iteración: 574 de 715\n",
            "Iteración: 575 de 715\n",
            "Iteración: 576 de 715\n",
            "Iteración: 577 de 715\n",
            "Iteración: 578 de 715\n",
            "Iteración: 579 de 715\n",
            "Iteración: 580 de 715\n",
            "Iteración: 581 de 715\n",
            "Iteración: 582 de 715\n",
            "Iteración: 583 de 715\n",
            "Iteración: 584 de 715\n",
            "Iteración: 585 de 715\n",
            "Iteración: 586 de 715\n",
            "Iteración: 587 de 715\n",
            "Iteración: 588 de 715\n",
            "Iteración: 589 de 715\n",
            "Iteración: 590 de 715\n",
            "Iteración: 591 de 715\n",
            "Iteración: 592 de 715\n",
            "Iteración: 593 de 715\n",
            "Iteración: 594 de 715\n",
            "Iteración: 595 de 715\n",
            "Iteración: 596 de 715\n",
            "Iteración: 597 de 715\n",
            "Iteración: 598 de 715\n",
            "Iteración: 599 de 715\n",
            "Iteración: 600 de 715\n",
            "Iteración: 601 de 715\n",
            "Iteración: 602 de 715\n",
            "Iteración: 603 de 715\n",
            "Iteración: 604 de 715\n",
            "Iteración: 605 de 715\n",
            "Iteración: 606 de 715\n",
            "Iteración: 607 de 715\n",
            "Iteración: 608 de 715\n",
            "Iteración: 609 de 715\n",
            "Iteración: 610 de 715\n",
            "Iteración: 611 de 715\n",
            "Iteración: 612 de 715\n",
            "Iteración: 613 de 715\n",
            "Iteración: 614 de 715\n",
            "Iteración: 615 de 715\n",
            "Iteración: 616 de 715\n",
            "Iteración: 617 de 715\n",
            "Iteración: 618 de 715\n",
            "Iteración: 619 de 715\n",
            "Iteración: 620 de 715\n",
            "Iteración: 621 de 715\n",
            "Iteración: 622 de 715\n",
            "Iteración: 623 de 715\n",
            "Iteración: 624 de 715\n",
            "Iteración: 625 de 715\n",
            "Iteración: 626 de 715\n",
            "Iteración: 627 de 715\n",
            "Iteración: 628 de 715\n",
            "Iteración: 629 de 715\n",
            "Iteración: 630 de 715\n",
            "Iteración: 631 de 715\n",
            "Iteración: 632 de 715\n",
            "Iteración: 633 de 715\n",
            "Iteración: 634 de 715\n",
            "Iteración: 635 de 715\n",
            "Iteración: 636 de 715\n",
            "Iteración: 637 de 715\n",
            "Iteración: 638 de 715\n",
            "Iteración: 639 de 715\n",
            "Iteración: 640 de 715\n",
            "Iteración: 641 de 715\n",
            "Iteración: 642 de 715\n",
            "Iteración: 643 de 715\n",
            "Iteración: 644 de 715\n",
            "Iteración: 645 de 715\n",
            "Iteración: 646 de 715\n",
            "Iteración: 647 de 715\n",
            "Iteración: 648 de 715\n",
            "Iteración: 649 de 715\n",
            "Iteración: 650 de 715\n",
            "Iteración: 651 de 715\n",
            "Iteración: 652 de 715\n",
            "Iteración: 653 de 715\n",
            "Iteración: 654 de 715\n",
            "Iteración: 655 de 715\n",
            "Iteración: 656 de 715\n",
            "Iteración: 657 de 715\n",
            "Iteración: 658 de 715\n",
            "Iteración: 659 de 715\n",
            "Iteración: 660 de 715\n",
            "Iteración: 661 de 715\n",
            "Iteración: 662 de 715\n",
            "Iteración: 663 de 715\n",
            "Iteración: 664 de 715\n",
            "Iteración: 665 de 715\n",
            "Iteración: 666 de 715\n",
            "Iteración: 667 de 715\n",
            "Iteración: 668 de 715\n",
            "Iteración: 669 de 715\n",
            "Iteración: 670 de 715\n",
            "Iteración: 671 de 715\n",
            "Iteración: 672 de 715\n",
            "Iteración: 673 de 715\n",
            "Iteración: 674 de 715\n",
            "Iteración: 675 de 715\n",
            "Iteración: 676 de 715\n",
            "Iteración: 677 de 715\n",
            "Iteración: 678 de 715\n",
            "Iteración: 679 de 715\n",
            "Iteración: 680 de 715\n",
            "Iteración: 681 de 715\n",
            "Iteración: 682 de 715\n",
            "Iteración: 683 de 715\n",
            "Iteración: 684 de 715\n",
            "Iteración: 685 de 715\n",
            "Iteración: 686 de 715\n",
            "Iteración: 687 de 715\n",
            "Iteración: 688 de 715\n",
            "Iteración: 689 de 715\n",
            "Iteración: 690 de 715\n",
            "Iteración: 691 de 715\n",
            "Iteración: 692 de 715\n",
            "Iteración: 693 de 715\n",
            "Iteración: 694 de 715\n",
            "Iteración: 695 de 715\n",
            "Iteración: 696 de 715\n",
            "Iteración: 697 de 715\n",
            "Iteración: 698 de 715\n",
            "Iteración: 699 de 715\n",
            "Iteración: 700 de 715\n",
            "Iteración: 701 de 715\n",
            "Iteración: 702 de 715\n",
            "Iteración: 703 de 715\n",
            "Iteración: 704 de 715\n",
            "Iteración: 705 de 715\n",
            "Iteración: 706 de 715\n",
            "Iteración: 707 de 715\n",
            "Iteración: 708 de 715\n",
            "Iteración: 709 de 715\n",
            "Iteración: 710 de 715\n",
            "Iteración: 711 de 715\n",
            "Iteración: 712 de 715\n",
            "Iteración: 713 de 715\n",
            "Iteración: 714 de 715\n",
            "Accuracy Score = 0.7260241016556219\n",
            "F1 Score (Micro) = 0.7260241016556219\n",
            "F1 Score (Macro) = 0.42063381441731396\n"
          ]
        }
      ],
      "id": "uarltMpiSqC4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Entrenamiento del modelo (50% de datos) LR = 1e-7"
      ],
      "metadata": {
        "id": "yFEjEXcOeHUZ"
      },
      "id": "yFEjEXcOeHUZ"
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainBERTSiameseConcat(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkYzh2tYeLZQ",
        "outputId": "00ae4a6d-2202-4c13-92c3-0d9cde2dd683"
      },
      "id": "LkYzh2tYeLZQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración: 0 de 4083, Loss: 0.06998984813690186\n",
            "Epoch: 0, iteración: 10 de 4083, Loss: 0.7256251811981201\n",
            "Epoch: 0, iteración: 20 de 4083, Loss: 0.7244583606719971\n",
            "Epoch: 0, iteración: 30 de 4083, Loss: 0.7038580894470214\n",
            "Epoch: 0, iteración: 40 de 4083, Loss: 0.7087534427642822\n",
            "Epoch: 0, iteración: 50 de 4083, Loss: 0.7203779220581055\n",
            "Epoch: 0, iteración: 60 de 4083, Loss: 0.7072153091430664\n",
            "Epoch: 0, iteración: 70 de 4083, Loss: 0.7014464855194091\n",
            "Epoch: 0, iteración: 80 de 4083, Loss: 0.7164917945861816\n",
            "Epoch: 0, iteración: 90 de 4083, Loss: 0.7073198318481445\n",
            "Epoch: 0, iteración: 100 de 4083, Loss: 0.7067512989044189\n",
            "Epoch: 0, iteración: 110 de 4083, Loss: 0.7066843986511231\n",
            "Epoch: 0, iteración: 120 de 4083, Loss: 0.6981516361236573\n",
            "Epoch: 0, iteración: 130 de 4083, Loss: 0.7079751014709472\n",
            "Epoch: 0, iteración: 140 de 4083, Loss: 0.6923242568969726\n",
            "Epoch: 0, iteración: 150 de 4083, Loss: 0.6968338966369629\n",
            "Epoch: 0, iteración: 160 de 4083, Loss: 0.6899566650390625\n",
            "Epoch: 0, iteración: 170 de 4083, Loss: 0.6990839004516601\n",
            "Epoch: 0, iteración: 180 de 4083, Loss: 0.6968461036682129\n",
            "Epoch: 0, iteración: 190 de 4083, Loss: 0.6950432777404785\n",
            "Epoch: 0, iteración: 200 de 4083, Loss: 0.6911473751068116\n",
            "Epoch: 0, iteración: 210 de 4083, Loss: 0.6881477355957031\n",
            "Epoch: 0, iteración: 220 de 4083, Loss: 0.6762651920318603\n",
            "Epoch: 0, iteración: 230 de 4083, Loss: 0.6789770126342773\n",
            "Epoch: 0, iteración: 240 de 4083, Loss: 0.6771658420562744\n",
            "Epoch: 0, iteración: 250 de 4083, Loss: 0.6854567050933837\n",
            "Epoch: 0, iteración: 260 de 4083, Loss: 0.6695834636688233\n",
            "Epoch: 0, iteración: 270 de 4083, Loss: 0.6797688484191895\n",
            "Epoch: 0, iteración: 280 de 4083, Loss: 0.6816482067108154\n",
            "Epoch: 0, iteración: 290 de 4083, Loss: 0.6649600982666015\n",
            "Epoch: 0, iteración: 300 de 4083, Loss: 0.6573718070983887\n",
            "Epoch: 0, iteración: 310 de 4083, Loss: 0.6710947990417481\n",
            "Epoch: 0, iteración: 320 de 4083, Loss: 0.663616418838501\n",
            "Epoch: 0, iteración: 330 de 4083, Loss: 0.6672682762145996\n",
            "Epoch: 0, iteración: 340 de 4083, Loss: 0.6659416675567627\n",
            "Epoch: 0, iteración: 350 de 4083, Loss: 0.6658961296081543\n",
            "Epoch: 0, iteración: 360 de 4083, Loss: 0.6700263977050781\n",
            "Epoch: 0, iteración: 370 de 4083, Loss: 0.6523487091064453\n",
            "Epoch: 0, iteración: 380 de 4083, Loss: 0.6567773818969727\n",
            "Epoch: 0, iteración: 390 de 4083, Loss: 0.658866024017334\n",
            "Epoch: 0, iteración: 400 de 4083, Loss: 0.6619186401367188\n",
            "Epoch: 0, iteración: 410 de 4083, Loss: 0.642824935913086\n",
            "Epoch: 0, iteración: 420 de 4083, Loss: 0.6427348613739013\n",
            "Epoch: 0, iteración: 430 de 4083, Loss: 0.6570381641387939\n",
            "Epoch: 0, iteración: 440 de 4083, Loss: 0.6475121021270752\n",
            "Epoch: 0, iteración: 450 de 4083, Loss: 0.6602386951446533\n",
            "Epoch: 0, iteración: 460 de 4083, Loss: 0.6543941974639893\n",
            "Epoch: 0, iteración: 470 de 4083, Loss: 0.6485896587371827\n",
            "Epoch: 0, iteración: 480 de 4083, Loss: 0.6358804702758789\n",
            "Epoch: 0, iteración: 490 de 4083, Loss: 0.6215337753295899\n",
            "Epoch: 0, iteración: 500 de 4083, Loss: 0.6575412273406982\n",
            "Epoch: 0, iteración: 510 de 4083, Loss: 0.6332464694976807\n",
            "Epoch: 0, iteración: 520 de 4083, Loss: 0.6404739856719971\n",
            "Epoch: 0, iteración: 530 de 4083, Loss: 0.6326961994171143\n",
            "Epoch: 0, iteración: 540 de 4083, Loss: 0.6241077899932861\n",
            "Epoch: 0, iteración: 550 de 4083, Loss: 0.6037148475646973\n",
            "Epoch: 0, iteración: 560 de 4083, Loss: 0.6495621681213379\n",
            "Epoch: 0, iteración: 570 de 4083, Loss: 0.6263067245483398\n",
            "Epoch: 0, iteración: 580 de 4083, Loss: 0.6616176128387451\n",
            "Epoch: 0, iteración: 590 de 4083, Loss: 0.6543526172637939\n",
            "Epoch: 0, iteración: 600 de 4083, Loss: 0.6363605499267578\n",
            "Epoch: 0, iteración: 610 de 4083, Loss: 0.6007575988769531\n",
            "Epoch: 0, iteración: 620 de 4083, Loss: 0.6245008945465088\n",
            "Epoch: 0, iteración: 630 de 4083, Loss: 0.6361000537872314\n",
            "Epoch: 0, iteración: 640 de 4083, Loss: 0.633182430267334\n",
            "Epoch: 0, iteración: 650 de 4083, Loss: 0.5867587566375733\n",
            "Epoch: 0, iteración: 660 de 4083, Loss: 0.619757890701294\n",
            "Epoch: 0, iteración: 670 de 4083, Loss: 0.6272481441497803\n",
            "Epoch: 0, iteración: 680 de 4083, Loss: 0.5969603538513184\n",
            "Epoch: 0, iteración: 690 de 4083, Loss: 0.6321103572845459\n",
            "Epoch: 0, iteración: 700 de 4083, Loss: 0.6431089401245117\n",
            "Epoch: 0, iteración: 710 de 4083, Loss: 0.5588724613189697\n",
            "Epoch: 0, iteración: 720 de 4083, Loss: 0.6067444801330566\n",
            "Epoch: 0, iteración: 730 de 4083, Loss: 0.6023287773132324\n",
            "Epoch: 0, iteración: 740 de 4083, Loss: 0.6340470314025879\n",
            "Epoch: 0, iteración: 750 de 4083, Loss: 0.6053629875183105\n",
            "Epoch: 0, iteración: 760 de 4083, Loss: 0.600566291809082\n",
            "Epoch: 0, iteración: 770 de 4083, Loss: 0.6028029918670654\n",
            "Epoch: 0, iteración: 780 de 4083, Loss: 0.6419277667999268\n",
            "Epoch: 0, iteración: 790 de 4083, Loss: 0.6247276306152344\n",
            "Epoch: 0, iteración: 800 de 4083, Loss: 0.5752109050750732\n",
            "Epoch: 0, iteración: 810 de 4083, Loss: 0.6483585357666015\n",
            "Epoch: 0, iteración: 820 de 4083, Loss: 0.5764156818389893\n",
            "Epoch: 0, iteración: 830 de 4083, Loss: 0.6107635974884034\n",
            "Epoch: 0, iteración: 840 de 4083, Loss: 0.6171050071716309\n",
            "Epoch: 0, iteración: 850 de 4083, Loss: 0.6050931930541992\n",
            "Epoch: 0, iteración: 860 de 4083, Loss: 0.6536524772644043\n",
            "Epoch: 0, iteración: 870 de 4083, Loss: 0.5771311283111572\n",
            "Epoch: 0, iteración: 880 de 4083, Loss: 0.5990403175354004\n",
            "Epoch: 0, iteración: 890 de 4083, Loss: 0.647418737411499\n",
            "Epoch: 0, iteración: 900 de 4083, Loss: 0.5958454608917236\n",
            "Epoch: 0, iteración: 910 de 4083, Loss: 0.6342082023620605\n",
            "Epoch: 0, iteración: 920 de 4083, Loss: 0.5742825031280517\n",
            "Epoch: 0, iteración: 930 de 4083, Loss: 0.5970419883728028\n",
            "Epoch: 0, iteración: 940 de 4083, Loss: 0.6119646072387696\n",
            "Epoch: 0, iteración: 950 de 4083, Loss: 0.5806686401367187\n",
            "Epoch: 0, iteración: 960 de 4083, Loss: 0.563145637512207\n",
            "Epoch: 0, iteración: 970 de 4083, Loss: 0.6163588047027588\n",
            "Epoch: 0, iteración: 980 de 4083, Loss: 0.5802908897399902\n",
            "Epoch: 0, iteración: 990 de 4083, Loss: 0.5696924209594727\n",
            "Epoch: 0, iteración: 1000 de 4083, Loss: 0.6182379245758056\n",
            "Epoch: 0, iteración: 1010 de 4083, Loss: 0.5872020721435547\n",
            "Epoch: 0, iteración: 1020 de 4083, Loss: 0.5999317169189453\n",
            "Epoch: 0, iteración: 1030 de 4083, Loss: 0.6299762725830078\n",
            "Epoch: 0, iteración: 1040 de 4083, Loss: 0.5846139430999756\n",
            "Epoch: 0, iteración: 1050 de 4083, Loss: 0.5928678512573242\n",
            "Epoch: 0, iteración: 1060 de 4083, Loss: 0.5896255970001221\n",
            "Epoch: 0, iteración: 1070 de 4083, Loss: 0.6675500869750977\n",
            "Epoch: 0, iteración: 1080 de 4083, Loss: 0.5390621662139893\n",
            "Epoch: 0, iteración: 1090 de 4083, Loss: 0.5990048885345459\n",
            "Epoch: 0, iteración: 1100 de 4083, Loss: 0.621584701538086\n",
            "Epoch: 0, iteración: 1110 de 4083, Loss: 0.6328651428222656\n",
            "Epoch: 0, iteración: 1120 de 4083, Loss: 0.5885768413543702\n",
            "Epoch: 0, iteración: 1130 de 4083, Loss: 0.5898714542388916\n",
            "Epoch: 0, iteración: 1140 de 4083, Loss: 0.6080471992492675\n",
            "Epoch: 0, iteración: 1150 de 4083, Loss: 0.6519574165344239\n",
            "Epoch: 0, iteración: 1160 de 4083, Loss: 0.5513701438903809\n",
            "Epoch: 0, iteración: 1170 de 4083, Loss: 0.5627945899963379\n",
            "Epoch: 0, iteración: 1180 de 4083, Loss: 0.6132556915283203\n",
            "Epoch: 0, iteración: 1190 de 4083, Loss: 0.6145097732543945\n",
            "Epoch: 0, iteración: 1200 de 4083, Loss: 0.6197278499603271\n",
            "Epoch: 0, iteración: 1210 de 4083, Loss: 0.6239251613616943\n",
            "Epoch: 0, iteración: 1220 de 4083, Loss: 0.6170485019683838\n",
            "Epoch: 0, iteración: 1230 de 4083, Loss: 0.5901746273040771\n",
            "Epoch: 0, iteración: 1240 de 4083, Loss: 0.5634734630584717\n",
            "Epoch: 0, iteración: 1250 de 4083, Loss: 0.6135016441345215\n",
            "Epoch: 0, iteración: 1260 de 4083, Loss: 0.6070724964141846\n",
            "Epoch: 0, iteración: 1270 de 4083, Loss: 0.6427611827850341\n",
            "Epoch: 0, iteración: 1280 de 4083, Loss: 0.5802553176879883\n",
            "Epoch: 0, iteración: 1290 de 4083, Loss: 0.6487780570983886\n",
            "Epoch: 0, iteración: 1300 de 4083, Loss: 0.6385558128356934\n",
            "Epoch: 0, iteración: 1310 de 4083, Loss: 0.5374529361724854\n",
            "Epoch: 0, iteración: 1320 de 4083, Loss: 0.5926790237426758\n",
            "Epoch: 0, iteración: 1330 de 4083, Loss: 0.628001356124878\n",
            "Epoch: 0, iteración: 1340 de 4083, Loss: 0.5880162239074707\n",
            "Epoch: 0, iteración: 1350 de 4083, Loss: 0.5610817909240723\n",
            "Epoch: 0, iteración: 1360 de 4083, Loss: 0.5473016262054443\n",
            "Epoch: 0, iteración: 1370 de 4083, Loss: 0.5750599384307862\n",
            "Epoch: 0, iteración: 1380 de 4083, Loss: 0.6365103721618652\n",
            "Epoch: 0, iteración: 1390 de 4083, Loss: 0.5669282913208008\n",
            "Epoch: 0, iteración: 1400 de 4083, Loss: 0.6193418979644776\n",
            "Epoch: 0, iteración: 1410 de 4083, Loss: 0.6489882469177246\n",
            "Epoch: 0, iteración: 1420 de 4083, Loss: 0.6124937534332275\n",
            "Epoch: 0, iteración: 1430 de 4083, Loss: 0.5959442615509033\n",
            "Epoch: 0, iteración: 1440 de 4083, Loss: 0.5573883056640625\n",
            "Epoch: 0, iteración: 1450 de 4083, Loss: 0.5504464626312255\n",
            "Epoch: 0, iteración: 1460 de 4083, Loss: 0.6208123207092285\n",
            "Epoch: 0, iteración: 1470 de 4083, Loss: 0.5337209701538086\n",
            "Epoch: 0, iteración: 1480 de 4083, Loss: 0.5050269603729248\n",
            "Epoch: 0, iteración: 1490 de 4083, Loss: 0.5761195182800293\n",
            "Epoch: 0, iteración: 1500 de 4083, Loss: 0.5907397270202637\n",
            "Epoch: 0, iteración: 1510 de 4083, Loss: 0.6059493541717529\n",
            "Epoch: 0, iteración: 1520 de 4083, Loss: 0.6131855964660644\n",
            "Epoch: 0, iteración: 1530 de 4083, Loss: 0.5423065185546875\n",
            "Epoch: 0, iteración: 1540 de 4083, Loss: 0.5702323913574219\n",
            "Epoch: 0, iteración: 1550 de 4083, Loss: 0.5727702140808105\n",
            "Epoch: 0, iteración: 1560 de 4083, Loss: 0.5837983131408692\n",
            "Epoch: 0, iteración: 1570 de 4083, Loss: 0.5174689292907715\n",
            "Epoch: 0, iteración: 1580 de 4083, Loss: 0.5666490077972413\n",
            "Epoch: 0, iteración: 1590 de 4083, Loss: 0.5978938102722168\n",
            "Epoch: 0, iteración: 1600 de 4083, Loss: 0.5837274074554444\n",
            "Epoch: 0, iteración: 1610 de 4083, Loss: 0.6299135208129882\n",
            "Epoch: 0, iteración: 1620 de 4083, Loss: 0.566217041015625\n",
            "Epoch: 0, iteración: 1630 de 4083, Loss: 0.5994513511657715\n",
            "Epoch: 0, iteración: 1640 de 4083, Loss: 0.5251392364501953\n",
            "Epoch: 0, iteración: 1650 de 4083, Loss: 0.49719820022583006\n",
            "Epoch: 0, iteración: 1660 de 4083, Loss: 0.6442821025848389\n",
            "Epoch: 0, iteración: 1670 de 4083, Loss: 0.551208209991455\n",
            "Epoch: 0, iteración: 1680 de 4083, Loss: 0.5681384086608887\n",
            "Epoch: 0, iteración: 1690 de 4083, Loss: 0.5997178554534912\n",
            "Epoch: 0, iteración: 1700 de 4083, Loss: 0.5063715934753418\n",
            "Epoch: 0, iteración: 1710 de 4083, Loss: 0.5597286701202393\n",
            "Epoch: 0, iteración: 1720 de 4083, Loss: 0.6102162837982178\n",
            "Epoch: 0, iteración: 1730 de 4083, Loss: 0.5649474143981934\n",
            "Epoch: 0, iteración: 1740 de 4083, Loss: 0.6631134986877442\n",
            "Epoch: 0, iteración: 1750 de 4083, Loss: 0.5782134056091308\n",
            "Epoch: 0, iteración: 1760 de 4083, Loss: 0.6714009284973145\n",
            "Epoch: 0, iteración: 1770 de 4083, Loss: 0.558729887008667\n",
            "Epoch: 0, iteración: 1780 de 4083, Loss: 0.6301500797271729\n",
            "Epoch: 0, iteración: 1790 de 4083, Loss: 0.6529881954193115\n",
            "Epoch: 0, iteración: 1800 de 4083, Loss: 0.6027878284454345\n",
            "Epoch: 0, iteración: 1810 de 4083, Loss: 0.5774264812469483\n",
            "Epoch: 0, iteración: 1820 de 4083, Loss: 0.5519067287445069\n",
            "Epoch: 0, iteración: 1830 de 4083, Loss: 0.5992716312408447\n",
            "Epoch: 0, iteración: 1840 de 4083, Loss: 0.5554285526275635\n",
            "Epoch: 0, iteración: 1850 de 4083, Loss: 0.5811773300170898\n",
            "Epoch: 0, iteración: 1860 de 4083, Loss: 0.5218160629272461\n",
            "Epoch: 0, iteración: 1870 de 4083, Loss: 0.5569284439086915\n",
            "Epoch: 0, iteración: 1880 de 4083, Loss: 0.5878646373748779\n",
            "Epoch: 0, iteración: 1890 de 4083, Loss: 0.6944243907928467\n",
            "Epoch: 0, iteración: 1900 de 4083, Loss: 0.5573519706726074\n",
            "Epoch: 0, iteración: 1910 de 4083, Loss: 0.5402710914611817\n",
            "Epoch: 0, iteración: 1920 de 4083, Loss: 0.5926768779754639\n",
            "Epoch: 0, iteración: 1930 de 4083, Loss: 0.575557279586792\n",
            "Epoch: 0, iteración: 1940 de 4083, Loss: 0.5198821067810059\n",
            "Epoch: 0, iteración: 1950 de 4083, Loss: 0.5290100574493408\n",
            "Epoch: 0, iteración: 1960 de 4083, Loss: 0.5631346702575684\n",
            "Epoch: 0, iteración: 1970 de 4083, Loss: 0.5844072341918946\n",
            "Epoch: 0, iteración: 1980 de 4083, Loss: 0.53717041015625\n",
            "Epoch: 0, iteración: 1990 de 4083, Loss: 0.4791108131408691\n",
            "Epoch: 0, iteración: 2000 de 4083, Loss: 0.555202579498291\n",
            "Epoch: 0, iteración: 2010 de 4083, Loss: 0.6087125778198242\n",
            "Epoch: 0, iteración: 2020 de 4083, Loss: 0.5230877876281739\n",
            "Epoch: 0, iteración: 2030 de 4083, Loss: 0.545015811920166\n",
            "Epoch: 0, iteración: 2040 de 4083, Loss: 0.5830828189849854\n",
            "Epoch: 0, iteración: 2050 de 4083, Loss: 0.6245437622070312\n",
            "Epoch: 0, iteración: 2060 de 4083, Loss: 0.557155990600586\n",
            "Epoch: 0, iteración: 2070 de 4083, Loss: 0.5310133934020996\n",
            "Epoch: 0, iteración: 2080 de 4083, Loss: 0.6112781524658203\n",
            "Epoch: 0, iteración: 2090 de 4083, Loss: 0.580355167388916\n",
            "Epoch: 0, iteración: 2100 de 4083, Loss: 0.6137041091918946\n",
            "Epoch: 0, iteración: 2110 de 4083, Loss: 0.5680216312408447\n",
            "Epoch: 0, iteración: 2120 de 4083, Loss: 0.5815287590026855\n",
            "Epoch: 0, iteración: 2130 de 4083, Loss: 0.5380665302276612\n",
            "Epoch: 0, iteración: 2140 de 4083, Loss: 0.6068880081176757\n",
            "Epoch: 0, iteración: 2150 de 4083, Loss: 0.5960631370544434\n",
            "Epoch: 0, iteración: 2160 de 4083, Loss: 0.595165205001831\n",
            "Epoch: 0, iteración: 2170 de 4083, Loss: 0.5915040016174317\n",
            "Epoch: 0, iteración: 2180 de 4083, Loss: 0.5515148639678955\n",
            "Epoch: 0, iteración: 2190 de 4083, Loss: 0.6021250724792481\n",
            "Epoch: 0, iteración: 2200 de 4083, Loss: 0.6080821514129638\n",
            "Epoch: 0, iteración: 2210 de 4083, Loss: 0.5089222431182862\n",
            "Epoch: 0, iteración: 2220 de 4083, Loss: 0.7209557056427002\n",
            "Epoch: 0, iteración: 2230 de 4083, Loss: 0.5980449199676514\n",
            "Epoch: 0, iteración: 2240 de 4083, Loss: 0.5856863021850586\n",
            "Epoch: 0, iteración: 2250 de 4083, Loss: 0.579529857635498\n",
            "Epoch: 0, iteración: 2260 de 4083, Loss: 0.5983561038970947\n",
            "Epoch: 0, iteración: 2270 de 4083, Loss: 0.5365679740905762\n",
            "Epoch: 0, iteración: 2280 de 4083, Loss: 0.6162807941436768\n",
            "Epoch: 0, iteración: 2290 de 4083, Loss: 0.5978734970092774\n",
            "Epoch: 0, iteración: 2300 de 4083, Loss: 0.6063992977142334\n",
            "Epoch: 0, iteración: 2310 de 4083, Loss: 0.6912210941314697\n",
            "Epoch: 0, iteración: 2320 de 4083, Loss: 0.6048168182373047\n",
            "Epoch: 0, iteración: 2330 de 4083, Loss: 0.5852875709533691\n",
            "Epoch: 0, iteración: 2340 de 4083, Loss: 0.6044469833374023\n",
            "Epoch: 0, iteración: 2350 de 4083, Loss: 0.624580717086792\n",
            "Epoch: 0, iteración: 2360 de 4083, Loss: 0.48526439666748045\n",
            "Epoch: 0, iteración: 2370 de 4083, Loss: 0.6206971645355225\n",
            "Epoch: 0, iteración: 2380 de 4083, Loss: 0.5431921005249023\n",
            "Epoch: 0, iteración: 2390 de 4083, Loss: 0.49538984298706057\n",
            "Epoch: 0, iteración: 2400 de 4083, Loss: 0.573317575454712\n",
            "Epoch: 0, iteración: 2410 de 4083, Loss: 0.5551808834075928\n",
            "Epoch: 0, iteración: 2420 de 4083, Loss: 0.5926644325256347\n",
            "Epoch: 0, iteración: 2430 de 4083, Loss: 0.656105375289917\n",
            "Epoch: 0, iteración: 2440 de 4083, Loss: 0.6818019390106201\n",
            "Epoch: 0, iteración: 2450 de 4083, Loss: 0.6057101726531983\n",
            "Epoch: 0, iteración: 2460 de 4083, Loss: 0.6163523674011231\n",
            "Epoch: 0, iteración: 2470 de 4083, Loss: 0.585421085357666\n",
            "Epoch: 0, iteración: 2480 de 4083, Loss: 0.5620813846588135\n",
            "Epoch: 0, iteración: 2490 de 4083, Loss: 0.6151628017425537\n",
            "Epoch: 0, iteración: 2500 de 4083, Loss: 0.5774499416351319\n",
            "Epoch: 0, iteración: 2510 de 4083, Loss: 0.5547461032867431\n",
            "Epoch: 0, iteración: 2520 de 4083, Loss: 0.614458417892456\n",
            "Epoch: 0, iteración: 2530 de 4083, Loss: 0.5285727977752686\n",
            "Epoch: 0, iteración: 2540 de 4083, Loss: 0.5645551681518555\n",
            "Epoch: 0, iteración: 2550 de 4083, Loss: 0.5407761096954345\n",
            "Epoch: 0, iteración: 2560 de 4083, Loss: 0.6411242008209228\n",
            "Epoch: 0, iteración: 2570 de 4083, Loss: 0.5805048942565918\n",
            "Epoch: 0, iteración: 2580 de 4083, Loss: 0.625254774093628\n",
            "Epoch: 0, iteración: 2590 de 4083, Loss: 0.5873828411102295\n",
            "Epoch: 0, iteración: 2600 de 4083, Loss: 0.6001172065734863\n",
            "Epoch: 0, iteración: 2610 de 4083, Loss: 0.6266896247863769\n",
            "Epoch: 0, iteración: 2620 de 4083, Loss: 0.5561544895172119\n",
            "Epoch: 0, iteración: 2630 de 4083, Loss: 0.5863501548767089\n",
            "Epoch: 0, iteración: 2640 de 4083, Loss: 0.5666993141174317\n",
            "Epoch: 0, iteración: 2650 de 4083, Loss: 0.6069918632507324\n",
            "Epoch: 0, iteración: 2660 de 4083, Loss: 0.525585412979126\n",
            "Epoch: 0, iteración: 2670 de 4083, Loss: 0.6203399658203125\n",
            "Epoch: 0, iteración: 2680 de 4083, Loss: 0.5914451599121093\n",
            "Epoch: 0, iteración: 2690 de 4083, Loss: 0.5857901573181152\n",
            "Epoch: 0, iteración: 2700 de 4083, Loss: 0.5562747478485107\n",
            "Epoch: 0, iteración: 2710 de 4083, Loss: 0.5606921672821045\n",
            "Epoch: 0, iteración: 2720 de 4083, Loss: 0.5772923469543457\n",
            "Epoch: 0, iteración: 2730 de 4083, Loss: 0.5526267528533936\n",
            "Epoch: 0, iteración: 2740 de 4083, Loss: 0.6090773105621338\n",
            "Epoch: 0, iteración: 2750 de 4083, Loss: 0.4779656887054443\n",
            "Epoch: 0, iteración: 2760 de 4083, Loss: 0.61244797706604\n",
            "Epoch: 0, iteración: 2770 de 4083, Loss: 0.5318254470825196\n",
            "Epoch: 0, iteración: 2780 de 4083, Loss: 0.5846994400024415\n",
            "Epoch: 0, iteración: 2790 de 4083, Loss: 0.6235626220703125\n",
            "Epoch: 0, iteración: 2800 de 4083, Loss: 0.5895932197570801\n",
            "Epoch: 0, iteración: 2810 de 4083, Loss: 0.6011311531066894\n",
            "Epoch: 0, iteración: 2820 de 4083, Loss: 0.607595682144165\n",
            "Epoch: 0, iteración: 2830 de 4083, Loss: 0.5611306667327881\n",
            "Epoch: 0, iteración: 2840 de 4083, Loss: 0.5782666683197022\n",
            "Epoch: 0, iteración: 2850 de 4083, Loss: 0.5998144149780273\n",
            "Epoch: 0, iteración: 2860 de 4083, Loss: 0.5633585929870606\n",
            "Epoch: 0, iteración: 2870 de 4083, Loss: 0.6433587074279785\n",
            "Epoch: 0, iteración: 2880 de 4083, Loss: 0.6724915504455566\n",
            "Epoch: 0, iteración: 2890 de 4083, Loss: 0.6004974365234375\n",
            "Epoch: 0, iteración: 2900 de 4083, Loss: 0.598806619644165\n",
            "Epoch: 0, iteración: 2910 de 4083, Loss: 0.5924468994140625\n",
            "Epoch: 0, iteración: 2920 de 4083, Loss: 0.6041594505310058\n",
            "Epoch: 0, iteración: 2930 de 4083, Loss: 0.6164353847503662\n",
            "Epoch: 0, iteración: 2940 de 4083, Loss: 0.5544785499572754\n",
            "Epoch: 0, iteración: 2950 de 4083, Loss: 0.6438498497009277\n",
            "Epoch: 0, iteración: 2960 de 4083, Loss: 0.6162796497344971\n",
            "Epoch: 0, iteración: 2970 de 4083, Loss: 0.6730707168579102\n",
            "Epoch: 0, iteración: 2980 de 4083, Loss: 0.6125849723815918\n",
            "Epoch: 0, iteración: 2990 de 4083, Loss: 0.5154314041137695\n",
            "Epoch: 0, iteración: 3000 de 4083, Loss: 0.5217241764068603\n",
            "Epoch: 0, iteración: 3010 de 4083, Loss: 0.6554817676544189\n",
            "Epoch: 0, iteración: 3020 de 4083, Loss: 0.5589504241943359\n",
            "Epoch: 0, iteración: 3030 de 4083, Loss: 0.5457464694976807\n",
            "Epoch: 0, iteración: 3040 de 4083, Loss: 0.5549899578094483\n",
            "Epoch: 0, iteración: 3050 de 4083, Loss: 0.6166100025177002\n",
            "Epoch: 0, iteración: 3060 de 4083, Loss: 0.6026818752288818\n",
            "Epoch: 0, iteración: 3070 de 4083, Loss: 0.5537013053894043\n",
            "Epoch: 0, iteración: 3080 de 4083, Loss: 0.5701331615447998\n",
            "Epoch: 0, iteración: 3090 de 4083, Loss: 0.562675142288208\n",
            "Epoch: 0, iteración: 3100 de 4083, Loss: 0.5473544597625732\n",
            "Epoch: 0, iteración: 3110 de 4083, Loss: 0.641957139968872\n",
            "Epoch: 0, iteración: 3120 de 4083, Loss: 0.6177527427673339\n",
            "Epoch: 0, iteración: 3130 de 4083, Loss: 0.5443427562713623\n",
            "Epoch: 0, iteración: 3140 de 4083, Loss: 0.5414217948913574\n",
            "Epoch: 0, iteración: 3150 de 4083, Loss: 0.5461541175842285\n",
            "Epoch: 0, iteración: 3160 de 4083, Loss: 0.624284315109253\n",
            "Epoch: 0, iteración: 3170 de 4083, Loss: 0.6041258335113525\n",
            "Epoch: 0, iteración: 3180 de 4083, Loss: 0.5545548439025879\n",
            "Epoch: 0, iteración: 3190 de 4083, Loss: 0.5714882850646973\n",
            "Epoch: 0, iteración: 3200 de 4083, Loss: 0.6470102310180664\n",
            "Epoch: 0, iteración: 3210 de 4083, Loss: 0.6055923938751221\n",
            "Epoch: 0, iteración: 3220 de 4083, Loss: 0.6298511505126954\n",
            "Epoch: 0, iteración: 3230 de 4083, Loss: 0.617230224609375\n",
            "Epoch: 0, iteración: 3240 de 4083, Loss: 0.560196828842163\n",
            "Epoch: 0, iteración: 3250 de 4083, Loss: 0.5729046821594238\n",
            "Epoch: 0, iteración: 3260 de 4083, Loss: 0.5736176490783691\n",
            "Epoch: 0, iteración: 3270 de 4083, Loss: 0.6621140003204345\n",
            "Epoch: 0, iteración: 3280 de 4083, Loss: 0.5597134590148926\n",
            "Epoch: 0, iteración: 3290 de 4083, Loss: 0.5907082557678223\n",
            "Epoch: 0, iteración: 3300 de 4083, Loss: 0.6087395668029785\n",
            "Epoch: 0, iteración: 3310 de 4083, Loss: 0.5426658153533935\n",
            "Epoch: 0, iteración: 3320 de 4083, Loss: 0.5114950656890869\n",
            "Epoch: 0, iteración: 3330 de 4083, Loss: 0.541491174697876\n",
            "Epoch: 0, iteración: 3340 de 4083, Loss: 0.5329331874847412\n",
            "Epoch: 0, iteración: 3350 de 4083, Loss: 0.5800518989562988\n",
            "Epoch: 0, iteración: 3360 de 4083, Loss: 0.47047958374023435\n",
            "Epoch: 0, iteración: 3370 de 4083, Loss: 0.5761127471923828\n",
            "Epoch: 0, iteración: 3380 de 4083, Loss: 0.5093986511230468\n",
            "Epoch: 0, iteración: 3390 de 4083, Loss: 0.6167949676513672\n",
            "Epoch: 0, iteración: 3400 de 4083, Loss: 0.48099384307861326\n",
            "Epoch: 0, iteración: 3410 de 4083, Loss: 0.575724744796753\n",
            "Epoch: 0, iteración: 3420 de 4083, Loss: 0.6132824897766114\n",
            "Epoch: 0, iteración: 3430 de 4083, Loss: 0.6315326690673828\n",
            "Epoch: 0, iteración: 3440 de 4083, Loss: 0.5690796375274658\n",
            "Epoch: 0, iteración: 3450 de 4083, Loss: 0.5523943901062012\n",
            "Epoch: 0, iteración: 3460 de 4083, Loss: 0.5735393524169922\n",
            "Epoch: 0, iteración: 3470 de 4083, Loss: 0.5408389568328857\n",
            "Epoch: 0, iteración: 3480 de 4083, Loss: 0.6903081893920898\n",
            "Epoch: 0, iteración: 3490 de 4083, Loss: 0.5216306209564209\n",
            "Epoch: 0, iteración: 3500 de 4083, Loss: 0.6341797351837158\n",
            "Epoch: 0, iteración: 3510 de 4083, Loss: 0.5723944664001465\n",
            "Epoch: 0, iteración: 3520 de 4083, Loss: 0.5566155433654785\n",
            "Epoch: 0, iteración: 3530 de 4083, Loss: 0.5157971858978272\n",
            "Epoch: 0, iteración: 3540 de 4083, Loss: 0.584135913848877\n",
            "Epoch: 0, iteración: 3550 de 4083, Loss: 0.577829647064209\n",
            "Epoch: 0, iteración: 3560 de 4083, Loss: 0.561102819442749\n",
            "Epoch: 0, iteración: 3570 de 4083, Loss: 0.6548136711120606\n",
            "Epoch: 0, iteración: 3580 de 4083, Loss: 0.5367701530456543\n",
            "Epoch: 0, iteración: 3590 de 4083, Loss: 0.6475496768951416\n",
            "Epoch: 0, iteración: 3600 de 4083, Loss: 0.6123239994049072\n",
            "Epoch: 0, iteración: 3610 de 4083, Loss: 0.6520851612091064\n",
            "Epoch: 0, iteración: 3620 de 4083, Loss: 0.5571846485137939\n",
            "Epoch: 0, iteración: 3630 de 4083, Loss: 0.5403526306152344\n",
            "Epoch: 0, iteración: 3640 de 4083, Loss: 0.5538534641265869\n",
            "Epoch: 0, iteración: 3650 de 4083, Loss: 0.5155622005462647\n",
            "Epoch: 0, iteración: 3660 de 4083, Loss: 0.5522355079650879\n",
            "Epoch: 0, iteración: 3670 de 4083, Loss: 0.5673422336578369\n",
            "Epoch: 0, iteración: 3680 de 4083, Loss: 0.5467629432678223\n",
            "Epoch: 0, iteración: 3690 de 4083, Loss: 0.5717463016510009\n",
            "Epoch: 0, iteración: 3700 de 4083, Loss: 0.5066364288330079\n",
            "Epoch: 0, iteración: 3710 de 4083, Loss: 0.5721585750579834\n",
            "Epoch: 0, iteración: 3720 de 4083, Loss: 0.5340705394744873\n",
            "Epoch: 0, iteración: 3730 de 4083, Loss: 0.5338886260986329\n",
            "Epoch: 0, iteración: 3740 de 4083, Loss: 0.571219539642334\n",
            "Epoch: 0, iteración: 3750 de 4083, Loss: 0.5940205574035644\n",
            "Epoch: 0, iteración: 3760 de 4083, Loss: 0.5742020606994629\n",
            "Epoch: 0, iteración: 3770 de 4083, Loss: 0.509600019454956\n",
            "Epoch: 0, iteración: 3780 de 4083, Loss: 0.5397040843963623\n",
            "Epoch: 0, iteración: 3790 de 4083, Loss: 0.4531064987182617\n",
            "Epoch: 0, iteración: 3800 de 4083, Loss: 0.6097615718841553\n",
            "Epoch: 0, iteración: 3810 de 4083, Loss: 0.5710922241210937\n",
            "Epoch: 0, iteración: 3820 de 4083, Loss: 0.5314400672912598\n",
            "Epoch: 0, iteración: 3830 de 4083, Loss: 0.6569680213928223\n",
            "Epoch: 0, iteración: 3840 de 4083, Loss: 0.6365567684173584\n",
            "Epoch: 0, iteración: 3850 de 4083, Loss: 0.5828280448913574\n",
            "Epoch: 0, iteración: 3860 de 4083, Loss: 0.5683721542358399\n",
            "Epoch: 0, iteración: 3870 de 4083, Loss: 0.5954771518707276\n",
            "Epoch: 0, iteración: 3880 de 4083, Loss: 0.660744571685791\n",
            "Epoch: 0, iteración: 3890 de 4083, Loss: 0.655995225906372\n",
            "Epoch: 0, iteración: 3900 de 4083, Loss: 0.5370065689086914\n",
            "Epoch: 0, iteración: 3910 de 4083, Loss: 0.5670004844665527\n",
            "Epoch: 0, iteración: 3920 de 4083, Loss: 0.6412419319152832\n",
            "Epoch: 0, iteración: 3930 de 4083, Loss: 0.5075839042663575\n",
            "Epoch: 0, iteración: 3940 de 4083, Loss: 0.6521241664886475\n",
            "Epoch: 0, iteración: 3950 de 4083, Loss: 0.5999576568603515\n",
            "Epoch: 0, iteración: 3960 de 4083, Loss: 0.5515315055847168\n",
            "Epoch: 0, iteración: 3970 de 4083, Loss: 0.6215817928314209\n",
            "Epoch: 0, iteración: 3980 de 4083, Loss: 0.6207554340362549\n",
            "Epoch: 0, iteración: 3990 de 4083, Loss: 0.570658016204834\n",
            "Epoch: 0, iteración: 4000 de 4083, Loss: 0.5546897888183594\n",
            "Epoch: 0, iteración: 4010 de 4083, Loss: 0.6110297203063965\n",
            "Epoch: 0, iteración: 4020 de 4083, Loss: 0.5771031856536866\n",
            "Epoch: 0, iteración: 4030 de 4083, Loss: 0.6940537929534912\n",
            "Epoch: 0, iteración: 4040 de 4083, Loss: 0.6666995048522949\n",
            "Epoch: 0, iteración: 4050 de 4083, Loss: 0.5957856178283691\n",
            "Epoch: 0, iteración: 4060 de 4083, Loss: 0.5571740150451661\n",
            "Epoch: 0, iteración: 4070 de 4083, Loss: 0.5869401931762696\n",
            "Epoch: 0, iteración: 4080 de 4083, Loss: 0.6318140506744385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_lr7_50.pth\")\n",
        "  print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "metadata": {
        "id": "SJKPlMnLeLWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080964fa-2350-4f6c-f369-ec28837bf91b"
      },
      "id": "SJKPlMnLeLWg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Evaluación del modelo"
      ],
      "metadata": {
        "id": "XPsYMmewS39X"
      },
      "id": "XPsYMmewS39X"
    },
    {
      "cell_type": "code",
      "source": [
        "def validationBERTSiameseConcat(epoch):\n",
        "  model.eval()\n",
        "  fin_targets=[]\n",
        "  fin_outputs=[]\n",
        "  num_iteraciones = len(testing_loader)\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testing_loader, 0):\n",
        "      ids1 = data['ids1'].to(device)\n",
        "      ids2 = data['ids2'].to(device)\n",
        "      mask1 = data['mask1'].to(device)\n",
        "      mask2 = data['mask2'].to(device)\n",
        "      token_type_ids1 = data[\"token_type_ids1\"].to(device)\n",
        "      token_type_ids2 = data[\"token_type_ids2\"].to(device)\n",
        "      targets = data['target'].to(device)\n",
        "\n",
        "      print(f\"Iteración: {i} de {num_iteraciones}\")\n",
        "\n",
        "      outputs = model(ids1, mask1, token_type_ids1, ids2, mask2, token_type_ids2)\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "  return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "1ffQNvIxS39l"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1ffQNvIxS39l"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "aCfOKAUVS39l"
      },
      "id": "aCfOKAUVS39l"
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_lr7_50.pth\"):\n",
        "  model = BERTSiameseConcat()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_lr7_50.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_lr7_50.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "metadata": {
        "id": "S-I5ejlxS39m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23a7ec0-8a4d-4286-94f3-144bec59e34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado correctamente\n"
          ]
        }
      ],
      "id": "S-I5ejlxS39m"
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationBERTSiameseConcat(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "metadata": {
        "id": "yPCeI5u0S39m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104f92d2-2ab3-4362-f806-0660cf37448a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración: 0 de 511\n",
            "Iteración: 1 de 511\n",
            "Iteración: 2 de 511\n",
            "Iteración: 3 de 511\n",
            "Iteración: 4 de 511\n",
            "Iteración: 5 de 511\n",
            "Iteración: 6 de 511\n",
            "Iteración: 7 de 511\n",
            "Iteración: 8 de 511\n",
            "Iteración: 9 de 511\n",
            "Iteración: 10 de 511\n",
            "Iteración: 11 de 511\n",
            "Iteración: 12 de 511\n",
            "Iteración: 13 de 511\n",
            "Iteración: 14 de 511\n",
            "Iteración: 15 de 511\n",
            "Iteración: 16 de 511\n",
            "Iteración: 17 de 511\n",
            "Iteración: 18 de 511\n",
            "Iteración: 19 de 511\n",
            "Iteración: 20 de 511\n",
            "Iteración: 21 de 511\n",
            "Iteración: 22 de 511\n",
            "Iteración: 23 de 511\n",
            "Iteración: 24 de 511\n",
            "Iteración: 25 de 511\n",
            "Iteración: 26 de 511\n",
            "Iteración: 27 de 511\n",
            "Iteración: 28 de 511\n",
            "Iteración: 29 de 511\n",
            "Iteración: 30 de 511\n",
            "Iteración: 31 de 511\n",
            "Iteración: 32 de 511\n",
            "Iteración: 33 de 511\n",
            "Iteración: 34 de 511\n",
            "Iteración: 35 de 511\n",
            "Iteración: 36 de 511\n",
            "Iteración: 37 de 511\n",
            "Iteración: 38 de 511\n",
            "Iteración: 39 de 511\n",
            "Iteración: 40 de 511\n",
            "Iteración: 41 de 511\n",
            "Iteración: 42 de 511\n",
            "Iteración: 43 de 511\n",
            "Iteración: 44 de 511\n",
            "Iteración: 45 de 511\n",
            "Iteración: 46 de 511\n",
            "Iteración: 47 de 511\n",
            "Iteración: 48 de 511\n",
            "Iteración: 49 de 511\n",
            "Iteración: 50 de 511\n",
            "Iteración: 51 de 511\n",
            "Iteración: 52 de 511\n",
            "Iteración: 53 de 511\n",
            "Iteración: 54 de 511\n",
            "Iteración: 55 de 511\n",
            "Iteración: 56 de 511\n",
            "Iteración: 57 de 511\n",
            "Iteración: 58 de 511\n",
            "Iteración: 59 de 511\n",
            "Iteración: 60 de 511\n",
            "Iteración: 61 de 511\n",
            "Iteración: 62 de 511\n",
            "Iteración: 63 de 511\n",
            "Iteración: 64 de 511\n",
            "Iteración: 65 de 511\n",
            "Iteración: 66 de 511\n",
            "Iteración: 67 de 511\n",
            "Iteración: 68 de 511\n",
            "Iteración: 69 de 511\n",
            "Iteración: 70 de 511\n",
            "Iteración: 71 de 511\n",
            "Iteración: 72 de 511\n",
            "Iteración: 73 de 511\n",
            "Iteración: 74 de 511\n",
            "Iteración: 75 de 511\n",
            "Iteración: 76 de 511\n",
            "Iteración: 77 de 511\n",
            "Iteración: 78 de 511\n",
            "Iteración: 79 de 511\n",
            "Iteración: 80 de 511\n",
            "Iteración: 81 de 511\n",
            "Iteración: 82 de 511\n",
            "Iteración: 83 de 511\n",
            "Iteración: 84 de 511\n",
            "Iteración: 85 de 511\n",
            "Iteración: 86 de 511\n",
            "Iteración: 87 de 511\n",
            "Iteración: 88 de 511\n",
            "Iteración: 89 de 511\n",
            "Iteración: 90 de 511\n",
            "Iteración: 91 de 511\n",
            "Iteración: 92 de 511\n",
            "Iteración: 93 de 511\n",
            "Iteración: 94 de 511\n",
            "Iteración: 95 de 511\n",
            "Iteración: 96 de 511\n",
            "Iteración: 97 de 511\n",
            "Iteración: 98 de 511\n",
            "Iteración: 99 de 511\n",
            "Iteración: 100 de 511\n",
            "Iteración: 101 de 511\n",
            "Iteración: 102 de 511\n",
            "Iteración: 103 de 511\n",
            "Iteración: 104 de 511\n",
            "Iteración: 105 de 511\n",
            "Iteración: 106 de 511\n",
            "Iteración: 107 de 511\n",
            "Iteración: 108 de 511\n",
            "Iteración: 109 de 511\n",
            "Iteración: 110 de 511\n",
            "Iteración: 111 de 511\n",
            "Iteración: 112 de 511\n",
            "Iteración: 113 de 511\n",
            "Iteración: 114 de 511\n",
            "Iteración: 115 de 511\n",
            "Iteración: 116 de 511\n",
            "Iteración: 117 de 511\n",
            "Iteración: 118 de 511\n",
            "Iteración: 119 de 511\n",
            "Iteración: 120 de 511\n",
            "Iteración: 121 de 511\n",
            "Iteración: 122 de 511\n",
            "Iteración: 123 de 511\n",
            "Iteración: 124 de 511\n",
            "Iteración: 125 de 511\n",
            "Iteración: 126 de 511\n",
            "Iteración: 127 de 511\n",
            "Iteración: 128 de 511\n",
            "Iteración: 129 de 511\n",
            "Iteración: 130 de 511\n",
            "Iteración: 131 de 511\n",
            "Iteración: 132 de 511\n",
            "Iteración: 133 de 511\n",
            "Iteración: 134 de 511\n",
            "Iteración: 135 de 511\n",
            "Iteración: 136 de 511\n",
            "Iteración: 137 de 511\n",
            "Iteración: 138 de 511\n",
            "Iteración: 139 de 511\n",
            "Iteración: 140 de 511\n",
            "Iteración: 141 de 511\n",
            "Iteración: 142 de 511\n",
            "Iteración: 143 de 511\n",
            "Iteración: 144 de 511\n",
            "Iteración: 145 de 511\n",
            "Iteración: 146 de 511\n",
            "Iteración: 147 de 511\n",
            "Iteración: 148 de 511\n",
            "Iteración: 149 de 511\n",
            "Iteración: 150 de 511\n",
            "Iteración: 151 de 511\n",
            "Iteración: 152 de 511\n",
            "Iteración: 153 de 511\n",
            "Iteración: 154 de 511\n",
            "Iteración: 155 de 511\n",
            "Iteración: 156 de 511\n",
            "Iteración: 157 de 511\n",
            "Iteración: 158 de 511\n",
            "Iteración: 159 de 511\n",
            "Iteración: 160 de 511\n",
            "Iteración: 161 de 511\n",
            "Iteración: 162 de 511\n",
            "Iteración: 163 de 511\n",
            "Iteración: 164 de 511\n",
            "Iteración: 165 de 511\n",
            "Iteración: 166 de 511\n",
            "Iteración: 167 de 511\n",
            "Iteración: 168 de 511\n",
            "Iteración: 169 de 511\n",
            "Iteración: 170 de 511\n",
            "Iteración: 171 de 511\n",
            "Iteración: 172 de 511\n",
            "Iteración: 173 de 511\n",
            "Iteración: 174 de 511\n",
            "Iteración: 175 de 511\n",
            "Iteración: 176 de 511\n",
            "Iteración: 177 de 511\n",
            "Iteración: 178 de 511\n",
            "Iteración: 179 de 511\n",
            "Iteración: 180 de 511\n",
            "Iteración: 181 de 511\n",
            "Iteración: 182 de 511\n",
            "Iteración: 183 de 511\n",
            "Iteración: 184 de 511\n",
            "Iteración: 185 de 511\n",
            "Iteración: 186 de 511\n",
            "Iteración: 187 de 511\n",
            "Iteración: 188 de 511\n",
            "Iteración: 189 de 511\n",
            "Iteración: 190 de 511\n",
            "Iteración: 191 de 511\n",
            "Iteración: 192 de 511\n",
            "Iteración: 193 de 511\n",
            "Iteración: 194 de 511\n",
            "Iteración: 195 de 511\n",
            "Iteración: 196 de 511\n",
            "Iteración: 197 de 511\n",
            "Iteración: 198 de 511\n",
            "Iteración: 199 de 511\n",
            "Iteración: 200 de 511\n",
            "Iteración: 201 de 511\n",
            "Iteración: 202 de 511\n",
            "Iteración: 203 de 511\n",
            "Iteración: 204 de 511\n",
            "Iteración: 205 de 511\n",
            "Iteración: 206 de 511\n",
            "Iteración: 207 de 511\n",
            "Iteración: 208 de 511\n",
            "Iteración: 209 de 511\n",
            "Iteración: 210 de 511\n",
            "Iteración: 211 de 511\n",
            "Iteración: 212 de 511\n",
            "Iteración: 213 de 511\n",
            "Iteración: 214 de 511\n",
            "Iteración: 215 de 511\n",
            "Iteración: 216 de 511\n",
            "Iteración: 217 de 511\n",
            "Iteración: 218 de 511\n",
            "Iteración: 219 de 511\n",
            "Iteración: 220 de 511\n",
            "Iteración: 221 de 511\n",
            "Iteración: 222 de 511\n",
            "Iteración: 223 de 511\n",
            "Iteración: 224 de 511\n",
            "Iteración: 225 de 511\n",
            "Iteración: 226 de 511\n",
            "Iteración: 227 de 511\n",
            "Iteración: 228 de 511\n",
            "Iteración: 229 de 511\n",
            "Iteración: 230 de 511\n",
            "Iteración: 231 de 511\n",
            "Iteración: 232 de 511\n",
            "Iteración: 233 de 511\n",
            "Iteración: 234 de 511\n",
            "Iteración: 235 de 511\n",
            "Iteración: 236 de 511\n",
            "Iteración: 237 de 511\n",
            "Iteración: 238 de 511\n",
            "Iteración: 239 de 511\n",
            "Iteración: 240 de 511\n",
            "Iteración: 241 de 511\n",
            "Iteración: 242 de 511\n",
            "Iteración: 243 de 511\n",
            "Iteración: 244 de 511\n",
            "Iteración: 245 de 511\n",
            "Iteración: 246 de 511\n",
            "Iteración: 247 de 511\n",
            "Iteración: 248 de 511\n",
            "Iteración: 249 de 511\n",
            "Iteración: 250 de 511\n",
            "Iteración: 251 de 511\n",
            "Iteración: 252 de 511\n",
            "Iteración: 253 de 511\n",
            "Iteración: 254 de 511\n",
            "Iteración: 255 de 511\n",
            "Iteración: 256 de 511\n",
            "Iteración: 257 de 511\n",
            "Iteración: 258 de 511\n",
            "Iteración: 259 de 511\n",
            "Iteración: 260 de 511\n",
            "Iteración: 261 de 511\n",
            "Iteración: 262 de 511\n",
            "Iteración: 263 de 511\n",
            "Iteración: 264 de 511\n",
            "Iteración: 265 de 511\n",
            "Iteración: 266 de 511\n",
            "Iteración: 267 de 511\n",
            "Iteración: 268 de 511\n",
            "Iteración: 269 de 511\n",
            "Iteración: 270 de 511\n",
            "Iteración: 271 de 511\n",
            "Iteración: 272 de 511\n",
            "Iteración: 273 de 511\n",
            "Iteración: 274 de 511\n",
            "Iteración: 275 de 511\n",
            "Iteración: 276 de 511\n",
            "Iteración: 277 de 511\n",
            "Iteración: 278 de 511\n",
            "Iteración: 279 de 511\n",
            "Iteración: 280 de 511\n",
            "Iteración: 281 de 511\n",
            "Iteración: 282 de 511\n",
            "Iteración: 283 de 511\n",
            "Iteración: 284 de 511\n",
            "Iteración: 285 de 511\n",
            "Iteración: 286 de 511\n",
            "Iteración: 287 de 511\n",
            "Iteración: 288 de 511\n",
            "Iteración: 289 de 511\n",
            "Iteración: 290 de 511\n",
            "Iteración: 291 de 511\n",
            "Iteración: 292 de 511\n",
            "Iteración: 293 de 511\n",
            "Iteración: 294 de 511\n",
            "Iteración: 295 de 511\n",
            "Iteración: 296 de 511\n",
            "Iteración: 297 de 511\n",
            "Iteración: 298 de 511\n",
            "Iteración: 299 de 511\n",
            "Iteración: 300 de 511\n",
            "Iteración: 301 de 511\n",
            "Iteración: 302 de 511\n",
            "Iteración: 303 de 511\n",
            "Iteración: 304 de 511\n",
            "Iteración: 305 de 511\n",
            "Iteración: 306 de 511\n",
            "Iteración: 307 de 511\n",
            "Iteración: 308 de 511\n",
            "Iteración: 309 de 511\n",
            "Iteración: 310 de 511\n",
            "Iteración: 311 de 511\n",
            "Iteración: 312 de 511\n",
            "Iteración: 313 de 511\n",
            "Iteración: 314 de 511\n",
            "Iteración: 315 de 511\n",
            "Iteración: 316 de 511\n",
            "Iteración: 317 de 511\n",
            "Iteración: 318 de 511\n",
            "Iteración: 319 de 511\n",
            "Iteración: 320 de 511\n",
            "Iteración: 321 de 511\n",
            "Iteración: 322 de 511\n",
            "Iteración: 323 de 511\n",
            "Iteración: 324 de 511\n",
            "Iteración: 325 de 511\n",
            "Iteración: 326 de 511\n",
            "Iteración: 327 de 511\n",
            "Iteración: 328 de 511\n",
            "Iteración: 329 de 511\n",
            "Iteración: 330 de 511\n",
            "Iteración: 331 de 511\n",
            "Iteración: 332 de 511\n",
            "Iteración: 333 de 511\n",
            "Iteración: 334 de 511\n",
            "Iteración: 335 de 511\n",
            "Iteración: 336 de 511\n",
            "Iteración: 337 de 511\n",
            "Iteración: 338 de 511\n",
            "Iteración: 339 de 511\n",
            "Iteración: 340 de 511\n",
            "Iteración: 341 de 511\n",
            "Iteración: 342 de 511\n",
            "Iteración: 343 de 511\n",
            "Iteración: 344 de 511\n",
            "Iteración: 345 de 511\n",
            "Iteración: 346 de 511\n",
            "Iteración: 347 de 511\n",
            "Iteración: 348 de 511\n",
            "Iteración: 349 de 511\n",
            "Iteración: 350 de 511\n",
            "Iteración: 351 de 511\n",
            "Iteración: 352 de 511\n",
            "Iteración: 353 de 511\n",
            "Iteración: 354 de 511\n",
            "Iteración: 355 de 511\n",
            "Iteración: 356 de 511\n",
            "Iteración: 357 de 511\n",
            "Iteración: 358 de 511\n",
            "Iteración: 359 de 511\n",
            "Iteración: 360 de 511\n",
            "Iteración: 361 de 511\n",
            "Iteración: 362 de 511\n",
            "Iteración: 363 de 511\n",
            "Iteración: 364 de 511\n",
            "Iteración: 365 de 511\n",
            "Iteración: 366 de 511\n",
            "Iteración: 367 de 511\n",
            "Iteración: 368 de 511\n",
            "Iteración: 369 de 511\n",
            "Iteración: 370 de 511\n",
            "Iteración: 371 de 511\n",
            "Iteración: 372 de 511\n",
            "Iteración: 373 de 511\n",
            "Iteración: 374 de 511\n",
            "Iteración: 375 de 511\n",
            "Iteración: 376 de 511\n",
            "Iteración: 377 de 511\n",
            "Iteración: 378 de 511\n",
            "Iteración: 379 de 511\n",
            "Iteración: 380 de 511\n",
            "Iteración: 381 de 511\n",
            "Iteración: 382 de 511\n",
            "Iteración: 383 de 511\n",
            "Iteración: 384 de 511\n",
            "Iteración: 385 de 511\n",
            "Iteración: 386 de 511\n",
            "Iteración: 387 de 511\n",
            "Iteración: 388 de 511\n",
            "Iteración: 389 de 511\n",
            "Iteración: 390 de 511\n",
            "Iteración: 391 de 511\n",
            "Iteración: 392 de 511\n",
            "Iteración: 393 de 511\n",
            "Iteración: 394 de 511\n",
            "Iteración: 395 de 511\n",
            "Iteración: 396 de 511\n",
            "Iteración: 397 de 511\n",
            "Iteración: 398 de 511\n",
            "Iteración: 399 de 511\n",
            "Iteración: 400 de 511\n",
            "Iteración: 401 de 511\n",
            "Iteración: 402 de 511\n",
            "Iteración: 403 de 511\n",
            "Iteración: 404 de 511\n",
            "Iteración: 405 de 511\n",
            "Iteración: 406 de 511\n",
            "Iteración: 407 de 511\n",
            "Iteración: 408 de 511\n",
            "Iteración: 409 de 511\n",
            "Iteración: 410 de 511\n",
            "Iteración: 411 de 511\n",
            "Iteración: 412 de 511\n",
            "Iteración: 413 de 511\n",
            "Iteración: 414 de 511\n",
            "Iteración: 415 de 511\n",
            "Iteración: 416 de 511\n",
            "Iteración: 417 de 511\n",
            "Iteración: 418 de 511\n",
            "Iteración: 419 de 511\n",
            "Iteración: 420 de 511\n",
            "Iteración: 421 de 511\n",
            "Iteración: 422 de 511\n",
            "Iteración: 423 de 511\n",
            "Iteración: 424 de 511\n",
            "Iteración: 425 de 511\n",
            "Iteración: 426 de 511\n",
            "Iteración: 427 de 511\n",
            "Iteración: 428 de 511\n",
            "Iteración: 429 de 511\n",
            "Iteración: 430 de 511\n",
            "Iteración: 431 de 511\n",
            "Iteración: 432 de 511\n",
            "Iteración: 433 de 511\n",
            "Iteración: 434 de 511\n",
            "Iteración: 435 de 511\n",
            "Iteración: 436 de 511\n",
            "Iteración: 437 de 511\n",
            "Iteración: 438 de 511\n",
            "Iteración: 439 de 511\n",
            "Iteración: 440 de 511\n",
            "Iteración: 441 de 511\n",
            "Iteración: 442 de 511\n",
            "Iteración: 443 de 511\n",
            "Iteración: 444 de 511\n",
            "Iteración: 445 de 511\n",
            "Iteración: 446 de 511\n",
            "Iteración: 447 de 511\n",
            "Iteración: 448 de 511\n",
            "Iteración: 449 de 511\n",
            "Iteración: 450 de 511\n",
            "Iteración: 451 de 511\n",
            "Iteración: 452 de 511\n",
            "Iteración: 453 de 511\n",
            "Iteración: 454 de 511\n",
            "Iteración: 455 de 511\n",
            "Iteración: 456 de 511\n",
            "Iteración: 457 de 511\n",
            "Iteración: 458 de 511\n",
            "Iteración: 459 de 511\n",
            "Iteración: 460 de 511\n",
            "Iteración: 461 de 511\n",
            "Iteración: 462 de 511\n",
            "Iteración: 463 de 511\n",
            "Iteración: 464 de 511\n",
            "Iteración: 465 de 511\n",
            "Iteración: 466 de 511\n",
            "Iteración: 467 de 511\n",
            "Iteración: 468 de 511\n",
            "Iteración: 469 de 511\n",
            "Iteración: 470 de 511\n",
            "Iteración: 471 de 511\n",
            "Iteración: 472 de 511\n",
            "Iteración: 473 de 511\n",
            "Iteración: 474 de 511\n",
            "Iteración: 475 de 511\n",
            "Iteración: 476 de 511\n",
            "Iteración: 477 de 511\n",
            "Iteración: 478 de 511\n",
            "Iteración: 479 de 511\n",
            "Iteración: 480 de 511\n",
            "Iteración: 481 de 511\n",
            "Iteración: 482 de 511\n",
            "Iteración: 483 de 511\n",
            "Iteración: 484 de 511\n",
            "Iteración: 485 de 511\n",
            "Iteración: 486 de 511\n",
            "Iteración: 487 de 511\n",
            "Iteración: 488 de 511\n",
            "Iteración: 489 de 511\n",
            "Iteración: 490 de 511\n",
            "Iteración: 491 de 511\n",
            "Iteración: 492 de 511\n",
            "Iteración: 493 de 511\n",
            "Iteración: 494 de 511\n",
            "Iteración: 495 de 511\n",
            "Iteración: 496 de 511\n",
            "Iteración: 497 de 511\n",
            "Iteración: 498 de 511\n",
            "Iteración: 499 de 511\n",
            "Iteración: 500 de 511\n",
            "Iteración: 501 de 511\n",
            "Iteración: 502 de 511\n",
            "Iteración: 503 de 511\n",
            "Iteración: 504 de 511\n",
            "Iteración: 505 de 511\n",
            "Iteración: 506 de 511\n",
            "Iteración: 507 de 511\n",
            "Iteración: 508 de 511\n",
            "Iteración: 509 de 511\n",
            "Iteración: 510 de 511\n",
            "Accuracy Score = 0.7262622860467253\n",
            "F1 Score (Micro) = 0.7262622860467253\n",
            "F1 Score (Macro) = 0.4207137535918266\n"
          ]
        }
      ],
      "id": "yPCeI5u0S39m"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Entrenamiento del modelo (50% de datos) Loss MSE y lr = 1e-7"
      ],
      "metadata": {
        "id": "Iyq_0W-Lja1C"
      },
      "id": "Iyq_0W-Lja1C"
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainBERTSiameseConcat(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foKUbBywjgRR",
        "outputId": "1ede0355-41c9-424a-b8e9-85955b8de1f8"
      },
      "id": "foKUbBywjgRR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración: 0 de 4083, Loss: 0.09142661690711976\n",
            "Epoch: 0, iteración: 10 de 4083, Loss: 0.9750309944152832\n",
            "Epoch: 0, iteración: 20 de 4083, Loss: 0.8977389335632324\n",
            "Epoch: 0, iteración: 30 de 4083, Loss: 1.0117053031921386\n",
            "Epoch: 0, iteración: 40 de 4083, Loss: 0.910208797454834\n",
            "Epoch: 0, iteración: 50 de 4083, Loss: 0.9546347618103027\n",
            "Epoch: 0, iteración: 60 de 4083, Loss: 0.8645976066589356\n",
            "Epoch: 0, iteración: 70 de 4083, Loss: 0.8153607368469238\n",
            "Epoch: 0, iteración: 80 de 4083, Loss: 0.8270837783813476\n",
            "Epoch: 0, iteración: 90 de 4083, Loss: 0.8262016296386718\n",
            "Epoch: 0, iteración: 100 de 4083, Loss: 0.7459123611450196\n",
            "Epoch: 0, iteración: 110 de 4083, Loss: 0.7221677780151368\n",
            "Epoch: 0, iteración: 120 de 4083, Loss: 0.6665257930755615\n",
            "Epoch: 0, iteración: 130 de 4083, Loss: 0.7931793212890625\n",
            "Epoch: 0, iteración: 140 de 4083, Loss: 0.7266057014465332\n",
            "Epoch: 0, iteración: 150 de 4083, Loss: 0.8019199371337891\n",
            "Epoch: 0, iteración: 160 de 4083, Loss: 0.6706379890441895\n",
            "Epoch: 0, iteración: 170 de 4083, Loss: 0.7321601867675781\n",
            "Epoch: 0, iteración: 180 de 4083, Loss: 0.6149808883666992\n",
            "Epoch: 0, iteración: 190 de 4083, Loss: 0.7460819721221924\n",
            "Epoch: 0, iteración: 200 de 4083, Loss: 0.6186511039733886\n",
            "Epoch: 0, iteración: 210 de 4083, Loss: 0.7606546878814697\n",
            "Epoch: 0, iteración: 220 de 4083, Loss: 0.6428788185119629\n",
            "Epoch: 0, iteración: 230 de 4083, Loss: 0.7080338478088379\n",
            "Epoch: 0, iteración: 240 de 4083, Loss: 0.6180231094360351\n",
            "Epoch: 0, iteración: 250 de 4083, Loss: 0.6490774631500245\n",
            "Epoch: 0, iteración: 260 de 4083, Loss: 0.6636276245117188\n",
            "Epoch: 0, iteración: 270 de 4083, Loss: 0.6095843315124512\n",
            "Epoch: 0, iteración: 280 de 4083, Loss: 0.5090673923492431\n",
            "Epoch: 0, iteración: 290 de 4083, Loss: 0.5814120292663574\n",
            "Epoch: 0, iteración: 300 de 4083, Loss: 0.5518918037414551\n",
            "Epoch: 0, iteración: 310 de 4083, Loss: 0.6265849113464356\n",
            "Epoch: 0, iteración: 320 de 4083, Loss: 0.6036665916442872\n",
            "Epoch: 0, iteración: 330 de 4083, Loss: 0.5426433086395264\n",
            "Epoch: 0, iteración: 340 de 4083, Loss: 0.5871407985687256\n",
            "Epoch: 0, iteración: 350 de 4083, Loss: 0.5577695369720459\n",
            "Epoch: 0, iteración: 360 de 4083, Loss: 0.525503396987915\n",
            "Epoch: 0, iteración: 370 de 4083, Loss: 0.5721076965332031\n",
            "Epoch: 0, iteración: 380 de 4083, Loss: 0.4820878028869629\n",
            "Epoch: 0, iteración: 390 de 4083, Loss: 0.47965826988220217\n",
            "Epoch: 0, iteración: 400 de 4083, Loss: 0.5014522075653076\n",
            "Epoch: 0, iteración: 410 de 4083, Loss: 0.4473316192626953\n",
            "Epoch: 0, iteración: 420 de 4083, Loss: 0.5042948722839355\n",
            "Epoch: 0, iteración: 430 de 4083, Loss: 0.46867761611938474\n",
            "Epoch: 0, iteración: 440 de 4083, Loss: 0.46666250228881834\n",
            "Epoch: 0, iteración: 450 de 4083, Loss: 0.416379451751709\n",
            "Epoch: 0, iteración: 460 de 4083, Loss: 0.40806946754455564\n",
            "Epoch: 0, iteración: 470 de 4083, Loss: 0.42690887451171877\n",
            "Epoch: 0, iteración: 480 de 4083, Loss: 0.3949483156204224\n",
            "Epoch: 0, iteración: 490 de 4083, Loss: 0.4311363220214844\n",
            "Epoch: 0, iteración: 500 de 4083, Loss: 0.418552827835083\n",
            "Epoch: 0, iteración: 510 de 4083, Loss: 0.39235873222351075\n",
            "Epoch: 0, iteración: 520 de 4083, Loss: 0.3297450304031372\n",
            "Epoch: 0, iteración: 530 de 4083, Loss: 0.38622379302978516\n",
            "Epoch: 0, iteración: 540 de 4083, Loss: 0.35600709915161133\n",
            "Epoch: 0, iteración: 550 de 4083, Loss: 0.3720874786376953\n",
            "Epoch: 0, iteración: 560 de 4083, Loss: 0.3704883098602295\n",
            "Epoch: 0, iteración: 570 de 4083, Loss: 0.32016692161560056\n",
            "Epoch: 0, iteración: 580 de 4083, Loss: 0.3357800245285034\n",
            "Epoch: 0, iteración: 590 de 4083, Loss: 0.31461710929870607\n",
            "Epoch: 0, iteración: 600 de 4083, Loss: 0.3205146789550781\n",
            "Epoch: 0, iteración: 610 de 4083, Loss: 0.32539317607879636\n",
            "Epoch: 0, iteración: 620 de 4083, Loss: 0.32526943683624265\n",
            "Epoch: 0, iteración: 630 de 4083, Loss: 0.31296463012695314\n",
            "Epoch: 0, iteración: 640 de 4083, Loss: 0.2853410720825195\n",
            "Epoch: 0, iteración: 650 de 4083, Loss: 0.3008705139160156\n",
            "Epoch: 0, iteración: 660 de 4083, Loss: 0.30309627056121824\n",
            "Epoch: 0, iteración: 670 de 4083, Loss: 0.26606533527374265\n",
            "Epoch: 0, iteración: 680 de 4083, Loss: 0.2968576908111572\n",
            "Epoch: 0, iteración: 690 de 4083, Loss: 0.28280961513519287\n",
            "Epoch: 0, iteración: 700 de 4083, Loss: 0.2643286943435669\n",
            "Epoch: 0, iteración: 710 de 4083, Loss: 0.28508267402648924\n",
            "Epoch: 0, iteración: 720 de 4083, Loss: 0.2675622463226318\n",
            "Epoch: 0, iteración: 730 de 4083, Loss: 0.2606262922286987\n",
            "Epoch: 0, iteración: 740 de 4083, Loss: 0.23395934104919433\n",
            "Epoch: 0, iteración: 750 de 4083, Loss: 0.2537997722625732\n",
            "Epoch: 0, iteración: 760 de 4083, Loss: 0.23389742374420167\n",
            "Epoch: 0, iteración: 770 de 4083, Loss: 0.2422117233276367\n",
            "Epoch: 0, iteración: 780 de 4083, Loss: 0.2404649019241333\n",
            "Epoch: 0, iteración: 790 de 4083, Loss: 0.23239524364471437\n",
            "Epoch: 0, iteración: 800 de 4083, Loss: 0.23090102672576904\n",
            "Epoch: 0, iteración: 810 de 4083, Loss: 0.23785755634307862\n",
            "Epoch: 0, iteración: 820 de 4083, Loss: 0.23103179931640624\n",
            "Epoch: 0, iteración: 830 de 4083, Loss: 0.21878111362457275\n",
            "Epoch: 0, iteración: 840 de 4083, Loss: 0.21962244510650636\n",
            "Epoch: 0, iteración: 850 de 4083, Loss: 0.216390061378479\n",
            "Epoch: 0, iteración: 860 de 4083, Loss: 0.21105294227600097\n",
            "Epoch: 0, iteración: 870 de 4083, Loss: 0.22214360237121583\n",
            "Epoch: 0, iteración: 880 de 4083, Loss: 0.2117990493774414\n",
            "Epoch: 0, iteración: 890 de 4083, Loss: 0.20888841152191162\n",
            "Epoch: 0, iteración: 900 de 4083, Loss: 0.2241534948348999\n",
            "Epoch: 0, iteración: 910 de 4083, Loss: 0.20338003635406493\n",
            "Epoch: 0, iteración: 920 de 4083, Loss: 0.19517388343811035\n",
            "Epoch: 0, iteración: 930 de 4083, Loss: 0.209672212600708\n",
            "Epoch: 0, iteración: 940 de 4083, Loss: 0.22299039363861084\n",
            "Epoch: 0, iteración: 950 de 4083, Loss: 0.21679246425628662\n",
            "Epoch: 0, iteración: 960 de 4083, Loss: 0.18063180446624755\n",
            "Epoch: 0, iteración: 970 de 4083, Loss: 0.23365683555603028\n",
            "Epoch: 0, iteración: 980 de 4083, Loss: 0.21386730670928955\n",
            "Epoch: 0, iteración: 990 de 4083, Loss: 0.24389162063598632\n",
            "Epoch: 0, iteración: 1000 de 4083, Loss: 0.1721557855606079\n",
            "Epoch: 0, iteración: 1010 de 4083, Loss: 0.20441031455993652\n",
            "Epoch: 0, iteración: 1020 de 4083, Loss: 0.17994879484176635\n",
            "Epoch: 0, iteración: 1030 de 4083, Loss: 0.22280209064483641\n",
            "Epoch: 0, iteración: 1040 de 4083, Loss: 0.1801570773124695\n",
            "Epoch: 0, iteración: 1050 de 4083, Loss: 0.1844702959060669\n",
            "Epoch: 0, iteración: 1060 de 4083, Loss: 0.22820570468902587\n",
            "Epoch: 0, iteración: 1070 de 4083, Loss: 0.21220021247863768\n",
            "Epoch: 0, iteración: 1080 de 4083, Loss: 0.23629546165466309\n",
            "Epoch: 0, iteración: 1090 de 4083, Loss: 0.2275852918624878\n",
            "Epoch: 0, iteración: 1100 de 4083, Loss: 0.22670085430145265\n",
            "Epoch: 0, iteración: 1110 de 4083, Loss: 0.1882542133331299\n",
            "Epoch: 0, iteración: 1120 de 4083, Loss: 0.17395156621932983\n",
            "Epoch: 0, iteración: 1130 de 4083, Loss: 0.18742525577545166\n",
            "Epoch: 0, iteración: 1140 de 4083, Loss: 0.24935142993927\n",
            "Epoch: 0, iteración: 1150 de 4083, Loss: 0.18804380893707276\n",
            "Epoch: 0, iteración: 1160 de 4083, Loss: 0.20855414867401123\n",
            "Epoch: 0, iteración: 1170 de 4083, Loss: 0.21933588981628419\n",
            "Epoch: 0, iteración: 1180 de 4083, Loss: 0.24200267791748048\n",
            "Epoch: 0, iteración: 1190 de 4083, Loss: 0.22838759422302246\n",
            "Epoch: 0, iteración: 1200 de 4083, Loss: 0.1846939206123352\n",
            "Epoch: 0, iteración: 1210 de 4083, Loss: 0.23127994537353516\n",
            "Epoch: 0, iteración: 1220 de 4083, Loss: 0.22796885967254638\n",
            "Epoch: 0, iteración: 1230 de 4083, Loss: 0.241532564163208\n",
            "Epoch: 0, iteración: 1240 de 4083, Loss: 0.20988950729370118\n",
            "Epoch: 0, iteración: 1250 de 4083, Loss: 0.21858065128326415\n",
            "Epoch: 0, iteración: 1260 de 4083, Loss: 0.2115386724472046\n",
            "Epoch: 0, iteración: 1270 de 4083, Loss: 0.21047048568725585\n",
            "Epoch: 0, iteración: 1280 de 4083, Loss: 0.22783849239349366\n",
            "Epoch: 0, iteración: 1290 de 4083, Loss: 0.18459900617599487\n",
            "Epoch: 0, iteración: 1300 de 4083, Loss: 0.1527345061302185\n",
            "Epoch: 0, iteración: 1310 de 4083, Loss: 0.2134521484375\n",
            "Epoch: 0, iteración: 1320 de 4083, Loss: 0.22269575595855712\n",
            "Epoch: 0, iteración: 1330 de 4083, Loss: 0.18999651670455933\n",
            "Epoch: 0, iteración: 1340 de 4083, Loss: 0.20122685432434081\n",
            "Epoch: 0, iteración: 1350 de 4083, Loss: 0.19479345083236693\n",
            "Epoch: 0, iteración: 1360 de 4083, Loss: 0.22195169925689698\n",
            "Epoch: 0, iteración: 1370 de 4083, Loss: 0.2289263963699341\n",
            "Epoch: 0, iteración: 1380 de 4083, Loss: 0.20617368221282958\n",
            "Epoch: 0, iteración: 1390 de 4083, Loss: 0.18539044857025147\n",
            "Epoch: 0, iteración: 1400 de 4083, Loss: 0.17713254690170288\n",
            "Epoch: 0, iteración: 1410 de 4083, Loss: 0.1726648688316345\n",
            "Epoch: 0, iteración: 1420 de 4083, Loss: 0.20383312702178955\n",
            "Epoch: 0, iteración: 1430 de 4083, Loss: 0.20285749435424805\n",
            "Epoch: 0, iteración: 1440 de 4083, Loss: 0.23011939525604247\n",
            "Epoch: 0, iteración: 1450 de 4083, Loss: 0.16657788753509523\n",
            "Epoch: 0, iteración: 1460 de 4083, Loss: 0.20999269485473632\n",
            "Epoch: 0, iteración: 1470 de 4083, Loss: 0.20377638339996337\n",
            "Epoch: 0, iteración: 1480 de 4083, Loss: 0.1860320210456848\n",
            "Epoch: 0, iteración: 1490 de 4083, Loss: 0.18511757850646973\n",
            "Epoch: 0, iteración: 1500 de 4083, Loss: 0.18993397951126098\n",
            "Epoch: 0, iteración: 1510 de 4083, Loss: 0.2090444803237915\n",
            "Epoch: 0, iteración: 1520 de 4083, Loss: 0.18372453451156617\n",
            "Epoch: 0, iteración: 1530 de 4083, Loss: 0.26139881610870364\n",
            "Epoch: 0, iteración: 1540 de 4083, Loss: 0.2076647996902466\n",
            "Epoch: 0, iteración: 1550 de 4083, Loss: 0.21787610054016113\n",
            "Epoch: 0, iteración: 1560 de 4083, Loss: 0.23111064434051515\n",
            "Epoch: 0, iteración: 1570 de 4083, Loss: 0.21732449531555176\n",
            "Epoch: 0, iteración: 1580 de 4083, Loss: 0.2151029109954834\n",
            "Epoch: 0, iteración: 1590 de 4083, Loss: 0.18460662364959718\n",
            "Epoch: 0, iteración: 1600 de 4083, Loss: 0.18654674291610718\n",
            "Epoch: 0, iteración: 1610 de 4083, Loss: 0.14109561443328858\n",
            "Epoch: 0, iteración: 1620 de 4083, Loss: 0.17306272983551024\n",
            "Epoch: 0, iteración: 1630 de 4083, Loss: 0.20298171043395996\n",
            "Epoch: 0, iteración: 1640 de 4083, Loss: 0.1892336368560791\n",
            "Epoch: 0, iteración: 1650 de 4083, Loss: 0.20898287296295165\n",
            "Epoch: 0, iteración: 1660 de 4083, Loss: 0.21503837108612062\n",
            "Epoch: 0, iteración: 1670 de 4083, Loss: 0.16953301429748535\n",
            "Epoch: 0, iteración: 1680 de 4083, Loss: 0.18747185468673705\n",
            "Epoch: 0, iteración: 1690 de 4083, Loss: 0.20413975715637206\n",
            "Epoch: 0, iteración: 1700 de 4083, Loss: 0.1998061180114746\n",
            "Epoch: 0, iteración: 1710 de 4083, Loss: 0.21329617500305176\n",
            "Epoch: 0, iteración: 1720 de 4083, Loss: 0.1982034921646118\n",
            "Epoch: 0, iteración: 1730 de 4083, Loss: 0.19004154205322266\n",
            "Epoch: 0, iteración: 1740 de 4083, Loss: 0.20312435626983644\n",
            "Epoch: 0, iteración: 1750 de 4083, Loss: 0.2281719446182251\n",
            "Epoch: 0, iteración: 1760 de 4083, Loss: 0.14738361835479735\n",
            "Epoch: 0, iteración: 1770 de 4083, Loss: 0.22315824031829834\n",
            "Epoch: 0, iteración: 1780 de 4083, Loss: 0.17479583024978637\n",
            "Epoch: 0, iteración: 1790 de 4083, Loss: 0.19035475254058837\n",
            "Epoch: 0, iteración: 1800 de 4083, Loss: 0.23801212310791015\n",
            "Epoch: 0, iteración: 1810 de 4083, Loss: 0.22968828678131104\n",
            "Epoch: 0, iteración: 1820 de 4083, Loss: 0.2178424835205078\n",
            "Epoch: 0, iteración: 1830 de 4083, Loss: 0.2103900671005249\n",
            "Epoch: 0, iteración: 1840 de 4083, Loss: 0.19348506927490233\n",
            "Epoch: 0, iteración: 1850 de 4083, Loss: 0.182289719581604\n",
            "Epoch: 0, iteración: 1860 de 4083, Loss: 0.20272245407104492\n",
            "Epoch: 0, iteración: 1870 de 4083, Loss: 0.20794358253479003\n",
            "Epoch: 0, iteración: 1880 de 4083, Loss: 0.2301255941390991\n",
            "Epoch: 0, iteración: 1890 de 4083, Loss: 0.1992608428001404\n",
            "Epoch: 0, iteración: 1900 de 4083, Loss: 0.22722508907318115\n",
            "Epoch: 0, iteración: 1910 de 4083, Loss: 0.16280050277709962\n",
            "Epoch: 0, iteración: 1920 de 4083, Loss: 0.23602807521820068\n",
            "Epoch: 0, iteración: 1930 de 4083, Loss: 0.22808363437652587\n",
            "Epoch: 0, iteración: 1940 de 4083, Loss: 0.16249651908874513\n",
            "Epoch: 0, iteración: 1950 de 4083, Loss: 0.19738894701004028\n",
            "Epoch: 0, iteración: 1960 de 4083, Loss: 0.19593436717987062\n",
            "Epoch: 0, iteración: 1970 de 4083, Loss: 0.19713003635406495\n",
            "Epoch: 0, iteración: 1980 de 4083, Loss: 0.20057737827301025\n",
            "Epoch: 0, iteración: 1990 de 4083, Loss: 0.15920450687408447\n",
            "Epoch: 0, iteración: 2000 de 4083, Loss: 0.20546886920928956\n",
            "Epoch: 0, iteración: 2010 de 4083, Loss: 0.22591967582702638\n",
            "Epoch: 0, iteración: 2020 de 4083, Loss: 0.23733673095703126\n",
            "Epoch: 0, iteración: 2030 de 4083, Loss: 0.19462708234786988\n",
            "Epoch: 0, iteración: 2040 de 4083, Loss: 0.1913721203804016\n",
            "Epoch: 0, iteración: 2050 de 4083, Loss: 0.22401869297027588\n",
            "Epoch: 0, iteración: 2060 de 4083, Loss: 0.22011945247650147\n",
            "Epoch: 0, iteración: 2070 de 4083, Loss: 0.21850626468658446\n",
            "Epoch: 0, iteración: 2080 de 4083, Loss: 0.18709838390350342\n",
            "Epoch: 0, iteración: 2090 de 4083, Loss: 0.16991997957229615\n",
            "Epoch: 0, iteración: 2100 de 4083, Loss: 0.1884632706642151\n",
            "Epoch: 0, iteración: 2110 de 4083, Loss: 0.18284823894500732\n",
            "Epoch: 0, iteración: 2120 de 4083, Loss: 0.18883731365203857\n",
            "Epoch: 0, iteración: 2130 de 4083, Loss: 0.25404818058013917\n",
            "Epoch: 0, iteración: 2140 de 4083, Loss: 0.1854820132255554\n",
            "Epoch: 0, iteración: 2150 de 4083, Loss: 0.23465213775634766\n",
            "Epoch: 0, iteración: 2160 de 4083, Loss: 0.23423972129821777\n",
            "Epoch: 0, iteración: 2170 de 4083, Loss: 0.2201976776123047\n",
            "Epoch: 0, iteración: 2180 de 4083, Loss: 0.2425691843032837\n",
            "Epoch: 0, iteración: 2190 de 4083, Loss: 0.19098645448684692\n",
            "Epoch: 0, iteración: 2200 de 4083, Loss: 0.21506574153900146\n",
            "Epoch: 0, iteración: 2210 de 4083, Loss: 0.15393974781036376\n",
            "Epoch: 0, iteración: 2220 de 4083, Loss: 0.17907335758209228\n",
            "Epoch: 0, iteración: 2230 de 4083, Loss: 0.20390763282775878\n",
            "Epoch: 0, iteración: 2240 de 4083, Loss: 0.19108539819717407\n",
            "Epoch: 0, iteración: 2250 de 4083, Loss: 0.20291221141815186\n",
            "Epoch: 0, iteración: 2260 de 4083, Loss: 0.22137489318847656\n",
            "Epoch: 0, iteración: 2270 de 4083, Loss: 0.1801137089729309\n",
            "Epoch: 0, iteración: 2280 de 4083, Loss: 0.1890688419342041\n",
            "Epoch: 0, iteración: 2290 de 4083, Loss: 0.18459450006484984\n",
            "Epoch: 0, iteración: 2300 de 4083, Loss: 0.21326851844787598\n",
            "Epoch: 0, iteración: 2310 de 4083, Loss: 0.1857217073440552\n",
            "Epoch: 0, iteración: 2320 de 4083, Loss: 0.15487018823623658\n",
            "Epoch: 0, iteración: 2330 de 4083, Loss: 0.207330060005188\n",
            "Epoch: 0, iteración: 2340 de 4083, Loss: 0.21246042251586914\n",
            "Epoch: 0, iteración: 2350 de 4083, Loss: 0.1627960681915283\n",
            "Epoch: 0, iteración: 2360 de 4083, Loss: 0.18097383975982667\n",
            "Epoch: 0, iteración: 2370 de 4083, Loss: 0.16732616424560548\n",
            "Epoch: 0, iteración: 2380 de 4083, Loss: 0.22768690586090087\n",
            "Epoch: 0, iteración: 2390 de 4083, Loss: 0.1704310417175293\n",
            "Epoch: 0, iteración: 2400 de 4083, Loss: 0.20489904880523682\n",
            "Epoch: 0, iteración: 2410 de 4083, Loss: 0.20924248695373535\n",
            "Epoch: 0, iteración: 2420 de 4083, Loss: 0.21091339588165284\n",
            "Epoch: 0, iteración: 2430 de 4083, Loss: 0.19487152099609376\n",
            "Epoch: 0, iteración: 2440 de 4083, Loss: 0.17775042057037355\n",
            "Epoch: 0, iteración: 2450 de 4083, Loss: 0.2305778980255127\n",
            "Epoch: 0, iteración: 2460 de 4083, Loss: 0.1934342384338379\n",
            "Epoch: 0, iteración: 2470 de 4083, Loss: 0.2360119104385376\n",
            "Epoch: 0, iteración: 2480 de 4083, Loss: 0.16852377653121947\n",
            "Epoch: 0, iteración: 2490 de 4083, Loss: 0.19925907850265503\n",
            "Epoch: 0, iteración: 2500 de 4083, Loss: 0.19695746898651123\n",
            "Epoch: 0, iteración: 2510 de 4083, Loss: 0.21886110305786133\n",
            "Epoch: 0, iteración: 2520 de 4083, Loss: 0.19167063236236573\n",
            "Epoch: 0, iteración: 2530 de 4083, Loss: 0.1781197667121887\n",
            "Epoch: 0, iteración: 2540 de 4083, Loss: 0.20442087650299073\n",
            "Epoch: 0, iteración: 2550 de 4083, Loss: 0.25171818733215334\n",
            "Epoch: 0, iteración: 2560 de 4083, Loss: 0.21485412120819092\n",
            "Epoch: 0, iteración: 2570 de 4083, Loss: 0.19494422674179077\n",
            "Epoch: 0, iteración: 2580 de 4083, Loss: 0.23103125095367433\n",
            "Epoch: 0, iteración: 2590 de 4083, Loss: 0.22400667667388915\n",
            "Epoch: 0, iteración: 2600 de 4083, Loss: 0.2762265205383301\n",
            "Epoch: 0, iteración: 2610 de 4083, Loss: 0.2164900779724121\n",
            "Epoch: 0, iteración: 2620 de 4083, Loss: 0.2100825786590576\n",
            "Epoch: 0, iteración: 2630 de 4083, Loss: 0.15977978706359863\n",
            "Epoch: 0, iteración: 2640 de 4083, Loss: 0.1953233003616333\n",
            "Epoch: 0, iteración: 2650 de 4083, Loss: 0.16996850967407226\n",
            "Epoch: 0, iteración: 2660 de 4083, Loss: 0.1736093521118164\n",
            "Epoch: 0, iteración: 2670 de 4083, Loss: 0.21230640411376953\n",
            "Epoch: 0, iteración: 2680 de 4083, Loss: 0.2123323678970337\n",
            "Epoch: 0, iteración: 2690 de 4083, Loss: 0.2320861577987671\n",
            "Epoch: 0, iteración: 2700 de 4083, Loss: 0.21388840675354004\n",
            "Epoch: 0, iteración: 2710 de 4083, Loss: 0.21584277153015136\n",
            "Epoch: 0, iteración: 2720 de 4083, Loss: 0.17304668426513672\n",
            "Epoch: 0, iteración: 2730 de 4083, Loss: 0.19054737091064453\n",
            "Epoch: 0, iteración: 2740 de 4083, Loss: 0.1917368531227112\n",
            "Epoch: 0, iteración: 2750 de 4083, Loss: 0.20100467205047606\n",
            "Epoch: 0, iteración: 2760 de 4083, Loss: 0.18461791276931763\n",
            "Epoch: 0, iteración: 2770 de 4083, Loss: 0.17387608289718628\n",
            "Epoch: 0, iteración: 2780 de 4083, Loss: 0.2091604709625244\n",
            "Epoch: 0, iteración: 2790 de 4083, Loss: 0.17959058284759521\n",
            "Epoch: 0, iteración: 2800 de 4083, Loss: 0.20744740962982178\n",
            "Epoch: 0, iteración: 2810 de 4083, Loss: 0.19406743049621583\n",
            "Epoch: 0, iteración: 2820 de 4083, Loss: 0.22771103382110597\n",
            "Epoch: 0, iteración: 2830 de 4083, Loss: 0.2119511604309082\n",
            "Epoch: 0, iteración: 2840 de 4083, Loss: 0.19563133716583253\n",
            "Epoch: 0, iteración: 2850 de 4083, Loss: 0.2051677942276001\n",
            "Epoch: 0, iteración: 2860 de 4083, Loss: 0.22284536361694335\n",
            "Epoch: 0, iteración: 2870 de 4083, Loss: 0.18274110555648804\n",
            "Epoch: 0, iteración: 2880 de 4083, Loss: 0.2135472774505615\n",
            "Epoch: 0, iteración: 2890 de 4083, Loss: 0.19549150466918946\n",
            "Epoch: 0, iteración: 2900 de 4083, Loss: 0.20003328323364258\n",
            "Epoch: 0, iteración: 2910 de 4083, Loss: 0.20809409618377686\n",
            "Epoch: 0, iteración: 2920 de 4083, Loss: 0.2161947011947632\n",
            "Epoch: 0, iteración: 2930 de 4083, Loss: 0.18555470705032348\n",
            "Epoch: 0, iteración: 2940 de 4083, Loss: 0.20385205745697021\n",
            "Epoch: 0, iteración: 2950 de 4083, Loss: 0.23836259841918944\n",
            "Epoch: 0, iteración: 2960 de 4083, Loss: 0.22805991172790527\n",
            "Epoch: 0, iteración: 2970 de 4083, Loss: 0.2550806999206543\n",
            "Epoch: 0, iteración: 2980 de 4083, Loss: 0.24344043731689452\n",
            "Epoch: 0, iteración: 2990 de 4083, Loss: 0.21949317455291747\n",
            "Epoch: 0, iteración: 3000 de 4083, Loss: 0.21248998641967773\n",
            "Epoch: 0, iteración: 3010 de 4083, Loss: 0.18513211011886596\n",
            "Epoch: 0, iteración: 3020 de 4083, Loss: 0.17977259159088135\n",
            "Epoch: 0, iteración: 3030 de 4083, Loss: 0.2441175699234009\n",
            "Epoch: 0, iteración: 3040 de 4083, Loss: 0.20162570476531982\n",
            "Epoch: 0, iteración: 3050 de 4083, Loss: 0.21260058879852295\n",
            "Epoch: 0, iteración: 3060 de 4083, Loss: 0.2059675931930542\n",
            "Epoch: 0, iteración: 3070 de 4083, Loss: 0.19647374153137206\n",
            "Epoch: 0, iteración: 3080 de 4083, Loss: 0.15843534469604492\n",
            "Epoch: 0, iteración: 3090 de 4083, Loss: 0.18239936828613282\n",
            "Epoch: 0, iteración: 3100 de 4083, Loss: 0.21784095764160155\n",
            "Epoch: 0, iteración: 3110 de 4083, Loss: 0.2016247272491455\n",
            "Epoch: 0, iteración: 3120 de 4083, Loss: 0.17839810848236085\n",
            "Epoch: 0, iteración: 3130 de 4083, Loss: 0.23182132244110107\n",
            "Epoch: 0, iteración: 3140 de 4083, Loss: 0.1824006676673889\n",
            "Epoch: 0, iteración: 3150 de 4083, Loss: 0.20583970546722413\n",
            "Epoch: 0, iteración: 3160 de 4083, Loss: 0.20553116798400878\n",
            "Epoch: 0, iteración: 3170 de 4083, Loss: 0.22506566047668458\n",
            "Epoch: 0, iteración: 3180 de 4083, Loss: 0.17927511930465698\n",
            "Epoch: 0, iteración: 3190 de 4083, Loss: 0.18169078826904297\n",
            "Epoch: 0, iteración: 3200 de 4083, Loss: 0.24799516201019287\n",
            "Epoch: 0, iteración: 3210 de 4083, Loss: 0.19964599609375\n",
            "Epoch: 0, iteración: 3220 de 4083, Loss: 0.22385156154632568\n",
            "Epoch: 0, iteración: 3230 de 4083, Loss: 0.206567645072937\n",
            "Epoch: 0, iteración: 3240 de 4083, Loss: 0.21029627323150635\n",
            "Epoch: 0, iteración: 3250 de 4083, Loss: 0.22580208778381347\n",
            "Epoch: 0, iteración: 3260 de 4083, Loss: 0.22217371463775634\n",
            "Epoch: 0, iteración: 3270 de 4083, Loss: 0.21446568965911866\n",
            "Epoch: 0, iteración: 3280 de 4083, Loss: 0.1985926866531372\n",
            "Epoch: 0, iteración: 3290 de 4083, Loss: 0.17562808990478515\n",
            "Epoch: 0, iteración: 3300 de 4083, Loss: 0.1715632677078247\n",
            "Epoch: 0, iteración: 3310 de 4083, Loss: 0.21233587265014647\n",
            "Epoch: 0, iteración: 3320 de 4083, Loss: 0.20534701347351075\n",
            "Epoch: 0, iteración: 3330 de 4083, Loss: 0.17301435470581056\n",
            "Epoch: 0, iteración: 3340 de 4083, Loss: 0.19906814098358155\n",
            "Epoch: 0, iteración: 3350 de 4083, Loss: 0.1954946994781494\n",
            "Epoch: 0, iteración: 3360 de 4083, Loss: 0.18842564821243285\n",
            "Epoch: 0, iteración: 3370 de 4083, Loss: 0.18161894083023072\n",
            "Epoch: 0, iteración: 3380 de 4083, Loss: 0.2158149242401123\n",
            "Epoch: 0, iteración: 3390 de 4083, Loss: 0.18722891807556152\n",
            "Epoch: 0, iteración: 3400 de 4083, Loss: 0.22388019561767578\n",
            "Epoch: 0, iteración: 3410 de 4083, Loss: 0.1788500428199768\n",
            "Epoch: 0, iteración: 3420 de 4083, Loss: 0.2194286823272705\n",
            "Epoch: 0, iteración: 3430 de 4083, Loss: 0.20125179290771483\n",
            "Epoch: 0, iteración: 3440 de 4083, Loss: 0.19099955558776854\n",
            "Epoch: 0, iteración: 3450 de 4083, Loss: 0.21477880477905273\n",
            "Epoch: 0, iteración: 3460 de 4083, Loss: 0.25656106472015383\n",
            "Epoch: 0, iteración: 3470 de 4083, Loss: 0.16232359409332275\n",
            "Epoch: 0, iteración: 3480 de 4083, Loss: 0.2014228343963623\n",
            "Epoch: 0, iteración: 3490 de 4083, Loss: 0.18241769075393677\n",
            "Epoch: 0, iteración: 3500 de 4083, Loss: 0.16878221035003663\n",
            "Epoch: 0, iteración: 3510 de 4083, Loss: 0.19015625715255738\n",
            "Epoch: 0, iteración: 3520 de 4083, Loss: 0.17536121606826782\n",
            "Epoch: 0, iteración: 3530 de 4083, Loss: 0.19962191581726074\n",
            "Epoch: 0, iteración: 3540 de 4083, Loss: 0.23131170272827148\n",
            "Epoch: 0, iteración: 3550 de 4083, Loss: 0.20911169052124023\n",
            "Epoch: 0, iteración: 3560 de 4083, Loss: 0.2068326711654663\n",
            "Epoch: 0, iteración: 3570 de 4083, Loss: 0.1927034616470337\n",
            "Epoch: 0, iteración: 3580 de 4083, Loss: 0.21926369667053222\n",
            "Epoch: 0, iteración: 3590 de 4083, Loss: 0.20204851627349854\n",
            "Epoch: 0, iteración: 3600 de 4083, Loss: 0.1971689820289612\n",
            "Epoch: 0, iteración: 3610 de 4083, Loss: 0.1664501190185547\n",
            "Epoch: 0, iteración: 3620 de 4083, Loss: 0.1844179153442383\n",
            "Epoch: 0, iteración: 3630 de 4083, Loss: 0.19446537494659424\n",
            "Epoch: 0, iteración: 3640 de 4083, Loss: 0.25543646812438964\n",
            "Epoch: 0, iteración: 3650 de 4083, Loss: 0.16902257204055787\n",
            "Epoch: 0, iteración: 3660 de 4083, Loss: 0.18767036199569703\n",
            "Epoch: 0, iteración: 3670 de 4083, Loss: 0.20589103698730468\n",
            "Epoch: 0, iteración: 3680 de 4083, Loss: 0.20610363483428956\n",
            "Epoch: 0, iteración: 3690 de 4083, Loss: 0.17036857604980468\n",
            "Epoch: 0, iteración: 3700 de 4083, Loss: 0.2257831573486328\n",
            "Epoch: 0, iteración: 3710 de 4083, Loss: 0.18940091133117676\n",
            "Epoch: 0, iteración: 3720 de 4083, Loss: 0.1865452766418457\n",
            "Epoch: 0, iteración: 3730 de 4083, Loss: 0.23235788345336914\n",
            "Epoch: 0, iteración: 3740 de 4083, Loss: 0.19213149547576905\n",
            "Epoch: 0, iteración: 3750 de 4083, Loss: 0.16635388135910034\n",
            "Epoch: 0, iteración: 3760 de 4083, Loss: 0.17120733261108398\n",
            "Epoch: 0, iteración: 3770 de 4083, Loss: 0.1760535717010498\n",
            "Epoch: 0, iteración: 3780 de 4083, Loss: 0.20335464477539061\n",
            "Epoch: 0, iteración: 3790 de 4083, Loss: 0.22031550407409667\n",
            "Epoch: 0, iteración: 3800 de 4083, Loss: 0.20154411792755128\n",
            "Epoch: 0, iteración: 3810 de 4083, Loss: 0.18626917600631715\n",
            "Epoch: 0, iteración: 3820 de 4083, Loss: 0.21089615821838378\n",
            "Epoch: 0, iteración: 3830 de 4083, Loss: 0.19525099992752076\n",
            "Epoch: 0, iteración: 3840 de 4083, Loss: 0.1830541491508484\n",
            "Epoch: 0, iteración: 3850 de 4083, Loss: 0.18136661052703856\n",
            "Epoch: 0, iteración: 3860 de 4083, Loss: 0.18432530164718627\n",
            "Epoch: 0, iteración: 3870 de 4083, Loss: 0.24178612232208252\n",
            "Epoch: 0, iteración: 3880 de 4083, Loss: 0.18728528022766114\n",
            "Epoch: 0, iteración: 3890 de 4083, Loss: 0.2230954647064209\n",
            "Epoch: 0, iteración: 3900 de 4083, Loss: 0.18600680828094482\n",
            "Epoch: 0, iteración: 3910 de 4083, Loss: 0.2139676332473755\n",
            "Epoch: 0, iteración: 3920 de 4083, Loss: 0.1699931263923645\n",
            "Epoch: 0, iteración: 3930 de 4083, Loss: 0.18054823875427245\n",
            "Epoch: 0, iteración: 3940 de 4083, Loss: 0.1892900824546814\n",
            "Epoch: 0, iteración: 3950 de 4083, Loss: 0.23047795295715331\n",
            "Epoch: 0, iteración: 3960 de 4083, Loss: 0.23611512184143066\n",
            "Epoch: 0, iteración: 3970 de 4083, Loss: 0.18709242343902588\n",
            "Epoch: 0, iteración: 3980 de 4083, Loss: 0.21580400466918945\n",
            "Epoch: 0, iteración: 3990 de 4083, Loss: 0.19593944549560546\n",
            "Epoch: 0, iteración: 4000 de 4083, Loss: 0.20852413177490234\n",
            "Epoch: 0, iteración: 4010 de 4083, Loss: 0.16748470067977905\n",
            "Epoch: 0, iteración: 4020 de 4083, Loss: 0.18960827589035034\n",
            "Epoch: 0, iteración: 4030 de 4083, Loss: 0.23771791458129882\n",
            "Epoch: 0, iteración: 4040 de 4083, Loss: 0.16778898239135742\n",
            "Epoch: 0, iteración: 4050 de 4083, Loss: 0.22006163597106934\n",
            "Epoch: 0, iteración: 4060 de 4083, Loss: 0.2107475757598877\n",
            "Epoch: 0, iteración: 4070 de 4083, Loss: 0.15903000831604003\n",
            "Epoch: 0, iteración: 4080 de 4083, Loss: 0.2182201623916626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_lr7_MSE_50.pth\")\n",
        "  print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "metadata": {
        "id": "iFsENbvBjijR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbabbd42-983c-4367-9fae-f81887a8836e"
      },
      "id": "iFsENbvBjijR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Evaluación del modelo"
      ],
      "metadata": {
        "id": "eXX1q6M4S7ML"
      },
      "id": "eXX1q6M4S7ML"
    },
    {
      "cell_type": "code",
      "source": [
        "def validationBERTSiameseConcat(epoch):\n",
        "  model.eval()\n",
        "  fin_targets=[]\n",
        "  fin_outputs=[]\n",
        "  num_iteraciones = len(testing_loader)\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testing_loader, 0):\n",
        "      ids1 = data['ids1'].to(device)\n",
        "      ids2 = data['ids2'].to(device)\n",
        "      mask1 = data['mask1'].to(device)\n",
        "      mask2 = data['mask2'].to(device)\n",
        "      token_type_ids1 = data[\"token_type_ids1\"].to(device)\n",
        "      token_type_ids2 = data[\"token_type_ids2\"].to(device)\n",
        "      targets = data['target'].to(device)\n",
        "\n",
        "      print(f\"Iteración: {i} de {num_iteraciones}\")\n",
        "\n",
        "      outputs = model(ids1, mask1, token_type_ids1, ids2, mask2, token_type_ids2)\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "  return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "QyH6mraQS7Mn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QyH6mraQS7Mn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "Hk5d0xpHS7Mn"
      },
      "id": "Hk5d0xpHS7Mn"
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_lr7_MSE_50.pth\"):\n",
        "  model = BERTSiameseConcat()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_lr7_MSE_50.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_lr7_MSE_50.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "metadata": {
        "id": "_AUTLUCVS7Mn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf398ba-976e-4043-e4e3-d8eae2ce2f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado correctamente\n"
          ]
        }
      ],
      "id": "_AUTLUCVS7Mn"
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationBERTSiameseConcat(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125aa8a6-972c-4394-bb1c-f353fba7558b",
        "id": "BSt4lJbxS7Mn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración: 0 de 511\n",
            "Iteración: 1 de 511\n",
            "Iteración: 2 de 511\n",
            "Iteración: 3 de 511\n",
            "Iteración: 4 de 511\n",
            "Iteración: 5 de 511\n",
            "Iteración: 6 de 511\n",
            "Iteración: 7 de 511\n",
            "Iteración: 8 de 511\n",
            "Iteración: 9 de 511\n",
            "Iteración: 10 de 511\n",
            "Iteración: 11 de 511\n",
            "Iteración: 12 de 511\n",
            "Iteración: 13 de 511\n",
            "Iteración: 14 de 511\n",
            "Iteración: 15 de 511\n",
            "Iteración: 16 de 511\n",
            "Iteración: 17 de 511\n",
            "Iteración: 18 de 511\n",
            "Iteración: 19 de 511\n",
            "Iteración: 20 de 511\n",
            "Iteración: 21 de 511\n",
            "Iteración: 22 de 511\n",
            "Iteración: 23 de 511\n",
            "Iteración: 24 de 511\n",
            "Iteración: 25 de 511\n",
            "Iteración: 26 de 511\n",
            "Iteración: 27 de 511\n",
            "Iteración: 28 de 511\n",
            "Iteración: 29 de 511\n",
            "Iteración: 30 de 511\n",
            "Iteración: 31 de 511\n",
            "Iteración: 32 de 511\n",
            "Iteración: 33 de 511\n",
            "Iteración: 34 de 511\n",
            "Iteración: 35 de 511\n",
            "Iteración: 36 de 511\n",
            "Iteración: 37 de 511\n",
            "Iteración: 38 de 511\n",
            "Iteración: 39 de 511\n",
            "Iteración: 40 de 511\n",
            "Iteración: 41 de 511\n",
            "Iteración: 42 de 511\n",
            "Iteración: 43 de 511\n",
            "Iteración: 44 de 511\n",
            "Iteración: 45 de 511\n",
            "Iteración: 46 de 511\n",
            "Iteración: 47 de 511\n",
            "Iteración: 48 de 511\n",
            "Iteración: 49 de 511\n",
            "Iteración: 50 de 511\n",
            "Iteración: 51 de 511\n",
            "Iteración: 52 de 511\n",
            "Iteración: 53 de 511\n",
            "Iteración: 54 de 511\n",
            "Iteración: 55 de 511\n",
            "Iteración: 56 de 511\n",
            "Iteración: 57 de 511\n",
            "Iteración: 58 de 511\n",
            "Iteración: 59 de 511\n",
            "Iteración: 60 de 511\n",
            "Iteración: 61 de 511\n",
            "Iteración: 62 de 511\n",
            "Iteración: 63 de 511\n",
            "Iteración: 64 de 511\n",
            "Iteración: 65 de 511\n",
            "Iteración: 66 de 511\n",
            "Iteración: 67 de 511\n",
            "Iteración: 68 de 511\n",
            "Iteración: 69 de 511\n",
            "Iteración: 70 de 511\n",
            "Iteración: 71 de 511\n",
            "Iteración: 72 de 511\n",
            "Iteración: 73 de 511\n",
            "Iteración: 74 de 511\n",
            "Iteración: 75 de 511\n",
            "Iteración: 76 de 511\n",
            "Iteración: 77 de 511\n",
            "Iteración: 78 de 511\n",
            "Iteración: 79 de 511\n",
            "Iteración: 80 de 511\n",
            "Iteración: 81 de 511\n",
            "Iteración: 82 de 511\n",
            "Iteración: 83 de 511\n",
            "Iteración: 84 de 511\n",
            "Iteración: 85 de 511\n",
            "Iteración: 86 de 511\n",
            "Iteración: 87 de 511\n",
            "Iteración: 88 de 511\n",
            "Iteración: 89 de 511\n",
            "Iteración: 90 de 511\n",
            "Iteración: 91 de 511\n",
            "Iteración: 92 de 511\n",
            "Iteración: 93 de 511\n",
            "Iteración: 94 de 511\n",
            "Iteración: 95 de 511\n",
            "Iteración: 96 de 511\n",
            "Iteración: 97 de 511\n",
            "Iteración: 98 de 511\n",
            "Iteración: 99 de 511\n",
            "Iteración: 100 de 511\n",
            "Iteración: 101 de 511\n",
            "Iteración: 102 de 511\n",
            "Iteración: 103 de 511\n",
            "Iteración: 104 de 511\n",
            "Iteración: 105 de 511\n",
            "Iteración: 106 de 511\n",
            "Iteración: 107 de 511\n",
            "Iteración: 108 de 511\n",
            "Iteración: 109 de 511\n",
            "Iteración: 110 de 511\n",
            "Iteración: 111 de 511\n",
            "Iteración: 112 de 511\n",
            "Iteración: 113 de 511\n",
            "Iteración: 114 de 511\n",
            "Iteración: 115 de 511\n",
            "Iteración: 116 de 511\n",
            "Iteración: 117 de 511\n",
            "Iteración: 118 de 511\n",
            "Iteración: 119 de 511\n",
            "Iteración: 120 de 511\n",
            "Iteración: 121 de 511\n",
            "Iteración: 122 de 511\n",
            "Iteración: 123 de 511\n",
            "Iteración: 124 de 511\n",
            "Iteración: 125 de 511\n",
            "Iteración: 126 de 511\n",
            "Iteración: 127 de 511\n",
            "Iteración: 128 de 511\n",
            "Iteración: 129 de 511\n",
            "Iteración: 130 de 511\n",
            "Iteración: 131 de 511\n",
            "Iteración: 132 de 511\n",
            "Iteración: 133 de 511\n",
            "Iteración: 134 de 511\n",
            "Iteración: 135 de 511\n",
            "Iteración: 136 de 511\n",
            "Iteración: 137 de 511\n",
            "Iteración: 138 de 511\n",
            "Iteración: 139 de 511\n",
            "Iteración: 140 de 511\n",
            "Iteración: 141 de 511\n",
            "Iteración: 142 de 511\n",
            "Iteración: 143 de 511\n",
            "Iteración: 144 de 511\n",
            "Iteración: 145 de 511\n",
            "Iteración: 146 de 511\n",
            "Iteración: 147 de 511\n",
            "Iteración: 148 de 511\n",
            "Iteración: 149 de 511\n",
            "Iteración: 150 de 511\n",
            "Iteración: 151 de 511\n",
            "Iteración: 152 de 511\n",
            "Iteración: 153 de 511\n",
            "Iteración: 154 de 511\n",
            "Iteración: 155 de 511\n",
            "Iteración: 156 de 511\n",
            "Iteración: 157 de 511\n",
            "Iteración: 158 de 511\n",
            "Iteración: 159 de 511\n",
            "Iteración: 160 de 511\n",
            "Iteración: 161 de 511\n",
            "Iteración: 162 de 511\n",
            "Iteración: 163 de 511\n",
            "Iteración: 164 de 511\n",
            "Iteración: 165 de 511\n",
            "Iteración: 166 de 511\n",
            "Iteración: 167 de 511\n",
            "Iteración: 168 de 511\n",
            "Iteración: 169 de 511\n",
            "Iteración: 170 de 511\n",
            "Iteración: 171 de 511\n",
            "Iteración: 172 de 511\n",
            "Iteración: 173 de 511\n",
            "Iteración: 174 de 511\n",
            "Iteración: 175 de 511\n",
            "Iteración: 176 de 511\n",
            "Iteración: 177 de 511\n",
            "Iteración: 178 de 511\n",
            "Iteración: 179 de 511\n",
            "Iteración: 180 de 511\n",
            "Iteración: 181 de 511\n",
            "Iteración: 182 de 511\n",
            "Iteración: 183 de 511\n",
            "Iteración: 184 de 511\n",
            "Iteración: 185 de 511\n",
            "Iteración: 186 de 511\n",
            "Iteración: 187 de 511\n",
            "Iteración: 188 de 511\n",
            "Iteración: 189 de 511\n",
            "Iteración: 190 de 511\n",
            "Iteración: 191 de 511\n",
            "Iteración: 192 de 511\n",
            "Iteración: 193 de 511\n",
            "Iteración: 194 de 511\n",
            "Iteración: 195 de 511\n",
            "Iteración: 196 de 511\n",
            "Iteración: 197 de 511\n",
            "Iteración: 198 de 511\n",
            "Iteración: 199 de 511\n",
            "Iteración: 200 de 511\n",
            "Iteración: 201 de 511\n",
            "Iteración: 202 de 511\n",
            "Iteración: 203 de 511\n",
            "Iteración: 204 de 511\n",
            "Iteración: 205 de 511\n",
            "Iteración: 206 de 511\n",
            "Iteración: 207 de 511\n",
            "Iteración: 208 de 511\n",
            "Iteración: 209 de 511\n",
            "Iteración: 210 de 511\n",
            "Iteración: 211 de 511\n",
            "Iteración: 212 de 511\n",
            "Iteración: 213 de 511\n",
            "Iteración: 214 de 511\n",
            "Iteración: 215 de 511\n",
            "Iteración: 216 de 511\n",
            "Iteración: 217 de 511\n",
            "Iteración: 218 de 511\n",
            "Iteración: 219 de 511\n",
            "Iteración: 220 de 511\n",
            "Iteración: 221 de 511\n",
            "Iteración: 222 de 511\n",
            "Iteración: 223 de 511\n",
            "Iteración: 224 de 511\n",
            "Iteración: 225 de 511\n",
            "Iteración: 226 de 511\n",
            "Iteración: 227 de 511\n",
            "Iteración: 228 de 511\n",
            "Iteración: 229 de 511\n",
            "Iteración: 230 de 511\n",
            "Iteración: 231 de 511\n",
            "Iteración: 232 de 511\n",
            "Iteración: 233 de 511\n",
            "Iteración: 234 de 511\n",
            "Iteración: 235 de 511\n",
            "Iteración: 236 de 511\n",
            "Iteración: 237 de 511\n",
            "Iteración: 238 de 511\n",
            "Iteración: 239 de 511\n",
            "Iteración: 240 de 511\n",
            "Iteración: 241 de 511\n",
            "Iteración: 242 de 511\n",
            "Iteración: 243 de 511\n",
            "Iteración: 244 de 511\n",
            "Iteración: 245 de 511\n",
            "Iteración: 246 de 511\n",
            "Iteración: 247 de 511\n",
            "Iteración: 248 de 511\n",
            "Iteración: 249 de 511\n",
            "Iteración: 250 de 511\n",
            "Iteración: 251 de 511\n",
            "Iteración: 252 de 511\n",
            "Iteración: 253 de 511\n",
            "Iteración: 254 de 511\n",
            "Iteración: 255 de 511\n",
            "Iteración: 256 de 511\n",
            "Iteración: 257 de 511\n",
            "Iteración: 258 de 511\n",
            "Iteración: 259 de 511\n",
            "Iteración: 260 de 511\n",
            "Iteración: 261 de 511\n",
            "Iteración: 262 de 511\n",
            "Iteración: 263 de 511\n",
            "Iteración: 264 de 511\n",
            "Iteración: 265 de 511\n",
            "Iteración: 266 de 511\n",
            "Iteración: 267 de 511\n",
            "Iteración: 268 de 511\n",
            "Iteración: 269 de 511\n",
            "Iteración: 270 de 511\n",
            "Iteración: 271 de 511\n",
            "Iteración: 272 de 511\n",
            "Iteración: 273 de 511\n",
            "Iteración: 274 de 511\n",
            "Iteración: 275 de 511\n",
            "Iteración: 276 de 511\n",
            "Iteración: 277 de 511\n",
            "Iteración: 278 de 511\n",
            "Iteración: 279 de 511\n",
            "Iteración: 280 de 511\n",
            "Iteración: 281 de 511\n",
            "Iteración: 282 de 511\n",
            "Iteración: 283 de 511\n",
            "Iteración: 284 de 511\n",
            "Iteración: 285 de 511\n",
            "Iteración: 286 de 511\n",
            "Iteración: 287 de 511\n",
            "Iteración: 288 de 511\n",
            "Iteración: 289 de 511\n",
            "Iteración: 290 de 511\n",
            "Iteración: 291 de 511\n",
            "Iteración: 292 de 511\n",
            "Iteración: 293 de 511\n",
            "Iteración: 294 de 511\n",
            "Iteración: 295 de 511\n",
            "Iteración: 296 de 511\n",
            "Iteración: 297 de 511\n",
            "Iteración: 298 de 511\n",
            "Iteración: 299 de 511\n",
            "Iteración: 300 de 511\n",
            "Iteración: 301 de 511\n",
            "Iteración: 302 de 511\n",
            "Iteración: 303 de 511\n",
            "Iteración: 304 de 511\n",
            "Iteración: 305 de 511\n",
            "Iteración: 306 de 511\n",
            "Iteración: 307 de 511\n",
            "Iteración: 308 de 511\n",
            "Iteración: 309 de 511\n",
            "Iteración: 310 de 511\n",
            "Iteración: 311 de 511\n",
            "Iteración: 312 de 511\n",
            "Iteración: 313 de 511\n",
            "Iteración: 314 de 511\n",
            "Iteración: 315 de 511\n",
            "Iteración: 316 de 511\n",
            "Iteración: 317 de 511\n",
            "Iteración: 318 de 511\n",
            "Iteración: 319 de 511\n",
            "Iteración: 320 de 511\n",
            "Iteración: 321 de 511\n",
            "Iteración: 322 de 511\n",
            "Iteración: 323 de 511\n",
            "Iteración: 324 de 511\n",
            "Iteración: 325 de 511\n",
            "Iteración: 326 de 511\n",
            "Iteración: 327 de 511\n",
            "Iteración: 328 de 511\n",
            "Iteración: 329 de 511\n",
            "Iteración: 330 de 511\n",
            "Iteración: 331 de 511\n",
            "Iteración: 332 de 511\n",
            "Iteración: 333 de 511\n",
            "Iteración: 334 de 511\n",
            "Iteración: 335 de 511\n",
            "Iteración: 336 de 511\n",
            "Iteración: 337 de 511\n",
            "Iteración: 338 de 511\n",
            "Iteración: 339 de 511\n",
            "Iteración: 340 de 511\n",
            "Iteración: 341 de 511\n",
            "Iteración: 342 de 511\n",
            "Iteración: 343 de 511\n",
            "Iteración: 344 de 511\n",
            "Iteración: 345 de 511\n",
            "Iteración: 346 de 511\n",
            "Iteración: 347 de 511\n",
            "Iteración: 348 de 511\n",
            "Iteración: 349 de 511\n",
            "Iteración: 350 de 511\n",
            "Iteración: 351 de 511\n",
            "Iteración: 352 de 511\n",
            "Iteración: 353 de 511\n",
            "Iteración: 354 de 511\n",
            "Iteración: 355 de 511\n",
            "Iteración: 356 de 511\n",
            "Iteración: 357 de 511\n",
            "Iteración: 358 de 511\n",
            "Iteración: 359 de 511\n",
            "Iteración: 360 de 511\n",
            "Iteración: 361 de 511\n",
            "Iteración: 362 de 511\n",
            "Iteración: 363 de 511\n",
            "Iteración: 364 de 511\n",
            "Iteración: 365 de 511\n",
            "Iteración: 366 de 511\n",
            "Iteración: 367 de 511\n",
            "Iteración: 368 de 511\n",
            "Iteración: 369 de 511\n",
            "Iteración: 370 de 511\n",
            "Iteración: 371 de 511\n",
            "Iteración: 372 de 511\n",
            "Iteración: 373 de 511\n",
            "Iteración: 374 de 511\n",
            "Iteración: 375 de 511\n",
            "Iteración: 376 de 511\n",
            "Iteración: 377 de 511\n",
            "Iteración: 378 de 511\n",
            "Iteración: 379 de 511\n",
            "Iteración: 380 de 511\n",
            "Iteración: 381 de 511\n",
            "Iteración: 382 de 511\n",
            "Iteración: 383 de 511\n",
            "Iteración: 384 de 511\n",
            "Iteración: 385 de 511\n",
            "Iteración: 386 de 511\n",
            "Iteración: 387 de 511\n",
            "Iteración: 388 de 511\n",
            "Iteración: 389 de 511\n",
            "Iteración: 390 de 511\n",
            "Iteración: 391 de 511\n",
            "Iteración: 392 de 511\n",
            "Iteración: 393 de 511\n",
            "Iteración: 394 de 511\n",
            "Iteración: 395 de 511\n",
            "Iteración: 396 de 511\n",
            "Iteración: 397 de 511\n",
            "Iteración: 398 de 511\n",
            "Iteración: 399 de 511\n",
            "Iteración: 400 de 511\n",
            "Iteración: 401 de 511\n",
            "Iteración: 402 de 511\n",
            "Iteración: 403 de 511\n",
            "Iteración: 404 de 511\n",
            "Iteración: 405 de 511\n",
            "Iteración: 406 de 511\n",
            "Iteración: 407 de 511\n",
            "Iteración: 408 de 511\n",
            "Iteración: 409 de 511\n",
            "Iteración: 410 de 511\n",
            "Iteración: 411 de 511\n",
            "Iteración: 412 de 511\n",
            "Iteración: 413 de 511\n",
            "Iteración: 414 de 511\n",
            "Iteración: 415 de 511\n",
            "Iteración: 416 de 511\n",
            "Iteración: 417 de 511\n",
            "Iteración: 418 de 511\n",
            "Iteración: 419 de 511\n",
            "Iteración: 420 de 511\n",
            "Iteración: 421 de 511\n",
            "Iteración: 422 de 511\n",
            "Iteración: 423 de 511\n",
            "Iteración: 424 de 511\n",
            "Iteración: 425 de 511\n",
            "Iteración: 426 de 511\n",
            "Iteración: 427 de 511\n",
            "Iteración: 428 de 511\n",
            "Iteración: 429 de 511\n",
            "Iteración: 430 de 511\n",
            "Iteración: 431 de 511\n",
            "Iteración: 432 de 511\n",
            "Iteración: 433 de 511\n",
            "Iteración: 434 de 511\n",
            "Iteración: 435 de 511\n",
            "Iteración: 436 de 511\n",
            "Iteración: 437 de 511\n",
            "Iteración: 438 de 511\n",
            "Iteración: 439 de 511\n",
            "Iteración: 440 de 511\n",
            "Iteración: 441 de 511\n",
            "Iteración: 442 de 511\n",
            "Iteración: 443 de 511\n",
            "Iteración: 444 de 511\n",
            "Iteración: 445 de 511\n",
            "Iteración: 446 de 511\n",
            "Iteración: 447 de 511\n",
            "Iteración: 448 de 511\n",
            "Iteración: 449 de 511\n",
            "Iteración: 450 de 511\n",
            "Iteración: 451 de 511\n",
            "Iteración: 452 de 511\n",
            "Iteración: 453 de 511\n",
            "Iteración: 454 de 511\n",
            "Iteración: 455 de 511\n",
            "Iteración: 456 de 511\n",
            "Iteración: 457 de 511\n",
            "Iteración: 458 de 511\n",
            "Iteración: 459 de 511\n",
            "Iteración: 460 de 511\n",
            "Iteración: 461 de 511\n",
            "Iteración: 462 de 511\n",
            "Iteración: 463 de 511\n",
            "Iteración: 464 de 511\n",
            "Iteración: 465 de 511\n",
            "Iteración: 466 de 511\n",
            "Iteración: 467 de 511\n",
            "Iteración: 468 de 511\n",
            "Iteración: 469 de 511\n",
            "Iteración: 470 de 511\n",
            "Iteración: 471 de 511\n",
            "Iteración: 472 de 511\n",
            "Iteración: 473 de 511\n",
            "Iteración: 474 de 511\n",
            "Iteración: 475 de 511\n",
            "Iteración: 476 de 511\n",
            "Iteración: 477 de 511\n",
            "Iteración: 478 de 511\n",
            "Iteración: 479 de 511\n",
            "Iteración: 480 de 511\n",
            "Iteración: 481 de 511\n",
            "Iteración: 482 de 511\n",
            "Iteración: 483 de 511\n",
            "Iteración: 484 de 511\n",
            "Iteración: 485 de 511\n",
            "Iteración: 486 de 511\n",
            "Iteración: 487 de 511\n",
            "Iteración: 488 de 511\n",
            "Iteración: 489 de 511\n",
            "Iteración: 490 de 511\n",
            "Iteración: 491 de 511\n",
            "Iteración: 492 de 511\n",
            "Iteración: 493 de 511\n",
            "Iteración: 494 de 511\n",
            "Iteración: 495 de 511\n",
            "Iteración: 496 de 511\n",
            "Iteración: 497 de 511\n",
            "Iteración: 498 de 511\n",
            "Iteración: 499 de 511\n",
            "Iteración: 500 de 511\n",
            "Iteración: 501 de 511\n",
            "Iteración: 502 de 511\n",
            "Iteración: 503 de 511\n",
            "Iteración: 504 de 511\n",
            "Iteración: 505 de 511\n",
            "Iteración: 506 de 511\n",
            "Iteración: 507 de 511\n",
            "Iteración: 508 de 511\n",
            "Iteración: 509 de 511\n",
            "Iteración: 510 de 511\n",
            "Accuracy Score = 0.7262622860467253\n",
            "F1 Score (Micro) = 0.7262622860467253\n",
            "F1 Score (Macro) = 0.4207137535918266\n"
          ]
        }
      ],
      "id": "BSt4lJbxS7Mn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Loss BCE + LeakyRelu + Sigmoid"
      ],
      "metadata": {
        "id": "QTuB8tGNQrxm"
      },
      "id": "QTuB8tGNQrxm"
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  trainBERTSiameseConcat(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "fda54f0e-ad7f-40d6-9153-ae1c618eb660",
        "id": "Q1_ejMGpQrxm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, iteración: 0 de 4083, Loss: 0.06848677396774291\n",
            "Epoch: 0, iteración: 10 de 4083, Loss: 0.6721079349517822\n",
            "Epoch: 0, iteración: 20 de 4083, Loss: 0.6728714942932129\n",
            "Epoch: 0, iteración: 30 de 4083, Loss: 0.6785274982452393\n",
            "Epoch: 0, iteración: 40 de 4083, Loss: 0.6701336860656738\n",
            "Epoch: 0, iteración: 50 de 4083, Loss: 0.6746286869049072\n",
            "Epoch: 0, iteración: 60 de 4083, Loss: 0.6716646671295166\n",
            "Epoch: 0, iteración: 70 de 4083, Loss: 0.6796284675598144\n",
            "Epoch: 0, iteración: 80 de 4083, Loss: 0.6731937408447266\n",
            "Epoch: 0, iteración: 90 de 4083, Loss: 0.675541877746582\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-9dee606bb1ab>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrainBERTSiameseConcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-2b1a807bcca8>\u001b[0m in \u001b[0;36mtrainBERTSiameseConcat\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mperdida\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "id": "Q1_ejMGpQrxm"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  torch.save(model.state_dict(), \"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_lr7_BCE_50.pth\")\n",
        "  print(\"Modelo guardado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al guardar el modelo: {e}\")"
      ],
      "metadata": {
        "id": "vDggKR8oQrxn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "vDggKR8oQrxn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Evaluación del modelo"
      ],
      "metadata": {
        "id": "nddaJsWJF4nj"
      },
      "id": "nddaJsWJF4nj"
    },
    {
      "cell_type": "code",
      "source": [
        "def validationBERTSiameseConcat(epoch):\n",
        "  model.eval()\n",
        "  fin_targets=[]\n",
        "  fin_outputs=[]\n",
        "  num_iteraciones = len(testing_loader)\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testing_loader, 0):\n",
        "      ids1 = data['ids1'].to(device)\n",
        "      ids2 = data['ids2'].to(device)\n",
        "      mask1 = data['mask1'].to(device)\n",
        "      mask2 = data['mask2'].to(device)\n",
        "      token_type_ids1 = data[\"token_type_ids1\"].to(device)\n",
        "      token_type_ids2 = data[\"token_type_ids2\"].to(device)\n",
        "      targets = data['target'].to(device)\n",
        "\n",
        "      print(f\"Iteración: {i} de {num_iteraciones}\")\n",
        "\n",
        "      outputs = model(ids1, mask1, token_type_ids1, ids2, mask2, token_type_ids2)\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "  return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "ckGWX6W7F7GD"
      },
      "id": "ckGWX6W7F7GD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Esta celda no se encuentra ejecutada porque solo se usa cuando la evaluación de un modelo se ha hecho en una sesión distinta a su entrenamiento. Si se hace en la misma sesión, no tenemos necesidad de cargar el modelo (que acabamos de entrenar). Por el contrario, si lo entrenamos \"hoy\" y lo evaluamos \"mañana\", en vez de reentrenarlo para poder evaluarlo, solo es necesario cargarlo."
      ],
      "metadata": {
        "id": "8Q_jGAQVPs7y"
      },
      "id": "8Q_jGAQVPs7y"
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_lr7_BCE_50.pth\"):\n",
        "  model = BERTSiameseConcat()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_lr7_BCE_50.pth\"))\n",
        "    print(\"Modelo cargado correctamente\")\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_siamese_bert_concat_lr7_BCE_50.pth\", map_location=\"cpu\"))\n",
        "    print(\"Modelo cargado correctamente con CPU\")\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "metadata": {
        "id": "dW9yFfatF-Ul"
      },
      "id": "dW9yFfatF-Ul",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  outputs, targets = validationBERTSiameseConcat(epoch)\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Accuracy Score = {accuracy}\")\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc7m1iQVGBue",
        "outputId": "9565186f-097c-40eb-ce6c-5a550cefab08"
      },
      "id": "mc7m1iQVGBue",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteración: 0 de 411\n",
            "Iteración: 1 de 411\n",
            "Iteración: 2 de 411\n",
            "Iteración: 3 de 411\n",
            "Iteración: 4 de 411\n",
            "Iteración: 5 de 411\n",
            "Iteración: 6 de 411\n",
            "Iteración: 7 de 411\n",
            "Iteración: 8 de 411\n",
            "Iteración: 9 de 411\n",
            "Iteración: 10 de 411\n",
            "Iteración: 11 de 411\n",
            "Iteración: 12 de 411\n",
            "Iteración: 13 de 411\n",
            "Iteración: 14 de 411\n",
            "Iteración: 15 de 411\n",
            "Iteración: 16 de 411\n",
            "Iteración: 17 de 411\n",
            "Iteración: 18 de 411\n",
            "Iteración: 19 de 411\n",
            "Iteración: 20 de 411\n",
            "Iteración: 21 de 411\n",
            "Iteración: 22 de 411\n",
            "Iteración: 23 de 411\n",
            "Iteración: 24 de 411\n",
            "Iteración: 25 de 411\n",
            "Iteración: 26 de 411\n",
            "Iteración: 27 de 411\n",
            "Iteración: 28 de 411\n",
            "Iteración: 29 de 411\n",
            "Iteración: 30 de 411\n",
            "Iteración: 31 de 411\n",
            "Iteración: 32 de 411\n",
            "Iteración: 33 de 411\n",
            "Iteración: 34 de 411\n",
            "Iteración: 35 de 411\n",
            "Iteración: 36 de 411\n",
            "Iteración: 37 de 411\n",
            "Iteración: 38 de 411\n",
            "Iteración: 39 de 411\n",
            "Iteración: 40 de 411\n",
            "Iteración: 41 de 411\n",
            "Iteración: 42 de 411\n",
            "Iteración: 43 de 411\n",
            "Iteración: 44 de 411\n",
            "Iteración: 45 de 411\n",
            "Iteración: 46 de 411\n",
            "Iteración: 47 de 411\n",
            "Iteración: 48 de 411\n",
            "Iteración: 49 de 411\n",
            "Iteración: 50 de 411\n",
            "Iteración: 51 de 411\n",
            "Iteración: 52 de 411\n",
            "Iteración: 53 de 411\n",
            "Iteración: 54 de 411\n",
            "Iteración: 55 de 411\n",
            "Iteración: 56 de 411\n",
            "Iteración: 57 de 411\n",
            "Iteración: 58 de 411\n",
            "Iteración: 59 de 411\n",
            "Iteración: 60 de 411\n",
            "Iteración: 61 de 411\n",
            "Iteración: 62 de 411\n",
            "Iteración: 63 de 411\n",
            "Iteración: 64 de 411\n",
            "Iteración: 65 de 411\n",
            "Iteración: 66 de 411\n",
            "Iteración: 67 de 411\n",
            "Iteración: 68 de 411\n",
            "Iteración: 69 de 411\n",
            "Iteración: 70 de 411\n",
            "Iteración: 71 de 411\n",
            "Iteración: 72 de 411\n",
            "Iteración: 73 de 411\n",
            "Iteración: 74 de 411\n",
            "Iteración: 75 de 411\n",
            "Iteración: 76 de 411\n",
            "Iteración: 77 de 411\n",
            "Iteración: 78 de 411\n",
            "Iteración: 79 de 411\n",
            "Iteración: 80 de 411\n",
            "Iteración: 81 de 411\n",
            "Iteración: 82 de 411\n",
            "Iteración: 83 de 411\n",
            "Iteración: 84 de 411\n",
            "Iteración: 85 de 411\n",
            "Iteración: 86 de 411\n",
            "Iteración: 87 de 411\n",
            "Iteración: 88 de 411\n",
            "Iteración: 89 de 411\n",
            "Iteración: 90 de 411\n",
            "Iteración: 91 de 411\n",
            "Iteración: 92 de 411\n",
            "Iteración: 93 de 411\n",
            "Iteración: 94 de 411\n",
            "Iteración: 95 de 411\n",
            "Iteración: 96 de 411\n",
            "Iteración: 97 de 411\n",
            "Iteración: 98 de 411\n",
            "Iteración: 99 de 411\n",
            "Iteración: 100 de 411\n",
            "Iteración: 101 de 411\n",
            "Iteración: 102 de 411\n",
            "Iteración: 103 de 411\n",
            "Iteración: 104 de 411\n",
            "Iteración: 105 de 411\n",
            "Iteración: 106 de 411\n",
            "Iteración: 107 de 411\n",
            "Iteración: 108 de 411\n",
            "Iteración: 109 de 411\n",
            "Iteración: 110 de 411\n",
            "Iteración: 111 de 411\n",
            "Iteración: 112 de 411\n",
            "Iteración: 113 de 411\n",
            "Iteración: 114 de 411\n",
            "Iteración: 115 de 411\n",
            "Iteración: 116 de 411\n",
            "Iteración: 117 de 411\n",
            "Iteración: 118 de 411\n",
            "Iteración: 119 de 411\n",
            "Iteración: 120 de 411\n",
            "Iteración: 121 de 411\n",
            "Iteración: 122 de 411\n",
            "Iteración: 123 de 411\n",
            "Iteración: 124 de 411\n",
            "Iteración: 125 de 411\n",
            "Iteración: 126 de 411\n",
            "Iteración: 127 de 411\n",
            "Iteración: 128 de 411\n",
            "Iteración: 129 de 411\n",
            "Iteración: 130 de 411\n",
            "Iteración: 131 de 411\n",
            "Iteración: 132 de 411\n",
            "Iteración: 133 de 411\n",
            "Iteración: 134 de 411\n",
            "Iteración: 135 de 411\n",
            "Iteración: 136 de 411\n",
            "Iteración: 137 de 411\n",
            "Iteración: 138 de 411\n",
            "Iteración: 139 de 411\n",
            "Iteración: 140 de 411\n",
            "Iteración: 141 de 411\n",
            "Iteración: 142 de 411\n",
            "Iteración: 143 de 411\n",
            "Iteración: 144 de 411\n",
            "Iteración: 145 de 411\n",
            "Iteración: 146 de 411\n",
            "Iteración: 147 de 411\n",
            "Iteración: 148 de 411\n",
            "Iteración: 149 de 411\n",
            "Iteración: 150 de 411\n",
            "Iteración: 151 de 411\n",
            "Iteración: 152 de 411\n",
            "Iteración: 153 de 411\n",
            "Iteración: 154 de 411\n",
            "Iteración: 155 de 411\n",
            "Iteración: 156 de 411\n",
            "Iteración: 157 de 411\n",
            "Iteración: 158 de 411\n",
            "Iteración: 159 de 411\n",
            "Iteración: 160 de 411\n",
            "Iteración: 161 de 411\n",
            "Iteración: 162 de 411\n",
            "Iteración: 163 de 411\n",
            "Iteración: 164 de 411\n",
            "Iteración: 165 de 411\n",
            "Iteración: 166 de 411\n",
            "Iteración: 167 de 411\n",
            "Iteración: 168 de 411\n",
            "Iteración: 169 de 411\n",
            "Iteración: 170 de 411\n",
            "Iteración: 171 de 411\n",
            "Iteración: 172 de 411\n",
            "Iteración: 173 de 411\n",
            "Iteración: 174 de 411\n",
            "Iteración: 175 de 411\n",
            "Iteración: 176 de 411\n",
            "Iteración: 177 de 411\n",
            "Iteración: 178 de 411\n",
            "Iteración: 179 de 411\n",
            "Iteración: 180 de 411\n",
            "Iteración: 181 de 411\n",
            "Iteración: 182 de 411\n",
            "Iteración: 183 de 411\n",
            "Iteración: 184 de 411\n",
            "Iteración: 185 de 411\n",
            "Iteración: 186 de 411\n",
            "Iteración: 187 de 411\n",
            "Iteración: 188 de 411\n",
            "Iteración: 189 de 411\n",
            "Iteración: 190 de 411\n",
            "Iteración: 191 de 411\n",
            "Iteración: 192 de 411\n",
            "Iteración: 193 de 411\n",
            "Iteración: 194 de 411\n",
            "Iteración: 195 de 411\n",
            "Iteración: 196 de 411\n",
            "Iteración: 197 de 411\n",
            "Iteración: 198 de 411\n",
            "Iteración: 199 de 411\n",
            "Iteración: 200 de 411\n",
            "Iteración: 201 de 411\n",
            "Iteración: 202 de 411\n",
            "Iteración: 203 de 411\n",
            "Iteración: 204 de 411\n",
            "Iteración: 205 de 411\n",
            "Iteración: 206 de 411\n",
            "Iteración: 207 de 411\n",
            "Iteración: 208 de 411\n",
            "Iteración: 209 de 411\n",
            "Iteración: 210 de 411\n",
            "Iteración: 211 de 411\n",
            "Iteración: 212 de 411\n",
            "Iteración: 213 de 411\n",
            "Iteración: 214 de 411\n",
            "Iteración: 215 de 411\n",
            "Iteración: 216 de 411\n",
            "Iteración: 217 de 411\n",
            "Iteración: 218 de 411\n",
            "Iteración: 219 de 411\n",
            "Iteración: 220 de 411\n",
            "Iteración: 221 de 411\n",
            "Iteración: 222 de 411\n",
            "Iteración: 223 de 411\n",
            "Iteración: 224 de 411\n",
            "Iteración: 225 de 411\n",
            "Iteración: 226 de 411\n",
            "Iteración: 227 de 411\n",
            "Iteración: 228 de 411\n",
            "Iteración: 229 de 411\n",
            "Iteración: 230 de 411\n",
            "Iteración: 231 de 411\n",
            "Iteración: 232 de 411\n",
            "Iteración: 233 de 411\n",
            "Iteración: 234 de 411\n",
            "Iteración: 235 de 411\n",
            "Iteración: 236 de 411\n",
            "Iteración: 237 de 411\n",
            "Iteración: 238 de 411\n",
            "Iteración: 239 de 411\n",
            "Iteración: 240 de 411\n",
            "Iteración: 241 de 411\n",
            "Iteración: 242 de 411\n",
            "Iteración: 243 de 411\n",
            "Iteración: 244 de 411\n",
            "Iteración: 245 de 411\n",
            "Iteración: 246 de 411\n",
            "Iteración: 247 de 411\n",
            "Iteración: 248 de 411\n",
            "Iteración: 249 de 411\n",
            "Iteración: 250 de 411\n",
            "Iteración: 251 de 411\n",
            "Iteración: 252 de 411\n",
            "Iteración: 253 de 411\n",
            "Iteración: 254 de 411\n",
            "Iteración: 255 de 411\n",
            "Iteración: 256 de 411\n",
            "Iteración: 257 de 411\n",
            "Iteración: 258 de 411\n",
            "Iteración: 259 de 411\n",
            "Iteración: 260 de 411\n",
            "Iteración: 261 de 411\n",
            "Iteración: 262 de 411\n",
            "Iteración: 263 de 411\n",
            "Iteración: 264 de 411\n",
            "Iteración: 265 de 411\n",
            "Iteración: 266 de 411\n",
            "Iteración: 267 de 411\n",
            "Iteración: 268 de 411\n",
            "Iteración: 269 de 411\n",
            "Iteración: 270 de 411\n",
            "Iteración: 271 de 411\n",
            "Iteración: 272 de 411\n",
            "Iteración: 273 de 411\n",
            "Iteración: 274 de 411\n",
            "Iteración: 275 de 411\n",
            "Iteración: 276 de 411\n",
            "Iteración: 277 de 411\n",
            "Iteración: 278 de 411\n",
            "Iteración: 279 de 411\n",
            "Iteración: 280 de 411\n",
            "Iteración: 281 de 411\n",
            "Iteración: 282 de 411\n",
            "Iteración: 283 de 411\n",
            "Iteración: 284 de 411\n",
            "Iteración: 285 de 411\n",
            "Iteración: 286 de 411\n",
            "Iteración: 287 de 411\n",
            "Iteración: 288 de 411\n",
            "Iteración: 289 de 411\n",
            "Iteración: 290 de 411\n",
            "Iteración: 291 de 411\n",
            "Iteración: 292 de 411\n",
            "Iteración: 293 de 411\n",
            "Iteración: 294 de 411\n",
            "Iteración: 295 de 411\n",
            "Iteración: 296 de 411\n",
            "Iteración: 297 de 411\n",
            "Iteración: 298 de 411\n",
            "Iteración: 299 de 411\n",
            "Iteración: 300 de 411\n",
            "Iteración: 301 de 411\n",
            "Iteración: 302 de 411\n",
            "Iteración: 303 de 411\n",
            "Iteración: 304 de 411\n",
            "Iteración: 305 de 411\n",
            "Iteración: 306 de 411\n",
            "Iteración: 307 de 411\n",
            "Iteración: 308 de 411\n",
            "Iteración: 309 de 411\n",
            "Iteración: 310 de 411\n",
            "Iteración: 311 de 411\n",
            "Iteración: 312 de 411\n",
            "Iteración: 313 de 411\n",
            "Iteración: 314 de 411\n",
            "Iteración: 315 de 411\n",
            "Iteración: 316 de 411\n",
            "Iteración: 317 de 411\n",
            "Iteración: 318 de 411\n",
            "Iteración: 319 de 411\n",
            "Iteración: 320 de 411\n",
            "Iteración: 321 de 411\n",
            "Iteración: 322 de 411\n",
            "Iteración: 323 de 411\n",
            "Iteración: 324 de 411\n",
            "Iteración: 325 de 411\n",
            "Iteración: 326 de 411\n",
            "Iteración: 327 de 411\n",
            "Iteración: 328 de 411\n",
            "Iteración: 329 de 411\n",
            "Iteración: 330 de 411\n",
            "Iteración: 331 de 411\n",
            "Iteración: 332 de 411\n",
            "Iteración: 333 de 411\n",
            "Iteración: 334 de 411\n",
            "Iteración: 335 de 411\n",
            "Iteración: 336 de 411\n",
            "Iteración: 337 de 411\n",
            "Iteración: 338 de 411\n",
            "Iteración: 339 de 411\n",
            "Iteración: 340 de 411\n",
            "Iteración: 341 de 411\n",
            "Iteración: 342 de 411\n",
            "Iteración: 343 de 411\n",
            "Iteración: 344 de 411\n",
            "Iteración: 345 de 411\n",
            "Iteración: 346 de 411\n",
            "Iteración: 347 de 411\n",
            "Iteración: 348 de 411\n",
            "Iteración: 349 de 411\n",
            "Iteración: 350 de 411\n",
            "Iteración: 351 de 411\n",
            "Iteración: 352 de 411\n",
            "Iteración: 353 de 411\n",
            "Iteración: 354 de 411\n",
            "Iteración: 355 de 411\n",
            "Iteración: 356 de 411\n",
            "Iteración: 357 de 411\n",
            "Iteración: 358 de 411\n",
            "Iteración: 359 de 411\n",
            "Iteración: 360 de 411\n",
            "Iteración: 361 de 411\n",
            "Iteración: 362 de 411\n",
            "Iteración: 363 de 411\n",
            "Iteración: 364 de 411\n",
            "Iteración: 365 de 411\n",
            "Iteración: 366 de 411\n",
            "Iteración: 367 de 411\n",
            "Iteración: 368 de 411\n",
            "Iteración: 369 de 411\n",
            "Iteración: 370 de 411\n",
            "Iteración: 371 de 411\n",
            "Iteración: 372 de 411\n",
            "Iteración: 373 de 411\n",
            "Iteración: 374 de 411\n",
            "Iteración: 375 de 411\n",
            "Iteración: 376 de 411\n",
            "Iteración: 377 de 411\n",
            "Iteración: 378 de 411\n",
            "Iteración: 379 de 411\n",
            "Iteración: 380 de 411\n",
            "Iteración: 381 de 411\n",
            "Iteración: 382 de 411\n",
            "Iteración: 383 de 411\n",
            "Iteración: 384 de 411\n",
            "Iteración: 385 de 411\n",
            "Iteración: 386 de 411\n",
            "Iteración: 387 de 411\n",
            "Iteración: 388 de 411\n",
            "Iteración: 389 de 411\n",
            "Iteración: 390 de 411\n",
            "Iteración: 391 de 411\n",
            "Iteración: 392 de 411\n",
            "Iteración: 393 de 411\n",
            "Iteración: 394 de 411\n",
            "Iteración: 395 de 411\n",
            "Iteración: 396 de 411\n",
            "Iteración: 397 de 411\n",
            "Iteración: 398 de 411\n",
            "Iteración: 399 de 411\n",
            "Iteración: 400 de 411\n",
            "Iteración: 401 de 411\n",
            "Iteración: 402 de 411\n",
            "Iteración: 403 de 411\n",
            "Iteración: 404 de 411\n",
            "Iteración: 405 de 411\n",
            "Iteración: 406 de 411\n",
            "Iteración: 407 de 411\n",
            "Iteración: 408 de 411\n",
            "Iteración: 409 de 411\n",
            "Iteración: 410 de 411\n",
            "Accuracy Score = 0.5291836191490171\n",
            "F1 Score (Micro) = 0.5291836191490171\n",
            "F1 Score (Macro) = 0.34605629600159143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Conclusiones"
      ],
      "metadata": {
        "id": "SQvFDISjVURk"
      },
      "id": "SQvFDISjVURk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Validación final del mejor modelo"
      ],
      "metadata": {
        "id": "gMb9u2E64a75"
      },
      "id": "gMb9u2E64a75"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez entrenados todos los modelos y probados con el conjunto de datos de train, se procede a evaluar el modelo que mejor resultados ha conseguido con los datos de validación, datos que ***bajo ninguna circunstancia*** el modelo ha visto en ninguna otra ocasión. El modelo que mejores resultados ha obtenido ha sido un modelo con arquitectura (...)"
      ],
      "metadata": {
        "id": "VBhYeoLN4qj5"
      },
      "id": "VBhYeoLN4qj5"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "exAD6sVK6vqv"
      },
      "id": "exAD6sVK6vqv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Ejemplo de uso del mejor modelo"
      ],
      "metadata": {
        "id": "OwZ84Y3TpqGS"
      },
      "id": "OwZ84Y3TpqGS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez se tiene el mejor modelo entrenado y evaludado, se quiere ver la eficacia del mismo y \"jugar un poco con él\"."
      ],
      "metadata": {
        "id": "rZHj8jirpxJ9"
      },
      "id": "rZHj8jirpxJ9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKkzjhrvqkhM"
      },
      "source": [
        "###3.2.1 Imports Generales"
      ],
      "id": "yKkzjhrvqkhM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zWnGRlOqkhb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import warnings"
      ],
      "id": "5zWnGRlOqkhb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwldUh7kqkhb"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "FwldUh7kqkhb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGHkQeBbqkhb"
      },
      "outputs": [],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "id": "aGHkQeBbqkhb"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "a8TtGZuOqD6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9ec3606-18c1-4e8d-bef8-d63f9d949efb"
      },
      "id": "a8TtGZuOqD6f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.2 Cargar el mejor modelo"
      ],
      "metadata": {
        "id": "YBhFxmsuqpb3"
      },
      "id": "YBhFxmsuqpb3"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "if os.path.exists(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30.pth\"):\n",
        "  model = BERTClass()\n",
        "  if device == \"cuda\":\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30.pth\"))\n",
        "  else:\n",
        "    model.load_state_dict(torch.load(\"./drive/MyDrive/Colab Notebooks/ProyectoIA_investigacion/modelo_single_bert_30.pth\", map_location=\"cpu\"))\n",
        "\n",
        "  model.eval()\n",
        "  model.to(device)"
      ],
      "metadata": {
        "id": "QgHIENMiqLF1"
      },
      "id": "QgHIENMiqLF1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.3 Pruebas"
      ],
      "metadata": {
        "id": "005B-PxWracB"
      },
      "id": "005B-PxWracB"
    },
    {
      "cell_type": "code",
      "source": [
        "texto_ejemplo = \"Bad potatoes.\""
      ],
      "metadata": {
        "id": "JtywCS35qHz2"
      },
      "id": "JtywCS35qHz2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def codificador(texto, tokenizador):\n",
        "  encoder_input = tokenizador(\n",
        "            texto,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors = \"pt\",\n",
        "            return_token_type_ids=True\n",
        "            )\n",
        "  return {\n",
        "    'ids': encoder_input[\"input_ids\"],\n",
        "    'mask': encoder_input[\"attention_mask\"],\n",
        "    \"token_type_ids\": encoder_input[\"token_type_ids\"]\n",
        "  }"
      ],
      "metadata": {
        "id": "itExwMio6Yid"
      },
      "id": "itExwMio6Yid",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = codificador(texto_ejemplo, tokenizerB)"
      ],
      "metadata": {
        "id": "EU_vR-wB6lj6"
      },
      "id": "EU_vR-wB6lj6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure that the model is also on the same device\n",
        "model = model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model.forward(**inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "4v64E8nA1RgD",
        "outputId": "99831447-c91f-4a50-c104-565fbd425905"
      },
      "id": "4v64E8nA1RgD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-72792a57c882>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-808cf10633dc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, mask, token_type_ids)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m#output_2 = self.l2(output_1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#output_3 = self.l3(output_2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1007\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2233\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizerB(texto_ejemplo, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "inputs\n"
      ],
      "metadata": {
        "id": "I3H23aCorpLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2465168-d553-4891-aeed-40237c159542"
      },
      "id": "I3H23aCorpLA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 2919, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = inputs[\"input_ids\"]\n",
        "token = inputs[\"token_type_ids\"]\n",
        "mask = inputs[\"attention_mask\"]"
      ],
      "metadata": {
        "id": "Ttd-zQjD-fDe"
      },
      "id": "Ttd-zQjD-fDe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move tensors to the same device as the model\n",
        "ids = ids.to(device)\n",
        "token = token.to(device)\n",
        "mask = mask.to(device)\n",
        "\n",
        "# Ensure that the model is also on the same device\n",
        "model = model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model.forward(ids, token, mask)"
      ],
      "metadata": {
        "id": "G17nCp2G7bd9"
      },
      "id": "G17nCp2G7bd9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Qzc7j5_9HS",
        "outputId": "b812f4e5-ac39-4bd9-f7e9-39082e7e8229"
      },
      "id": "Z8Qzc7j5_9HS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5134]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://huggingface.co/mrcaelumn/yelp_restaurant_review_sentiment_analysis?text=I+like+you.+I+love+you (distil bert, ya para usar)\n",
        "- https://huggingface.co/lxyuan/distilbert-base-multilingual-cased-sentiments-student (ya para usar)"
      ],
      "metadata": {
        "id": "GkSrepJSEn0T"
      },
      "id": "GkSrepJSEn0T"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Consideraciones finales"
      ],
      "metadata": {
        "id": "vFSvgQD74WPJ"
      },
      "id": "vFSvgQD74WPJ"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NsF6uzckFsbf"
      },
      "id": "NsF6uzckFsbf"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NJDMx5uoWwXJ",
        "03BiL7vFWLag",
        "80a8a97f-2ba6-4c86-b2fb-78c24ea4277b",
        "3885801a-2264-4c3c-98c2-6bf2c290c4ee",
        "-Y-2FltvwMsC",
        "Rqj1sKsmyl3Q",
        "z9lEl1H_ytuQ",
        "3l9pdwSJWhCW",
        "85lAOqvoMP7U",
        "sz_1bepUX51c",
        "_SUW133cYIci",
        "qhJHq8koYx30",
        "N-KJyb4WYQCq",
        "kf0xyIiBm1mw",
        "k6OlyEQenkPG",
        "CvHzmOUdntM3",
        "myPmGiiVobFK",
        "MA3LbTijppvt",
        "ezWGQXOLqPPN",
        "37c594e9-7808-49bb-9298-0821c577699b",
        "7fb3fc8b-060d-4833-867a-2e8b32b42bf8",
        "DbD8Gjf8BXsG",
        "toI_jaffsbZl",
        "ee7f1644-da90-430f-867b-5b36c5bf415b",
        "abdddfde-8ac2-4946-990d-5d9cb91c69e5",
        "FZP2e-QzqRm2",
        "I5Q1F4Wsdy1_",
        "E4DqT19lM8vB",
        "LNeSMvUGipqW",
        "lbTcX4U-qwFM",
        "HVkxNFdhu9fy",
        "CJhWf1i2gYTn",
        "ab3ASpCjDTj-",
        "7VRFfPgnwDyl",
        "a90TNTnwofqq",
        "nA01-MlTCvP0",
        "ya_X8G8fCyt3",
        "3IPno8yWigzH",
        "krD6TS-tl-Pc",
        "bMio1RB1JkJw",
        "NvBbUoa3irJ_",
        "kgejl67emCxQ",
        "ih3AZP8g-O1M",
        "mfSNGdWuCoHp",
        "PHJCm_YGCuEA",
        "PrHK5EkTjdWo",
        "GGSONSbKDNhm",
        "9gKLmkw9i-Js",
        "ETOGNCt0jv_g",
        "212fd36f-aaf2-4231-ab08-22ecc241a444",
        "uxRYSHGBd1xR",
        "qN98yOU8eACw",
        "TzhTX-s-ejQf",
        "wHWQqYES30Gg",
        "8XUnO2ag4nZT",
        "SJSrbOrY4nZY",
        "uxGFgrja4nZY",
        "qLBKOi734nZZ",
        "VJUBEWAR4nZZ",
        "YrBtRBXm4nZZ",
        "OISXg3AL4nZZ",
        "c0nrqlVD4nZa",
        "k_4rEjvp4nZa",
        "SK8D5HD-XNGu",
        "TDREd3hYXNGz",
        "IU1lENq3XNG0",
        "QcMJtZ-_XNG0",
        "5L3BT6Y5XNG0",
        "XGwnRAp3XNG1",
        "GhTjLi4nXNG1",
        "XUvcylIZqwMj",
        "4CPoi1eDNyOP",
        "n3Lo8Zl_P0U5",
        "EdV1_YRxL7AI",
        "h1jRUvqNEeRL",
        "wk73KhLtVfPP",
        "wu2RPx0GXJ7u",
        "g7Hwx74FXZ7t",
        "zAJPsa7QFSh5",
        "mdwhRYyQFguy",
        "8MlPEA0kRmIT",
        "MzuD-XEySqCu",
        "yFEjEXcOeHUZ",
        "XPsYMmewS39X",
        "Iyq_0W-Lja1C",
        "eXX1q6M4S7ML",
        "nddaJsWJF4nj",
        "gMb9u2E64a75",
        "OwZ84Y3TpqGS",
        "vFSvgQD74WPJ"
      ],
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}